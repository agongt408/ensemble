{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(threshold=1000)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.callbacks import LearningRateScheduler, History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/albert/github/tensorflow/src/')\n",
    "import evaluation,data, training, models\n",
    "# from src.bk import models_bk2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "P_param = 5\n",
    "K_param = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dict, train_files = data.get_data('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0867080688477\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3EAAABpCAYAAACUGaonAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f743f300e50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start = time.time()\n",
    "batch = data.batch_generator(train_dict, P=P_param, K=K_param, preprocess=True,\n",
    "                                    shape=(256,128)).next()\n",
    "print time.time() - start\n",
    "\n",
    "i = 0\n",
    "\n",
    "plt.figure(figsize=(15,2))\n",
    "for j in range(P_param*K_param):\n",
    "    plt.subplot(1,20,j+1)\n",
    "    im = batch[0][i][j].squeeze().astype(np.uint8)\n",
    "#         print im.min(), im.max()\n",
    "    plt.imshow(im)\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f73a5208e10>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAD8CAYAAAC2PJlnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f743f300fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 10\n",
    "steps_per_epoch = 100\n",
    "\n",
    "lr = []\n",
    "for era in range(1,21):\n",
    "#     exec(step_decay_cont_str % (epochs, era))\n",
    "    for j in range(10):\n",
    "        lr.append(training.step_decay_cont(epochs, era)(j))\n",
    "plt.plot(np.arange(200), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called 0\n",
      "[64]\n",
      "[64]\n",
      "[-1, 0, 1, 2, 3]\n",
      "called 0\n",
      "[64]\n",
      "[64]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[96]\n",
      "[96]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[160]\n",
      "[160]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[192]\n",
      "[192]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[224]\n",
      "[224]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[256]\n",
      "[256]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[160]\n",
      "[160]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[192]\n",
      "[192]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[224]\n",
      "[224]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[256]\n",
      "[256]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[288]\n",
      "[288]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[320]\n",
      "[320]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[352]\n",
      "[352]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[384]\n",
      "[384]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[416]\n",
      "[416]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[448]\n",
      "[448]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[480]\n",
      "[480]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[512]\n",
      "[512]\n",
      "called 0\n",
      "[256]\n",
      "[256]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[288]\n",
      "[288]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[320]\n",
      "[320]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[352]\n",
      "[352]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[384]\n",
      "[384]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[416]\n",
      "[416]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[448]\n",
      "[448]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[480]\n",
      "[480]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[512]\n",
      "[512]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[544]\n",
      "[544]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[576]\n",
      "[576]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[608]\n",
      "[608]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[640]\n",
      "[640]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[672]\n",
      "[672]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[704]\n",
      "[704]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[736]\n",
      "[736]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[768]\n",
      "[768]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[800]\n",
      "[800]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[832]\n",
      "[832]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[864]\n",
      "[864]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[896]\n",
      "[896]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[928]\n",
      "[928]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[960]\n",
      "[960]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[992]\n",
      "[992]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[1024]\n",
      "[1024]\n",
      "called 0\n",
      "[512]\n",
      "[512]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[544]\n",
      "[544]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[576]\n",
      "[576]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[608]\n",
      "[608]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[640]\n",
      "[640]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[672]\n",
      "[672]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[704]\n",
      "[704]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[736]\n",
      "[736]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[768]\n",
      "[768]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[800]\n",
      "[800]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[832]\n",
      "[832]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[864]\n",
      "[864]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[896]\n",
      "[896]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[928]\n",
      "[928]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[960]\n",
      "[960]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[992]\n",
      "[992]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[1024]\n",
      "[1024]\n",
      "called 0\n",
      "[1024]\n",
      "[1024]\n",
      "l_start 310\n",
      "fill_masks [array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  0.,  0.])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fill_masks [array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fill_masks [array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  0.,  0.])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fill_masks [array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fill_masks [array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  0.,  0.])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fill_masks [array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fill_masks [array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        0.,  0.])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fill_masks [array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fill_masks [array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fill_masks [array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,\n",
      "        0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  0.,  0.])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fill_masks [array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,\n",
      "        0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fill_masks [array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,\n",
      "        0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  0.,  0.])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fill_masks [array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,\n",
      "        0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fill_masks [array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,\n",
      "        0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  0.,  0.])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fill_masks [array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,\n",
      "        0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fill_masks [array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,\n",
      "        0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  0.,  0.])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called 0\n",
      "[64]\n",
      "[64]\n",
      "[-1, 0, 1, 2, 3]\n",
      "called 0\n",
      "[64]\n",
      "[64]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[96]\n",
      "[96]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[160]\n",
      "[160]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[192]\n",
      "[192]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[224]\n",
      "[224]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[256]\n",
      "[256]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[160]\n",
      "[160]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[192]\n",
      "[192]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[224]\n",
      "[224]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[256]\n",
      "[256]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[288]\n",
      "[288]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[320]\n",
      "[320]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[352]\n",
      "[352]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[384]\n",
      "[384]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[416]\n",
      "[416]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[448]\n",
      "[448]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[480]\n",
      "[480]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[512]\n",
      "[512]\n",
      "called 0\n",
      "[256]\n",
      "[256]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[288]\n",
      "[288]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[320]\n",
      "[320]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[352]\n",
      "[352]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[384]\n",
      "[384]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[416]\n",
      "[416]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[448]\n",
      "[448]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[480]\n",
      "[480]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[512]\n",
      "[512]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[544]\n",
      "[544]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[576]\n",
      "[576]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[608]\n",
      "[608]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[640]\n",
      "[640]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[672]\n",
      "[672]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[704]\n",
      "[704]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[736]\n",
      "[736]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[768]\n",
      "[768]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[800]\n",
      "[800]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[832]\n",
      "[832]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[864]\n",
      "[864]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[896]\n",
      "[896]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[928]\n",
      "[928]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[960]\n",
      "[960]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[992]\n",
      "[992]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[1024]\n",
      "[1024]\n",
      "idx [65452, 4]\n",
      "gather [65452]\n",
      "idx [69464, 4]\n",
      "gather [69464]\n",
      "idx [73476, 4]\n",
      "gather [73476]\n",
      "idx [77488, 4]\n",
      "gather [77488]\n",
      "idx [81500, 4]\n",
      "gather [81500]\n",
      "idx [85512, 4]\n",
      "gather [85512]\n",
      "idx [89524, 4]\n",
      "gather [89524]\n",
      "idx [93536, 4]\n",
      "gather [93536]\n",
      "idx [97548, 4]\n",
      "gather [97548]\n",
      "idx [101560, 4]\n",
      "gather [101560]\n",
      "idx [105572, 4]\n",
      "gather [105572]\n",
      "idx [109584, 4]\n",
      "gather [109584]\n",
      "idx [113596, 4]\n",
      "gather [113596]\n",
      "idx [117608, 4]\n",
      "gather [117608]\n",
      "idx [121620, 4]\n",
      "gather [121620]\n",
      "idx [125632, 4]\n",
      "gather [125632]\n",
      "called 0\n",
      "[64]\n",
      "[64]\n",
      "[-1, 0, 1, 2, 3]\n",
      "called 0\n",
      "[64]\n",
      "[64]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[96]\n",
      "[96]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[160]\n",
      "[160]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[192]\n",
      "[192]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[224]\n",
      "[224]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[256]\n",
      "[256]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[160]\n",
      "[160]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[192]\n",
      "[192]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[224]\n",
      "[224]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[256]\n",
      "[256]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[288]\n",
      "[288]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[320]\n",
      "[320]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[352]\n",
      "[352]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[384]\n",
      "[384]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[416]\n",
      "[416]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[448]\n",
      "[448]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[480]\n",
      "[480]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[512]\n",
      "[512]\n",
      "called 0\n",
      "[256]\n",
      "[256]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[288]\n",
      "[288]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[320]\n",
      "[320]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[352]\n",
      "[352]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[384]\n",
      "[384]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[416]\n",
      "[416]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[448]\n",
      "[448]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[480]\n",
      "[480]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[512]\n",
      "[512]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[544]\n",
      "[544]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[576]\n",
      "[576]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[608]\n",
      "[608]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[640]\n",
      "[640]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[672]\n",
      "[672]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[704]\n",
      "[704]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[736]\n",
      "[736]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[768]\n",
      "[768]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[800]\n",
      "[800]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[832]\n",
      "[832]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[864]\n",
      "[864]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[896]\n",
      "[896]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[928]\n",
      "[928]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[960]\n",
      "[960]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[992]\n",
      "[992]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[1024]\n",
      "[1024]\n",
      "called 0\n",
      "[512]\n",
      "[512]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[544]\n",
      "[544]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[576]\n",
      "[576]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[608]\n",
      "[608]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[640]\n",
      "[640]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[672]\n",
      "[672]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[704]\n",
      "[704]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[736]\n",
      "[736]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[768]\n",
      "[768]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[800]\n",
      "[800]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[832]\n",
      "[832]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[864]\n",
      "[864]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[896]\n",
      "[896]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[928]\n",
      "[928]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[960]\n",
      "[960]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[992]\n",
      "[992]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[1024]\n",
      "[1024]\n",
      "Weights for the model were loaded successfully\n",
      "called 0\n",
      "[1024]\n",
      "[1024]\n",
      "n_add 0\n",
      "n_add2 1\n",
      "n_add3 1\n",
      "name ['l_326']\n",
      "l_326\n",
      "name ['l_327']\n",
      "l_327\n",
      "name ['l_328']\n",
      "l_328\n",
      "name ['l_344']\n",
      "l_344\n",
      "name ['l_345']\n",
      "l_345\n",
      "name ['l_346']\n",
      "l_346\n",
      "name ['l_369']\n",
      "l_369\n",
      "name ['l_370']\n",
      "l_370\n",
      "name ['l_371']\n",
      "l_371\n",
      "name ['l_387']\n",
      "l_387\n",
      "name ['l_388']\n",
      "l_388\n",
      "name ['l_389']\n",
      "l_389\n",
      "name ['l_412']\n",
      "l_412\n",
      "name ['l_413']\n",
      "l_413\n",
      "name ['l_414']\n",
      "l_414\n",
      "name ['l_430']\n",
      "l_430\n",
      "name ['l_431']\n",
      "l_431\n",
      "name ['l_432']\n",
      "l_432\n",
      "name ['l_455']\n",
      "l_455\n",
      "name ['l_456']\n",
      "l_456\n",
      "name ['l_457']\n",
      "l_457\n",
      "name ['l_473']\n",
      "l_473\n",
      "name ['l_474']\n",
      "l_474\n",
      "name ['l_475']\n",
      "l_475\n",
      "name ['l_498']\n",
      "l_498\n",
      "name ['l_499']\n",
      "l_499\n",
      "name ['l_500']\n",
      "l_500\n",
      "name ['l_516']\n",
      "l_516\n",
      "name ['l_517']\n",
      "l_517\n",
      "name ['l_518']\n",
      "l_518\n",
      "name ['l_541']\n",
      "l_541\n",
      "name ['l_542']\n",
      "l_542\n",
      "name ['l_543']\n",
      "l_543\n",
      "name ['l_559']\n",
      "l_559\n",
      "name ['l_560']\n",
      "l_560\n",
      "name ['l_561']\n",
      "l_561\n",
      "name ['l_584']\n",
      "l_584\n",
      "name ['l_585']\n",
      "l_585\n",
      "name ['l_586']\n",
      "l_586\n",
      "name ['l_602']\n",
      "l_602\n",
      "name ['l_603']\n",
      "l_603\n",
      "name ['l_604']\n",
      "l_604\n",
      "name ['l_627']\n",
      "l_627\n",
      "name ['l_628']\n",
      "l_628\n",
      "name ['l_629']\n",
      "l_629\n",
      "name ['l_645']\n",
      "l_645\n",
      "name ['l_646']\n",
      "l_646\n",
      "name ['l_647']\n",
      "l_647\n",
      "name ['l_670']\n",
      "l_670\n",
      "name ['l_671']\n",
      "l_671\n",
      "name ['l_672']\n",
      "l_672\n",
      "name ['l_688']\n",
      "l_688\n",
      "name ['l_689']\n",
      "l_689\n",
      "name ['l_690']\n",
      "l_690\n",
      "name ['l_713']\n",
      "l_713\n",
      "name ['l_714']\n",
      "l_714\n",
      "name ['l_715']\n",
      "l_715\n",
      "name ['l_731']\n",
      "l_731\n",
      "name ['l_732']\n",
      "l_732\n",
      "name ['l_733']\n",
      "l_733\n",
      "name ['l_756']\n",
      "l_756\n",
      "name ['l_757']\n",
      "l_757\n",
      "name ['l_758']\n",
      "l_758\n",
      "name ['l_774']\n",
      "l_774\n",
      "name ['l_775']\n",
      "l_775\n",
      "name ['l_776']\n",
      "l_776\n",
      "name ['l_799']\n",
      "l_799\n",
      "name ['l_800']\n",
      "l_800\n",
      "name ['l_801']\n",
      "l_801\n",
      "name ['l_817']\n",
      "l_817\n",
      "name ['l_818']\n",
      "l_818\n",
      "name ['l_819']\n",
      "l_819\n",
      "name ['l_842']\n",
      "l_842\n",
      "name ['l_843']\n",
      "l_843\n",
      "name ['l_844']\n",
      "l_844\n",
      "name ['l_860']\n",
      "l_860\n",
      "name ['l_861']\n",
      "l_861\n",
      "name ['l_862']\n",
      "l_862\n",
      "name ['l_885']\n",
      "l_885\n",
      "name ['l_886']\n",
      "l_886\n",
      "name ['l_887']\n",
      "l_887\n",
      "name ['l_903']\n",
      "l_903\n",
      "name ['l_904']\n",
      "l_904\n",
      "name ['l_905']\n",
      "l_905\n",
      "name ['l_928']\n",
      "l_928\n",
      "name ['l_929']\n",
      "l_929\n",
      "name ['l_930']\n",
      "l_930\n",
      "name ['l_946']\n",
      "l_946\n",
      "name ['l_947']\n",
      "l_947\n",
      "name ['l_948']\n",
      "l_948\n",
      "name ['l_971']\n",
      "l_971\n",
      "name ['l_972']\n",
      "l_972\n",
      "name ['l_973']\n",
      "l_973\n",
      "name ['l_989']\n",
      "l_989\n",
      "name ['l_990']\n",
      "l_990\n",
      "name ['l_991']\n",
      "l_991\n",
      "name ['l_1021']\n",
      "l_1021\n",
      "name ['l_1022']\n",
      "l_1022\n",
      "name ['l_1023']\n",
      "l_1023\n",
      "name ['l_1039']\n",
      "l_1039\n",
      "name ['l_1040']\n",
      "l_1040\n",
      "name ['l_1041']\n",
      "l_1041\n",
      "conv2d_121 [[<tf.Tensor 'input_2_2:0' shape=(?, 256, 128, 3) dtype=float32>]]\n",
      "batch_normalization_157 [[<tf.Tensor 'conv2d_121_1/convolution:0' shape=(?, 128, 64, 64) dtype=float32>]]\n",
      "called 0\n",
      "[64]\n",
      "[64]\n",
      "activation_123 [[<tf.Tensor 'batch_normalization_157_1/cond/Merge:0' shape=(?, 128, 64, 64) dtype=float32>]]\n",
      "max_pooling2d_2 [[<tf.Tensor 'activation_123_1/Relu:0' shape=(?, 128, 64, 64) dtype=float32>]]\n",
      "batch_normalization_158 [[<tf.Tensor 'max_pooling2d_2_1/MaxPool:0' shape=(?, 64, 32, 64) dtype=float32>]]\n",
      "called 0\n",
      "[64]\n",
      "[64]\n",
      "activation_124 [[<tf.Tensor 'batch_normalization_158_1/cond/Merge:0' shape=(?, 64, 32, 64) dtype=float32>]]\n",
      "conv2d_122 [[<tf.Tensor 'activation_124_1/Relu:0' shape=(?, 64, 32, 64) dtype=float32>]]\n",
      "batch_normalization_159 [[<tf.Tensor 'conv2d_122_1/convolution:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_125 [[<tf.Tensor 'batch_normalization_159_1/cond/Merge:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "conv2d_123 [[<tf.Tensor 'activation_125_1/Relu:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "concatenate_59 [[<tf.Tensor 'max_pooling2d_2_1/MaxPool:0' shape=(?, 64, 32, 64) dtype=float32>, <tf.Tensor 'conv2d_123_1/convolution:0' shape=(?, 64, 32, 32) dtype=float32>]]\n",
      "[None, 64, 32, 96]\n",
      "batch_normalization_160 [[<tf.Tensor 'concatenate_59_2/concat:0' shape=(?, 64, 32, 96) dtype=float32>]]\n",
      "called 0\n",
      "[96]\n",
      "[96]\n",
      "activation_126 [[<tf.Tensor 'batch_normalization_160_1/cond/Merge:0' shape=(?, 64, 32, 96) dtype=float32>]]\n",
      "conv2d_124 [[<tf.Tensor 'activation_126_1/Relu:0' shape=(?, 64, 32, 96) dtype=float32>]]\n",
      "batch_normalization_161 [[<tf.Tensor 'conv2d_124_1/convolution:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation_127 [[<tf.Tensor 'batch_normalization_161_1/cond/Merge:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "conv2d_125 [[<tf.Tensor 'activation_127_1/Relu:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "concatenate_60 [[<tf.Tensor 'concatenate_59_2/concat:0' shape=(?, 64, 32, 96) dtype=float32>, <tf.Tensor 'conv2d_125_1/convolution:0' shape=(?, 64, 32, 32) dtype=float32>]]\n",
      "[None, 64, 32, 128]\n",
      "batch_normalization_162 [[<tf.Tensor 'concatenate_60_2/concat:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_128 [[<tf.Tensor 'batch_normalization_162_1/cond/Merge:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "conv2d_126 [[<tf.Tensor 'activation_128_1/Relu:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "batch_normalization_163 [[<tf.Tensor 'conv2d_126_1/convolution:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_129 [[<tf.Tensor 'batch_normalization_163_1/cond/Merge:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "conv2d_127 [[<tf.Tensor 'activation_129_1/Relu:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "concatenate_61 [[<tf.Tensor 'concatenate_60_2/concat:0' shape=(?, 64, 32, 128) dtype=float32>, <tf.Tensor 'conv2d_127_1/convolution:0' shape=(?, 64, 32, 32) dtype=float32>]]\n",
      "[None, 64, 32, 160]\n",
      "batch_normalization_164 [[<tf.Tensor 'concatenate_61_2/concat:0' shape=(?, 64, 32, 160) dtype=float32>]]\n",
      "called 0\n",
      "[160]\n",
      "[160]\n",
      "activation_130 [[<tf.Tensor 'batch_normalization_164_1/cond/Merge:0' shape=(?, 64, 32, 160) dtype=float32>]]\n",
      "conv2d_128 [[<tf.Tensor 'activation_130_1/Relu:0' shape=(?, 64, 32, 160) dtype=float32>]]\n",
      "batch_normalization_165 [[<tf.Tensor 'conv2d_128_1/convolution:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_131 [[<tf.Tensor 'batch_normalization_165_1/cond/Merge:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "conv2d_129 [[<tf.Tensor 'activation_131_1/Relu:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "concatenate_62 [[<tf.Tensor 'concatenate_61_2/concat:0' shape=(?, 64, 32, 160) dtype=float32>, <tf.Tensor 'conv2d_129_1/convolution:0' shape=(?, 64, 32, 32) dtype=float32>]]\n",
      "[None, 64, 32, 192]\n",
      "batch_normalization_166 [[<tf.Tensor 'concatenate_62_2/concat:0' shape=(?, 64, 32, 192) dtype=float32>]]\n",
      "called 0\n",
      "[192]\n",
      "[192]\n",
      "activation_132 [[<tf.Tensor 'batch_normalization_166_1/cond/Merge:0' shape=(?, 64, 32, 192) dtype=float32>]]\n",
      "conv2d_130 [[<tf.Tensor 'activation_132_1/Relu:0' shape=(?, 64, 32, 192) dtype=float32>]]\n",
      "batch_normalization_167 [[<tf.Tensor 'conv2d_130_1/convolution:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_133 [[<tf.Tensor 'batch_normalization_167_1/cond/Merge:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "conv2d_131 [[<tf.Tensor 'activation_133_1/Relu:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "concatenate_63 [[<tf.Tensor 'concatenate_62_2/concat:0' shape=(?, 64, 32, 192) dtype=float32>, <tf.Tensor 'conv2d_131_1/convolution:0' shape=(?, 64, 32, 32) dtype=float32>]]\n",
      "[None, 64, 32, 224]\n",
      "batch_normalization_168 [[<tf.Tensor 'concatenate_63_2/concat:0' shape=(?, 64, 32, 224) dtype=float32>]]\n",
      "called 0\n",
      "[224]\n",
      "[224]\n",
      "activation_134 [[<tf.Tensor 'batch_normalization_168_1/cond/Merge:0' shape=(?, 64, 32, 224) dtype=float32>]]\n",
      "conv2d_132 [[<tf.Tensor 'activation_134_1/Relu:0' shape=(?, 64, 32, 224) dtype=float32>]]\n",
      "batch_normalization_169 [[<tf.Tensor 'conv2d_132_1/convolution:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_135 [[<tf.Tensor 'batch_normalization_169_1/cond/Merge:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "conv2d_133 [[<tf.Tensor 'activation_135_1/Relu:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "concatenate_64 [[<tf.Tensor 'concatenate_63_2/concat:0' shape=(?, 64, 32, 224) dtype=float32>, <tf.Tensor 'conv2d_133_1/convolution:0' shape=(?, 64, 32, 32) dtype=float32>]]\n",
      "[None, 64, 32, 256]\n",
      "batch_normalization_170 [[<tf.Tensor 'concatenate_64_2/concat:0' shape=(?, 64, 32, 256) dtype=float32>]]\n",
      "called 0\n",
      "[256]\n",
      "[256]\n",
      "activation_136 [[<tf.Tensor 'batch_normalization_170_1/cond/Merge:0' shape=(?, 64, 32, 256) dtype=float32>]]\n",
      "conv2d_134 [[<tf.Tensor 'activation_136_1/Relu:0' shape=(?, 64, 32, 256) dtype=float32>]]\n",
      "average_pooling2d_4 [[<tf.Tensor 'conv2d_134_1/convolution:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "batch_normalization_171 [[<tf.Tensor 'average_pooling2d_4_1/AvgPool:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_137 [[<tf.Tensor 'batch_normalization_171_1/cond/Merge:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "conv2d_135 [[<tf.Tensor 'activation_137_1/Relu:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "batch_normalization_172 [[<tf.Tensor 'conv2d_135_1/convolution:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_138 [[<tf.Tensor 'batch_normalization_172_1/cond/Merge:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "conv2d_136 [[<tf.Tensor 'activation_138_1/Relu:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "concatenate_65 [[<tf.Tensor 'average_pooling2d_4_1/AvgPool:0' shape=(?, 32, 16, 128) dtype=float32>, <tf.Tensor 'conv2d_136_1/convolution:0' shape=(?, 32, 16, 32) dtype=float32>]]\n",
      "[None, 32, 16, 160]\n",
      "batch_normalization_173 [[<tf.Tensor 'concatenate_65_2/concat:0' shape=(?, 32, 16, 160) dtype=float32>]]\n",
      "called 0\n",
      "[160]\n",
      "[160]\n",
      "activation_139 [[<tf.Tensor 'batch_normalization_173_1/cond/Merge:0' shape=(?, 32, 16, 160) dtype=float32>]]\n",
      "conv2d_137 [[<tf.Tensor 'activation_139_1/Relu:0' shape=(?, 32, 16, 160) dtype=float32>]]\n",
      "batch_normalization_174 [[<tf.Tensor 'conv2d_137_1/convolution:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_140 [[<tf.Tensor 'batch_normalization_174_1/cond/Merge:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "conv2d_138 [[<tf.Tensor 'activation_140_1/Relu:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "concatenate_66 [[<tf.Tensor 'concatenate_65_2/concat:0' shape=(?, 32, 16, 160) dtype=float32>, <tf.Tensor 'conv2d_138_1/convolution:0' shape=(?, 32, 16, 32) dtype=float32>]]\n",
      "[None, 32, 16, 192]\n",
      "batch_normalization_175 [[<tf.Tensor 'concatenate_66_2/concat:0' shape=(?, 32, 16, 192) dtype=float32>]]\n",
      "called 0\n",
      "[192]\n",
      "[192]\n",
      "activation_141 [[<tf.Tensor 'batch_normalization_175_1/cond/Merge:0' shape=(?, 32, 16, 192) dtype=float32>]]\n",
      "conv2d_139 [[<tf.Tensor 'activation_141_1/Relu:0' shape=(?, 32, 16, 192) dtype=float32>]]\n",
      "batch_normalization_176 [[<tf.Tensor 'conv2d_139_1/convolution:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_142 [[<tf.Tensor 'batch_normalization_176_1/cond/Merge:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "conv2d_140 [[<tf.Tensor 'activation_142_1/Relu:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "concatenate_67 [[<tf.Tensor 'concatenate_66_2/concat:0' shape=(?, 32, 16, 192) dtype=float32>, <tf.Tensor 'conv2d_140_1/convolution:0' shape=(?, 32, 16, 32) dtype=float32>]]\n",
      "[None, 32, 16, 224]\n",
      "batch_normalization_177 [[<tf.Tensor 'concatenate_67_2/concat:0' shape=(?, 32, 16, 224) dtype=float32>]]\n",
      "called 0\n",
      "[224]\n",
      "[224]\n",
      "activation_143 [[<tf.Tensor 'batch_normalization_177_1/cond/Merge:0' shape=(?, 32, 16, 224) dtype=float32>]]\n",
      "conv2d_141 [[<tf.Tensor 'activation_143_1/Relu:0' shape=(?, 32, 16, 224) dtype=float32>]]\n",
      "batch_normalization_178 [[<tf.Tensor 'conv2d_141_1/convolution:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_144 [[<tf.Tensor 'batch_normalization_178_1/cond/Merge:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "conv2d_142 [[<tf.Tensor 'activation_144_1/Relu:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "concatenate_68 [[<tf.Tensor 'concatenate_67_2/concat:0' shape=(?, 32, 16, 224) dtype=float32>, <tf.Tensor 'conv2d_142_1/convolution:0' shape=(?, 32, 16, 32) dtype=float32>]]\n",
      "[None, 32, 16, 256]\n",
      "batch_normalization_179 [[<tf.Tensor 'concatenate_68_2/concat:0' shape=(?, 32, 16, 256) dtype=float32>]]\n",
      "called 0\n",
      "[256]\n",
      "[256]\n",
      "activation_145 [[<tf.Tensor 'batch_normalization_179_1/cond/Merge:0' shape=(?, 32, 16, 256) dtype=float32>]]\n",
      "conv2d_143 [[<tf.Tensor 'activation_145_1/Relu:0' shape=(?, 32, 16, 256) dtype=float32>]]\n",
      "batch_normalization_180 [[<tf.Tensor 'conv2d_143_1/convolution:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_146 [[<tf.Tensor 'batch_normalization_180_1/cond/Merge:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "conv2d_144 [[<tf.Tensor 'activation_146_1/Relu:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "concatenate_69 [[<tf.Tensor 'concatenate_68_2/concat:0' shape=(?, 32, 16, 256) dtype=float32>, <tf.Tensor 'conv2d_144_1/convolution:0' shape=(?, 32, 16, 32) dtype=float32>]]\n",
      "[None, 32, 16, 288]\n",
      "batch_normalization_181 [[<tf.Tensor 'concatenate_69_2/concat:0' shape=(?, 32, 16, 288) dtype=float32>]]\n",
      "called 0\n",
      "[288]\n",
      "[288]\n",
      "activation_147 [[<tf.Tensor 'batch_normalization_181_1/cond/Merge:0' shape=(?, 32, 16, 288) dtype=float32>]]\n",
      "conv2d_145 [[<tf.Tensor 'activation_147_1/Relu:0' shape=(?, 32, 16, 288) dtype=float32>]]\n",
      "batch_normalization_182 [[<tf.Tensor 'conv2d_145_1/convolution:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_148 [[<tf.Tensor 'batch_normalization_182_1/cond/Merge:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "conv2d_146 [[<tf.Tensor 'activation_148_1/Relu:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "concatenate_70 [[<tf.Tensor 'concatenate_69_2/concat:0' shape=(?, 32, 16, 288) dtype=float32>, <tf.Tensor 'conv2d_146_1/convolution:0' shape=(?, 32, 16, 32) dtype=float32>]]\n",
      "[None, 32, 16, 320]\n",
      "batch_normalization_183 [[<tf.Tensor 'concatenate_70_2/concat:0' shape=(?, 32, 16, 320) dtype=float32>]]\n",
      "called 0\n",
      "[320]\n",
      "[320]\n",
      "activation_149 [[<tf.Tensor 'batch_normalization_183_1/cond/Merge:0' shape=(?, 32, 16, 320) dtype=float32>]]\n",
      "conv2d_147 [[<tf.Tensor 'activation_149_1/Relu:0' shape=(?, 32, 16, 320) dtype=float32>]]\n",
      "batch_normalization_184 [[<tf.Tensor 'conv2d_147_1/convolution:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_150 [[<tf.Tensor 'batch_normalization_184_1/cond/Merge:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "conv2d_148 [[<tf.Tensor 'activation_150_1/Relu:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "concatenate_71 [[<tf.Tensor 'concatenate_70_2/concat:0' shape=(?, 32, 16, 320) dtype=float32>, <tf.Tensor 'conv2d_148_1/convolution:0' shape=(?, 32, 16, 32) dtype=float32>]]\n",
      "[None, 32, 16, 352]\n",
      "batch_normalization_185 [[<tf.Tensor 'concatenate_71_2/concat:0' shape=(?, 32, 16, 352) dtype=float32>]]\n",
      "called 0\n",
      "[352]\n",
      "[352]\n",
      "activation_151 [[<tf.Tensor 'batch_normalization_185_1/cond/Merge:0' shape=(?, 32, 16, 352) dtype=float32>]]\n",
      "conv2d_149 [[<tf.Tensor 'activation_151_1/Relu:0' shape=(?, 32, 16, 352) dtype=float32>]]\n",
      "batch_normalization_186 [[<tf.Tensor 'conv2d_149_1/convolution:0' shape=(?, 32, 16, 128) dtype=float32>]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_152 [[<tf.Tensor 'batch_normalization_186_1/cond/Merge:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "conv2d_150 [[<tf.Tensor 'activation_152_1/Relu:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "concatenate_72 [[<tf.Tensor 'concatenate_71_2/concat:0' shape=(?, 32, 16, 352) dtype=float32>, <tf.Tensor 'conv2d_150_1/convolution:0' shape=(?, 32, 16, 32) dtype=float32>]]\n",
      "[None, 32, 16, 384]\n",
      "batch_normalization_187 [[<tf.Tensor 'concatenate_72_2/concat:0' shape=(?, 32, 16, 384) dtype=float32>]]\n",
      "called 0\n",
      "[384]\n",
      "[384]\n",
      "activation_153 [[<tf.Tensor 'batch_normalization_187_1/cond/Merge:0' shape=(?, 32, 16, 384) dtype=float32>]]\n",
      "conv2d_151 [[<tf.Tensor 'activation_153_1/Relu:0' shape=(?, 32, 16, 384) dtype=float32>]]\n",
      "batch_normalization_188 [[<tf.Tensor 'conv2d_151_1/convolution:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_154 [[<tf.Tensor 'batch_normalization_188_1/cond/Merge:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "conv2d_152 [[<tf.Tensor 'activation_154_1/Relu:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "concatenate_73 [[<tf.Tensor 'concatenate_72_2/concat:0' shape=(?, 32, 16, 384) dtype=float32>, <tf.Tensor 'conv2d_152_1/convolution:0' shape=(?, 32, 16, 32) dtype=float32>]]\n",
      "[None, 32, 16, 416]\n",
      "batch_normalization_189 [[<tf.Tensor 'concatenate_73_2/concat:0' shape=(?, 32, 16, 416) dtype=float32>]]\n",
      "called 0\n",
      "[416]\n",
      "[416]\n",
      "activation_155 [[<tf.Tensor 'batch_normalization_189_1/cond/Merge:0' shape=(?, 32, 16, 416) dtype=float32>]]\n",
      "conv2d_153 [[<tf.Tensor 'activation_155_1/Relu:0' shape=(?, 32, 16, 416) dtype=float32>]]\n",
      "batch_normalization_190 [[<tf.Tensor 'conv2d_153_1/convolution:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_156 [[<tf.Tensor 'batch_normalization_190_1/cond/Merge:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "conv2d_154 [[<tf.Tensor 'activation_156_1/Relu:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "concatenate_74 [[<tf.Tensor 'concatenate_73_2/concat:0' shape=(?, 32, 16, 416) dtype=float32>, <tf.Tensor 'conv2d_154_1/convolution:0' shape=(?, 32, 16, 32) dtype=float32>]]\n",
      "[None, 32, 16, 448]\n",
      "batch_normalization_191 [[<tf.Tensor 'concatenate_74_2/concat:0' shape=(?, 32, 16, 448) dtype=float32>]]\n",
      "called 0\n",
      "[448]\n",
      "[448]\n",
      "activation_157 [[<tf.Tensor 'batch_normalization_191_1/cond/Merge:0' shape=(?, 32, 16, 448) dtype=float32>]]\n",
      "conv2d_155 [[<tf.Tensor 'activation_157_1/Relu:0' shape=(?, 32, 16, 448) dtype=float32>]]\n",
      "batch_normalization_192 [[<tf.Tensor 'conv2d_155_1/convolution:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_158 [[<tf.Tensor 'batch_normalization_192_1/cond/Merge:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "conv2d_156 [[<tf.Tensor 'activation_158_1/Relu:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "concatenate_75 [[<tf.Tensor 'concatenate_74_2/concat:0' shape=(?, 32, 16, 448) dtype=float32>, <tf.Tensor 'conv2d_156_1/convolution:0' shape=(?, 32, 16, 32) dtype=float32>]]\n",
      "[None, 32, 16, 480]\n",
      "batch_normalization_193 [[<tf.Tensor 'concatenate_75_2/concat:0' shape=(?, 32, 16, 480) dtype=float32>]]\n",
      "called 0\n",
      "[480]\n",
      "[480]\n",
      "activation_159 [[<tf.Tensor 'batch_normalization_193_1/cond/Merge:0' shape=(?, 32, 16, 480) dtype=float32>]]\n",
      "conv2d_157 [[<tf.Tensor 'activation_159_1/Relu:0' shape=(?, 32, 16, 480) dtype=float32>]]\n",
      "batch_normalization_194 [[<tf.Tensor 'conv2d_157_1/convolution:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_160 [[<tf.Tensor 'batch_normalization_194_1/cond/Merge:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "conv2d_158 [[<tf.Tensor 'activation_160_1/Relu:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "concatenate_76 [[<tf.Tensor 'concatenate_75_2/concat:0' shape=(?, 32, 16, 480) dtype=float32>, <tf.Tensor 'conv2d_158_1/convolution:0' shape=(?, 32, 16, 32) dtype=float32>]]\n",
      "[None, 32, 16, 512]\n",
      "batch_normalization_195 [[<tf.Tensor 'concatenate_76_2/concat:0' shape=(?, 32, 16, 512) dtype=float32>]]\n",
      "called 0\n",
      "[512]\n",
      "[512]\n",
      "activation_161 [[<tf.Tensor 'batch_normalization_195_1/cond/Merge:0' shape=(?, 32, 16, 512) dtype=float32>]]\n",
      "conv2d_159 [[<tf.Tensor 'activation_161_1/Relu:0' shape=(?, 32, 16, 512) dtype=float32>]]\n",
      "average_pooling2d_5 [[<tf.Tensor 'conv2d_159_1/convolution:0' shape=(?, 32, 16, 256) dtype=float32>]]\n",
      "batch_normalization_196 [[<tf.Tensor 'average_pooling2d_5_1/AvgPool:0' shape=(?, 16, 8, 256) dtype=float32>]]\n",
      "called 0\n",
      "[256]\n",
      "[256]\n",
      "activation_162 [[<tf.Tensor 'batch_normalization_196_1/cond/Merge:0' shape=(?, 16, 8, 256) dtype=float32>]]\n",
      "conv2d_160 [[<tf.Tensor 'activation_162_1/Relu:0' shape=(?, 16, 8, 256) dtype=float32>]]\n",
      "batch_normalization_197 [[<tf.Tensor 'conv2d_160_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_163 [[<tf.Tensor 'batch_normalization_197_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_161 [[<tf.Tensor 'activation_163_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_77 [[<tf.Tensor 'average_pooling2d_5_1/AvgPool:0' shape=(?, 16, 8, 256) dtype=float32>, <tf.Tensor 'conv2d_161_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 288]\n",
      "batch_normalization_198 [[<tf.Tensor 'concatenate_77_2/concat:0' shape=(?, 16, 8, 288) dtype=float32>]]\n",
      "called 0\n",
      "[288]\n",
      "[288]\n",
      "activation_164 [[<tf.Tensor 'batch_normalization_198_1/cond/Merge:0' shape=(?, 16, 8, 288) dtype=float32>]]\n",
      "conv2d_162 [[<tf.Tensor 'activation_164_1/Relu:0' shape=(?, 16, 8, 288) dtype=float32>]]\n",
      "batch_normalization_199 [[<tf.Tensor 'conv2d_162_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_165 [[<tf.Tensor 'batch_normalization_199_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_163 [[<tf.Tensor 'activation_165_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_78 [[<tf.Tensor 'concatenate_77_2/concat:0' shape=(?, 16, 8, 288) dtype=float32>, <tf.Tensor 'conv2d_163_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 320]\n",
      "batch_normalization_200 [[<tf.Tensor 'concatenate_78_2/concat:0' shape=(?, 16, 8, 320) dtype=float32>]]\n",
      "called 0\n",
      "[320]\n",
      "[320]\n",
      "activation_166 [[<tf.Tensor 'batch_normalization_200_1/cond/Merge:0' shape=(?, 16, 8, 320) dtype=float32>]]\n",
      "conv2d_164 [[<tf.Tensor 'activation_166_1/Relu:0' shape=(?, 16, 8, 320) dtype=float32>]]\n",
      "batch_normalization_201 [[<tf.Tensor 'conv2d_164_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_167 [[<tf.Tensor 'batch_normalization_201_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_165 [[<tf.Tensor 'activation_167_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_79 [[<tf.Tensor 'concatenate_78_2/concat:0' shape=(?, 16, 8, 320) dtype=float32>, <tf.Tensor 'conv2d_165_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 352]\n",
      "batch_normalization_202 [[<tf.Tensor 'concatenate_79_2/concat:0' shape=(?, 16, 8, 352) dtype=float32>]]\n",
      "called 0\n",
      "[352]\n",
      "[352]\n",
      "activation_168 [[<tf.Tensor 'batch_normalization_202_1/cond/Merge:0' shape=(?, 16, 8, 352) dtype=float32>]]\n",
      "conv2d_166 [[<tf.Tensor 'activation_168_1/Relu:0' shape=(?, 16, 8, 352) dtype=float32>]]\n",
      "batch_normalization_203 [[<tf.Tensor 'conv2d_166_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_169 [[<tf.Tensor 'batch_normalization_203_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_167 [[<tf.Tensor 'activation_169_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_80 [[<tf.Tensor 'concatenate_79_2/concat:0' shape=(?, 16, 8, 352) dtype=float32>, <tf.Tensor 'conv2d_167_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 384]\n",
      "batch_normalization_204 [[<tf.Tensor 'concatenate_80_2/concat:0' shape=(?, 16, 8, 384) dtype=float32>]]\n",
      "called 0\n",
      "[384]\n",
      "[384]\n",
      "activation_170 [[<tf.Tensor 'batch_normalization_204_1/cond/Merge:0' shape=(?, 16, 8, 384) dtype=float32>]]\n",
      "conv2d_168 [[<tf.Tensor 'activation_170_1/Relu:0' shape=(?, 16, 8, 384) dtype=float32>]]\n",
      "batch_normalization_205 [[<tf.Tensor 'conv2d_168_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_171 [[<tf.Tensor 'batch_normalization_205_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_169 [[<tf.Tensor 'activation_171_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_81 [[<tf.Tensor 'concatenate_80_2/concat:0' shape=(?, 16, 8, 384) dtype=float32>, <tf.Tensor 'conv2d_169_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 416]\n",
      "batch_normalization_206 [[<tf.Tensor 'concatenate_81_2/concat:0' shape=(?, 16, 8, 416) dtype=float32>]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called 0\n",
      "[416]\n",
      "[416]\n",
      "activation_172 [[<tf.Tensor 'batch_normalization_206_1/cond/Merge:0' shape=(?, 16, 8, 416) dtype=float32>]]\n",
      "conv2d_170 [[<tf.Tensor 'activation_172_1/Relu:0' shape=(?, 16, 8, 416) dtype=float32>]]\n",
      "batch_normalization_207 [[<tf.Tensor 'conv2d_170_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_173 [[<tf.Tensor 'batch_normalization_207_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_171 [[<tf.Tensor 'activation_173_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_82 [[<tf.Tensor 'concatenate_81_2/concat:0' shape=(?, 16, 8, 416) dtype=float32>, <tf.Tensor 'conv2d_171_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 448]\n",
      "batch_normalization_208 [[<tf.Tensor 'concatenate_82_2/concat:0' shape=(?, 16, 8, 448) dtype=float32>]]\n",
      "called 0\n",
      "[448]\n",
      "[448]\n",
      "activation_174 [[<tf.Tensor 'batch_normalization_208_1/cond/Merge:0' shape=(?, 16, 8, 448) dtype=float32>]]\n",
      "conv2d_172 [[<tf.Tensor 'activation_174_1/Relu:0' shape=(?, 16, 8, 448) dtype=float32>]]\n",
      "batch_normalization_209 [[<tf.Tensor 'conv2d_172_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_175 [[<tf.Tensor 'batch_normalization_209_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_173 [[<tf.Tensor 'activation_175_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_83 [[<tf.Tensor 'concatenate_82_2/concat:0' shape=(?, 16, 8, 448) dtype=float32>, <tf.Tensor 'conv2d_173_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 480]\n",
      "batch_normalization_210 [[<tf.Tensor 'concatenate_83_2/concat:0' shape=(?, 16, 8, 480) dtype=float32>]]\n",
      "called 0\n",
      "[480]\n",
      "[480]\n",
      "activation_176 [[<tf.Tensor 'batch_normalization_210_1/cond/Merge:0' shape=(?, 16, 8, 480) dtype=float32>]]\n",
      "conv2d_174 [[<tf.Tensor 'activation_176_1/Relu:0' shape=(?, 16, 8, 480) dtype=float32>]]\n",
      "batch_normalization_211 [[<tf.Tensor 'conv2d_174_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_177 [[<tf.Tensor 'batch_normalization_211_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_175 [[<tf.Tensor 'activation_177_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_84 [[<tf.Tensor 'concatenate_83_2/concat:0' shape=(?, 16, 8, 480) dtype=float32>, <tf.Tensor 'conv2d_175_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 512]\n",
      "batch_normalization_212 [[<tf.Tensor 'concatenate_84_2/concat:0' shape=(?, 16, 8, 512) dtype=float32>]]\n",
      "called 0\n",
      "[512]\n",
      "[512]\n",
      "activation_178 [[<tf.Tensor 'batch_normalization_212_1/cond/Merge:0' shape=(?, 16, 8, 512) dtype=float32>]]\n",
      "conv2d_176 [[<tf.Tensor 'activation_178_1/Relu:0' shape=(?, 16, 8, 512) dtype=float32>]]\n",
      "batch_normalization_213 [[<tf.Tensor 'conv2d_176_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_179 [[<tf.Tensor 'batch_normalization_213_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_177 [[<tf.Tensor 'activation_179_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_85 [[<tf.Tensor 'concatenate_84_2/concat:0' shape=(?, 16, 8, 512) dtype=float32>, <tf.Tensor 'conv2d_177_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 544]\n",
      "batch_normalization_214 [[<tf.Tensor 'concatenate_85_2/concat:0' shape=(?, 16, 8, 544) dtype=float32>]]\n",
      "called 0\n",
      "[544]\n",
      "[544]\n",
      "activation_180 [[<tf.Tensor 'batch_normalization_214_1/cond/Merge:0' shape=(?, 16, 8, 544) dtype=float32>]]\n",
      "conv2d_178 [[<tf.Tensor 'activation_180_1/Relu:0' shape=(?, 16, 8, 544) dtype=float32>]]\n",
      "batch_normalization_215 [[<tf.Tensor 'conv2d_178_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_181 [[<tf.Tensor 'batch_normalization_215_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_179 [[<tf.Tensor 'activation_181_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_86 [[<tf.Tensor 'concatenate_85_2/concat:0' shape=(?, 16, 8, 544) dtype=float32>, <tf.Tensor 'conv2d_179_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 576]\n",
      "batch_normalization_216 [[<tf.Tensor 'concatenate_86_2/concat:0' shape=(?, 16, 8, 576) dtype=float32>]]\n",
      "called 0\n",
      "[576]\n",
      "[576]\n",
      "activation_182 [[<tf.Tensor 'batch_normalization_216_1/cond/Merge:0' shape=(?, 16, 8, 576) dtype=float32>]]\n",
      "conv2d_180 [[<tf.Tensor 'activation_182_1/Relu:0' shape=(?, 16, 8, 576) dtype=float32>]]\n",
      "batch_normalization_217 [[<tf.Tensor 'conv2d_180_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_183 [[<tf.Tensor 'batch_normalization_217_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_181 [[<tf.Tensor 'activation_183_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_87 [[<tf.Tensor 'concatenate_86_2/concat:0' shape=(?, 16, 8, 576) dtype=float32>, <tf.Tensor 'conv2d_181_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 608]\n",
      "batch_normalization_218 [[<tf.Tensor 'concatenate_87_2/concat:0' shape=(?, 16, 8, 608) dtype=float32>]]\n",
      "called 0\n",
      "[608]\n",
      "[608]\n",
      "activation_184 [[<tf.Tensor 'batch_normalization_218_1/cond/Merge:0' shape=(?, 16, 8, 608) dtype=float32>]]\n",
      "conv2d_182 [[<tf.Tensor 'activation_184_1/Relu:0' shape=(?, 16, 8, 608) dtype=float32>]]\n",
      "batch_normalization_219 [[<tf.Tensor 'conv2d_182_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_185 [[<tf.Tensor 'batch_normalization_219_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_183 [[<tf.Tensor 'activation_185_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_88 [[<tf.Tensor 'concatenate_87_2/concat:0' shape=(?, 16, 8, 608) dtype=float32>, <tf.Tensor 'conv2d_183_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 640]\n",
      "batch_normalization_220 [[<tf.Tensor 'concatenate_88_2/concat:0' shape=(?, 16, 8, 640) dtype=float32>]]\n",
      "called 0\n",
      "[640]\n",
      "[640]\n",
      "activation_186 [[<tf.Tensor 'batch_normalization_220_1/cond/Merge:0' shape=(?, 16, 8, 640) dtype=float32>]]\n",
      "conv2d_184 [[<tf.Tensor 'activation_186_1/Relu:0' shape=(?, 16, 8, 640) dtype=float32>]]\n",
      "batch_normalization_221 [[<tf.Tensor 'conv2d_184_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_187 [[<tf.Tensor 'batch_normalization_221_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_185 [[<tf.Tensor 'activation_187_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_89 [[<tf.Tensor 'concatenate_88_2/concat:0' shape=(?, 16, 8, 640) dtype=float32>, <tf.Tensor 'conv2d_185_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 672]\n",
      "batch_normalization_222 [[<tf.Tensor 'concatenate_89_2/concat:0' shape=(?, 16, 8, 672) dtype=float32>]]\n",
      "called 0\n",
      "[672]\n",
      "[672]\n",
      "activation_188 [[<tf.Tensor 'batch_normalization_222_1/cond/Merge:0' shape=(?, 16, 8, 672) dtype=float32>]]\n",
      "conv2d_186 [[<tf.Tensor 'activation_188_1/Relu:0' shape=(?, 16, 8, 672) dtype=float32>]]\n",
      "batch_normalization_223 [[<tf.Tensor 'conv2d_186_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_189 [[<tf.Tensor 'batch_normalization_223_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_187 [[<tf.Tensor 'activation_189_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_90 [[<tf.Tensor 'concatenate_89_2/concat:0' shape=(?, 16, 8, 672) dtype=float32>, <tf.Tensor 'conv2d_187_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 704]\n",
      "batch_normalization_224 [[<tf.Tensor 'concatenate_90_2/concat:0' shape=(?, 16, 8, 704) dtype=float32>]]\n",
      "called 0\n",
      "[704]\n",
      "[704]\n",
      "activation_190 [[<tf.Tensor 'batch_normalization_224_1/cond/Merge:0' shape=(?, 16, 8, 704) dtype=float32>]]\n",
      "conv2d_188 [[<tf.Tensor 'activation_190_1/Relu:0' shape=(?, 16, 8, 704) dtype=float32>]]\n",
      "batch_normalization_225 [[<tf.Tensor 'conv2d_188_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_191 [[<tf.Tensor 'batch_normalization_225_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_189 [[<tf.Tensor 'activation_191_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_91 [[<tf.Tensor 'concatenate_90_2/concat:0' shape=(?, 16, 8, 704) dtype=float32>, <tf.Tensor 'conv2d_189_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 736]\n",
      "batch_normalization_226 [[<tf.Tensor 'concatenate_91_2/concat:0' shape=(?, 16, 8, 736) dtype=float32>]]\n",
      "called 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[736]\n",
      "[736]\n",
      "activation_192 [[<tf.Tensor 'batch_normalization_226_1/cond/Merge:0' shape=(?, 16, 8, 736) dtype=float32>]]\n",
      "conv2d_190 [[<tf.Tensor 'activation_192_1/Relu:0' shape=(?, 16, 8, 736) dtype=float32>]]\n",
      "batch_normalization_227 [[<tf.Tensor 'conv2d_190_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_193 [[<tf.Tensor 'batch_normalization_227_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_191 [[<tf.Tensor 'activation_193_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_92 [[<tf.Tensor 'concatenate_91_2/concat:0' shape=(?, 16, 8, 736) dtype=float32>, <tf.Tensor 'conv2d_191_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 768]\n",
      "batch_normalization_228 [[<tf.Tensor 'concatenate_92_2/concat:0' shape=(?, 16, 8, 768) dtype=float32>]]\n",
      "called 0\n",
      "[768]\n",
      "[768]\n",
      "activation_194 [[<tf.Tensor 'batch_normalization_228_1/cond/Merge:0' shape=(?, 16, 8, 768) dtype=float32>]]\n",
      "conv2d_192 [[<tf.Tensor 'activation_194_1/Relu:0' shape=(?, 16, 8, 768) dtype=float32>]]\n",
      "batch_normalization_229 [[<tf.Tensor 'conv2d_192_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_195 [[<tf.Tensor 'batch_normalization_229_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_193 [[<tf.Tensor 'activation_195_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_93 [[<tf.Tensor 'concatenate_92_2/concat:0' shape=(?, 16, 8, 768) dtype=float32>, <tf.Tensor 'conv2d_193_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 800]\n",
      "batch_normalization_230 [[<tf.Tensor 'concatenate_93_2/concat:0' shape=(?, 16, 8, 800) dtype=float32>]]\n",
      "called 0\n",
      "[800]\n",
      "[800]\n",
      "activation_196 [[<tf.Tensor 'batch_normalization_230_1/cond/Merge:0' shape=(?, 16, 8, 800) dtype=float32>]]\n",
      "conv2d_194 [[<tf.Tensor 'activation_196_1/Relu:0' shape=(?, 16, 8, 800) dtype=float32>]]\n",
      "batch_normalization_231 [[<tf.Tensor 'conv2d_194_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_197 [[<tf.Tensor 'batch_normalization_231_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_195 [[<tf.Tensor 'activation_197_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_94 [[<tf.Tensor 'concatenate_93_2/concat:0' shape=(?, 16, 8, 800) dtype=float32>, <tf.Tensor 'conv2d_195_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 832]\n",
      "batch_normalization_232 [[<tf.Tensor 'concatenate_94_2/concat:0' shape=(?, 16, 8, 832) dtype=float32>]]\n",
      "called 0\n",
      "[832]\n",
      "[832]\n",
      "activation_198 [[<tf.Tensor 'batch_normalization_232_1/cond/Merge:0' shape=(?, 16, 8, 832) dtype=float32>]]\n",
      "conv2d_196 [[<tf.Tensor 'activation_198_1/Relu:0' shape=(?, 16, 8, 832) dtype=float32>]]\n",
      "batch_normalization_233 [[<tf.Tensor 'conv2d_196_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_199 [[<tf.Tensor 'batch_normalization_233_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_197 [[<tf.Tensor 'activation_199_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_95 [[<tf.Tensor 'concatenate_94_2/concat:0' shape=(?, 16, 8, 832) dtype=float32>, <tf.Tensor 'conv2d_197_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 864]\n",
      "batch_normalization_234 [[<tf.Tensor 'concatenate_95_2/concat:0' shape=(?, 16, 8, 864) dtype=float32>]]\n",
      "called 0\n",
      "[864]\n",
      "[864]\n",
      "activation_200 [[<tf.Tensor 'batch_normalization_234_1/cond/Merge:0' shape=(?, 16, 8, 864) dtype=float32>]]\n",
      "conv2d_198 [[<tf.Tensor 'activation_200_1/Relu:0' shape=(?, 16, 8, 864) dtype=float32>]]\n",
      "batch_normalization_235 [[<tf.Tensor 'conv2d_198_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_201 [[<tf.Tensor 'batch_normalization_235_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_199 [[<tf.Tensor 'activation_201_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_96 [[<tf.Tensor 'concatenate_95_2/concat:0' shape=(?, 16, 8, 864) dtype=float32>, <tf.Tensor 'conv2d_199_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 896]\n",
      "batch_normalization_236 [[<tf.Tensor 'concatenate_96_2/concat:0' shape=(?, 16, 8, 896) dtype=float32>]]\n",
      "called 0\n",
      "[896]\n",
      "[896]\n",
      "activation_202 [[<tf.Tensor 'batch_normalization_236_1/cond/Merge:0' shape=(?, 16, 8, 896) dtype=float32>]]\n",
      "conv2d_200 [[<tf.Tensor 'activation_202_1/Relu:0' shape=(?, 16, 8, 896) dtype=float32>]]\n",
      "batch_normalization_237 [[<tf.Tensor 'conv2d_200_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_203 [[<tf.Tensor 'batch_normalization_237_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_201 [[<tf.Tensor 'activation_203_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_97 [[<tf.Tensor 'concatenate_96_2/concat:0' shape=(?, 16, 8, 896) dtype=float32>, <tf.Tensor 'conv2d_201_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 928]\n",
      "batch_normalization_238 [[<tf.Tensor 'concatenate_97_2/concat:0' shape=(?, 16, 8, 928) dtype=float32>]]\n",
      "called 0\n",
      "[928]\n",
      "[928]\n",
      "activation_204 [[<tf.Tensor 'batch_normalization_238_1/cond/Merge:0' shape=(?, 16, 8, 928) dtype=float32>]]\n",
      "conv2d_202 [[<tf.Tensor 'activation_204_1/Relu:0' shape=(?, 16, 8, 928) dtype=float32>]]\n",
      "batch_normalization_239 [[<tf.Tensor 'conv2d_202_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_205 [[<tf.Tensor 'batch_normalization_239_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_203 [[<tf.Tensor 'activation_205_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_98 [[<tf.Tensor 'concatenate_97_2/concat:0' shape=(?, 16, 8, 928) dtype=float32>, <tf.Tensor 'conv2d_203_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 960]\n",
      "batch_normalization_240 [[<tf.Tensor 'concatenate_98_2/concat:0' shape=(?, 16, 8, 960) dtype=float32>]]\n",
      "called 0\n",
      "[960]\n",
      "[960]\n",
      "activation_206 [[<tf.Tensor 'batch_normalization_240_1/cond/Merge:0' shape=(?, 16, 8, 960) dtype=float32>]]\n",
      "conv2d_204 [[<tf.Tensor 'activation_206_1/Relu:0' shape=(?, 16, 8, 960) dtype=float32>]]\n",
      "batch_normalization_241 [[<tf.Tensor 'conv2d_204_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_207 [[<tf.Tensor 'batch_normalization_241_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_205 [[<tf.Tensor 'activation_207_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_99 [[<tf.Tensor 'concatenate_98_2/concat:0' shape=(?, 16, 8, 960) dtype=float32>, <tf.Tensor 'conv2d_205_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 992]\n",
      "batch_normalization_242 [[<tf.Tensor 'concatenate_99_2/concat:0' shape=(?, 16, 8, 992) dtype=float32>]]\n",
      "called 0\n",
      "[992]\n",
      "[992]\n",
      "activation_208 [[<tf.Tensor 'batch_normalization_242_1/cond/Merge:0' shape=(?, 16, 8, 992) dtype=float32>]]\n",
      "conv2d_206 [[<tf.Tensor 'activation_208_1/Relu:0' shape=(?, 16, 8, 992) dtype=float32>]]\n",
      "batch_normalization_243 [[<tf.Tensor 'conv2d_206_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_209 [[<tf.Tensor 'batch_normalization_243_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_207 [[<tf.Tensor 'activation_209_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_100 [[<tf.Tensor 'concatenate_99_2/concat:0' shape=(?, 16, 8, 992) dtype=float32>, <tf.Tensor 'conv2d_207_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 1024]\n",
      "batch_normalization_244 [[<tf.Tensor 'concatenate_100_2/concat:0' shape=(?, 16, 8, 1024) dtype=float32>]]\n",
      "called 0\n",
      "[1024]\n",
      "[1024]\n",
      "activation_210 [[<tf.Tensor 'batch_normalization_244_1/cond/Merge:0' shape=(?, 16, 8, 1024) dtype=float32>]]\n",
      "conv2d_208 [[<tf.Tensor 'activation_210_1/Relu:0' shape=(?, 16, 8, 1024) dtype=float32>]]\n",
      "average_pooling2d_6 [[<tf.Tensor 'conv2d_208_1/convolution:0' shape=(?, 16, 8, 512) dtype=float32>]]\n",
      "reshape_311 [[<tf.Tensor 'average_pooling2d_6_1/AvgPool:0' shape=(?, 8, 4, 512) dtype=float32>]]\n",
      "m_312 [[]]\n",
      "lmda_313 [[<tf.Tensor 'Const:0' shape=(512,) dtype=float32>, <tf.Tensor 'lambda_1/Reshape:0' shape=(20, 8, 4, 512) dtype=float32>]]\n",
      "[20, 8, 4, 512]\n",
      "m_314 [[]]\n",
      "lmda_315 [[<tf.Tensor 'Const_1:0' shape=(512,) dtype=float32>, <tf.Tensor 'lambda_1/Reshape:0' shape=(20, 8, 4, 512) dtype=float32>]]\n",
      "[20, 8, 4, 512]\n",
      "m_316 [[]]\n",
      "lmda_317 [[<tf.Tensor 'Const_2:0' shape=(512,) dtype=float32>, <tf.Tensor 'lambda_1/Reshape:0' shape=(20, 8, 4, 512) dtype=float32>]]\n",
      "[20, 8, 4, 512]\n",
      "batch_normalization_123 [[<tf.Tensor 'lambda_2_1/Mul:0' shape=(20, 8, 4, 512) dtype=float32>], [<tf.Tensor 'lambda_3_1/Mul:0' shape=(20, 8, 4, 512) dtype=float32>], [<tf.Tensor 'lambda_4_1/Mul:0' shape=(20, 8, 4, 512) dtype=float32>]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m_319 [[]]\n",
      "lmda_320 [[<tf.Tensor 'Const_3:0' shape=(512,) dtype=float32>, <tf.Tensor 'batch_normalization_123_1/cond/Merge:0' shape=(20, 8, 4, 512) dtype=float32>]]\n",
      "[20, 8, 4, 512]\n",
      "m_321 [[]]\n",
      "lmda_322 [[<tf.Tensor 'Const_4:0' shape=(512,) dtype=float32>, <tf.Tensor 'batch_normalization_123_2/cond/Merge:0' shape=(20, 8, 4, 512) dtype=float32>]]\n",
      "[20, 8, 4, 512]\n",
      "m_323 [[]]\n",
      "lmda_324 [[<tf.Tensor 'Const_5:0' shape=(512,) dtype=float32>, <tf.Tensor 'batch_normalization_123_3/cond/Merge:0' shape=(20, 8, 4, 512) dtype=float32>]]\n",
      "[20, 8, 4, 512]\n",
      "activation_211 [[<tf.Tensor 'lambda_5_1/Mul:0' shape=(20, 8, 4, 512) dtype=float32>], [<tf.Tensor 'lambda_6_1/Mul:0' shape=(20, 8, 4, 512) dtype=float32>], [<tf.Tensor 'lambda_7_1/Mul:0' shape=(20, 8, 4, 512) dtype=float32>]]\n",
      "l_326 [[<tf.Tensor 'activation_211_1/Relu:0' shape=(20, 8, 4, 512) dtype=float32>]]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "l_327 [[<tf.Tensor 'activation_211_2/Relu:0' shape=(20, 8, 4, 512) dtype=float32>]]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "l_328 [[<tf.Tensor 'activation_211_3/Relu:0' shape=(20, 8, 4, 512) dtype=float32>]]\n",
      "1 [108800]\n",
      "2 [20, 8, 4, 1, 170]\n",
      "3 [20, 8, 4, 1, 510]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "1 [108800]\n",
      "2 [20, 8, 4, 1, 170]\n",
      "3 [20, 8, 4, 1, 510]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "conv2d_209 [[<tf.Tensor 'lambda_8/Reshape_1:0' shape=(20, 8, 4, 512) dtype=float32>], [<tf.Tensor 'lambda_9/Reshape_1:0' shape=(20, 8, 4, 512) dtype=float32>], [<tf.Tensor 'lambda_10/Reshape_1:0' shape=(20, 8, 4, 512) dtype=float32>]]\n",
      "idx [65452, 4]\n",
      "gather [65452]\n",
      "m_330 [[]]\n",
      "lmda_331 [[<tf.Tensor 'Const_6:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_209_1/convolution:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_332 [[]]\n",
      "lmda_333 [[<tf.Tensor 'Const_7:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_209_2/convolution:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_334 [[]]\n",
      "lmda_335 [[<tf.Tensor 'Const_8:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_209_3/convolution:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "batch_normalization_124 [[<tf.Tensor 'lambda_11_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_12_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_13_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "m_337 [[]]\n",
      "lmda_338 [[<tf.Tensor 'Const_9:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_124_1/cond/Merge:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_339 [[]]\n",
      "lmda_340 [[<tf.Tensor 'Const_10:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_124_2/cond/Merge:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_341 [[]]\n",
      "lmda_342 [[<tf.Tensor 'Const_11:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_124_3/cond/Merge:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "activation_212 [[<tf.Tensor 'lambda_14_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_15_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_16_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "l_344 [[<tf.Tensor 'activation_212_1/Relu:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "l_345 [[<tf.Tensor 'activation_212_2/Relu:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "l_346 [[<tf.Tensor 'activation_212_3/Relu:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "1 [26880]\n",
      "2 [20, 8, 4, 1, 42]\n",
      "3 [20, 8, 4, 1, 126]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "1 [26880]\n",
      "2 [20, 8, 4, 1, 42]\n",
      "3 [20, 8, 4, 1, 126]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "conv2d_210 [[<tf.Tensor 'lambda_17/Reshape_1:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_18/Reshape_1:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_19/Reshape_1:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "m_348 [[]]\n",
      "lmda_349 [[<tf.Tensor 'Const_12:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_210_1/convolution:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "[20, 8, 4, 32]\n",
      "m_350 [[]]\n",
      "lmda_351 [[<tf.Tensor 'Const_13:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_210_2/convolution:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "[20, 8, 4, 32]\n",
      "m_352 [[]]\n",
      "lmda_353 [[<tf.Tensor 'Const_14:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_210_3/convolution:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "[20, 8, 4, 32]\n",
      "concatenate_101 [[<tf.Tensor 'lambda_2_1/Mul:0' shape=(20, 8, 4, 512) dtype=float32>, <tf.Tensor 'lambda_20_1/Mul:0' shape=(20, 8, 4, 32) dtype=float32>], [<tf.Tensor 'lambda_3_1/Mul:0' shape=(20, 8, 4, 512) dtype=float32>, <tf.Tensor 'lambda_21_1/Mul:0' shape=(20, 8, 4, 32) dtype=float32>], [<tf.Tensor 'lambda_4_1/Mul:0' shape=(20, 8, 4, 512) dtype=float32>, <tf.Tensor 'lambda_22_1/Mul:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "m_355 [[]]\n",
      "lmda_356 [[<tf.Tensor 'Const_15:0' shape=(544,) dtype=float32>, <tf.Tensor 'concatenate_101_1/concat:0' shape=(20, 8, 4, 544) dtype=float32>]]\n",
      "[20, 8, 4, 544]\n",
      "m_357 [[]]\n",
      "lmda_358 [[<tf.Tensor 'Const_16:0' shape=(544,) dtype=float32>, <tf.Tensor 'concatenate_101_2/concat:0' shape=(20, 8, 4, 544) dtype=float32>]]\n",
      "[20, 8, 4, 544]\n",
      "m_359 [[]]\n",
      "lmda_360 [[<tf.Tensor 'Const_17:0' shape=(544,) dtype=float32>, <tf.Tensor 'concatenate_101_3/concat:0' shape=(20, 8, 4, 544) dtype=float32>]]\n",
      "[20, 8, 4, 544]\n",
      "batch_normalization_125 [[<tf.Tensor 'lambda_23_1/Mul:0' shape=(20, 8, 4, 544) dtype=float32>], [<tf.Tensor 'lambda_24_1/Mul:0' shape=(20, 8, 4, 544) dtype=float32>], [<tf.Tensor 'lambda_25_1/Mul:0' shape=(20, 8, 4, 544) dtype=float32>]]\n",
      "m_362 [[]]\n",
      "lmda_363 [[<tf.Tensor 'Const_18:0' shape=(544,) dtype=float32>, <tf.Tensor 'batch_normalization_125_1/cond/Merge:0' shape=(20, 8, 4, 544) dtype=float32>]]\n",
      "[20, 8, 4, 544]\n",
      "m_364 [[]]\n",
      "lmda_365 [[<tf.Tensor 'Const_19:0' shape=(544,) dtype=float32>, <tf.Tensor 'batch_normalization_125_2/cond/Merge:0' shape=(20, 8, 4, 544) dtype=float32>]]\n",
      "[20, 8, 4, 544]\n",
      "m_366 [[]]\n",
      "lmda_367 [[<tf.Tensor 'Const_20:0' shape=(544,) dtype=float32>, <tf.Tensor 'batch_normalization_125_3/cond/Merge:0' shape=(20, 8, 4, 544) dtype=float32>]]\n",
      "[20, 8, 4, 544]\n",
      "activation_213 [[<tf.Tensor 'lambda_26_1/Mul:0' shape=(20, 8, 4, 544) dtype=float32>], [<tf.Tensor 'lambda_27_1/Mul:0' shape=(20, 8, 4, 544) dtype=float32>], [<tf.Tensor 'lambda_28_1/Mul:0' shape=(20, 8, 4, 544) dtype=float32>]]\n",
      "l_369 [[<tf.Tensor 'activation_213_1/Relu:0' shape=(20, 8, 4, 544) dtype=float32>]]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [7040]\n",
      "6 [20, 8, 4, 1, 11]\n",
      "7 [20, 8, 4, 1, 32]\n",
      "8 [20, 8, 4, 1, 32]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [7040]\n",
      "6 [20, 8, 4, 1, 11]\n",
      "7 [20, 8, 4, 1, 32]\n",
      "8 [20, 8, 4, 1, 32]\n",
      "l_370 [[<tf.Tensor 'activation_213_2/Relu:0' shape=(20, 8, 4, 544) dtype=float32>]]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [7040]\n",
      "6 [20, 8, 4, 1, 11]\n",
      "7 [20, 8, 4, 1, 32]\n",
      "8 [20, 8, 4, 1, 32]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [7040]\n",
      "6 [20, 8, 4, 1, 11]\n",
      "7 [20, 8, 4, 1, 32]\n",
      "8 [20, 8, 4, 1, 32]\n",
      "l_371 [[<tf.Tensor 'activation_213_3/Relu:0' shape=(20, 8, 4, 544) dtype=float32>]]\n",
      "1 [108800]\n",
      "2 [20, 8, 4, 1, 170]\n",
      "3 [20, 8, 4, 1, 510]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [6400]\n",
      "6 [20, 8, 4, 1, 10]\n",
      "7 [20, 8, 4, 1, 30]\n",
      "8 [20, 8, 4, 1, 32]\n",
      "1 [108800]\n",
      "2 [20, 8, 4, 1, 170]\n",
      "3 [20, 8, 4, 1, 510]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [6400]\n",
      "6 [20, 8, 4, 1, 10]\n",
      "7 [20, 8, 4, 1, 30]\n",
      "8 [20, 8, 4, 1, 32]\n",
      "conv2d_211 [[<tf.Tensor 'lambda_29/Reshape_4:0' shape=(20, 8, 4, 544) dtype=float32>], [<tf.Tensor 'lambda_30/Reshape_4:0' shape=(20, 8, 4, 544) dtype=float32>], [<tf.Tensor 'lambda_31/Reshape_4:0' shape=(20, 8, 4, 544) dtype=float32>]]\n",
      "idx [69464, 4]\n",
      "gather [69464]\n",
      "m_373 [[]]\n",
      "lmda_374 [[<tf.Tensor 'Const_21:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_211_1/convolution:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_375 [[]]\n",
      "lmda_376 [[<tf.Tensor 'Const_22:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_211_2/convolution:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_377 [[]]\n",
      "lmda_378 [[<tf.Tensor 'Const_23:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_211_3/convolution:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "batch_normalization_126 [[<tf.Tensor 'lambda_32_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_33_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_34_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "m_380 [[]]\n",
      "lmda_381 [[<tf.Tensor 'Const_24:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_126_1/cond/Merge:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_382 [[]]\n",
      "lmda_383 [[<tf.Tensor 'Const_25:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_126_2/cond/Merge:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_384 [[]]\n",
      "lmda_385 [[<tf.Tensor 'Const_26:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_126_3/cond/Merge:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "activation_214 [[<tf.Tensor 'lambda_35_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_36_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_37_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "l_387 [[<tf.Tensor 'activation_214_1/Relu:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "l_388 [[<tf.Tensor 'activation_214_2/Relu:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "l_389 [[<tf.Tensor 'activation_214_3/Relu:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "1 [26880]\n",
      "2 [20, 8, 4, 1, 42]\n",
      "3 [20, 8, 4, 1, 126]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "1 [26880]\n",
      "2 [20, 8, 4, 1, 42]\n",
      "3 [20, 8, 4, 1, 126]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "conv2d_212 [[<tf.Tensor 'lambda_38/Reshape_1:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_39/Reshape_1:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_40/Reshape_1:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "m_391 [[]]\n",
      "lmda_392 [[<tf.Tensor 'Const_27:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_212_1/convolution:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "[20, 8, 4, 32]\n",
      "m_393 [[]]\n",
      "lmda_394 [[<tf.Tensor 'Const_28:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_212_2/convolution:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "[20, 8, 4, 32]\n",
      "m_395 [[]]\n",
      "lmda_396 [[<tf.Tensor 'Const_29:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_212_3/convolution:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "[20, 8, 4, 32]\n",
      "concatenate_102 [[<tf.Tensor 'concatenate_101_1/concat:0' shape=(20, 8, 4, 544) dtype=float32>, <tf.Tensor 'lambda_41_1/Mul:0' shape=(20, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_101_2/concat:0' shape=(20, 8, 4, 544) dtype=float32>, <tf.Tensor 'lambda_42_1/Mul:0' shape=(20, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_101_3/concat:0' shape=(20, 8, 4, 544) dtype=float32>, <tf.Tensor 'lambda_43_1/Mul:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "m_398 [[]]\n",
      "lmda_399 [[<tf.Tensor 'Const_30:0' shape=(576,) dtype=float32>, <tf.Tensor 'concatenate_102_1/concat:0' shape=(20, 8, 4, 576) dtype=float32>]]\n",
      "[20, 8, 4, 576]\n",
      "m_400 [[]]\n",
      "lmda_401 [[<tf.Tensor 'Const_31:0' shape=(576,) dtype=float32>, <tf.Tensor 'concatenate_102_2/concat:0' shape=(20, 8, 4, 576) dtype=float32>]]\n",
      "[20, 8, 4, 576]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m_402 [[]]\n",
      "lmda_403 [[<tf.Tensor 'Const_32:0' shape=(576,) dtype=float32>, <tf.Tensor 'concatenate_102_3/concat:0' shape=(20, 8, 4, 576) dtype=float32>]]\n",
      "[20, 8, 4, 576]\n",
      "batch_normalization_127 [[<tf.Tensor 'lambda_44_1/Mul:0' shape=(20, 8, 4, 576) dtype=float32>], [<tf.Tensor 'lambda_45_1/Mul:0' shape=(20, 8, 4, 576) dtype=float32>], [<tf.Tensor 'lambda_46_1/Mul:0' shape=(20, 8, 4, 576) dtype=float32>]]\n",
      "m_405 [[]]\n",
      "lmda_406 [[<tf.Tensor 'Const_33:0' shape=(576,) dtype=float32>, <tf.Tensor 'batch_normalization_127_1/cond/Merge:0' shape=(20, 8, 4, 576) dtype=float32>]]\n",
      "[20, 8, 4, 576]\n",
      "m_407 [[]]\n",
      "lmda_408 [[<tf.Tensor 'Const_34:0' shape=(576,) dtype=float32>, <tf.Tensor 'batch_normalization_127_2/cond/Merge:0' shape=(20, 8, 4, 576) dtype=float32>]]\n",
      "[20, 8, 4, 576]\n",
      "m_409 [[]]\n",
      "lmda_410 [[<tf.Tensor 'Const_35:0' shape=(576,) dtype=float32>, <tf.Tensor 'batch_normalization_127_3/cond/Merge:0' shape=(20, 8, 4, 576) dtype=float32>]]\n",
      "[20, 8, 4, 576]\n",
      "activation_215 [[<tf.Tensor 'lambda_47_1/Mul:0' shape=(20, 8, 4, 576) dtype=float32>], [<tf.Tensor 'lambda_48_1/Mul:0' shape=(20, 8, 4, 576) dtype=float32>], [<tf.Tensor 'lambda_49_1/Mul:0' shape=(20, 8, 4, 576) dtype=float32>]]\n",
      "l_412 [[<tf.Tensor 'activation_215_1/Relu:0' shape=(20, 8, 4, 576) dtype=float32>]]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [14080]\n",
      "6 [20, 8, 4, 2, 11]\n",
      "7 [20, 8, 4, 2, 32]\n",
      "8 [20, 8, 4, 2, 32]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [14080]\n",
      "6 [20, 8, 4, 2, 11]\n",
      "7 [20, 8, 4, 2, 32]\n",
      "8 [20, 8, 4, 2, 32]\n",
      "l_413 [[<tf.Tensor 'activation_215_2/Relu:0' shape=(20, 8, 4, 576) dtype=float32>]]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [14080]\n",
      "6 [20, 8, 4, 2, 11]\n",
      "7 [20, 8, 4, 2, 32]\n",
      "8 [20, 8, 4, 2, 32]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [14080]\n",
      "6 [20, 8, 4, 2, 11]\n",
      "7 [20, 8, 4, 2, 32]\n",
      "8 [20, 8, 4, 2, 32]\n",
      "l_414 [[<tf.Tensor 'activation_215_3/Relu:0' shape=(20, 8, 4, 576) dtype=float32>]]\n",
      "1 [108800]\n",
      "2 [20, 8, 4, 1, 170]\n",
      "3 [20, 8, 4, 1, 510]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [12800]\n",
      "6 [20, 8, 4, 2, 10]\n",
      "7 [20, 8, 4, 2, 30]\n",
      "8 [20, 8, 4, 2, 32]\n",
      "1 [108800]\n",
      "2 [20, 8, 4, 1, 170]\n",
      "3 [20, 8, 4, 1, 510]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [12800]\n",
      "6 [20, 8, 4, 2, 10]\n",
      "7 [20, 8, 4, 2, 30]\n",
      "8 [20, 8, 4, 2, 32]\n",
      "conv2d_213 [[<tf.Tensor 'lambda_50/Reshape_4:0' shape=(20, 8, 4, 576) dtype=float32>], [<tf.Tensor 'lambda_51/Reshape_4:0' shape=(20, 8, 4, 576) dtype=float32>], [<tf.Tensor 'lambda_52/Reshape_4:0' shape=(20, 8, 4, 576) dtype=float32>]]\n",
      "idx [73476, 4]\n",
      "gather [73476]\n",
      "m_416 [[]]\n",
      "lmda_417 [[<tf.Tensor 'Const_36:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_213_1/convolution:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_418 [[]]\n",
      "lmda_419 [[<tf.Tensor 'Const_37:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_213_2/convolution:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_420 [[]]\n",
      "lmda_421 [[<tf.Tensor 'Const_38:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_213_3/convolution:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "batch_normalization_128 [[<tf.Tensor 'lambda_53_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_54_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_55_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "m_423 [[]]\n",
      "lmda_424 [[<tf.Tensor 'Const_39:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_128_1/cond/Merge:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_425 [[]]\n",
      "lmda_426 [[<tf.Tensor 'Const_40:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_128_2/cond/Merge:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_427 [[]]\n",
      "lmda_428 [[<tf.Tensor 'Const_41:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_128_3/cond/Merge:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "activation_216 [[<tf.Tensor 'lambda_56_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_57_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_58_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "l_430 [[<tf.Tensor 'activation_216_1/Relu:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "l_431 [[<tf.Tensor 'activation_216_2/Relu:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "l_432 [[<tf.Tensor 'activation_216_3/Relu:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "1 [26880]\n",
      "2 [20, 8, 4, 1, 42]\n",
      "3 [20, 8, 4, 1, 126]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "1 [26880]\n",
      "2 [20, 8, 4, 1, 42]\n",
      "3 [20, 8, 4, 1, 126]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "conv2d_214 [[<tf.Tensor 'lambda_59/Reshape_1:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_60/Reshape_1:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_61/Reshape_1:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "m_434 [[]]\n",
      "lmda_435 [[<tf.Tensor 'Const_42:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_214_1/convolution:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "[20, 8, 4, 32]\n",
      "m_436 [[]]\n",
      "lmda_437 [[<tf.Tensor 'Const_43:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_214_2/convolution:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "[20, 8, 4, 32]\n",
      "m_438 [[]]\n",
      "lmda_439 [[<tf.Tensor 'Const_44:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_214_3/convolution:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "[20, 8, 4, 32]\n",
      "concatenate_103 [[<tf.Tensor 'concatenate_102_1/concat:0' shape=(20, 8, 4, 576) dtype=float32>, <tf.Tensor 'lambda_62_1/Mul:0' shape=(20, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_102_2/concat:0' shape=(20, 8, 4, 576) dtype=float32>, <tf.Tensor 'lambda_63_1/Mul:0' shape=(20, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_102_3/concat:0' shape=(20, 8, 4, 576) dtype=float32>, <tf.Tensor 'lambda_64_1/Mul:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "m_441 [[]]\n",
      "lmda_442 [[<tf.Tensor 'Const_45:0' shape=(608,) dtype=float32>, <tf.Tensor 'concatenate_103_1/concat:0' shape=(20, 8, 4, 608) dtype=float32>]]\n",
      "[20, 8, 4, 608]\n",
      "m_443 [[]]\n",
      "lmda_444 [[<tf.Tensor 'Const_46:0' shape=(608,) dtype=float32>, <tf.Tensor 'concatenate_103_2/concat:0' shape=(20, 8, 4, 608) dtype=float32>]]\n",
      "[20, 8, 4, 608]\n",
      "m_445 [[]]\n",
      "lmda_446 [[<tf.Tensor 'Const_47:0' shape=(608,) dtype=float32>, <tf.Tensor 'concatenate_103_3/concat:0' shape=(20, 8, 4, 608) dtype=float32>]]\n",
      "[20, 8, 4, 608]\n",
      "batch_normalization_129 [[<tf.Tensor 'lambda_65_1/Mul:0' shape=(20, 8, 4, 608) dtype=float32>], [<tf.Tensor 'lambda_66_1/Mul:0' shape=(20, 8, 4, 608) dtype=float32>], [<tf.Tensor 'lambda_67_1/Mul:0' shape=(20, 8, 4, 608) dtype=float32>]]\n",
      "m_448 [[]]\n",
      "lmda_449 [[<tf.Tensor 'Const_48:0' shape=(608,) dtype=float32>, <tf.Tensor 'batch_normalization_129_1/cond/Merge:0' shape=(20, 8, 4, 608) dtype=float32>]]\n",
      "[20, 8, 4, 608]\n",
      "m_450 [[]]\n",
      "lmda_451 [[<tf.Tensor 'Const_49:0' shape=(608,) dtype=float32>, <tf.Tensor 'batch_normalization_129_2/cond/Merge:0' shape=(20, 8, 4, 608) dtype=float32>]]\n",
      "[20, 8, 4, 608]\n",
      "m_452 [[]]\n",
      "lmda_453 [[<tf.Tensor 'Const_50:0' shape=(608,) dtype=float32>, <tf.Tensor 'batch_normalization_129_3/cond/Merge:0' shape=(20, 8, 4, 608) dtype=float32>]]\n",
      "[20, 8, 4, 608]\n",
      "activation_217 [[<tf.Tensor 'lambda_68_1/Mul:0' shape=(20, 8, 4, 608) dtype=float32>], [<tf.Tensor 'lambda_69_1/Mul:0' shape=(20, 8, 4, 608) dtype=float32>], [<tf.Tensor 'lambda_70_1/Mul:0' shape=(20, 8, 4, 608) dtype=float32>]]\n",
      "l_455 [[<tf.Tensor 'activation_217_1/Relu:0' shape=(20, 8, 4, 608) dtype=float32>]]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [21120]\n",
      "6 [20, 8, 4, 3, 11]\n",
      "7 [20, 8, 4, 3, 32]\n",
      "8 [20, 8, 4, 3, 32]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [21120]\n",
      "6 [20, 8, 4, 3, 11]\n",
      "7 [20, 8, 4, 3, 32]\n",
      "8 [20, 8, 4, 3, 32]\n",
      "l_456 [[<tf.Tensor 'activation_217_2/Relu:0' shape=(20, 8, 4, 608) dtype=float32>]]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [21120]\n",
      "6 [20, 8, 4, 3, 11]\n",
      "7 [20, 8, 4, 3, 32]\n",
      "8 [20, 8, 4, 3, 32]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [21120]\n",
      "6 [20, 8, 4, 3, 11]\n",
      "7 [20, 8, 4, 3, 32]\n",
      "8 [20, 8, 4, 3, 32]\n",
      "l_457 [[<tf.Tensor 'activation_217_3/Relu:0' shape=(20, 8, 4, 608) dtype=float32>]]\n",
      "1 [108800]\n",
      "2 [20, 8, 4, 1, 170]\n",
      "3 [20, 8, 4, 1, 510]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [19200]\n",
      "6 [20, 8, 4, 3, 10]\n",
      "7 [20, 8, 4, 3, 30]\n",
      "8 [20, 8, 4, 3, 32]\n",
      "1 [108800]\n",
      "2 [20, 8, 4, 1, 170]\n",
      "3 [20, 8, 4, 1, 510]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [19200]\n",
      "6 [20, 8, 4, 3, 10]\n",
      "7 [20, 8, 4, 3, 30]\n",
      "8 [20, 8, 4, 3, 32]\n",
      "conv2d_215 [[<tf.Tensor 'lambda_71/Reshape_4:0' shape=(20, 8, 4, 608) dtype=float32>], [<tf.Tensor 'lambda_72/Reshape_4:0' shape=(20, 8, 4, 608) dtype=float32>], [<tf.Tensor 'lambda_73/Reshape_4:0' shape=(20, 8, 4, 608) dtype=float32>]]\n",
      "idx [77488, 4]\n",
      "gather [77488]\n",
      "m_459 [[]]\n",
      "lmda_460 [[<tf.Tensor 'Const_51:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_215_1/convolution:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_461 [[]]\n",
      "lmda_462 [[<tf.Tensor 'Const_52:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_215_2/convolution:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_463 [[]]\n",
      "lmda_464 [[<tf.Tensor 'Const_53:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_215_3/convolution:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "batch_normalization_130 [[<tf.Tensor 'lambda_74_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_75_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_76_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m_466 [[]]\n",
      "lmda_467 [[<tf.Tensor 'Const_54:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_130_1/cond/Merge:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_468 [[]]\n",
      "lmda_469 [[<tf.Tensor 'Const_55:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_130_2/cond/Merge:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_470 [[]]\n",
      "lmda_471 [[<tf.Tensor 'Const_56:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_130_3/cond/Merge:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "activation_218 [[<tf.Tensor 'lambda_77_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_78_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_79_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "l_473 [[<tf.Tensor 'activation_218_1/Relu:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "l_474 [[<tf.Tensor 'activation_218_2/Relu:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "l_475 [[<tf.Tensor 'activation_218_3/Relu:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "1 [26880]\n",
      "2 [20, 8, 4, 1, 42]\n",
      "3 [20, 8, 4, 1, 126]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "1 [26880]\n",
      "2 [20, 8, 4, 1, 42]\n",
      "3 [20, 8, 4, 1, 126]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "conv2d_216 [[<tf.Tensor 'lambda_80/Reshape_1:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_81/Reshape_1:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_82/Reshape_1:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "m_477 [[]]\n",
      "lmda_478 [[<tf.Tensor 'Const_57:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_216_1/convolution:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "[20, 8, 4, 32]\n",
      "m_479 [[]]\n",
      "lmda_480 [[<tf.Tensor 'Const_58:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_216_2/convolution:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "[20, 8, 4, 32]\n",
      "m_481 [[]]\n",
      "lmda_482 [[<tf.Tensor 'Const_59:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_216_3/convolution:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "[20, 8, 4, 32]\n",
      "concatenate_104 [[<tf.Tensor 'concatenate_103_1/concat:0' shape=(20, 8, 4, 608) dtype=float32>, <tf.Tensor 'lambda_83_1/Mul:0' shape=(20, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_103_2/concat:0' shape=(20, 8, 4, 608) dtype=float32>, <tf.Tensor 'lambda_84_1/Mul:0' shape=(20, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_103_3/concat:0' shape=(20, 8, 4, 608) dtype=float32>, <tf.Tensor 'lambda_85_1/Mul:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "m_484 [[]]\n",
      "lmda_485 [[<tf.Tensor 'Const_60:0' shape=(640,) dtype=float32>, <tf.Tensor 'concatenate_104_1/concat:0' shape=(20, 8, 4, 640) dtype=float32>]]\n",
      "[20, 8, 4, 640]\n",
      "m_486 [[]]\n",
      "lmda_487 [[<tf.Tensor 'Const_61:0' shape=(640,) dtype=float32>, <tf.Tensor 'concatenate_104_2/concat:0' shape=(20, 8, 4, 640) dtype=float32>]]\n",
      "[20, 8, 4, 640]\n",
      "m_488 [[]]\n",
      "lmda_489 [[<tf.Tensor 'Const_62:0' shape=(640,) dtype=float32>, <tf.Tensor 'concatenate_104_3/concat:0' shape=(20, 8, 4, 640) dtype=float32>]]\n",
      "[20, 8, 4, 640]\n",
      "batch_normalization_131 [[<tf.Tensor 'lambda_86_1/Mul:0' shape=(20, 8, 4, 640) dtype=float32>], [<tf.Tensor 'lambda_87_1/Mul:0' shape=(20, 8, 4, 640) dtype=float32>], [<tf.Tensor 'lambda_88_1/Mul:0' shape=(20, 8, 4, 640) dtype=float32>]]\n",
      "m_491 [[]]\n",
      "lmda_492 [[<tf.Tensor 'Const_63:0' shape=(640,) dtype=float32>, <tf.Tensor 'batch_normalization_131_1/cond/Merge:0' shape=(20, 8, 4, 640) dtype=float32>]]\n",
      "[20, 8, 4, 640]\n",
      "m_493 [[]]\n",
      "lmda_494 [[<tf.Tensor 'Const_64:0' shape=(640,) dtype=float32>, <tf.Tensor 'batch_normalization_131_2/cond/Merge:0' shape=(20, 8, 4, 640) dtype=float32>]]\n",
      "[20, 8, 4, 640]\n",
      "m_495 [[]]\n",
      "lmda_496 [[<tf.Tensor 'Const_65:0' shape=(640,) dtype=float32>, <tf.Tensor 'batch_normalization_131_3/cond/Merge:0' shape=(20, 8, 4, 640) dtype=float32>]]\n",
      "[20, 8, 4, 640]\n",
      "activation_219 [[<tf.Tensor 'lambda_89_1/Mul:0' shape=(20, 8, 4, 640) dtype=float32>], [<tf.Tensor 'lambda_90_1/Mul:0' shape=(20, 8, 4, 640) dtype=float32>], [<tf.Tensor 'lambda_91_1/Mul:0' shape=(20, 8, 4, 640) dtype=float32>]]\n",
      "l_498 [[<tf.Tensor 'activation_219_1/Relu:0' shape=(20, 8, 4, 640) dtype=float32>]]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [28160]\n",
      "6 [20, 8, 4, 4, 11]\n",
      "7 [20, 8, 4, 4, 32]\n",
      "8 [20, 8, 4, 4, 32]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [28160]\n",
      "6 [20, 8, 4, 4, 11]\n",
      "7 [20, 8, 4, 4, 32]\n",
      "8 [20, 8, 4, 4, 32]\n",
      "l_499 [[<tf.Tensor 'activation_219_2/Relu:0' shape=(20, 8, 4, 640) dtype=float32>]]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [28160]\n",
      "6 [20, 8, 4, 4, 11]\n",
      "7 [20, 8, 4, 4, 32]\n",
      "8 [20, 8, 4, 4, 32]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [28160]\n",
      "6 [20, 8, 4, 4, 11]\n",
      "7 [20, 8, 4, 4, 32]\n",
      "8 [20, 8, 4, 4, 32]\n",
      "l_500 [[<tf.Tensor 'activation_219_3/Relu:0' shape=(20, 8, 4, 640) dtype=float32>]]\n",
      "1 [108800]\n",
      "2 [20, 8, 4, 1, 170]\n",
      "3 [20, 8, 4, 1, 510]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [25600]\n",
      "6 [20, 8, 4, 4, 10]\n",
      "7 [20, 8, 4, 4, 30]\n",
      "8 [20, 8, 4, 4, 32]\n",
      "1 [108800]\n",
      "2 [20, 8, 4, 1, 170]\n",
      "3 [20, 8, 4, 1, 510]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [25600]\n",
      "6 [20, 8, 4, 4, 10]\n",
      "7 [20, 8, 4, 4, 30]\n",
      "8 [20, 8, 4, 4, 32]\n",
      "conv2d_217 [[<tf.Tensor 'lambda_92/Reshape_4:0' shape=(20, 8, 4, 640) dtype=float32>], [<tf.Tensor 'lambda_93/Reshape_4:0' shape=(20, 8, 4, 640) dtype=float32>], [<tf.Tensor 'lambda_94/Reshape_4:0' shape=(20, 8, 4, 640) dtype=float32>]]\n",
      "idx [81500, 4]\n",
      "gather [81500]\n",
      "m_502 [[]]\n",
      "lmda_503 [[<tf.Tensor 'Const_66:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_217_1/convolution:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_504 [[]]\n",
      "lmda_505 [[<tf.Tensor 'Const_67:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_217_2/convolution:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_506 [[]]\n",
      "lmda_507 [[<tf.Tensor 'Const_68:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_217_3/convolution:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "batch_normalization_132 [[<tf.Tensor 'lambda_95_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_96_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_97_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "m_509 [[]]\n",
      "lmda_510 [[<tf.Tensor 'Const_69:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_132_1/cond/Merge:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_511 [[]]\n",
      "lmda_512 [[<tf.Tensor 'Const_70:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_132_2/cond/Merge:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_513 [[]]\n",
      "lmda_514 [[<tf.Tensor 'Const_71:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_132_3/cond/Merge:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "activation_220 [[<tf.Tensor 'lambda_98_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_99_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_100_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "l_516 [[<tf.Tensor 'activation_220_1/Relu:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "l_517 [[<tf.Tensor 'activation_220_2/Relu:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "l_518 [[<tf.Tensor 'activation_220_3/Relu:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "1 [26880]\n",
      "2 [20, 8, 4, 1, 42]\n",
      "3 [20, 8, 4, 1, 126]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "1 [26880]\n",
      "2 [20, 8, 4, 1, 42]\n",
      "3 [20, 8, 4, 1, 126]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "conv2d_218 [[<tf.Tensor 'lambda_101/Reshape_1:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_102/Reshape_1:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_103/Reshape_1:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "m_520 [[]]\n",
      "lmda_521 [[<tf.Tensor 'Const_72:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_218_1/convolution:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "[20, 8, 4, 32]\n",
      "m_522 [[]]\n",
      "lmda_523 [[<tf.Tensor 'Const_73:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_218_2/convolution:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "[20, 8, 4, 32]\n",
      "m_524 [[]]\n",
      "lmda_525 [[<tf.Tensor 'Const_74:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_218_3/convolution:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "[20, 8, 4, 32]\n",
      "concatenate_105 [[<tf.Tensor 'concatenate_104_1/concat:0' shape=(20, 8, 4, 640) dtype=float32>, <tf.Tensor 'lambda_104_1/Mul:0' shape=(20, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_104_2/concat:0' shape=(20, 8, 4, 640) dtype=float32>, <tf.Tensor 'lambda_105_1/Mul:0' shape=(20, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_104_3/concat:0' shape=(20, 8, 4, 640) dtype=float32>, <tf.Tensor 'lambda_106_1/Mul:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "m_527 [[]]\n",
      "lmda_528 [[<tf.Tensor 'Const_75:0' shape=(672,) dtype=float32>, <tf.Tensor 'concatenate_105_1/concat:0' shape=(20, 8, 4, 672) dtype=float32>]]\n",
      "[20, 8, 4, 672]\n",
      "m_529 [[]]\n",
      "lmda_530 [[<tf.Tensor 'Const_76:0' shape=(672,) dtype=float32>, <tf.Tensor 'concatenate_105_2/concat:0' shape=(20, 8, 4, 672) dtype=float32>]]\n",
      "[20, 8, 4, 672]\n",
      "m_531 [[]]\n",
      "lmda_532 [[<tf.Tensor 'Const_77:0' shape=(672,) dtype=float32>, <tf.Tensor 'concatenate_105_3/concat:0' shape=(20, 8, 4, 672) dtype=float32>]]\n",
      "[20, 8, 4, 672]\n",
      "batch_normalization_133 [[<tf.Tensor 'lambda_107_1/Mul:0' shape=(20, 8, 4, 672) dtype=float32>], [<tf.Tensor 'lambda_108_1/Mul:0' shape=(20, 8, 4, 672) dtype=float32>], [<tf.Tensor 'lambda_109_1/Mul:0' shape=(20, 8, 4, 672) dtype=float32>]]\n",
      "m_534 [[]]\n",
      "lmda_535 [[<tf.Tensor 'Const_78:0' shape=(672,) dtype=float32>, <tf.Tensor 'batch_normalization_133_1/cond/Merge:0' shape=(20, 8, 4, 672) dtype=float32>]]\n",
      "[20, 8, 4, 672]\n",
      "m_536 [[]]\n",
      "lmda_537 [[<tf.Tensor 'Const_79:0' shape=(672,) dtype=float32>, <tf.Tensor 'batch_normalization_133_2/cond/Merge:0' shape=(20, 8, 4, 672) dtype=float32>]]\n",
      "[20, 8, 4, 672]\n",
      "m_538 [[]]\n",
      "lmda_539 [[<tf.Tensor 'Const_80:0' shape=(672,) dtype=float32>, <tf.Tensor 'batch_normalization_133_3/cond/Merge:0' shape=(20, 8, 4, 672) dtype=float32>]]\n",
      "[20, 8, 4, 672]\n",
      "activation_221 [[<tf.Tensor 'lambda_110_1/Mul:0' shape=(20, 8, 4, 672) dtype=float32>], [<tf.Tensor 'lambda_111_1/Mul:0' shape=(20, 8, 4, 672) dtype=float32>], [<tf.Tensor 'lambda_112_1/Mul:0' shape=(20, 8, 4, 672) dtype=float32>]]\n",
      "l_541 [[<tf.Tensor 'activation_221_1/Relu:0' shape=(20, 8, 4, 672) dtype=float32>]]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [35200]\n",
      "6 [20, 8, 4, 5, 11]\n",
      "7 [20, 8, 4, 5, 32]\n",
      "8 [20, 8, 4, 5, 32]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [35200]\n",
      "6 [20, 8, 4, 5, 11]\n",
      "7 [20, 8, 4, 5, 32]\n",
      "8 [20, 8, 4, 5, 32]\n",
      "l_542 [[<tf.Tensor 'activation_221_2/Relu:0' shape=(20, 8, 4, 672) dtype=float32>]]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [35200]\n",
      "6 [20, 8, 4, 5, 11]\n",
      "7 [20, 8, 4, 5, 32]\n",
      "8 [20, 8, 4, 5, 32]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [35200]\n",
      "6 [20, 8, 4, 5, 11]\n",
      "7 [20, 8, 4, 5, 32]\n",
      "8 [20, 8, 4, 5, 32]\n",
      "l_543 [[<tf.Tensor 'activation_221_3/Relu:0' shape=(20, 8, 4, 672) dtype=float32>]]\n",
      "1 [108800]\n",
      "2 [20, 8, 4, 1, 170]\n",
      "3 [20, 8, 4, 1, 510]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [32000]\n",
      "6 [20, 8, 4, 5, 10]\n",
      "7 [20, 8, 4, 5, 30]\n",
      "8 [20, 8, 4, 5, 32]\n",
      "1 [108800]\n",
      "2 [20, 8, 4, 1, 170]\n",
      "3 [20, 8, 4, 1, 510]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [32000]\n",
      "6 [20, 8, 4, 5, 10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 [20, 8, 4, 5, 30]\n",
      "8 [20, 8, 4, 5, 32]\n",
      "conv2d_219 [[<tf.Tensor 'lambda_113/Reshape_4:0' shape=(20, 8, 4, 672) dtype=float32>], [<tf.Tensor 'lambda_114/Reshape_4:0' shape=(20, 8, 4, 672) dtype=float32>], [<tf.Tensor 'lambda_115/Reshape_4:0' shape=(20, 8, 4, 672) dtype=float32>]]\n",
      "idx [85512, 4]\n",
      "gather [85512]\n",
      "m_545 [[]]\n",
      "lmda_546 [[<tf.Tensor 'Const_81:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_219_1/convolution:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_547 [[]]\n",
      "lmda_548 [[<tf.Tensor 'Const_82:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_219_2/convolution:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_549 [[]]\n",
      "lmda_550 [[<tf.Tensor 'Const_83:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_219_3/convolution:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "batch_normalization_134 [[<tf.Tensor 'lambda_116_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_117_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_118_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "m_552 [[]]\n",
      "lmda_553 [[<tf.Tensor 'Const_84:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_134_1/cond/Merge:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_554 [[]]\n",
      "lmda_555 [[<tf.Tensor 'Const_85:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_134_2/cond/Merge:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_556 [[]]\n",
      "lmda_557 [[<tf.Tensor 'Const_86:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_134_3/cond/Merge:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "activation_222 [[<tf.Tensor 'lambda_119_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_120_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_121_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "l_559 [[<tf.Tensor 'activation_222_1/Relu:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "l_560 [[<tf.Tensor 'activation_222_2/Relu:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "l_561 [[<tf.Tensor 'activation_222_3/Relu:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "1 [26880]\n",
      "2 [20, 8, 4, 1, 42]\n",
      "3 [20, 8, 4, 1, 126]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "1 [26880]\n",
      "2 [20, 8, 4, 1, 42]\n",
      "3 [20, 8, 4, 1, 126]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "conv2d_220 [[<tf.Tensor 'lambda_122/Reshape_1:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_123/Reshape_1:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_124/Reshape_1:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "m_563 [[]]\n",
      "lmda_564 [[<tf.Tensor 'Const_87:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_220_1/convolution:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "[20, 8, 4, 32]\n",
      "m_565 [[]]\n",
      "lmda_566 [[<tf.Tensor 'Const_88:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_220_2/convolution:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "[20, 8, 4, 32]\n",
      "m_567 [[]]\n",
      "lmda_568 [[<tf.Tensor 'Const_89:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_220_3/convolution:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "[20, 8, 4, 32]\n",
      "concatenate_106 [[<tf.Tensor 'concatenate_105_1/concat:0' shape=(20, 8, 4, 672) dtype=float32>, <tf.Tensor 'lambda_125_1/Mul:0' shape=(20, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_105_2/concat:0' shape=(20, 8, 4, 672) dtype=float32>, <tf.Tensor 'lambda_126_1/Mul:0' shape=(20, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_105_3/concat:0' shape=(20, 8, 4, 672) dtype=float32>, <tf.Tensor 'lambda_127_1/Mul:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "m_570 [[]]\n",
      "lmda_571 [[<tf.Tensor 'Const_90:0' shape=(704,) dtype=float32>, <tf.Tensor 'concatenate_106_1/concat:0' shape=(20, 8, 4, 704) dtype=float32>]]\n",
      "[20, 8, 4, 704]\n",
      "m_572 [[]]\n",
      "lmda_573 [[<tf.Tensor 'Const_91:0' shape=(704,) dtype=float32>, <tf.Tensor 'concatenate_106_2/concat:0' shape=(20, 8, 4, 704) dtype=float32>]]\n",
      "[20, 8, 4, 704]\n",
      "m_574 [[]]\n",
      "lmda_575 [[<tf.Tensor 'Const_92:0' shape=(704,) dtype=float32>, <tf.Tensor 'concatenate_106_3/concat:0' shape=(20, 8, 4, 704) dtype=float32>]]\n",
      "[20, 8, 4, 704]\n",
      "batch_normalization_135 [[<tf.Tensor 'lambda_128_1/Mul:0' shape=(20, 8, 4, 704) dtype=float32>], [<tf.Tensor 'lambda_129_1/Mul:0' shape=(20, 8, 4, 704) dtype=float32>], [<tf.Tensor 'lambda_130_1/Mul:0' shape=(20, 8, 4, 704) dtype=float32>]]\n",
      "m_577 [[]]\n",
      "lmda_578 [[<tf.Tensor 'Const_93:0' shape=(704,) dtype=float32>, <tf.Tensor 'batch_normalization_135_1/cond/Merge:0' shape=(20, 8, 4, 704) dtype=float32>]]\n",
      "[20, 8, 4, 704]\n",
      "m_579 [[]]\n",
      "lmda_580 [[<tf.Tensor 'Const_94:0' shape=(704,) dtype=float32>, <tf.Tensor 'batch_normalization_135_2/cond/Merge:0' shape=(20, 8, 4, 704) dtype=float32>]]\n",
      "[20, 8, 4, 704]\n",
      "m_581 [[]]\n",
      "lmda_582 [[<tf.Tensor 'Const_95:0' shape=(704,) dtype=float32>, <tf.Tensor 'batch_normalization_135_3/cond/Merge:0' shape=(20, 8, 4, 704) dtype=float32>]]\n",
      "[20, 8, 4, 704]\n",
      "activation_223 [[<tf.Tensor 'lambda_131_1/Mul:0' shape=(20, 8, 4, 704) dtype=float32>], [<tf.Tensor 'lambda_132_1/Mul:0' shape=(20, 8, 4, 704) dtype=float32>], [<tf.Tensor 'lambda_133_1/Mul:0' shape=(20, 8, 4, 704) dtype=float32>]]\n",
      "l_584 [[<tf.Tensor 'activation_223_1/Relu:0' shape=(20, 8, 4, 704) dtype=float32>]]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [42240]\n",
      "6 [20, 8, 4, 6, 11]\n",
      "7 [20, 8, 4, 6, 32]\n",
      "8 [20, 8, 4, 6, 32]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [42240]\n",
      "6 [20, 8, 4, 6, 11]\n",
      "7 [20, 8, 4, 6, 32]\n",
      "8 [20, 8, 4, 6, 32]\n",
      "l_585 [[<tf.Tensor 'activation_223_2/Relu:0' shape=(20, 8, 4, 704) dtype=float32>]]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [42240]\n",
      "6 [20, 8, 4, 6, 11]\n",
      "7 [20, 8, 4, 6, 32]\n",
      "8 [20, 8, 4, 6, 32]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [42240]\n",
      "6 [20, 8, 4, 6, 11]\n",
      "7 [20, 8, 4, 6, 32]\n",
      "8 [20, 8, 4, 6, 32]\n",
      "l_586 [[<tf.Tensor 'activation_223_3/Relu:0' shape=(20, 8, 4, 704) dtype=float32>]]\n",
      "1 [108800]\n",
      "2 [20, 8, 4, 1, 170]\n",
      "3 [20, 8, 4, 1, 510]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [38400]\n",
      "6 [20, 8, 4, 6, 10]\n",
      "7 [20, 8, 4, 6, 30]\n",
      "8 [20, 8, 4, 6, 32]\n",
      "1 [108800]\n",
      "2 [20, 8, 4, 1, 170]\n",
      "3 [20, 8, 4, 1, 510]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [38400]\n",
      "6 [20, 8, 4, 6, 10]\n",
      "7 [20, 8, 4, 6, 30]\n",
      "8 [20, 8, 4, 6, 32]\n",
      "conv2d_221 [[<tf.Tensor 'lambda_134/Reshape_4:0' shape=(20, 8, 4, 704) dtype=float32>], [<tf.Tensor 'lambda_135/Reshape_4:0' shape=(20, 8, 4, 704) dtype=float32>], [<tf.Tensor 'lambda_136/Reshape_4:0' shape=(20, 8, 4, 704) dtype=float32>]]\n",
      "idx [89524, 4]\n",
      "gather [89524]\n",
      "m_588 [[]]\n",
      "lmda_589 [[<tf.Tensor 'Const_96:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_221_1/convolution:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_590 [[]]\n",
      "lmda_591 [[<tf.Tensor 'Const_97:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_221_2/convolution:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_592 [[]]\n",
      "lmda_593 [[<tf.Tensor 'Const_98:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_221_3/convolution:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "batch_normalization_136 [[<tf.Tensor 'lambda_137_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_138_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_139_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "m_595 [[]]\n",
      "lmda_596 [[<tf.Tensor 'Const_99:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_136_1/cond/Merge:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_597 [[]]\n",
      "lmda_598 [[<tf.Tensor 'Const_100:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_136_2/cond/Merge:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_599 [[]]\n",
      "lmda_600 [[<tf.Tensor 'Const_101:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_136_3/cond/Merge:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "activation_224 [[<tf.Tensor 'lambda_140_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_141_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_142_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "l_602 [[<tf.Tensor 'activation_224_1/Relu:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "l_603 [[<tf.Tensor 'activation_224_2/Relu:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "l_604 [[<tf.Tensor 'activation_224_3/Relu:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "1 [26880]\n",
      "2 [20, 8, 4, 1, 42]\n",
      "3 [20, 8, 4, 1, 126]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "1 [26880]\n",
      "2 [20, 8, 4, 1, 42]\n",
      "3 [20, 8, 4, 1, 126]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "conv2d_222 [[<tf.Tensor 'lambda_143/Reshape_1:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_144/Reshape_1:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_145/Reshape_1:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "m_606 [[]]\n",
      "lmda_607 [[<tf.Tensor 'Const_102:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_222_1/convolution:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "[20, 8, 4, 32]\n",
      "m_608 [[]]\n",
      "lmda_609 [[<tf.Tensor 'Const_103:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_222_2/convolution:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "[20, 8, 4, 32]\n",
      "m_610 [[]]\n",
      "lmda_611 [[<tf.Tensor 'Const_104:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_222_3/convolution:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "[20, 8, 4, 32]\n",
      "concatenate_107 [[<tf.Tensor 'concatenate_106_1/concat:0' shape=(20, 8, 4, 704) dtype=float32>, <tf.Tensor 'lambda_146_1/Mul:0' shape=(20, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_106_2/concat:0' shape=(20, 8, 4, 704) dtype=float32>, <tf.Tensor 'lambda_147_1/Mul:0' shape=(20, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_106_3/concat:0' shape=(20, 8, 4, 704) dtype=float32>, <tf.Tensor 'lambda_148_1/Mul:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "m_613 [[]]\n",
      "lmda_614 [[<tf.Tensor 'Const_105:0' shape=(736,) dtype=float32>, <tf.Tensor 'concatenate_107_1/concat:0' shape=(20, 8, 4, 736) dtype=float32>]]\n",
      "[20, 8, 4, 736]\n",
      "m_615 [[]]\n",
      "lmda_616 [[<tf.Tensor 'Const_106:0' shape=(736,) dtype=float32>, <tf.Tensor 'concatenate_107_2/concat:0' shape=(20, 8, 4, 736) dtype=float32>]]\n",
      "[20, 8, 4, 736]\n",
      "m_617 [[]]\n",
      "lmda_618 [[<tf.Tensor 'Const_107:0' shape=(736,) dtype=float32>, <tf.Tensor 'concatenate_107_3/concat:0' shape=(20, 8, 4, 736) dtype=float32>]]\n",
      "[20, 8, 4, 736]\n",
      "batch_normalization_137 [[<tf.Tensor 'lambda_149_1/Mul:0' shape=(20, 8, 4, 736) dtype=float32>], [<tf.Tensor 'lambda_150_1/Mul:0' shape=(20, 8, 4, 736) dtype=float32>], [<tf.Tensor 'lambda_151_1/Mul:0' shape=(20, 8, 4, 736) dtype=float32>]]\n",
      "m_620 [[]]\n",
      "lmda_621 [[<tf.Tensor 'Const_108:0' shape=(736,) dtype=float32>, <tf.Tensor 'batch_normalization_137_1/cond/Merge:0' shape=(20, 8, 4, 736) dtype=float32>]]\n",
      "[20, 8, 4, 736]\n",
      "m_622 [[]]\n",
      "lmda_623 [[<tf.Tensor 'Const_109:0' shape=(736,) dtype=float32>, <tf.Tensor 'batch_normalization_137_2/cond/Merge:0' shape=(20, 8, 4, 736) dtype=float32>]]\n",
      "[20, 8, 4, 736]\n",
      "m_624 [[]]\n",
      "lmda_625 [[<tf.Tensor 'Const_110:0' shape=(736,) dtype=float32>, <tf.Tensor 'batch_normalization_137_3/cond/Merge:0' shape=(20, 8, 4, 736) dtype=float32>]]\n",
      "[20, 8, 4, 736]\n",
      "activation_225 [[<tf.Tensor 'lambda_152_1/Mul:0' shape=(20, 8, 4, 736) dtype=float32>], [<tf.Tensor 'lambda_153_1/Mul:0' shape=(20, 8, 4, 736) dtype=float32>], [<tf.Tensor 'lambda_154_1/Mul:0' shape=(20, 8, 4, 736) dtype=float32>]]\n",
      "l_627 [[<tf.Tensor 'activation_225_1/Relu:0' shape=(20, 8, 4, 736) dtype=float32>]]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [49280]\n",
      "6 [20, 8, 4, 7, 11]\n",
      "7 [20, 8, 4, 7, 32]\n",
      "8 [20, 8, 4, 7, 32]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [49280]\n",
      "6 [20, 8, 4, 7, 11]\n",
      "7 [20, 8, 4, 7, 32]\n",
      "8 [20, 8, 4, 7, 32]\n",
      "l_628 [[<tf.Tensor 'activation_225_2/Relu:0' shape=(20, 8, 4, 736) dtype=float32>]]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [49280]\n",
      "6 [20, 8, 4, 7, 11]\n",
      "7 [20, 8, 4, 7, 32]\n",
      "8 [20, 8, 4, 7, 32]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [49280]\n",
      "6 [20, 8, 4, 7, 11]\n",
      "7 [20, 8, 4, 7, 32]\n",
      "8 [20, 8, 4, 7, 32]\n",
      "l_629 [[<tf.Tensor 'activation_225_3/Relu:0' shape=(20, 8, 4, 736) dtype=float32>]]\n",
      "1 [108800]\n",
      "2 [20, 8, 4, 1, 170]\n",
      "3 [20, 8, 4, 1, 510]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [44800]\n",
      "6 [20, 8, 4, 7, 10]\n",
      "7 [20, 8, 4, 7, 30]\n",
      "8 [20, 8, 4, 7, 32]\n",
      "1 [108800]\n",
      "2 [20, 8, 4, 1, 170]\n",
      "3 [20, 8, 4, 1, 510]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [44800]\n",
      "6 [20, 8, 4, 7, 10]\n",
      "7 [20, 8, 4, 7, 30]\n",
      "8 [20, 8, 4, 7, 32]\n",
      "conv2d_223 [[<tf.Tensor 'lambda_155/Reshape_4:0' shape=(20, 8, 4, 736) dtype=float32>], [<tf.Tensor 'lambda_156/Reshape_4:0' shape=(20, 8, 4, 736) dtype=float32>], [<tf.Tensor 'lambda_157/Reshape_4:0' shape=(20, 8, 4, 736) dtype=float32>]]\n",
      "idx [93536, 4]\n",
      "gather [93536]\n",
      "m_631 [[]]\n",
      "lmda_632 [[<tf.Tensor 'Const_111:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_223_1/convolution:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_633 [[]]\n",
      "lmda_634 [[<tf.Tensor 'Const_112:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_223_2/convolution:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_635 [[]]\n",
      "lmda_636 [[<tf.Tensor 'Const_113:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_223_3/convolution:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "batch_normalization_138 [[<tf.Tensor 'lambda_158_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_159_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_160_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "m_638 [[]]\n",
      "lmda_639 [[<tf.Tensor 'Const_114:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_138_1/cond/Merge:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_640 [[]]\n",
      "lmda_641 [[<tf.Tensor 'Const_115:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_138_2/cond/Merge:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_642 [[]]\n",
      "lmda_643 [[<tf.Tensor 'Const_116:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_138_3/cond/Merge:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "activation_226 [[<tf.Tensor 'lambda_161_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_162_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_163_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "l_645 [[<tf.Tensor 'activation_226_1/Relu:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "l_646 [[<tf.Tensor 'activation_226_2/Relu:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "l_647 [[<tf.Tensor 'activation_226_3/Relu:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "1 [26880]\n",
      "2 [20, 8, 4, 1, 42]\n",
      "3 [20, 8, 4, 1, 126]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "1 [26880]\n",
      "2 [20, 8, 4, 1, 42]\n",
      "3 [20, 8, 4, 1, 126]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "conv2d_224 [[<tf.Tensor 'lambda_164/Reshape_1:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_165/Reshape_1:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_166/Reshape_1:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "m_649 [[]]\n",
      "lmda_650 [[<tf.Tensor 'Const_117:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_224_1/convolution:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "[20, 8, 4, 32]\n",
      "m_651 [[]]\n",
      "lmda_652 [[<tf.Tensor 'Const_118:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_224_2/convolution:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "[20, 8, 4, 32]\n",
      "m_653 [[]]\n",
      "lmda_654 [[<tf.Tensor 'Const_119:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_224_3/convolution:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "[20, 8, 4, 32]\n",
      "concatenate_108 [[<tf.Tensor 'concatenate_107_1/concat:0' shape=(20, 8, 4, 736) dtype=float32>, <tf.Tensor 'lambda_167_1/Mul:0' shape=(20, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_107_2/concat:0' shape=(20, 8, 4, 736) dtype=float32>, <tf.Tensor 'lambda_168_1/Mul:0' shape=(20, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_107_3/concat:0' shape=(20, 8, 4, 736) dtype=float32>, <tf.Tensor 'lambda_169_1/Mul:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "m_656 [[]]\n",
      "lmda_657 [[<tf.Tensor 'Const_120:0' shape=(768,) dtype=float32>, <tf.Tensor 'concatenate_108_1/concat:0' shape=(20, 8, 4, 768) dtype=float32>]]\n",
      "[20, 8, 4, 768]\n",
      "m_658 [[]]\n",
      "lmda_659 [[<tf.Tensor 'Const_121:0' shape=(768,) dtype=float32>, <tf.Tensor 'concatenate_108_2/concat:0' shape=(20, 8, 4, 768) dtype=float32>]]\n",
      "[20, 8, 4, 768]\n",
      "m_660 [[]]\n",
      "lmda_661 [[<tf.Tensor 'Const_122:0' shape=(768,) dtype=float32>, <tf.Tensor 'concatenate_108_3/concat:0' shape=(20, 8, 4, 768) dtype=float32>]]\n",
      "[20, 8, 4, 768]\n",
      "batch_normalization_139 [[<tf.Tensor 'lambda_170_1/Mul:0' shape=(20, 8, 4, 768) dtype=float32>], [<tf.Tensor 'lambda_171_1/Mul:0' shape=(20, 8, 4, 768) dtype=float32>], [<tf.Tensor 'lambda_172_1/Mul:0' shape=(20, 8, 4, 768) dtype=float32>]]\n",
      "m_663 [[]]\n",
      "lmda_664 [[<tf.Tensor 'Const_123:0' shape=(768,) dtype=float32>, <tf.Tensor 'batch_normalization_139_1/cond/Merge:0' shape=(20, 8, 4, 768) dtype=float32>]]\n",
      "[20, 8, 4, 768]\n",
      "m_665 [[]]\n",
      "lmda_666 [[<tf.Tensor 'Const_124:0' shape=(768,) dtype=float32>, <tf.Tensor 'batch_normalization_139_2/cond/Merge:0' shape=(20, 8, 4, 768) dtype=float32>]]\n",
      "[20, 8, 4, 768]\n",
      "m_667 [[]]\n",
      "lmda_668 [[<tf.Tensor 'Const_125:0' shape=(768,) dtype=float32>, <tf.Tensor 'batch_normalization_139_3/cond/Merge:0' shape=(20, 8, 4, 768) dtype=float32>]]\n",
      "[20, 8, 4, 768]\n",
      "activation_227 [[<tf.Tensor 'lambda_173_1/Mul:0' shape=(20, 8, 4, 768) dtype=float32>], [<tf.Tensor 'lambda_174_1/Mul:0' shape=(20, 8, 4, 768) dtype=float32>], [<tf.Tensor 'lambda_175_1/Mul:0' shape=(20, 8, 4, 768) dtype=float32>]]\n",
      "l_670 [[<tf.Tensor 'activation_227_1/Relu:0' shape=(20, 8, 4, 768) dtype=float32>]]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [56320]\n",
      "6 [20, 8, 4, 8, 11]\n",
      "7 [20, 8, 4, 8, 32]\n",
      "8 [20, 8, 4, 8, 32]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [56320]\n",
      "6 [20, 8, 4, 8, 11]\n",
      "7 [20, 8, 4, 8, 32]\n",
      "8 [20, 8, 4, 8, 32]\n",
      "l_671 [[<tf.Tensor 'activation_227_2/Relu:0' shape=(20, 8, 4, 768) dtype=float32>]]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [56320]\n",
      "6 [20, 8, 4, 8, 11]\n",
      "7 [20, 8, 4, 8, 32]\n",
      "8 [20, 8, 4, 8, 32]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [56320]\n",
      "6 [20, 8, 4, 8, 11]\n",
      "7 [20, 8, 4, 8, 32]\n",
      "8 [20, 8, 4, 8, 32]\n",
      "l_672 [[<tf.Tensor 'activation_227_3/Relu:0' shape=(20, 8, 4, 768) dtype=float32>]]\n",
      "1 [108800]\n",
      "2 [20, 8, 4, 1, 170]\n",
      "3 [20, 8, 4, 1, 510]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [51200]\n",
      "6 [20, 8, 4, 8, 10]\n",
      "7 [20, 8, 4, 8, 30]\n",
      "8 [20, 8, 4, 8, 32]\n",
      "1 [108800]\n",
      "2 [20, 8, 4, 1, 170]\n",
      "3 [20, 8, 4, 1, 510]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [51200]\n",
      "6 [20, 8, 4, 8, 10]\n",
      "7 [20, 8, 4, 8, 30]\n",
      "8 [20, 8, 4, 8, 32]\n",
      "conv2d_225 [[<tf.Tensor 'lambda_176/Reshape_4:0' shape=(20, 8, 4, 768) dtype=float32>], [<tf.Tensor 'lambda_177/Reshape_4:0' shape=(20, 8, 4, 768) dtype=float32>], [<tf.Tensor 'lambda_178/Reshape_4:0' shape=(20, 8, 4, 768) dtype=float32>]]\n",
      "idx [97548, 4]\n",
      "gather [97548]\n",
      "m_674 [[]]\n",
      "lmda_675 [[<tf.Tensor 'Const_126:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_225_1/convolution:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_676 [[]]\n",
      "lmda_677 [[<tf.Tensor 'Const_127:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_225_2/convolution:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_678 [[]]\n",
      "lmda_679 [[<tf.Tensor 'Const_128:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_225_3/convolution:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "batch_normalization_140 [[<tf.Tensor 'lambda_179_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_180_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_181_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "m_681 [[]]\n",
      "lmda_682 [[<tf.Tensor 'Const_129:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_140_1/cond/Merge:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_683 [[]]\n",
      "lmda_684 [[<tf.Tensor 'Const_130:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_140_2/cond/Merge:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_685 [[]]\n",
      "lmda_686 [[<tf.Tensor 'Const_131:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_140_3/cond/Merge:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "activation_228 [[<tf.Tensor 'lambda_182_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_183_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_184_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "l_688 [[<tf.Tensor 'activation_228_1/Relu:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "l_689 [[<tf.Tensor 'activation_228_2/Relu:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "l_690 [[<tf.Tensor 'activation_228_3/Relu:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "1 [26880]\n",
      "2 [20, 8, 4, 1, 42]\n",
      "3 [20, 8, 4, 1, 126]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "1 [26880]\n",
      "2 [20, 8, 4, 1, 42]\n",
      "3 [20, 8, 4, 1, 126]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "conv2d_226 [[<tf.Tensor 'lambda_185/Reshape_1:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_186/Reshape_1:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_187/Reshape_1:0' shape=(20, 8, 4, 128) dtype=float32>]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m_692 [[]]\n",
      "lmda_693 [[<tf.Tensor 'Const_132:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_226_1/convolution:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "[20, 8, 4, 32]\n",
      "m_694 [[]]\n",
      "lmda_695 [[<tf.Tensor 'Const_133:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_226_2/convolution:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "[20, 8, 4, 32]\n",
      "m_696 [[]]\n",
      "lmda_697 [[<tf.Tensor 'Const_134:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_226_3/convolution:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "[20, 8, 4, 32]\n",
      "concatenate_109 [[<tf.Tensor 'concatenate_108_1/concat:0' shape=(20, 8, 4, 768) dtype=float32>, <tf.Tensor 'lambda_188_1/Mul:0' shape=(20, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_108_2/concat:0' shape=(20, 8, 4, 768) dtype=float32>, <tf.Tensor 'lambda_189_1/Mul:0' shape=(20, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_108_3/concat:0' shape=(20, 8, 4, 768) dtype=float32>, <tf.Tensor 'lambda_190_1/Mul:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "m_699 [[]]\n",
      "lmda_700 [[<tf.Tensor 'Const_135:0' shape=(800,) dtype=float32>, <tf.Tensor 'concatenate_109_1/concat:0' shape=(20, 8, 4, 800) dtype=float32>]]\n",
      "[20, 8, 4, 800]\n",
      "m_701 [[]]\n",
      "lmda_702 [[<tf.Tensor 'Const_136:0' shape=(800,) dtype=float32>, <tf.Tensor 'concatenate_109_2/concat:0' shape=(20, 8, 4, 800) dtype=float32>]]\n",
      "[20, 8, 4, 800]\n",
      "m_703 [[]]\n",
      "lmda_704 [[<tf.Tensor 'Const_137:0' shape=(800,) dtype=float32>, <tf.Tensor 'concatenate_109_3/concat:0' shape=(20, 8, 4, 800) dtype=float32>]]\n",
      "[20, 8, 4, 800]\n",
      "batch_normalization_141 [[<tf.Tensor 'lambda_191_1/Mul:0' shape=(20, 8, 4, 800) dtype=float32>], [<tf.Tensor 'lambda_192_1/Mul:0' shape=(20, 8, 4, 800) dtype=float32>], [<tf.Tensor 'lambda_193_1/Mul:0' shape=(20, 8, 4, 800) dtype=float32>]]\n",
      "m_706 [[]]\n",
      "lmda_707 [[<tf.Tensor 'Const_138:0' shape=(800,) dtype=float32>, <tf.Tensor 'batch_normalization_141_1/cond/Merge:0' shape=(20, 8, 4, 800) dtype=float32>]]\n",
      "[20, 8, 4, 800]\n",
      "m_708 [[]]\n",
      "lmda_709 [[<tf.Tensor 'Const_139:0' shape=(800,) dtype=float32>, <tf.Tensor 'batch_normalization_141_2/cond/Merge:0' shape=(20, 8, 4, 800) dtype=float32>]]\n",
      "[20, 8, 4, 800]\n",
      "m_710 [[]]\n",
      "lmda_711 [[<tf.Tensor 'Const_140:0' shape=(800,) dtype=float32>, <tf.Tensor 'batch_normalization_141_3/cond/Merge:0' shape=(20, 8, 4, 800) dtype=float32>]]\n",
      "[20, 8, 4, 800]\n",
      "activation_229 [[<tf.Tensor 'lambda_194_1/Mul:0' shape=(20, 8, 4, 800) dtype=float32>], [<tf.Tensor 'lambda_195_1/Mul:0' shape=(20, 8, 4, 800) dtype=float32>], [<tf.Tensor 'lambda_196_1/Mul:0' shape=(20, 8, 4, 800) dtype=float32>]]\n",
      "l_713 [[<tf.Tensor 'activation_229_1/Relu:0' shape=(20, 8, 4, 800) dtype=float32>]]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [63360]\n",
      "6 [20, 8, 4, 9, 11]\n",
      "7 [20, 8, 4, 9, 32]\n",
      "8 [20, 8, 4, 9, 32]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [63360]\n",
      "6 [20, 8, 4, 9, 11]\n",
      "7 [20, 8, 4, 9, 32]\n",
      "8 [20, 8, 4, 9, 32]\n",
      "l_714 [[<tf.Tensor 'activation_229_2/Relu:0' shape=(20, 8, 4, 800) dtype=float32>]]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [63360]\n",
      "6 [20, 8, 4, 9, 11]\n",
      "7 [20, 8, 4, 9, 32]\n",
      "8 [20, 8, 4, 9, 32]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [63360]\n",
      "6 [20, 8, 4, 9, 11]\n",
      "7 [20, 8, 4, 9, 32]\n",
      "8 [20, 8, 4, 9, 32]\n",
      "l_715 [[<tf.Tensor 'activation_229_3/Relu:0' shape=(20, 8, 4, 800) dtype=float32>]]\n",
      "1 [108800]\n",
      "2 [20, 8, 4, 1, 170]\n",
      "3 [20, 8, 4, 1, 510]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [57600]\n",
      "6 [20, 8, 4, 9, 10]\n",
      "7 [20, 8, 4, 9, 30]\n",
      "8 [20, 8, 4, 9, 32]\n",
      "1 [108800]\n",
      "2 [20, 8, 4, 1, 170]\n",
      "3 [20, 8, 4, 1, 510]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [57600]\n",
      "6 [20, 8, 4, 9, 10]\n",
      "7 [20, 8, 4, 9, 30]\n",
      "8 [20, 8, 4, 9, 32]\n",
      "conv2d_227 [[<tf.Tensor 'lambda_197/Reshape_4:0' shape=(20, 8, 4, 800) dtype=float32>], [<tf.Tensor 'lambda_198/Reshape_4:0' shape=(20, 8, 4, 800) dtype=float32>], [<tf.Tensor 'lambda_199/Reshape_4:0' shape=(20, 8, 4, 800) dtype=float32>]]\n",
      "idx [101560, 4]\n",
      "gather [101560]\n",
      "m_717 [[]]\n",
      "lmda_718 [[<tf.Tensor 'Const_141:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_227_1/convolution:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_719 [[]]\n",
      "lmda_720 [[<tf.Tensor 'Const_142:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_227_2/convolution:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_721 [[]]\n",
      "lmda_722 [[<tf.Tensor 'Const_143:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_227_3/convolution:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "batch_normalization_142 [[<tf.Tensor 'lambda_200_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_201_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_202_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "m_724 [[]]\n",
      "lmda_725 [[<tf.Tensor 'Const_144:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_142_1/cond/Merge:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_726 [[]]\n",
      "lmda_727 [[<tf.Tensor 'Const_145:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_142_2/cond/Merge:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_728 [[]]\n",
      "lmda_729 [[<tf.Tensor 'Const_146:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_142_3/cond/Merge:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "activation_230 [[<tf.Tensor 'lambda_203_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_204_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_205_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "l_731 [[<tf.Tensor 'activation_230_1/Relu:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "l_732 [[<tf.Tensor 'activation_230_2/Relu:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "l_733 [[<tf.Tensor 'activation_230_3/Relu:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "1 [26880]\n",
      "2 [20, 8, 4, 1, 42]\n",
      "3 [20, 8, 4, 1, 126]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "1 [26880]\n",
      "2 [20, 8, 4, 1, 42]\n",
      "3 [20, 8, 4, 1, 126]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "conv2d_228 [[<tf.Tensor 'lambda_206/Reshape_1:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_207/Reshape_1:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_208/Reshape_1:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "m_735 [[]]\n",
      "lmda_736 [[<tf.Tensor 'Const_147:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_228_1/convolution:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "[20, 8, 4, 32]\n",
      "m_737 [[]]\n",
      "lmda_738 [[<tf.Tensor 'Const_148:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_228_2/convolution:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "[20, 8, 4, 32]\n",
      "m_739 [[]]\n",
      "lmda_740 [[<tf.Tensor 'Const_149:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_228_3/convolution:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "[20, 8, 4, 32]\n",
      "concatenate_110 [[<tf.Tensor 'concatenate_109_1/concat:0' shape=(20, 8, 4, 800) dtype=float32>, <tf.Tensor 'lambda_209_1/Mul:0' shape=(20, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_109_2/concat:0' shape=(20, 8, 4, 800) dtype=float32>, <tf.Tensor 'lambda_210_1/Mul:0' shape=(20, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_109_3/concat:0' shape=(20, 8, 4, 800) dtype=float32>, <tf.Tensor 'lambda_211_1/Mul:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "m_742 [[]]\n",
      "lmda_743 [[<tf.Tensor 'Const_150:0' shape=(832,) dtype=float32>, <tf.Tensor 'concatenate_110_1/concat:0' shape=(20, 8, 4, 832) dtype=float32>]]\n",
      "[20, 8, 4, 832]\n",
      "m_744 [[]]\n",
      "lmda_745 [[<tf.Tensor 'Const_151:0' shape=(832,) dtype=float32>, <tf.Tensor 'concatenate_110_2/concat:0' shape=(20, 8, 4, 832) dtype=float32>]]\n",
      "[20, 8, 4, 832]\n",
      "m_746 [[]]\n",
      "lmda_747 [[<tf.Tensor 'Const_152:0' shape=(832,) dtype=float32>, <tf.Tensor 'concatenate_110_3/concat:0' shape=(20, 8, 4, 832) dtype=float32>]]\n",
      "[20, 8, 4, 832]\n",
      "batch_normalization_143 [[<tf.Tensor 'lambda_212_1/Mul:0' shape=(20, 8, 4, 832) dtype=float32>], [<tf.Tensor 'lambda_213_1/Mul:0' shape=(20, 8, 4, 832) dtype=float32>], [<tf.Tensor 'lambda_214_1/Mul:0' shape=(20, 8, 4, 832) dtype=float32>]]\n",
      "m_749 [[]]\n",
      "lmda_750 [[<tf.Tensor 'Const_153:0' shape=(832,) dtype=float32>, <tf.Tensor 'batch_normalization_143_1/cond/Merge:0' shape=(20, 8, 4, 832) dtype=float32>]]\n",
      "[20, 8, 4, 832]\n",
      "m_751 [[]]\n",
      "lmda_752 [[<tf.Tensor 'Const_154:0' shape=(832,) dtype=float32>, <tf.Tensor 'batch_normalization_143_2/cond/Merge:0' shape=(20, 8, 4, 832) dtype=float32>]]\n",
      "[20, 8, 4, 832]\n",
      "m_753 [[]]\n",
      "lmda_754 [[<tf.Tensor 'Const_155:0' shape=(832,) dtype=float32>, <tf.Tensor 'batch_normalization_143_3/cond/Merge:0' shape=(20, 8, 4, 832) dtype=float32>]]\n",
      "[20, 8, 4, 832]\n",
      "activation_231 [[<tf.Tensor 'lambda_215_1/Mul:0' shape=(20, 8, 4, 832) dtype=float32>], [<tf.Tensor 'lambda_216_1/Mul:0' shape=(20, 8, 4, 832) dtype=float32>], [<tf.Tensor 'lambda_217_1/Mul:0' shape=(20, 8, 4, 832) dtype=float32>]]\n",
      "l_756 [[<tf.Tensor 'activation_231_1/Relu:0' shape=(20, 8, 4, 832) dtype=float32>]]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [70400]\n",
      "6 [20, 8, 4, 10, 11]\n",
      "7 [20, 8, 4, 10, 32]\n",
      "8 [20, 8, 4, 10, 32]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [70400]\n",
      "6 [20, 8, 4, 10, 11]\n",
      "7 [20, 8, 4, 10, 32]\n",
      "8 [20, 8, 4, 10, 32]\n",
      "l_757 [[<tf.Tensor 'activation_231_2/Relu:0' shape=(20, 8, 4, 832) dtype=float32>]]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [70400]\n",
      "6 [20, 8, 4, 10, 11]\n",
      "7 [20, 8, 4, 10, 32]\n",
      "8 [20, 8, 4, 10, 32]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [70400]\n",
      "6 [20, 8, 4, 10, 11]\n",
      "7 [20, 8, 4, 10, 32]\n",
      "8 [20, 8, 4, 10, 32]\n",
      "l_758 [[<tf.Tensor 'activation_231_3/Relu:0' shape=(20, 8, 4, 832) dtype=float32>]]\n",
      "1 [108800]\n",
      "2 [20, 8, 4, 1, 170]\n",
      "3 [20, 8, 4, 1, 510]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [64000]\n",
      "6 [20, 8, 4, 10, 10]\n",
      "7 [20, 8, 4, 10, 30]\n",
      "8 [20, 8, 4, 10, 32]\n",
      "1 [108800]\n",
      "2 [20, 8, 4, 1, 170]\n",
      "3 [20, 8, 4, 1, 510]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [64000]\n",
      "6 [20, 8, 4, 10, 10]\n",
      "7 [20, 8, 4, 10, 30]\n",
      "8 [20, 8, 4, 10, 32]\n",
      "conv2d_229 [[<tf.Tensor 'lambda_218/Reshape_4:0' shape=(20, 8, 4, 832) dtype=float32>], [<tf.Tensor 'lambda_219/Reshape_4:0' shape=(20, 8, 4, 832) dtype=float32>], [<tf.Tensor 'lambda_220/Reshape_4:0' shape=(20, 8, 4, 832) dtype=float32>]]\n",
      "idx [105572, 4]\n",
      "gather [105572]\n",
      "m_760 [[]]\n",
      "lmda_761 [[<tf.Tensor 'Const_156:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_229_1/convolution:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_762 [[]]\n",
      "lmda_763 [[<tf.Tensor 'Const_157:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_229_2/convolution:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_764 [[]]\n",
      "lmda_765 [[<tf.Tensor 'Const_158:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_229_3/convolution:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "batch_normalization_144 [[<tf.Tensor 'lambda_221_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_222_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_223_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m_767 [[]]\n",
      "lmda_768 [[<tf.Tensor 'Const_159:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_144_1/cond/Merge:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_769 [[]]\n",
      "lmda_770 [[<tf.Tensor 'Const_160:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_144_2/cond/Merge:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_771 [[]]\n",
      "lmda_772 [[<tf.Tensor 'Const_161:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_144_3/cond/Merge:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "activation_232 [[<tf.Tensor 'lambda_224_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_225_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_226_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "l_774 [[<tf.Tensor 'activation_232_1/Relu:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "l_775 [[<tf.Tensor 'activation_232_2/Relu:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "l_776 [[<tf.Tensor 'activation_232_3/Relu:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "1 [26880]\n",
      "2 [20, 8, 4, 1, 42]\n",
      "3 [20, 8, 4, 1, 126]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "1 [26880]\n",
      "2 [20, 8, 4, 1, 42]\n",
      "3 [20, 8, 4, 1, 126]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "conv2d_230 [[<tf.Tensor 'lambda_227/Reshape_1:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_228/Reshape_1:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_229/Reshape_1:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "m_778 [[]]\n",
      "lmda_779 [[<tf.Tensor 'Const_162:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_230_1/convolution:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "[20, 8, 4, 32]\n",
      "m_780 [[]]\n",
      "lmda_781 [[<tf.Tensor 'Const_163:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_230_2/convolution:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "[20, 8, 4, 32]\n",
      "m_782 [[]]\n",
      "lmda_783 [[<tf.Tensor 'Const_164:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_230_3/convolution:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "[20, 8, 4, 32]\n",
      "concatenate_111 [[<tf.Tensor 'concatenate_110_1/concat:0' shape=(20, 8, 4, 832) dtype=float32>, <tf.Tensor 'lambda_230_1/Mul:0' shape=(20, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_110_2/concat:0' shape=(20, 8, 4, 832) dtype=float32>, <tf.Tensor 'lambda_231_1/Mul:0' shape=(20, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_110_3/concat:0' shape=(20, 8, 4, 832) dtype=float32>, <tf.Tensor 'lambda_232_1/Mul:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "m_785 [[]]\n",
      "lmda_786 [[<tf.Tensor 'Const_165:0' shape=(864,) dtype=float32>, <tf.Tensor 'concatenate_111_1/concat:0' shape=(20, 8, 4, 864) dtype=float32>]]\n",
      "[20, 8, 4, 864]\n",
      "m_787 [[]]\n",
      "lmda_788 [[<tf.Tensor 'Const_166:0' shape=(864,) dtype=float32>, <tf.Tensor 'concatenate_111_2/concat:0' shape=(20, 8, 4, 864) dtype=float32>]]\n",
      "[20, 8, 4, 864]\n",
      "m_789 [[]]\n",
      "lmda_790 [[<tf.Tensor 'Const_167:0' shape=(864,) dtype=float32>, <tf.Tensor 'concatenate_111_3/concat:0' shape=(20, 8, 4, 864) dtype=float32>]]\n",
      "[20, 8, 4, 864]\n",
      "batch_normalization_145 [[<tf.Tensor 'lambda_233_1/Mul:0' shape=(20, 8, 4, 864) dtype=float32>], [<tf.Tensor 'lambda_234_1/Mul:0' shape=(20, 8, 4, 864) dtype=float32>], [<tf.Tensor 'lambda_235_1/Mul:0' shape=(20, 8, 4, 864) dtype=float32>]]\n",
      "m_792 [[]]\n",
      "lmda_793 [[<tf.Tensor 'Const_168:0' shape=(864,) dtype=float32>, <tf.Tensor 'batch_normalization_145_1/cond/Merge:0' shape=(20, 8, 4, 864) dtype=float32>]]\n",
      "[20, 8, 4, 864]\n",
      "m_794 [[]]\n",
      "lmda_795 [[<tf.Tensor 'Const_169:0' shape=(864,) dtype=float32>, <tf.Tensor 'batch_normalization_145_2/cond/Merge:0' shape=(20, 8, 4, 864) dtype=float32>]]\n",
      "[20, 8, 4, 864]\n",
      "m_796 [[]]\n",
      "lmda_797 [[<tf.Tensor 'Const_170:0' shape=(864,) dtype=float32>, <tf.Tensor 'batch_normalization_145_3/cond/Merge:0' shape=(20, 8, 4, 864) dtype=float32>]]\n",
      "[20, 8, 4, 864]\n",
      "activation_233 [[<tf.Tensor 'lambda_236_1/Mul:0' shape=(20, 8, 4, 864) dtype=float32>], [<tf.Tensor 'lambda_237_1/Mul:0' shape=(20, 8, 4, 864) dtype=float32>], [<tf.Tensor 'lambda_238_1/Mul:0' shape=(20, 8, 4, 864) dtype=float32>]]\n",
      "l_799 [[<tf.Tensor 'activation_233_1/Relu:0' shape=(20, 8, 4, 864) dtype=float32>]]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [77440]\n",
      "6 [20, 8, 4, 11, 11]\n",
      "7 [20, 8, 4, 11, 32]\n",
      "8 [20, 8, 4, 11, 32]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [77440]\n",
      "6 [20, 8, 4, 11, 11]\n",
      "7 [20, 8, 4, 11, 32]\n",
      "8 [20, 8, 4, 11, 32]\n",
      "l_800 [[<tf.Tensor 'activation_233_2/Relu:0' shape=(20, 8, 4, 864) dtype=float32>]]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [77440]\n",
      "6 [20, 8, 4, 11, 11]\n",
      "7 [20, 8, 4, 11, 32]\n",
      "8 [20, 8, 4, 11, 32]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [77440]\n",
      "6 [20, 8, 4, 11, 11]\n",
      "7 [20, 8, 4, 11, 32]\n",
      "8 [20, 8, 4, 11, 32]\n",
      "l_801 [[<tf.Tensor 'activation_233_3/Relu:0' shape=(20, 8, 4, 864) dtype=float32>]]\n",
      "1 [108800]\n",
      "2 [20, 8, 4, 1, 170]\n",
      "3 [20, 8, 4, 1, 510]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [70400]\n",
      "6 [20, 8, 4, 11, 10]\n",
      "7 [20, 8, 4, 11, 30]\n",
      "8 [20, 8, 4, 11, 32]\n",
      "1 [108800]\n",
      "2 [20, 8, 4, 1, 170]\n",
      "3 [20, 8, 4, 1, 510]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [70400]\n",
      "6 [20, 8, 4, 11, 10]\n",
      "7 [20, 8, 4, 11, 30]\n",
      "8 [20, 8, 4, 11, 32]\n",
      "conv2d_231 [[<tf.Tensor 'lambda_239/Reshape_4:0' shape=(20, 8, 4, 864) dtype=float32>], [<tf.Tensor 'lambda_240/Reshape_4:0' shape=(20, 8, 4, 864) dtype=float32>], [<tf.Tensor 'lambda_241/Reshape_4:0' shape=(20, 8, 4, 864) dtype=float32>]]\n",
      "idx [109584, 4]\n",
      "gather [109584]\n",
      "m_803 [[]]\n",
      "lmda_804 [[<tf.Tensor 'Const_171:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_231_1/convolution:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_805 [[]]\n",
      "lmda_806 [[<tf.Tensor 'Const_172:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_231_2/convolution:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_807 [[]]\n",
      "lmda_808 [[<tf.Tensor 'Const_173:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_231_3/convolution:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "batch_normalization_146 [[<tf.Tensor 'lambda_242_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_243_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_244_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "m_810 [[]]\n",
      "lmda_811 [[<tf.Tensor 'Const_174:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_146_1/cond/Merge:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_812 [[]]\n",
      "lmda_813 [[<tf.Tensor 'Const_175:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_146_2/cond/Merge:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_814 [[]]\n",
      "lmda_815 [[<tf.Tensor 'Const_176:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_146_3/cond/Merge:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "activation_234 [[<tf.Tensor 'lambda_245_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_246_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_247_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "l_817 [[<tf.Tensor 'activation_234_1/Relu:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "l_818 [[<tf.Tensor 'activation_234_2/Relu:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "l_819 [[<tf.Tensor 'activation_234_3/Relu:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "1 [26880]\n",
      "2 [20, 8, 4, 1, 42]\n",
      "3 [20, 8, 4, 1, 126]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "1 [26880]\n",
      "2 [20, 8, 4, 1, 42]\n",
      "3 [20, 8, 4, 1, 126]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "conv2d_232 [[<tf.Tensor 'lambda_248/Reshape_1:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_249/Reshape_1:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_250/Reshape_1:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "m_821 [[]]\n",
      "lmda_822 [[<tf.Tensor 'Const_177:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_232_1/convolution:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "[20, 8, 4, 32]\n",
      "m_823 [[]]\n",
      "lmda_824 [[<tf.Tensor 'Const_178:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_232_2/convolution:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "[20, 8, 4, 32]\n",
      "m_825 [[]]\n",
      "lmda_826 [[<tf.Tensor 'Const_179:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_232_3/convolution:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "[20, 8, 4, 32]\n",
      "concatenate_112 [[<tf.Tensor 'concatenate_111_1/concat:0' shape=(20, 8, 4, 864) dtype=float32>, <tf.Tensor 'lambda_251_1/Mul:0' shape=(20, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_111_2/concat:0' shape=(20, 8, 4, 864) dtype=float32>, <tf.Tensor 'lambda_252_1/Mul:0' shape=(20, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_111_3/concat:0' shape=(20, 8, 4, 864) dtype=float32>, <tf.Tensor 'lambda_253_1/Mul:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "m_828 [[]]\n",
      "lmda_829 [[<tf.Tensor 'Const_180:0' shape=(896,) dtype=float32>, <tf.Tensor 'concatenate_112_1/concat:0' shape=(20, 8, 4, 896) dtype=float32>]]\n",
      "[20, 8, 4, 896]\n",
      "m_830 [[]]\n",
      "lmda_831 [[<tf.Tensor 'Const_181:0' shape=(896,) dtype=float32>, <tf.Tensor 'concatenate_112_2/concat:0' shape=(20, 8, 4, 896) dtype=float32>]]\n",
      "[20, 8, 4, 896]\n",
      "m_832 [[]]\n",
      "lmda_833 [[<tf.Tensor 'Const_182:0' shape=(896,) dtype=float32>, <tf.Tensor 'concatenate_112_3/concat:0' shape=(20, 8, 4, 896) dtype=float32>]]\n",
      "[20, 8, 4, 896]\n",
      "batch_normalization_147 [[<tf.Tensor 'lambda_254_1/Mul:0' shape=(20, 8, 4, 896) dtype=float32>], [<tf.Tensor 'lambda_255_1/Mul:0' shape=(20, 8, 4, 896) dtype=float32>], [<tf.Tensor 'lambda_256_1/Mul:0' shape=(20, 8, 4, 896) dtype=float32>]]\n",
      "m_835 [[]]\n",
      "lmda_836 [[<tf.Tensor 'Const_183:0' shape=(896,) dtype=float32>, <tf.Tensor 'batch_normalization_147_1/cond/Merge:0' shape=(20, 8, 4, 896) dtype=float32>]]\n",
      "[20, 8, 4, 896]\n",
      "m_837 [[]]\n",
      "lmda_838 [[<tf.Tensor 'Const_184:0' shape=(896,) dtype=float32>, <tf.Tensor 'batch_normalization_147_2/cond/Merge:0' shape=(20, 8, 4, 896) dtype=float32>]]\n",
      "[20, 8, 4, 896]\n",
      "m_839 [[]]\n",
      "lmda_840 [[<tf.Tensor 'Const_185:0' shape=(896,) dtype=float32>, <tf.Tensor 'batch_normalization_147_3/cond/Merge:0' shape=(20, 8, 4, 896) dtype=float32>]]\n",
      "[20, 8, 4, 896]\n",
      "activation_235 [[<tf.Tensor 'lambda_257_1/Mul:0' shape=(20, 8, 4, 896) dtype=float32>], [<tf.Tensor 'lambda_258_1/Mul:0' shape=(20, 8, 4, 896) dtype=float32>], [<tf.Tensor 'lambda_259_1/Mul:0' shape=(20, 8, 4, 896) dtype=float32>]]\n",
      "l_842 [[<tf.Tensor 'activation_235_1/Relu:0' shape=(20, 8, 4, 896) dtype=float32>]]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [84480]\n",
      "6 [20, 8, 4, 12, 11]\n",
      "7 [20, 8, 4, 12, 32]\n",
      "8 [20, 8, 4, 12, 32]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [84480]\n",
      "6 [20, 8, 4, 12, 11]\n",
      "7 [20, 8, 4, 12, 32]\n",
      "8 [20, 8, 4, 12, 32]\n",
      "l_843 [[<tf.Tensor 'activation_235_2/Relu:0' shape=(20, 8, 4, 896) dtype=float32>]]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [84480]\n",
      "6 [20, 8, 4, 12, 11]\n",
      "7 [20, 8, 4, 12, 32]\n",
      "8 [20, 8, 4, 12, 32]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [84480]\n",
      "6 [20, 8, 4, 12, 11]\n",
      "7 [20, 8, 4, 12, 32]\n",
      "8 [20, 8, 4, 12, 32]\n",
      "l_844 [[<tf.Tensor 'activation_235_3/Relu:0' shape=(20, 8, 4, 896) dtype=float32>]]\n",
      "1 [108800]\n",
      "2 [20, 8, 4, 1, 170]\n",
      "3 [20, 8, 4, 1, 510]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [76800]\n",
      "6 [20, 8, 4, 12, 10]\n",
      "7 [20, 8, 4, 12, 30]\n",
      "8 [20, 8, 4, 12, 32]\n",
      "1 [108800]\n",
      "2 [20, 8, 4, 1, 170]\n",
      "3 [20, 8, 4, 1, 510]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [76800]\n",
      "6 [20, 8, 4, 12, 10]\n",
      "7 [20, 8, 4, 12, 30]\n",
      "8 [20, 8, 4, 12, 32]\n",
      "conv2d_233 [[<tf.Tensor 'lambda_260/Reshape_4:0' shape=(20, 8, 4, 896) dtype=float32>], [<tf.Tensor 'lambda_261/Reshape_4:0' shape=(20, 8, 4, 896) dtype=float32>], [<tf.Tensor 'lambda_262/Reshape_4:0' shape=(20, 8, 4, 896) dtype=float32>]]\n",
      "idx [113596, 4]\n",
      "gather [113596]\n",
      "m_846 [[]]\n",
      "lmda_847 [[<tf.Tensor 'Const_186:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_233_1/convolution:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_848 [[]]\n",
      "lmda_849 [[<tf.Tensor 'Const_187:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_233_2/convolution:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_850 [[]]\n",
      "lmda_851 [[<tf.Tensor 'Const_188:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_233_3/convolution:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "batch_normalization_148 [[<tf.Tensor 'lambda_263_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_264_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_265_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "m_853 [[]]\n",
      "lmda_854 [[<tf.Tensor 'Const_189:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_148_1/cond/Merge:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_855 [[]]\n",
      "lmda_856 [[<tf.Tensor 'Const_190:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_148_2/cond/Merge:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_857 [[]]\n",
      "lmda_858 [[<tf.Tensor 'Const_191:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_148_3/cond/Merge:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "activation_236 [[<tf.Tensor 'lambda_266_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_267_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_268_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "l_860 [[<tf.Tensor 'activation_236_1/Relu:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "l_861 [[<tf.Tensor 'activation_236_2/Relu:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "l_862 [[<tf.Tensor 'activation_236_3/Relu:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "1 [26880]\n",
      "2 [20, 8, 4, 1, 42]\n",
      "3 [20, 8, 4, 1, 126]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "1 [26880]\n",
      "2 [20, 8, 4, 1, 42]\n",
      "3 [20, 8, 4, 1, 126]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "conv2d_234 [[<tf.Tensor 'lambda_269/Reshape_1:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_270/Reshape_1:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_271/Reshape_1:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "m_864 [[]]\n",
      "lmda_865 [[<tf.Tensor 'Const_192:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_234_1/convolution:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "[20, 8, 4, 32]\n",
      "m_866 [[]]\n",
      "lmda_867 [[<tf.Tensor 'Const_193:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_234_2/convolution:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "[20, 8, 4, 32]\n",
      "m_868 [[]]\n",
      "lmda_869 [[<tf.Tensor 'Const_194:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_234_3/convolution:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "[20, 8, 4, 32]\n",
      "concatenate_113 [[<tf.Tensor 'concatenate_112_1/concat:0' shape=(20, 8, 4, 896) dtype=float32>, <tf.Tensor 'lambda_272_1/Mul:0' shape=(20, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_112_2/concat:0' shape=(20, 8, 4, 896) dtype=float32>, <tf.Tensor 'lambda_273_1/Mul:0' shape=(20, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_112_3/concat:0' shape=(20, 8, 4, 896) dtype=float32>, <tf.Tensor 'lambda_274_1/Mul:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "m_871 [[]]\n",
      "lmda_872 [[<tf.Tensor 'Const_195:0' shape=(928,) dtype=float32>, <tf.Tensor 'concatenate_113_1/concat:0' shape=(20, 8, 4, 928) dtype=float32>]]\n",
      "[20, 8, 4, 928]\n",
      "m_873 [[]]\n",
      "lmda_874 [[<tf.Tensor 'Const_196:0' shape=(928,) dtype=float32>, <tf.Tensor 'concatenate_113_2/concat:0' shape=(20, 8, 4, 928) dtype=float32>]]\n",
      "[20, 8, 4, 928]\n",
      "m_875 [[]]\n",
      "lmda_876 [[<tf.Tensor 'Const_197:0' shape=(928,) dtype=float32>, <tf.Tensor 'concatenate_113_3/concat:0' shape=(20, 8, 4, 928) dtype=float32>]]\n",
      "[20, 8, 4, 928]\n",
      "batch_normalization_149 [[<tf.Tensor 'lambda_275_1/Mul:0' shape=(20, 8, 4, 928) dtype=float32>], [<tf.Tensor 'lambda_276_1/Mul:0' shape=(20, 8, 4, 928) dtype=float32>], [<tf.Tensor 'lambda_277_1/Mul:0' shape=(20, 8, 4, 928) dtype=float32>]]\n",
      "m_878 [[]]\n",
      "lmda_879 [[<tf.Tensor 'Const_198:0' shape=(928,) dtype=float32>, <tf.Tensor 'batch_normalization_149_1/cond/Merge:0' shape=(20, 8, 4, 928) dtype=float32>]]\n",
      "[20, 8, 4, 928]\n",
      "m_880 [[]]\n",
      "lmda_881 [[<tf.Tensor 'Const_199:0' shape=(928,) dtype=float32>, <tf.Tensor 'batch_normalization_149_2/cond/Merge:0' shape=(20, 8, 4, 928) dtype=float32>]]\n",
      "[20, 8, 4, 928]\n",
      "m_882 [[]]\n",
      "lmda_883 [[<tf.Tensor 'Const_200:0' shape=(928,) dtype=float32>, <tf.Tensor 'batch_normalization_149_3/cond/Merge:0' shape=(20, 8, 4, 928) dtype=float32>]]\n",
      "[20, 8, 4, 928]\n",
      "activation_237 [[<tf.Tensor 'lambda_278_1/Mul:0' shape=(20, 8, 4, 928) dtype=float32>], [<tf.Tensor 'lambda_279_1/Mul:0' shape=(20, 8, 4, 928) dtype=float32>], [<tf.Tensor 'lambda_280_1/Mul:0' shape=(20, 8, 4, 928) dtype=float32>]]\n",
      "l_885 [[<tf.Tensor 'activation_237_1/Relu:0' shape=(20, 8, 4, 928) dtype=float32>]]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [91520]\n",
      "6 [20, 8, 4, 13, 11]\n",
      "7 [20, 8, 4, 13, 32]\n",
      "8 [20, 8, 4, 13, 32]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [91520]\n",
      "6 [20, 8, 4, 13, 11]\n",
      "7 [20, 8, 4, 13, 32]\n",
      "8 [20, 8, 4, 13, 32]\n",
      "l_886 [[<tf.Tensor 'activation_237_2/Relu:0' shape=(20, 8, 4, 928) dtype=float32>]]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [91520]\n",
      "6 [20, 8, 4, 13, 11]\n",
      "7 [20, 8, 4, 13, 32]\n",
      "8 [20, 8, 4, 13, 32]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [91520]\n",
      "6 [20, 8, 4, 13, 11]\n",
      "7 [20, 8, 4, 13, 32]\n",
      "8 [20, 8, 4, 13, 32]\n",
      "l_887 [[<tf.Tensor 'activation_237_3/Relu:0' shape=(20, 8, 4, 928) dtype=float32>]]\n",
      "1 [108800]\n",
      "2 [20, 8, 4, 1, 170]\n",
      "3 [20, 8, 4, 1, 510]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [83200]\n",
      "6 [20, 8, 4, 13, 10]\n",
      "7 [20, 8, 4, 13, 30]\n",
      "8 [20, 8, 4, 13, 32]\n",
      "1 [108800]\n",
      "2 [20, 8, 4, 1, 170]\n",
      "3 [20, 8, 4, 1, 510]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [83200]\n",
      "6 [20, 8, 4, 13, 10]\n",
      "7 [20, 8, 4, 13, 30]\n",
      "8 [20, 8, 4, 13, 32]\n",
      "conv2d_235 [[<tf.Tensor 'lambda_281/Reshape_4:0' shape=(20, 8, 4, 928) dtype=float32>], [<tf.Tensor 'lambda_282/Reshape_4:0' shape=(20, 8, 4, 928) dtype=float32>], [<tf.Tensor 'lambda_283/Reshape_4:0' shape=(20, 8, 4, 928) dtype=float32>]]\n",
      "idx [117608, 4]\n",
      "gather [117608]\n",
      "m_889 [[]]\n",
      "lmda_890 [[<tf.Tensor 'Const_201:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_235_1/convolution:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_891 [[]]\n",
      "lmda_892 [[<tf.Tensor 'Const_202:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_235_2/convolution:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_893 [[]]\n",
      "lmda_894 [[<tf.Tensor 'Const_203:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_235_3/convolution:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "batch_normalization_150 [[<tf.Tensor 'lambda_284_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_285_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_286_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "m_896 [[]]\n",
      "lmda_897 [[<tf.Tensor 'Const_204:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_150_1/cond/Merge:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_898 [[]]\n",
      "lmda_899 [[<tf.Tensor 'Const_205:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_150_2/cond/Merge:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_900 [[]]\n",
      "lmda_901 [[<tf.Tensor 'Const_206:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_150_3/cond/Merge:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "activation_238 [[<tf.Tensor 'lambda_287_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_288_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_289_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "l_903 [[<tf.Tensor 'activation_238_1/Relu:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "l_904 [[<tf.Tensor 'activation_238_2/Relu:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "l_905 [[<tf.Tensor 'activation_238_3/Relu:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "1 [26880]\n",
      "2 [20, 8, 4, 1, 42]\n",
      "3 [20, 8, 4, 1, 126]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "1 [26880]\n",
      "2 [20, 8, 4, 1, 42]\n",
      "3 [20, 8, 4, 1, 126]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "conv2d_236 [[<tf.Tensor 'lambda_290/Reshape_1:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_291/Reshape_1:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_292/Reshape_1:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "m_907 [[]]\n",
      "lmda_908 [[<tf.Tensor 'Const_207:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_236_1/convolution:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "[20, 8, 4, 32]\n",
      "m_909 [[]]\n",
      "lmda_910 [[<tf.Tensor 'Const_208:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_236_2/convolution:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "[20, 8, 4, 32]\n",
      "m_911 [[]]\n",
      "lmda_912 [[<tf.Tensor 'Const_209:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_236_3/convolution:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "[20, 8, 4, 32]\n",
      "concatenate_114 [[<tf.Tensor 'concatenate_113_1/concat:0' shape=(20, 8, 4, 928) dtype=float32>, <tf.Tensor 'lambda_293_1/Mul:0' shape=(20, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_113_2/concat:0' shape=(20, 8, 4, 928) dtype=float32>, <tf.Tensor 'lambda_294_1/Mul:0' shape=(20, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_113_3/concat:0' shape=(20, 8, 4, 928) dtype=float32>, <tf.Tensor 'lambda_295_1/Mul:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "m_914 [[]]\n",
      "lmda_915 [[<tf.Tensor 'Const_210:0' shape=(960,) dtype=float32>, <tf.Tensor 'concatenate_114_1/concat:0' shape=(20, 8, 4, 960) dtype=float32>]]\n",
      "[20, 8, 4, 960]\n",
      "m_916 [[]]\n",
      "lmda_917 [[<tf.Tensor 'Const_211:0' shape=(960,) dtype=float32>, <tf.Tensor 'concatenate_114_2/concat:0' shape=(20, 8, 4, 960) dtype=float32>]]\n",
      "[20, 8, 4, 960]\n",
      "m_918 [[]]\n",
      "lmda_919 [[<tf.Tensor 'Const_212:0' shape=(960,) dtype=float32>, <tf.Tensor 'concatenate_114_3/concat:0' shape=(20, 8, 4, 960) dtype=float32>]]\n",
      "[20, 8, 4, 960]\n",
      "batch_normalization_151 [[<tf.Tensor 'lambda_296_1/Mul:0' shape=(20, 8, 4, 960) dtype=float32>], [<tf.Tensor 'lambda_297_1/Mul:0' shape=(20, 8, 4, 960) dtype=float32>], [<tf.Tensor 'lambda_298_1/Mul:0' shape=(20, 8, 4, 960) dtype=float32>]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m_921 [[]]\n",
      "lmda_922 [[<tf.Tensor 'Const_213:0' shape=(960,) dtype=float32>, <tf.Tensor 'batch_normalization_151_1/cond/Merge:0' shape=(20, 8, 4, 960) dtype=float32>]]\n",
      "[20, 8, 4, 960]\n",
      "m_923 [[]]\n",
      "lmda_924 [[<tf.Tensor 'Const_214:0' shape=(960,) dtype=float32>, <tf.Tensor 'batch_normalization_151_2/cond/Merge:0' shape=(20, 8, 4, 960) dtype=float32>]]\n",
      "[20, 8, 4, 960]\n",
      "m_925 [[]]\n",
      "lmda_926 [[<tf.Tensor 'Const_215:0' shape=(960,) dtype=float32>, <tf.Tensor 'batch_normalization_151_3/cond/Merge:0' shape=(20, 8, 4, 960) dtype=float32>]]\n",
      "[20, 8, 4, 960]\n",
      "activation_239 [[<tf.Tensor 'lambda_299_1/Mul:0' shape=(20, 8, 4, 960) dtype=float32>], [<tf.Tensor 'lambda_300_1/Mul:0' shape=(20, 8, 4, 960) dtype=float32>], [<tf.Tensor 'lambda_301_1/Mul:0' shape=(20, 8, 4, 960) dtype=float32>]]\n",
      "l_928 [[<tf.Tensor 'activation_239_1/Relu:0' shape=(20, 8, 4, 960) dtype=float32>]]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [98560]\n",
      "6 [20, 8, 4, 14, 11]\n",
      "7 [20, 8, 4, 14, 32]\n",
      "8 [20, 8, 4, 14, 32]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [98560]\n",
      "6 [20, 8, 4, 14, 11]\n",
      "7 [20, 8, 4, 14, 32]\n",
      "8 [20, 8, 4, 14, 32]\n",
      "l_929 [[<tf.Tensor 'activation_239_2/Relu:0' shape=(20, 8, 4, 960) dtype=float32>]]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [98560]\n",
      "6 [20, 8, 4, 14, 11]\n",
      "7 [20, 8, 4, 14, 32]\n",
      "8 [20, 8, 4, 14, 32]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [98560]\n",
      "6 [20, 8, 4, 14, 11]\n",
      "7 [20, 8, 4, 14, 32]\n",
      "8 [20, 8, 4, 14, 32]\n",
      "l_930 [[<tf.Tensor 'activation_239_3/Relu:0' shape=(20, 8, 4, 960) dtype=float32>]]\n",
      "1 [108800]\n",
      "2 [20, 8, 4, 1, 170]\n",
      "3 [20, 8, 4, 1, 510]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [89600]\n",
      "6 [20, 8, 4, 14, 10]\n",
      "7 [20, 8, 4, 14, 30]\n",
      "8 [20, 8, 4, 14, 32]\n",
      "1 [108800]\n",
      "2 [20, 8, 4, 1, 170]\n",
      "3 [20, 8, 4, 1, 510]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [89600]\n",
      "6 [20, 8, 4, 14, 10]\n",
      "7 [20, 8, 4, 14, 30]\n",
      "8 [20, 8, 4, 14, 32]\n",
      "conv2d_237 [[<tf.Tensor 'lambda_302/Reshape_4:0' shape=(20, 8, 4, 960) dtype=float32>], [<tf.Tensor 'lambda_303/Reshape_4:0' shape=(20, 8, 4, 960) dtype=float32>], [<tf.Tensor 'lambda_304/Reshape_4:0' shape=(20, 8, 4, 960) dtype=float32>]]\n",
      "idx [121620, 4]\n",
      "gather [121620]\n",
      "m_932 [[]]\n",
      "lmda_933 [[<tf.Tensor 'Const_216:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_237_1/convolution:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_934 [[]]\n",
      "lmda_935 [[<tf.Tensor 'Const_217:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_237_2/convolution:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_936 [[]]\n",
      "lmda_937 [[<tf.Tensor 'Const_218:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_237_3/convolution:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "batch_normalization_152 [[<tf.Tensor 'lambda_305_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_306_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_307_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "m_939 [[]]\n",
      "lmda_940 [[<tf.Tensor 'Const_219:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_152_1/cond/Merge:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_941 [[]]\n",
      "lmda_942 [[<tf.Tensor 'Const_220:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_152_2/cond/Merge:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_943 [[]]\n",
      "lmda_944 [[<tf.Tensor 'Const_221:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_152_3/cond/Merge:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "activation_240 [[<tf.Tensor 'lambda_308_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_309_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_310_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "l_946 [[<tf.Tensor 'activation_240_1/Relu:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "l_947 [[<tf.Tensor 'activation_240_2/Relu:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "l_948 [[<tf.Tensor 'activation_240_3/Relu:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "1 [26880]\n",
      "2 [20, 8, 4, 1, 42]\n",
      "3 [20, 8, 4, 1, 126]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "1 [26880]\n",
      "2 [20, 8, 4, 1, 42]\n",
      "3 [20, 8, 4, 1, 126]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "conv2d_238 [[<tf.Tensor 'lambda_311/Reshape_1:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_312/Reshape_1:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_313/Reshape_1:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "m_950 [[]]\n",
      "lmda_951 [[<tf.Tensor 'Const_222:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_238_1/convolution:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "[20, 8, 4, 32]\n",
      "m_952 [[]]\n",
      "lmda_953 [[<tf.Tensor 'Const_223:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_238_2/convolution:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "[20, 8, 4, 32]\n",
      "m_954 [[]]\n",
      "lmda_955 [[<tf.Tensor 'Const_224:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_238_3/convolution:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "[20, 8, 4, 32]\n",
      "concatenate_115 [[<tf.Tensor 'concatenate_114_1/concat:0' shape=(20, 8, 4, 960) dtype=float32>, <tf.Tensor 'lambda_314_1/Mul:0' shape=(20, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_114_2/concat:0' shape=(20, 8, 4, 960) dtype=float32>, <tf.Tensor 'lambda_315_1/Mul:0' shape=(20, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_114_3/concat:0' shape=(20, 8, 4, 960) dtype=float32>, <tf.Tensor 'lambda_316_1/Mul:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "m_957 [[]]\n",
      "lmda_958 [[<tf.Tensor 'Const_225:0' shape=(992,) dtype=float32>, <tf.Tensor 'concatenate_115_1/concat:0' shape=(20, 8, 4, 992) dtype=float32>]]\n",
      "[20, 8, 4, 992]\n",
      "m_959 [[]]\n",
      "lmda_960 [[<tf.Tensor 'Const_226:0' shape=(992,) dtype=float32>, <tf.Tensor 'concatenate_115_2/concat:0' shape=(20, 8, 4, 992) dtype=float32>]]\n",
      "[20, 8, 4, 992]\n",
      "m_961 [[]]\n",
      "lmda_962 [[<tf.Tensor 'Const_227:0' shape=(992,) dtype=float32>, <tf.Tensor 'concatenate_115_3/concat:0' shape=(20, 8, 4, 992) dtype=float32>]]\n",
      "[20, 8, 4, 992]\n",
      "batch_normalization_153 [[<tf.Tensor 'lambda_317_1/Mul:0' shape=(20, 8, 4, 992) dtype=float32>], [<tf.Tensor 'lambda_318_1/Mul:0' shape=(20, 8, 4, 992) dtype=float32>], [<tf.Tensor 'lambda_319_1/Mul:0' shape=(20, 8, 4, 992) dtype=float32>]]\n",
      "m_964 [[]]\n",
      "lmda_965 [[<tf.Tensor 'Const_228:0' shape=(992,) dtype=float32>, <tf.Tensor 'batch_normalization_153_1/cond/Merge:0' shape=(20, 8, 4, 992) dtype=float32>]]\n",
      "[20, 8, 4, 992]\n",
      "m_966 [[]]\n",
      "lmda_967 [[<tf.Tensor 'Const_229:0' shape=(992,) dtype=float32>, <tf.Tensor 'batch_normalization_153_2/cond/Merge:0' shape=(20, 8, 4, 992) dtype=float32>]]\n",
      "[20, 8, 4, 992]\n",
      "m_968 [[]]\n",
      "lmda_969 [[<tf.Tensor 'Const_230:0' shape=(992,) dtype=float32>, <tf.Tensor 'batch_normalization_153_3/cond/Merge:0' shape=(20, 8, 4, 992) dtype=float32>]]\n",
      "[20, 8, 4, 992]\n",
      "activation_241 [[<tf.Tensor 'lambda_320_1/Mul:0' shape=(20, 8, 4, 992) dtype=float32>], [<tf.Tensor 'lambda_321_1/Mul:0' shape=(20, 8, 4, 992) dtype=float32>], [<tf.Tensor 'lambda_322_1/Mul:0' shape=(20, 8, 4, 992) dtype=float32>]]\n",
      "l_971 [[<tf.Tensor 'activation_241_1/Relu:0' shape=(20, 8, 4, 992) dtype=float32>]]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [105600]\n",
      "6 [20, 8, 4, 15, 11]\n",
      "7 [20, 8, 4, 15, 32]\n",
      "8 [20, 8, 4, 15, 32]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [105600]\n",
      "6 [20, 8, 4, 15, 11]\n",
      "7 [20, 8, 4, 15, 32]\n",
      "8 [20, 8, 4, 15, 32]\n",
      "l_972 [[<tf.Tensor 'activation_241_2/Relu:0' shape=(20, 8, 4, 992) dtype=float32>]]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [105600]\n",
      "6 [20, 8, 4, 15, 11]\n",
      "7 [20, 8, 4, 15, 32]\n",
      "8 [20, 8, 4, 15, 32]\n",
      "1 [109440]\n",
      "2 [20, 8, 4, 1, 171]\n",
      "3 [20, 8, 4, 1, 512]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [105600]\n",
      "6 [20, 8, 4, 15, 11]\n",
      "7 [20, 8, 4, 15, 32]\n",
      "8 [20, 8, 4, 15, 32]\n",
      "l_973 [[<tf.Tensor 'activation_241_3/Relu:0' shape=(20, 8, 4, 992) dtype=float32>]]\n",
      "1 [108800]\n",
      "2 [20, 8, 4, 1, 170]\n",
      "3 [20, 8, 4, 1, 510]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [96000]\n",
      "6 [20, 8, 4, 15, 10]\n",
      "7 [20, 8, 4, 15, 30]\n",
      "8 [20, 8, 4, 15, 32]\n",
      "1 [108800]\n",
      "2 [20, 8, 4, 1, 170]\n",
      "3 [20, 8, 4, 1, 510]\n",
      "4 [20, 8, 4, 1, 512]\n",
      "5 [96000]\n",
      "6 [20, 8, 4, 15, 10]\n",
      "7 [20, 8, 4, 15, 30]\n",
      "8 [20, 8, 4, 15, 32]\n",
      "conv2d_239 [[<tf.Tensor 'lambda_323/Reshape_4:0' shape=(20, 8, 4, 992) dtype=float32>], [<tf.Tensor 'lambda_324/Reshape_4:0' shape=(20, 8, 4, 992) dtype=float32>], [<tf.Tensor 'lambda_325/Reshape_4:0' shape=(20, 8, 4, 992) dtype=float32>]]\n",
      "idx [125632, 4]\n",
      "gather [125632]\n",
      "m_975 [[]]\n",
      "lmda_976 [[<tf.Tensor 'Const_231:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_239_1/convolution:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_977 [[]]\n",
      "lmda_978 [[<tf.Tensor 'Const_232:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_239_2/convolution:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_979 [[]]\n",
      "lmda_980 [[<tf.Tensor 'Const_233:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_239_3/convolution:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "batch_normalization_154 [[<tf.Tensor 'lambda_326_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_327_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_328_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "m_982 [[]]\n",
      "lmda_983 [[<tf.Tensor 'Const_234:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_154_1/cond/Merge:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_984 [[]]\n",
      "lmda_985 [[<tf.Tensor 'Const_235:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_154_2/cond/Merge:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "m_986 [[]]\n",
      "lmda_987 [[<tf.Tensor 'Const_236:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_154_3/cond/Merge:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "[20, 8, 4, 128]\n",
      "activation_242 [[<tf.Tensor 'lambda_329_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_330_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_331_1/Mul:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "l_989 [[<tf.Tensor 'activation_242_1/Relu:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "l_990 [[<tf.Tensor 'activation_242_2/Relu:0' shape=(20, 8, 4, 128) dtype=float32>]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "1 [27520]\n",
      "2 [20, 8, 4, 1, 43]\n",
      "3 [20, 8, 4, 1, 128]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "l_991 [[<tf.Tensor 'activation_242_3/Relu:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "1 [26880]\n",
      "2 [20, 8, 4, 1, 42]\n",
      "3 [20, 8, 4, 1, 126]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "1 [26880]\n",
      "2 [20, 8, 4, 1, 42]\n",
      "3 [20, 8, 4, 1, 126]\n",
      "4 [20, 8, 4, 1, 128]\n",
      "conv2d_240 [[<tf.Tensor 'lambda_332/Reshape_1:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_333/Reshape_1:0' shape=(20, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_334/Reshape_1:0' shape=(20, 8, 4, 128) dtype=float32>]]\n",
      "m_993 [[]]\n",
      "lmda_994 [[<tf.Tensor 'Const_237:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_240_1/convolution:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "[20, 8, 4, 32]\n",
      "m_995 [[]]\n",
      "lmda_996 [[<tf.Tensor 'Const_238:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_240_2/convolution:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "[20, 8, 4, 32]\n",
      "m_997 [[]]\n",
      "lmda_998 [[<tf.Tensor 'Const_239:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_240_3/convolution:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "[20, 8, 4, 32]\n",
      "concatenate_116 [[<tf.Tensor 'concatenate_115_1/concat:0' shape=(20, 8, 4, 992) dtype=float32>, <tf.Tensor 'lambda_335_1/Mul:0' shape=(20, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_115_2/concat:0' shape=(20, 8, 4, 992) dtype=float32>, <tf.Tensor 'lambda_336_1/Mul:0' shape=(20, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_115_3/concat:0' shape=(20, 8, 4, 992) dtype=float32>, <tf.Tensor 'lambda_337_1/Mul:0' shape=(20, 8, 4, 32) dtype=float32>]]\n",
      "m_1000 [[]]\n",
      "lmda_1001 [[<tf.Tensor 'Const_240:0' shape=(1024,) dtype=float32>, <tf.Tensor 'concatenate_116_1/concat:0' shape=(20, 8, 4, 1024) dtype=float32>]]\n",
      "[20, 8, 4, 1024]\n",
      "m_1002 [[]]\n",
      "lmda_1003 [[<tf.Tensor 'Const_241:0' shape=(1024,) dtype=float32>, <tf.Tensor 'concatenate_116_2/concat:0' shape=(20, 8, 4, 1024) dtype=float32>]]\n",
      "[20, 8, 4, 1024]\n",
      "m_1004 [[]]\n",
      "lmda_1005 [[<tf.Tensor 'Const_242:0' shape=(1024,) dtype=float32>, <tf.Tensor 'concatenate_116_3/concat:0' shape=(20, 8, 4, 1024) dtype=float32>]]\n",
      "[20, 8, 4, 1024]\n",
      "batch_normalization_155 [[<tf.Tensor 'lambda_338_1/Mul:0' shape=(20, 8, 4, 1024) dtype=float32>], [<tf.Tensor 'lambda_339_1/Mul:0' shape=(20, 8, 4, 1024) dtype=float32>], [<tf.Tensor 'lambda_340_1/Mul:0' shape=(20, 8, 4, 1024) dtype=float32>]]\n",
      "m_1007 [[]]\n",
      "lmda_1008 [[<tf.Tensor 'Const_243:0' shape=(1024,) dtype=float32>, <tf.Tensor 'batch_normalization_155_1/cond/Merge:0' shape=(20, 8, 4, 1024) dtype=float32>]]\n",
      "[20, 8, 4, 1024]\n",
      "m_1009 [[]]\n",
      "lmda_1010 [[<tf.Tensor 'Const_244:0' shape=(1024,) dtype=float32>, <tf.Tensor 'batch_normalization_155_2/cond/Merge:0' shape=(20, 8, 4, 1024) dtype=float32>]]\n",
      "[20, 8, 4, 1024]\n",
      "m_1011 [[]]\n",
      "lmda_1012 [[<tf.Tensor 'Const_245:0' shape=(1024,) dtype=float32>, <tf.Tensor 'batch_normalization_155_3/cond/Merge:0' shape=(20, 8, 4, 1024) dtype=float32>]]\n",
      "[20, 8, 4, 1024]\n",
      "activation_243 [[<tf.Tensor 'lambda_341_1/Mul:0' shape=(20, 8, 4, 1024) dtype=float32>], [<tf.Tensor 'lambda_342_1/Mul:0' shape=(20, 8, 4, 1024) dtype=float32>], [<tf.Tensor 'lambda_343_1/Mul:0' shape=(20, 8, 4, 1024) dtype=float32>]]\n",
      "m_1014 [[]]\n",
      "lmda_1015 [[<tf.Tensor 'Const_246:0' shape=(1024,) dtype=float32>, <tf.Tensor 'activation_243_1/Relu:0' shape=(20, 8, 4, 1024) dtype=float32>]]\n",
      "[20, 8, 4, 1024]\n",
      "m_1016 [[]]\n",
      "lmda_1017 [[<tf.Tensor 'Const_247:0' shape=(1024,) dtype=float32>, <tf.Tensor 'activation_243_2/Relu:0' shape=(20, 8, 4, 1024) dtype=float32>]]\n",
      "[20, 8, 4, 1024]\n",
      "m_1018 [[]]\n",
      "lmda_1019 [[<tf.Tensor 'Const_248:0' shape=(1024,) dtype=float32>, <tf.Tensor 'activation_243_3/Relu:0' shape=(20, 8, 4, 1024) dtype=float32>]]\n",
      "[20, 8, 4, 1024]\n",
      "global_average_pooling2d_2 [[<tf.Tensor 'lambda_344_1/Mul:0' shape=(20, 8, 4, 1024) dtype=float32>], [<tf.Tensor 'lambda_345_1/Mul:0' shape=(20, 8, 4, 1024) dtype=float32>], [<tf.Tensor 'lambda_346_1/Mul:0' shape=(20, 8, 4, 1024) dtype=float32>]]\n",
      "l_1021 [[<tf.Tensor 'global_average_pooling2d_2_1/Mean:0' shape=(20, 1024) dtype=float32>]]\n",
      "1 [3420]\n",
      "2 [20, 1, 171]\n",
      "3 [20, 1, 512]\n",
      "4 [20, 1, 512]\n",
      "5 [3520]\n",
      "6 [20, 16, 11]\n",
      "7 [20, 16, 32]\n",
      "8 [20, 16, 32]\n",
      "1 [3420]\n",
      "2 [20, 1, 171]\n",
      "3 [20, 1, 512]\n",
      "4 [20, 1, 512]\n",
      "5 [3520]\n",
      "6 [20, 16, 11]\n",
      "7 [20, 16, 32]\n",
      "8 [20, 16, 32]\n",
      "l_1022 [[<tf.Tensor 'global_average_pooling2d_2_2/Mean:0' shape=(20, 1024) dtype=float32>]]\n",
      "1 [3420]\n",
      "2 [20, 1, 171]\n",
      "3 [20, 1, 512]\n",
      "4 [20, 1, 512]\n",
      "5 [3520]\n",
      "6 [20, 16, 11]\n",
      "7 [20, 16, 32]\n",
      "8 [20, 16, 32]\n",
      "1 [3420]\n",
      "2 [20, 1, 171]\n",
      "3 [20, 1, 512]\n",
      "4 [20, 1, 512]\n",
      "5 [3520]\n",
      "6 [20, 16, 11]\n",
      "7 [20, 16, 32]\n",
      "8 [20, 16, 32]\n",
      "l_1023 [[<tf.Tensor 'global_average_pooling2d_2_3/Mean:0' shape=(20, 1024) dtype=float32>]]\n",
      "1 [3400]\n",
      "2 [20, 1, 170]\n",
      "3 [20, 1, 510]\n",
      "4 [20, 1, 512]\n",
      "5 [3200]\n",
      "6 [20, 16, 10]\n",
      "7 [20, 16, 30]\n",
      "8 [20, 16, 32]\n",
      "1 [3400]\n",
      "2 [20, 1, 170]\n",
      "3 [20, 1, 510]\n",
      "4 [20, 1, 512]\n",
      "5 [3200]\n",
      "6 [20, 16, 10]\n",
      "7 [20, 16, 30]\n",
      "8 [20, 16, 32]\n",
      "dense_3 [[<tf.Tensor 'lambda_347/Reshape_4:0' shape=(20, 1024) dtype=float32>], [<tf.Tensor 'lambda_348/Reshape_4:0' shape=(20, 1024) dtype=float32>], [<tf.Tensor 'lambda_349/Reshape_4:0' shape=(20, 1024) dtype=float32>]]\n",
      "m_1025 [[]]\n",
      "lmda_1026 [[<tf.Tensor 'Const_249:0' shape=(1024,) dtype=float32>, <tf.Tensor 'dense_3_1/BiasAdd:0' shape=(20, 1024) dtype=float32>]]\n",
      "[20, 1024]\n",
      "m_1027 [[]]\n",
      "lmda_1028 [[<tf.Tensor 'Const_250:0' shape=(1024,) dtype=float32>, <tf.Tensor 'dense_3_2/BiasAdd:0' shape=(20, 1024) dtype=float32>]]\n",
      "[20, 1024]\n",
      "m_1029 [[]]\n",
      "lmda_1030 [[<tf.Tensor 'Const_251:0' shape=(1024,) dtype=float32>, <tf.Tensor 'dense_3_3/BiasAdd:0' shape=(20, 1024) dtype=float32>]]\n",
      "[20, 1024]\n",
      "batch_normalization_156 [[<tf.Tensor 'lambda_350_1/Mul:0' shape=(20, 1024) dtype=float32>], [<tf.Tensor 'lambda_351_1/Mul:0' shape=(20, 1024) dtype=float32>], [<tf.Tensor 'lambda_352_1/Mul:0' shape=(20, 1024) dtype=float32>]]\n",
      "m_1032 [[]]\n",
      "lmda_1033 [[<tf.Tensor 'Const_252:0' shape=(1024,) dtype=float32>, <tf.Tensor 'batch_normalization_156_1/cond/Merge:0' shape=(20, 1024) dtype=float32>]]\n",
      "[20, 1024]\n",
      "m_1034 [[]]\n",
      "lmda_1035 [[<tf.Tensor 'Const_253:0' shape=(1024,) dtype=float32>, <tf.Tensor 'batch_normalization_156_2/cond/Merge:0' shape=(20, 1024) dtype=float32>]]\n",
      "[20, 1024]\n",
      "m_1036 [[]]\n",
      "lmda_1037 [[<tf.Tensor 'Const_254:0' shape=(1024,) dtype=float32>, <tf.Tensor 'batch_normalization_156_3/cond/Merge:0' shape=(20, 1024) dtype=float32>]]\n",
      "[20, 1024]\n",
      "activation_244 [[<tf.Tensor 'lambda_353_1/Mul:0' shape=(20, 1024) dtype=float32>], [<tf.Tensor 'lambda_354_1/Mul:0' shape=(20, 1024) dtype=float32>], [<tf.Tensor 'lambda_355_1/Mul:0' shape=(20, 1024) dtype=float32>]]\n",
      "l_1039 [[<tf.Tensor 'activation_244_1/Relu:0' shape=(20, 1024) dtype=float32>]]\n",
      "1 [6820]\n",
      "2 [20, 1, 341]\n",
      "3 [20, 1, 1023]\n",
      "4 [20, 1, 1024]\n",
      "1 [6820]\n",
      "2 [20, 1, 341]\n",
      "3 [20, 1, 1023]\n",
      "4 [20, 1, 1024]\n",
      "l_1040 [[<tf.Tensor 'activation_244_2/Relu:0' shape=(20, 1024) dtype=float32>]]\n",
      "1 [6820]\n",
      "2 [20, 1, 341]\n",
      "3 [20, 1, 1023]\n",
      "4 [20, 1, 1024]\n",
      "1 [6820]\n",
      "2 [20, 1, 341]\n",
      "3 [20, 1, 1023]\n",
      "4 [20, 1, 1024]\n",
      "l_1041 [[<tf.Tensor 'activation_244_3/Relu:0' shape=(20, 1024) dtype=float32>]]\n",
      "1 [6840]\n",
      "2 [20, 1, 342]\n",
      "3 [20, 1, 1024]\n",
      "4 [20, 1, 1024]\n",
      "1 [6840]\n",
      "2 [20, 1, 342]\n",
      "3 [20, 1, 1024]\n",
      "4 [20, 1, 1024]\n",
      "dense_4 [[<tf.Tensor 'lambda_356/Reshape_1:0' shape=(20, 1024) dtype=float32>], [<tf.Tensor 'lambda_357/Reshape_1:0' shape=(20, 1024) dtype=float32>], [<tf.Tensor 'lambda_358/Reshape_1:0' shape=(20, 1024) dtype=float32>]]\n",
      "ip_1043 [[]]\n",
      "ip_1044 [[]]\n",
      "l_1045 [[<tf.Tensor 'Const_255:0' shape=(2560, 2) dtype=int32>, <tf.Tensor 'Const_256:0' shape=(1,) dtype=float32>, <tf.Tensor 'dense_4_1/BiasAdd:0' shape=(20, 384) dtype=float32>]]\n",
      "[None, None]\n",
      "ip_1046 [[]]\n",
      "ip_1047 [[]]\n",
      "l_1048 [[<tf.Tensor 'Const_257:0' shape=(2560, 2) dtype=int32>, <tf.Tensor 'Const_258:0' shape=(1,) dtype=float32>, <tf.Tensor 'dense_4_2/BiasAdd:0' shape=(20, 384) dtype=float32>]]\n",
      "[None, None]\n",
      "ip_1049 [[]]\n",
      "ip_1050 [[]]\n",
      "l_1051 [[<tf.Tensor 'Const_259:0' shape=(2560, 2) dtype=int32>, <tf.Tensor 'Const_260:0' shape=(1,) dtype=float32>, <tf.Tensor 'dense_4_3/BiasAdd:0' shape=(20, 384) dtype=float32>]]\n",
      "[None, None]\n",
      "[<tf.Tensor 'lambda_359_1/Reshape:0' shape=(?, ?) dtype=float32>, <tf.Tensor 'lambda_360_1/Reshape:0' shape=(?, ?) dtype=float32>, <tf.Tensor 'lambda_361_1/Reshape:0' shape=(?, ?) dtype=float32>]\n",
      "0.2\n",
      "[0, 128, 256, 384]\n",
      "(20, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 128)\n",
      "(20, 128)\n"
     ]
    }
   ],
   "source": [
    "model, base, _ = models.DenseNetDrop(P_param=P_param, K_param=K_param,\n",
    "                                    weights='imagenet', diagnostic=True, \n",
    "                                  blocks=4, tile=True)\n",
    "\n",
    "# model, _, _ = models_bk2.DenseNet121Drop(P_param=P_param, K_param=K_param,\n",
    "#                                     weights='imagenet', diagnostic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_3\n",
      "1 conv2d_241\n",
      "2 batch_normalization_245\n",
      "3 activation_245\n",
      "4 max_pooling2d_3\n",
      "5 batch_normalization_246\n",
      "6 activation_246\n",
      "7 conv2d_242\n",
      "8 batch_normalization_247\n",
      "9 activation_247\n",
      "10 conv2d_243\n",
      "11 concatenate_117\n",
      "12 batch_normalization_248\n",
      "13 activation_248\n",
      "14 conv2d_244\n",
      "15 batch_normalization_249\n",
      "16 activation_249\n",
      "17 conv2d_245\n",
      "18 concatenate_118\n",
      "19 batch_normalization_250\n",
      "20 activation_250\n",
      "21 conv2d_246\n",
      "22 batch_normalization_251\n",
      "23 activation_251\n",
      "24 conv2d_247\n",
      "25 concatenate_119\n",
      "26 batch_normalization_252\n",
      "27 activation_252\n",
      "28 conv2d_248\n",
      "29 batch_normalization_253\n",
      "30 activation_253\n",
      "31 conv2d_249\n",
      "32 concatenate_120\n",
      "33 batch_normalization_254\n",
      "34 activation_254\n",
      "35 conv2d_250\n",
      "36 batch_normalization_255\n",
      "37 activation_255\n",
      "38 conv2d_251\n",
      "39 concatenate_121\n",
      "40 batch_normalization_256\n",
      "41 activation_256\n",
      "42 conv2d_252\n",
      "43 batch_normalization_257\n",
      "44 activation_257\n",
      "45 conv2d_253\n",
      "46 concatenate_122\n",
      "47 batch_normalization_258\n",
      "48 activation_258\n",
      "49 conv2d_254\n",
      "50 average_pooling2d_7\n",
      "51 batch_normalization_259\n",
      "52 activation_259\n",
      "53 conv2d_255\n",
      "54 batch_normalization_260\n",
      "55 activation_260\n",
      "56 conv2d_256\n",
      "57 concatenate_123\n",
      "58 batch_normalization_261\n",
      "59 activation_261\n",
      "60 conv2d_257\n",
      "61 batch_normalization_262\n",
      "62 activation_262\n",
      "63 conv2d_258\n",
      "64 concatenate_124\n",
      "65 batch_normalization_263\n",
      "66 activation_263\n",
      "67 conv2d_259\n",
      "68 batch_normalization_264\n",
      "69 activation_264\n",
      "70 conv2d_260\n",
      "71 concatenate_125\n",
      "72 batch_normalization_265\n",
      "73 activation_265\n",
      "74 conv2d_261\n",
      "75 batch_normalization_266\n",
      "76 activation_266\n",
      "77 conv2d_262\n",
      "78 concatenate_126\n",
      "79 batch_normalization_267\n",
      "80 activation_267\n",
      "81 conv2d_263\n",
      "82 batch_normalization_268\n",
      "83 activation_268\n",
      "84 conv2d_264\n",
      "85 concatenate_127\n",
      "86 batch_normalization_269\n",
      "87 activation_269\n",
      "88 conv2d_265\n",
      "89 batch_normalization_270\n",
      "90 activation_270\n",
      "91 conv2d_266\n",
      "92 concatenate_128\n",
      "93 batch_normalization_271\n",
      "94 activation_271\n",
      "95 conv2d_267\n",
      "96 batch_normalization_272\n",
      "97 activation_272\n",
      "98 conv2d_268\n",
      "99 concatenate_129\n",
      "100 batch_normalization_273\n",
      "101 activation_273\n",
      "102 conv2d_269\n",
      "103 batch_normalization_274\n",
      "104 activation_274\n",
      "105 conv2d_270\n",
      "106 concatenate_130\n",
      "107 batch_normalization_275\n",
      "108 activation_275\n",
      "109 conv2d_271\n",
      "110 batch_normalization_276\n",
      "111 activation_276\n",
      "112 conv2d_272\n",
      "113 concatenate_131\n",
      "114 batch_normalization_277\n",
      "115 activation_277\n",
      "116 conv2d_273\n",
      "117 batch_normalization_278\n",
      "118 activation_278\n",
      "119 conv2d_274\n",
      "120 concatenate_132\n",
      "121 batch_normalization_279\n",
      "122 activation_279\n",
      "123 conv2d_275\n",
      "124 batch_normalization_280\n",
      "125 activation_280\n",
      "126 conv2d_276\n",
      "127 concatenate_133\n",
      "128 batch_normalization_281\n",
      "129 activation_281\n",
      "130 conv2d_277\n",
      "131 batch_normalization_282\n",
      "132 activation_282\n",
      "133 conv2d_278\n",
      "134 concatenate_134\n",
      "135 batch_normalization_283\n",
      "136 activation_283\n",
      "137 conv2d_279\n",
      "138 average_pooling2d_8\n",
      "139 batch_normalization_284\n",
      "140 activation_284\n",
      "141 conv2d_280\n",
      "142 batch_normalization_285\n",
      "143 activation_285\n",
      "144 conv2d_281\n",
      "145 concatenate_135\n",
      "146 batch_normalization_286\n",
      "147 activation_286\n",
      "148 conv2d_282\n",
      "149 batch_normalization_287\n",
      "150 activation_287\n",
      "151 conv2d_283\n",
      "152 concatenate_136\n",
      "153 batch_normalization_288\n",
      "154 activation_288\n",
      "155 conv2d_284\n",
      "156 batch_normalization_289\n",
      "157 activation_289\n",
      "158 conv2d_285\n",
      "159 concatenate_137\n",
      "160 batch_normalization_290\n",
      "161 activation_290\n",
      "162 conv2d_286\n",
      "163 batch_normalization_291\n",
      "164 activation_291\n",
      "165 conv2d_287\n",
      "166 concatenate_138\n",
      "167 batch_normalization_292\n",
      "168 activation_292\n",
      "169 conv2d_288\n",
      "170 batch_normalization_293\n",
      "171 activation_293\n",
      "172 conv2d_289\n",
      "173 concatenate_139\n",
      "174 batch_normalization_294\n",
      "175 activation_294\n",
      "176 conv2d_290\n",
      "177 batch_normalization_295\n",
      "178 activation_295\n",
      "179 conv2d_291\n",
      "180 concatenate_140\n",
      "181 batch_normalization_296\n",
      "182 activation_296\n",
      "183 conv2d_292\n",
      "184 batch_normalization_297\n",
      "185 activation_297\n",
      "186 conv2d_293\n",
      "187 concatenate_141\n",
      "188 batch_normalization_298\n",
      "189 activation_298\n",
      "190 conv2d_294\n",
      "191 batch_normalization_299\n",
      "192 activation_299\n",
      "193 conv2d_295\n",
      "194 concatenate_142\n",
      "195 batch_normalization_300\n",
      "196 activation_300\n",
      "197 conv2d_296\n",
      "198 batch_normalization_301\n",
      "199 activation_301\n",
      "200 conv2d_297\n",
      "201 concatenate_143\n",
      "202 batch_normalization_302\n",
      "203 activation_302\n",
      "204 conv2d_298\n",
      "205 batch_normalization_303\n",
      "206 activation_303\n",
      "207 conv2d_299\n",
      "208 concatenate_144\n",
      "209 batch_normalization_304\n",
      "210 activation_304\n",
      "211 conv2d_300\n",
      "212 batch_normalization_305\n",
      "213 activation_305\n",
      "214 conv2d_301\n",
      "215 concatenate_145\n",
      "216 batch_normalization_306\n",
      "217 activation_306\n",
      "218 conv2d_302\n",
      "219 batch_normalization_307\n",
      "220 activation_307\n",
      "221 conv2d_303\n",
      "222 concatenate_146\n",
      "223 batch_normalization_308\n",
      "224 activation_308\n",
      "225 conv2d_304\n",
      "226 batch_normalization_309\n",
      "227 activation_309\n",
      "228 conv2d_305\n",
      "229 concatenate_147\n",
      "230 batch_normalization_310\n",
      "231 activation_310\n",
      "232 conv2d_306\n",
      "233 batch_normalization_311\n",
      "234 activation_311\n",
      "235 conv2d_307\n",
      "236 concatenate_148\n",
      "237 batch_normalization_312\n",
      "238 activation_312\n",
      "239 conv2d_308\n",
      "240 batch_normalization_313\n",
      "241 activation_313\n",
      "242 conv2d_309\n",
      "243 concatenate_149\n",
      "244 batch_normalization_314\n",
      "245 activation_314\n",
      "246 conv2d_310\n",
      "247 batch_normalization_315\n",
      "248 activation_315\n",
      "249 conv2d_311\n",
      "250 concatenate_150\n",
      "251 batch_normalization_316\n",
      "252 activation_316\n",
      "253 conv2d_312\n",
      "254 batch_normalization_317\n",
      "255 activation_317\n",
      "256 conv2d_313\n",
      "257 concatenate_151\n",
      "258 batch_normalization_318\n",
      "259 activation_318\n",
      "260 conv2d_314\n",
      "261 batch_normalization_319\n",
      "262 activation_319\n",
      "263 conv2d_315\n",
      "264 concatenate_152\n",
      "265 batch_normalization_320\n",
      "266 activation_320\n",
      "267 conv2d_316\n",
      "268 batch_normalization_321\n",
      "269 activation_321\n",
      "270 conv2d_317\n",
      "271 concatenate_153\n",
      "272 batch_normalization_322\n",
      "273 activation_322\n",
      "274 conv2d_318\n",
      "275 batch_normalization_323\n",
      "276 activation_323\n",
      "277 conv2d_319\n",
      "278 concatenate_154\n",
      "279 batch_normalization_324\n",
      "280 activation_324\n",
      "281 conv2d_320\n",
      "282 batch_normalization_325\n",
      "283 activation_325\n",
      "284 conv2d_321\n",
      "285 concatenate_155\n",
      "286 batch_normalization_326\n",
      "287 activation_326\n",
      "288 conv2d_322\n",
      "289 batch_normalization_327\n",
      "290 activation_327\n",
      "291 conv2d_323\n",
      "292 concatenate_156\n",
      "293 batch_normalization_328\n",
      "294 activation_328\n",
      "295 conv2d_324\n",
      "296 batch_normalization_329\n",
      "297 activation_329\n",
      "298 conv2d_325\n",
      "299 concatenate_157\n",
      "300 batch_normalization_330\n",
      "301 activation_330\n",
      "302 conv2d_326\n",
      "303 batch_normalization_331\n",
      "304 activation_331\n",
      "305 conv2d_327\n",
      "306 concatenate_158\n",
      "307 batch_normalization_332\n",
      "308 activation_332\n",
      "309 conv2d_328\n",
      "310 average_pooling2d_9\n",
      "311 batch_normalization_333\n",
      "312 activation_333\n",
      "313 conv2d_329\n",
      "314 batch_normalization_334\n",
      "315 activation_334\n",
      "316 conv2d_330\n",
      "317 concatenate_159\n",
      "318 batch_normalization_335\n",
      "319 activation_335\n",
      "320 conv2d_331\n",
      "321 batch_normalization_336\n",
      "322 activation_336\n",
      "323 conv2d_332\n",
      "324 concatenate_160\n",
      "325 batch_normalization_337\n",
      "326 activation_337\n",
      "327 conv2d_333\n",
      "328 batch_normalization_338\n",
      "329 activation_338\n",
      "330 conv2d_334\n",
      "331 concatenate_161\n",
      "332 batch_normalization_339\n",
      "333 activation_339\n",
      "334 conv2d_335\n",
      "335 batch_normalization_340\n",
      "336 activation_340\n",
      "337 conv2d_336\n",
      "338 concatenate_162\n",
      "339 batch_normalization_341\n",
      "340 activation_341\n",
      "341 conv2d_337\n",
      "342 batch_normalization_342\n",
      "343 activation_342\n",
      "344 conv2d_338\n",
      "345 concatenate_163\n",
      "346 batch_normalization_343\n",
      "347 activation_343\n",
      "348 conv2d_339\n",
      "349 batch_normalization_344\n",
      "350 activation_344\n",
      "351 conv2d_340\n",
      "352 concatenate_164\n",
      "353 batch_normalization_345\n",
      "354 activation_345\n",
      "355 conv2d_341\n",
      "356 batch_normalization_346\n",
      "357 activation_346\n",
      "358 conv2d_342\n",
      "359 concatenate_165\n",
      "360 batch_normalization_347\n",
      "361 activation_347\n",
      "362 conv2d_343\n",
      "363 batch_normalization_348\n",
      "364 activation_348\n",
      "365 conv2d_344\n",
      "366 concatenate_166\n",
      "367 batch_normalization_349\n",
      "368 activation_349\n",
      "369 conv2d_345\n",
      "370 batch_normalization_350\n",
      "371 activation_350\n",
      "372 conv2d_346\n",
      "373 concatenate_167\n",
      "374 batch_normalization_351\n",
      "375 activation_351\n",
      "376 conv2d_347\n",
      "377 batch_normalization_352\n",
      "378 activation_352\n",
      "379 conv2d_348\n",
      "380 concatenate_168\n",
      "381 batch_normalization_353\n",
      "382 activation_353\n",
      "383 conv2d_349\n",
      "384 batch_normalization_354\n",
      "385 activation_354\n",
      "386 conv2d_350\n",
      "387 concatenate_169\n",
      "388 batch_normalization_355\n",
      "389 activation_355\n",
      "390 conv2d_351\n",
      "391 batch_normalization_356\n",
      "392 activation_356\n",
      "393 conv2d_352\n",
      "394 concatenate_170\n",
      "395 batch_normalization_357\n",
      "396 activation_357\n",
      "397 conv2d_353\n",
      "398 batch_normalization_358\n",
      "399 activation_358\n",
      "400 conv2d_354\n",
      "401 concatenate_171\n",
      "402 batch_normalization_359\n",
      "403 activation_359\n",
      "404 conv2d_355\n",
      "405 batch_normalization_360\n",
      "406 activation_360\n",
      "407 conv2d_356\n",
      "408 concatenate_172\n",
      "409 batch_normalization_361\n",
      "410 activation_361\n",
      "411 conv2d_357\n",
      "412 batch_normalization_362\n",
      "413 activation_362\n",
      "414 conv2d_358\n",
      "415 concatenate_173\n",
      "416 batch_normalization_363\n",
      "417 activation_363\n",
      "418 conv2d_359\n",
      "419 batch_normalization_364\n",
      "420 activation_364\n",
      "421 conv2d_360\n",
      "422 concatenate_174\n",
      "423 batch_normalization_365\n",
      "424 activation_365\n",
      "425 global_average_pooling2d_3\n",
      "426 dense_5\n",
      "427 batch_normalization_366\n",
      "428 activation_366\n",
      "429 dense_6\n"
     ]
    }
   ],
   "source": [
    "for l in range(len(base.layers)):\n",
    "    print l, base.layers[l].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_2 [<keras.engine.topology.Node object at 0x7fa485ee9f50>]\n",
      "1 conv2d_121 [<keras.engine.topology.Node object at 0x7fa48d4b9150>]\n",
      "2 batch_normalization_157 [<keras.engine.topology.Node object at 0x7fa46cfd2250>]\n",
      "3 activation_123 [<keras.engine.topology.Node object at 0x7fa46b68ad50>]\n",
      "4 max_pooling2d_2 [<keras.engine.topology.Node object at 0x7fa46b612550>]\n",
      "5 batch_normalization_158 [<keras.engine.topology.Node object at 0x7fa46b5c0950>]\n",
      "6 activation_124 [<keras.engine.topology.Node object at 0x7fa46b68ae50>]\n",
      "7 conv2d_122 [<keras.engine.topology.Node object at 0x7fa48d4b9850>]\n",
      "8 batch_normalization_159 [<keras.engine.topology.Node object at 0x7fa46b549c50>]\n",
      "9 activation_125 [<keras.engine.topology.Node object at 0x7fa46b5fa790>]\n",
      "10 conv2d_123 [<keras.engine.topology.Node object at 0x7fa48d4b9ad0>]\n",
      "11 concatenate_59 [<keras.engine.topology.Node object at 0x7fa46b4bee50>, <keras.engine.topology.Node object at 0x7fa46b4beed0>]\n",
      "12 batch_normalization_160 [<keras.engine.topology.Node object at 0x7fa46b4693d0>]\n",
      "13 activation_126 [<keras.engine.topology.Node object at 0x7fa46b5108d0>]\n",
      "14 conv2d_124 [<keras.engine.topology.Node object at 0x7fa48d4b9dd0>]\n",
      "15 batch_normalization_161 [<keras.engine.topology.Node object at 0x7fa46b3f7c50>]\n",
      "16 activation_127 [<keras.engine.topology.Node object at 0x7fa46b456790>]\n",
      "17 conv2d_125 [<keras.engine.topology.Node object at 0x7fa48d4be050>]\n",
      "18 concatenate_60 [<keras.engine.topology.Node object at 0x7fa46b36af10>, <keras.engine.topology.Node object at 0x7fa46b3f70d0>]\n",
      "19 batch_normalization_162 [<keras.engine.topology.Node object at 0x7fa46b315410>]\n",
      "20 activation_128 [<keras.engine.topology.Node object at 0x7fa46b469b10>]\n",
      "21 conv2d_126 [<keras.engine.topology.Node object at 0x7fa48d4be350>]\n",
      "22 batch_normalization_163 [<keras.engine.topology.Node object at 0x7fa46b2a0cd0>]\n",
      "23 activation_129 [<keras.engine.topology.Node object at 0x7fa46b36ae90>]\n",
      "24 conv2d_127 [<keras.engine.topology.Node object at 0x7fa48d4be5d0>]\n",
      "25 concatenate_61 [<keras.engine.topology.Node object at 0x7fa46b2b8450>, <keras.engine.topology.Node object at 0x7fa46b2b8710>]\n",
      "26 batch_normalization_164 [<keras.engine.topology.Node object at 0x7fa46b242450>]\n",
      "27 activation_130 [<keras.engine.topology.Node object at 0x7fa46b2a0090>]\n",
      "28 conv2d_128 [<keras.engine.topology.Node object at 0x7fa48d4be8d0>]\n",
      "29 batch_normalization_165 [<keras.engine.topology.Node object at 0x7fa46b1ced10>]\n",
      "30 activation_131 [<keras.engine.topology.Node object at 0x7fa46b266a10>]\n",
      "31 conv2d_129 [<keras.engine.topology.Node object at 0x7fa48d4beb50>]\n",
      "32 concatenate_62 [<keras.engine.topology.Node object at 0x7fa46b164490>, <keras.engine.topology.Node object at 0x7fa46b164750>]\n",
      "33 batch_normalization_166 [<keras.engine.topology.Node object at 0x7fa46b0ee490>]\n",
      "34 activation_132 [<keras.engine.topology.Node object at 0x7fa46b1ce0d0>]\n",
      "35 conv2d_130 [<keras.engine.topology.Node object at 0x7fa48d4bee50>]\n",
      "36 batch_normalization_167 [<keras.engine.topology.Node object at 0x7fa46b07ad50>]\n",
      "37 activation_133 [<keras.engine.topology.Node object at 0x7fa46b0da790>]\n",
      "38 conv2d_131 [<keras.engine.topology.Node object at 0x7fa483ff1110>]\n",
      "39 concatenate_63 [<keras.engine.topology.Node object at 0x7fa46aff0f90>, <keras.engine.topology.Node object at 0x7fa46b07a110>]\n",
      "40 batch_normalization_168 [<keras.engine.topology.Node object at 0x7fa46af9c4d0>]\n",
      "41 activation_134 [<keras.engine.topology.Node object at 0x7fa46b0eebd0>]\n",
      "42 conv2d_132 [<keras.engine.topology.Node object at 0x7fa483ff1410>]\n",
      "43 batch_normalization_169 [<keras.engine.topology.Node object at 0x7fa46af26d90>]\n",
      "44 activation_135 [<keras.engine.topology.Node object at 0x7fa46b02ae50>]\n",
      "45 conv2d_133 [<keras.engine.topology.Node object at 0x7fa483ff1690>]\n",
      "46 concatenate_64 [<keras.engine.topology.Node object at 0x7fa46af3e510>, <keras.engine.topology.Node object at 0x7fa46af3e7d0>]\n",
      "47 batch_normalization_170 [<keras.engine.topology.Node object at 0x7fa46aec7510>]\n",
      "48 activation_136 [<keras.engine.topology.Node object at 0x7fa46af26150>]\n",
      "49 conv2d_134 [<keras.engine.topology.Node object at 0x7fa483ff1990>]\n",
      "50 average_pooling2d_4 [<keras.engine.topology.Node object at 0x7fa46ae25f50>]\n",
      "51 batch_normalization_171 [<keras.engine.topology.Node object at 0x7fa46ade8190>]\n",
      "52 activation_137 [<keras.engine.topology.Node object at 0x7fa46aeb1810>]\n",
      "53 conv2d_135 [<keras.engine.topology.Node object at 0x7fa483ff1cd0>]\n",
      "54 batch_normalization_172 [<keras.engine.topology.Node object at 0x7fa46ad8b350>]\n",
      "55 activation_138 [<keras.engine.topology.Node object at 0x7fa46ad60710>]\n",
      "56 conv2d_136 [<keras.engine.topology.Node object at 0x7fa483ff1f50>]\n",
      "57 concatenate_65 [<keras.engine.topology.Node object at 0x7fa46ad76910>, <keras.engine.topology.Node object at 0x7fa46ad76d50>]\n",
      "58 batch_normalization_173 [<keras.engine.topology.Node object at 0x7fa46ac96090>]\n",
      "59 activation_139 [<keras.engine.topology.Node object at 0x7fa46ade8790>]\n",
      "60 conv2d_137 [<keras.engine.topology.Node object at 0x7fa483ffb290>]\n",
      "61 batch_normalization_174 [<keras.engine.topology.Node object at 0x7fa46ac39390>]\n",
      "62 activation_140 [<keras.engine.topology.Node object at 0x7fa46acebcd0>]\n",
      "63 conv2d_138 [<keras.engine.topology.Node object at 0x7fa483ffb510>]\n",
      "64 concatenate_66 [<keras.engine.topology.Node object at 0x7fa46abea610>, <keras.engine.topology.Node object at 0x7fa46ac22950>]\n",
      "65 batch_normalization_175 [<keras.engine.topology.Node object at 0x7fa46abc20d0>]\n",
      "66 activation_141 [<keras.engine.topology.Node object at 0x7fa46ac22f50>]\n",
      "67 conv2d_139 [<keras.engine.topology.Node object at 0x7fa483ffb810>]\n",
      "68 batch_normalization_176 [<keras.engine.topology.Node object at 0x7fa46aae43d0>]\n",
      "69 activation_142 [<keras.engine.topology.Node object at 0x7fa46abab350>]\n",
      "70 conv2d_140 [<keras.engine.topology.Node object at 0x7fa483ffba90>]\n",
      "71 concatenate_67 [<keras.engine.topology.Node object at 0x7fa46ab3ad10>, <keras.engine.topology.Node object at 0x7fa46abc2810>]\n",
      "72 batch_normalization_177 [<keras.engine.topology.Node object at 0x7fa46aa70110>]\n",
      "73 activation_143 [<keras.engine.topology.Node object at 0x7fa46aafded0>]\n",
      "74 conv2d_141 [<keras.engine.topology.Node object at 0x7fa483ffbd90>]\n",
      "75 batch_normalization_178 [<keras.engine.topology.Node object at 0x7fa46aa12410>]\n",
      "76 activation_144 [<keras.engine.topology.Node object at 0x7fa46ab4de10>]\n",
      "77 conv2d_142 [<keras.engine.topology.Node object at 0x7fa485ef8050>]\n",
      "78 concatenate_68 [<keras.engine.topology.Node object at 0x7fa46a9c1650>, <keras.engine.topology.Node object at 0x7fa46a9e6dd0>]\n",
      "79 batch_normalization_179 [<keras.engine.topology.Node object at 0x7fa46a918150>]\n",
      "80 activation_145 [<keras.engine.topology.Node object at 0x7fa46a9aaf10>]\n",
      "81 conv2d_143 [<keras.engine.topology.Node object at 0x7fa485ef8350>]\n",
      "82 batch_normalization_180 [<keras.engine.topology.Node object at 0x7fa46a8be450>]\n",
      "83 activation_146 [<keras.engine.topology.Node object at 0x7fa46a911810>]\n",
      "84 conv2d_144 [<keras.engine.topology.Node object at 0x7fa485ef85d0>]\n",
      "85 concatenate_69 [<keras.engine.topology.Node object at 0x7fa46a8a5a10>, <keras.engine.topology.Node object at 0x7fa46a8a5e50>]\n",
      "86 batch_normalization_181 [<keras.engine.topology.Node object at 0x7fa46a847190>]\n",
      "87 activation_147 [<keras.engine.topology.Node object at 0x7fa46a918890>]\n",
      "88 conv2d_145 [<keras.engine.topology.Node object at 0x7fa485ef88d0>]\n",
      "89 batch_normalization_182 [<keras.engine.topology.Node object at 0x7fa46a76d490>]\n",
      "90 activation_148 [<keras.engine.topology.Node object at 0x7fa46a7c1850>]\n",
      "91 conv2d_146 [<keras.engine.topology.Node object at 0x7fa485ef8b50>]\n",
      "92 concatenate_70 [<keras.engine.topology.Node object at 0x7fa46a756a50>, <keras.engine.topology.Node object at 0x7fa46a756e90>]\n",
      "93 batch_normalization_183 [<keras.engine.topology.Node object at 0x7fa46a6f31d0>]\n",
      "94 activation_149 [<keras.engine.topology.Node object at 0x7fa46a71a690>]\n",
      "95 conv2d_147 [<keras.engine.topology.Node object at 0x7fa485ef8e50>]\n",
      "96 batch_normalization_184 [<keras.engine.topology.Node object at 0x7fa46a680a90>]\n",
      "97 activation_150 [<keras.engine.topology.Node object at 0x7fa46a6f3910>]\n",
      "98 conv2d_148 [<keras.engine.topology.Node object at 0x7fa485f02110>]\n",
      "99 concatenate_71 [<keras.engine.topology.Node object at 0x7fa46a6174d0>, <keras.engine.topology.Node object at 0x7fa46a680f10>]\n",
      "100 batch_normalization_185 [<keras.engine.topology.Node object at 0x7fa46a59e210>]\n",
      "101 activation_151 [<keras.engine.topology.Node object at 0x7fa46a5f4810>]\n",
      "102 conv2d_149 [<keras.engine.topology.Node object at 0x7fa485f02410>]\n",
      "103 batch_normalization_186 [<keras.engine.topology.Node object at 0x7fa46a52bad0>]\n",
      "104 activation_152 [<keras.engine.topology.Node object at 0x7fa46a59e950>]\n",
      "105 conv2d_150 [<keras.engine.topology.Node object at 0x7fa485f02690>]\n",
      "106 concatenate_72 [<keras.engine.topology.Node object at 0x7fa46a4a1e90>, <keras.engine.topology.Node object at 0x7fa46a544510>]\n",
      "107 batch_normalization_187 [<keras.engine.topology.Node object at 0x7fa46a4cd250>]\n",
      "108 activation_153 [<keras.engine.topology.Node object at 0x7fa46a515e50>]\n",
      "109 conv2d_151 [<keras.engine.topology.Node object at 0x7fa485f02990>]\n",
      "110 batch_normalization_188 [<keras.engine.topology.Node object at 0x7fa46a3d6b10>]\n",
      "111 activation_154 [<keras.engine.topology.Node object at 0x7fa46a4b76d0>]\n",
      "112 conv2d_152 [<keras.engine.topology.Node object at 0x7fa485f02c10>]\n",
      "113 concatenate_73 [<keras.engine.topology.Node object at 0x7fa46a441910>, <keras.engine.topology.Node object at 0x7fa46a441e90>]\n",
      "114 batch_normalization_189 [<keras.engine.topology.Node object at 0x7fa46a379290>]\n",
      "115 activation_155 [<keras.engine.topology.Node object at 0x7fa46a3d6f90>]\n",
      "116 conv2d_153 [<keras.engine.topology.Node object at 0x7fa485f02f10>]\n",
      "117 batch_normalization_190 [<keras.engine.topology.Node object at 0x7fa469fe3b50>]\n",
      "118 activation_156 [<keras.engine.topology.Node object at 0x7fa46a35f590>]\n",
      "119 conv2d_154 [<keras.engine.topology.Node object at 0x7fa48d39b1d0>]\n",
      "120 concatenate_74 [<keras.engine.topology.Node object at 0x7fa469fcf950>, <keras.engine.topology.Node object at 0x7fa469fcfed0>]\n",
      "121 batch_normalization_191 [<keras.engine.topology.Node object at 0x7fa469f042d0>]\n",
      "122 activation_157 [<keras.engine.topology.Node object at 0x7fa469fe3fd0>]\n",
      "123 conv2d_155 [<keras.engine.topology.Node object at 0x7fa48d39b4d0>]\n",
      "124 batch_normalization_192 [<keras.engine.topology.Node object at 0x7fa469e8fb90>]\n",
      "125 activation_158 [<keras.engine.topology.Node object at 0x7fa469f6d5d0>]\n",
      "126 conv2d_156 [<keras.engine.topology.Node object at 0x7fa48d39b750>]\n",
      "127 concatenate_75 [<keras.engine.topology.Node object at 0x7fa469e04910>, <keras.engine.topology.Node object at 0x7fa469e04f50>]\n",
      "128 batch_normalization_193 [<keras.engine.topology.Node object at 0x7fa469e31310>]\n",
      "129 activation_159 [<keras.engine.topology.Node object at 0x7fa469e79f10>]\n",
      "130 conv2d_157 [<keras.engine.topology.Node object at 0x7fa48d39ba50>]\n",
      "131 batch_normalization_194 [<keras.engine.topology.Node object at 0x7fa469d3cb90>]\n",
      "132 activation_160 [<keras.engine.topology.Node object at 0x7fa469ea7310>]\n",
      "133 conv2d_158 [<keras.engine.topology.Node object at 0x7fa48d39bcd0>]\n",
      "134 concatenate_76 [<keras.engine.topology.Node object at 0x7fa469cb2f90>, <keras.engine.topology.Node object at 0x7fa469d54410>]\n",
      "135 batch_normalization_195 [<keras.engine.topology.Node object at 0x7fa469ce0350>]\n",
      "136 activation_161 [<keras.engine.topology.Node object at 0x7fa469d54610>]\n",
      "137 conv2d_159 [<keras.engine.topology.Node object at 0x7fa48d39bfd0>]\n",
      "138 average_pooling2d_5 [<keras.engine.topology.Node object at 0x7fa469c8f890>]\n",
      "139 batch_normalization_196 [<keras.engine.topology.Node object at 0x7fa469bfd1d0>]\n",
      "140 activation_162 [<keras.engine.topology.Node object at 0x7fa469cc8710>]\n",
      "141 conv2d_160 [<keras.engine.topology.Node object at 0x7fa48d38a350>]\n",
      "142 batch_normalization_197 [<keras.engine.topology.Node object at 0x7fa469b89750>]\n",
      "143 activation_163 [<keras.engine.topology.Node object at 0x7fa469c672d0>]\n",
      "144 conv2d_161 [<keras.engine.topology.Node object at 0x7fa48d38a5d0>]\n",
      "145 concatenate_77 [<keras.engine.topology.Node object at 0x7fa469b89b90>, <keras.engine.topology.Node object at 0x7fa469b89bd0>]\n",
      "146 batch_normalization_198 [<keras.engine.topology.Node object at 0x7fa469ac1f90>]\n",
      "147 activation_164 [<keras.engine.topology.Node object at 0x7fa469affcd0>]\n",
      "148 conv2d_162 [<keras.engine.topology.Node object at 0x7fa48d38a8d0>]\n",
      "149 batch_normalization_199 [<keras.engine.topology.Node object at 0x7fa469a35790>]\n",
      "150 activation_165 [<keras.engine.topology.Node object at 0x7fa469b533d0>]\n",
      "151 conv2d_163 [<keras.engine.topology.Node object at 0x7fa48d38ab50>]\n",
      "152 concatenate_78 [<keras.engine.topology.Node object at 0x7fa469a89910>, <keras.engine.topology.Node object at 0x7fa469aa0590>]\n",
      "153 batch_normalization_200 [<keras.engine.topology.Node object at 0x7fa4699d5250>]\n",
      "154 activation_166 [<keras.engine.topology.Node object at 0x7fa469a2db50>]\n",
      "155 conv2d_164 [<keras.engine.topology.Node object at 0x7fa48d38ae50>]\n",
      "156 batch_normalization_201 [<keras.engine.topology.Node object at 0x7fa469963790>]\n",
      "157 activation_167 [<keras.engine.topology.Node object at 0x7fa4699d5910>]\n",
      "158 conv2d_165 [<keras.engine.topology.Node object at 0x7fa48d3d7110>]\n",
      "159 concatenate_79 [<keras.engine.topology.Node object at 0x7fa469963bd0>, <keras.engine.topology.Node object at 0x7fa469963f10>]\n",
      "160 batch_normalization_202 [<keras.engine.topology.Node object at 0x7fa469884050>]\n",
      "161 activation_168 [<keras.engine.topology.Node object at 0x7fa46994e650>]\n",
      "162 conv2d_166 [<keras.engine.topology.Node object at 0x7fa48d3d7410>]\n",
      "163 batch_normalization_203 [<keras.engine.topology.Node object at 0x7fa46980d810>]\n",
      "164 activation_169 [<keras.engine.topology.Node object at 0x7fa46992a410>]\n",
      "165 conv2d_167 [<keras.engine.topology.Node object at 0x7fa48d3d7690>]\n",
      "166 concatenate_80 [<keras.engine.topology.Node object at 0x7fa469884690>, <keras.engine.topology.Node object at 0x7fa4697f7610>]\n",
      "167 batch_normalization_204 [<keras.engine.topology.Node object at 0x7fa4697b1090>]\n",
      "168 activation_170 [<keras.engine.topology.Node object at 0x7fa4697bed50>]\n",
      "169 conv2d_168 [<keras.engine.topology.Node object at 0x7fa48d3d7990>]\n",
      "170 batch_normalization_205 [<keras.engine.topology.Node object at 0x7fa4696bc850>]\n",
      "171 activation_171 [<keras.engine.topology.Node object at 0x7fa46980dc50>]\n",
      "172 conv2d_169 [<keras.engine.topology.Node object at 0x7fa48d3d7c10>]\n",
      "173 concatenate_81 [<keras.engine.topology.Node object at 0x7fa4697b16d0>, <keras.engine.topology.Node object at 0x7fa469726650>]\n",
      "174 batch_normalization_206 [<keras.engine.topology.Node object at 0x7fa46965c0d0>]\n",
      "175 activation_172 [<keras.engine.topology.Node object at 0x7fa4696e8d90>]\n",
      "176 conv2d_170 [<keras.engine.topology.Node object at 0x7fa48d3d7f10>]\n",
      "177 batch_normalization_207 [<keras.engine.topology.Node object at 0x7fa46957e310>]\n",
      "178 activation_173 [<keras.engine.topology.Node object at 0x7fa469632f50>]\n",
      "179 conv2d_171 [<keras.engine.topology.Node object at 0x7fa48d3ca1d0>]\n",
      "180 concatenate_82 [<keras.engine.topology.Node object at 0x7fa4695e7fd0>, <keras.engine.topology.Node object at 0x7fa4696bcc90>]\n",
      "181 batch_normalization_208 [<keras.engine.topology.Node object at 0x7fa469508150>]\n",
      "182 activation_174 [<keras.engine.topology.Node object at 0x7fa4695b0590>]\n",
      "183 conv2d_172 [<keras.engine.topology.Node object at 0x7fa48d3ca4d0>]\n",
      "184 batch_normalization_209 [<keras.engine.topology.Node object at 0x7fa4694aa310>]\n",
      "185 activation_175 [<keras.engine.topology.Node object at 0x7fa469598990>]\n",
      "186 conv2d_173 [<keras.engine.topology.Node object at 0x7fa48d3ca750>]\n",
      "187 concatenate_83 [<keras.engine.topology.Node object at 0x7fa46947cc50>, <keras.engine.topology.Node object at 0x7fa469508750>]\n",
      "188 batch_normalization_210 [<keras.engine.topology.Node object at 0x7fa4693b7050>]\n",
      "189 activation_176 [<keras.engine.topology.Node object at 0x7fa469441e10>]\n",
      "190 conv2d_174 [<keras.engine.topology.Node object at 0x7fa48d3caa50>]\n",
      "191 batch_normalization_211 [<keras.engine.topology.Node object at 0x7fa469359350>]\n",
      "192 activation_177 [<keras.engine.topology.Node object at 0x7fa4694938d0>]\n",
      "193 conv2d_175 [<keras.engine.topology.Node object at 0x7fa48d3cacd0>]\n",
      "194 concatenate_84 [<keras.engine.topology.Node object at 0x7fa469309590>, <keras.engine.topology.Node object at 0x7fa4693afc90>]\n",
      "195 batch_normalization_212 [<keras.engine.topology.Node object at 0x7fa4692e0090>]\n",
      "196 activation_178 [<keras.engine.topology.Node object at 0x7fa469371e50>]\n",
      "197 conv2d_176 [<keras.engine.topology.Node object at 0x7fa48d3cafd0>]\n",
      "198 batch_normalization_213 [<keras.engine.topology.Node object at 0x7fa469204390>]\n",
      "199 activation_179 [<keras.engine.topology.Node object at 0x7fa4693b7790>]\n",
      "200 conv2d_177 [<keras.engine.topology.Node object at 0x7fa48d3dd290>]\n",
      "201 concatenate_85 [<keras.engine.topology.Node object at 0x7fa4691b35d0>, <keras.engine.topology.Node object at 0x7fa469258cd0>]\n",
      "202 batch_normalization_214 [<keras.engine.topology.Node object at 0x7fa46918d0d0>]\n",
      "203 activation_180 [<keras.engine.topology.Node object at 0x7fa4691e4ed0>]\n",
      "204 conv2d_178 [<keras.engine.topology.Node object at 0x7fa48d3dd590>]\n",
      "205 batch_normalization_215 [<keras.engine.topology.Node object at 0x7fa46912f3d0>]\n",
      "206 activation_181 [<keras.engine.topology.Node object at 0x7fa4692e07d0>]\n",
      "207 conv2d_179 [<keras.engine.topology.Node object at 0x7fa48d3dd810>]\n",
      "208 concatenate_86 [<keras.engine.topology.Node object at 0x7fa4690e0610>, <keras.engine.topology.Node object at 0x7fa469103d10>]\n",
      "209 batch_normalization_216 [<keras.engine.topology.Node object at 0x7fa469039110>]\n",
      "210 activation_182 [<keras.engine.topology.Node object at 0x7fa4690c6ed0>]\n",
      "211 conv2d_180 [<keras.engine.topology.Node object at 0x7fa48d3ddb10>]\n",
      "212 batch_normalization_217 [<keras.engine.topology.Node object at 0x7fa468fdc410>]\n",
      "213 activation_183 [<keras.engine.topology.Node object at 0x7fa46918d810>]\n",
      "214 conv2d_181 [<keras.engine.topology.Node object at 0x7fa48d3ddd90>]\n",
      "215 concatenate_87 [<keras.engine.topology.Node object at 0x7fa468f8d650>, <keras.engine.topology.Node object at 0x7fa469031d50>]\n",
      "216 batch_normalization_218 [<keras.engine.topology.Node object at 0x7fa468f65150>]\n",
      "217 activation_184 [<keras.engine.topology.Node object at 0x7fa468f72f10>]\n",
      "218 conv2d_182 [<keras.engine.topology.Node object at 0x7fa48d4000d0>]\n",
      "219 batch_normalization_219 [<keras.engine.topology.Node object at 0x7fa468e8d450>]\n",
      "220 activation_185 [<keras.engine.topology.Node object at 0x7fa469039850>]\n",
      "221 conv2d_183 [<keras.engine.topology.Node object at 0x7fa48d400350>]\n",
      "222 concatenate_88 [<keras.engine.topology.Node object at 0x7fa468eddd90>, <keras.engine.topology.Node object at 0x7fa468f65890>]\n",
      "223 batch_normalization_220 [<keras.engine.topology.Node object at 0x7fa468e12190>]\n",
      "224 activation_186 [<keras.engine.topology.Node object at 0x7fa468ea4f50>]\n",
      "225 conv2d_184 [<keras.engine.topology.Node object at 0x7fa48d400650>]\n",
      "226 batch_normalization_221 [<keras.engine.topology.Node object at 0x7fa468d36490>]\n",
      "227 activation_187 [<keras.engine.topology.Node object at 0x7fa468d888d0>]\n",
      "228 conv2d_185 [<keras.engine.topology.Node object at 0x7fa48d4008d0>]\n",
      "229 concatenate_89 [<keras.engine.topology.Node object at 0x7fa468d67710>, <keras.engine.topology.Node object at 0x7fa468d9ea10>]\n",
      "230 batch_normalization_222 [<keras.engine.topology.Node object at 0x7fa468cbb1d0>]\n",
      "231 activation_188 [<keras.engine.topology.Node object at 0x7fa468d9ee50>]\n",
      "232 conv2d_186 [<keras.engine.topology.Node object at 0x7fa48d400bd0>]\n",
      "233 batch_normalization_223 [<keras.engine.topology.Node object at 0x7fa468c4aa90>]\n",
      "234 activation_189 [<keras.engine.topology.Node object at 0x7fa468cbb910>]\n",
      "235 conv2d_187 [<keras.engine.topology.Node object at 0x7fa48d400e50>]\n",
      "236 concatenate_90 [<keras.engine.topology.Node object at 0x7fa468c604d0>, <keras.engine.topology.Node object at 0x7fa468c4af10>]\n",
      "237 batch_normalization_224 [<keras.engine.topology.Node object at 0x7fa468be9210>]\n",
      "238 activation_190 [<keras.engine.topology.Node object at 0x7fa468c36e10>]\n",
      "239 conv2d_188 [<keras.engine.topology.Node object at 0x7fa48d40a190>]\n",
      "240 batch_normalization_225 [<keras.engine.topology.Node object at 0x7fa468af5ad0>]\n",
      "241 activation_191 [<keras.engine.topology.Node object at 0x7fa468bd4510>]\n",
      "242 conv2d_189 [<keras.engine.topology.Node object at 0x7fa48d40a410>]\n",
      "243 concatenate_91 [<keras.engine.topology.Node object at 0x7fa468b608d0>, <keras.engine.topology.Node object at 0x7fa468b60e50>]\n",
      "244 batch_normalization_226 [<keras.engine.topology.Node object at 0x7fa468a97250>]\n",
      "245 activation_192 [<keras.engine.topology.Node object at 0x7fa468af5f50>]\n",
      "246 conv2d_190 [<keras.engine.topology.Node object at 0x7fa48d40a710>]\n",
      "247 batch_normalization_227 [<keras.engine.topology.Node object at 0x7fa468a22b10>]\n",
      "248 activation_193 [<keras.engine.topology.Node object at 0x7fa468a81550>]\n",
      "249 conv2d_191 [<keras.engine.topology.Node object at 0x7fa48d40a990>]\n",
      "250 concatenate_92 [<keras.engine.topology.Node object at 0x7fa468a0d910>, <keras.engine.topology.Node object at 0x7fa468a0de90>]\n",
      "251 batch_normalization_228 [<keras.engine.topology.Node object at 0x7fa468945290>]\n",
      "252 activation_194 [<keras.engine.topology.Node object at 0x7fa468a22f90>]\n",
      "253 conv2d_192 [<keras.engine.topology.Node object at 0x7fa48d40ac90>]\n",
      "254 batch_normalization_229 [<keras.engine.topology.Node object at 0x7fa4688d0b50>]\n",
      "255 activation_195 [<keras.engine.topology.Node object at 0x7fa4689459d0>]\n",
      "256 conv2d_193 [<keras.engine.topology.Node object at 0x7fa48d40af10>]\n",
      "257 concatenate_93 [<keras.engine.topology.Node object at 0x7fa468847f10>, <keras.engine.topology.Node object at 0x7fa4688e9590>]\n",
      "258 batch_normalization_230 [<keras.engine.topology.Node object at 0x7fa4688702d0>]\n",
      "259 activation_196 [<keras.engine.topology.Node object at 0x7fa468898810>]\n",
      "260 conv2d_194 [<keras.engine.topology.Node object at 0x7fa48d418250>]\n",
      "261 batch_normalization_231 [<keras.engine.topology.Node object at 0x7fa46877db90>]\n",
      "262 activation_197 [<keras.engine.topology.Node object at 0x7fa46885c710>]\n",
      "263 conv2d_195 [<keras.engine.topology.Node object at 0x7fa48d4184d0>]\n",
      "264 concatenate_94 [<keras.engine.topology.Node object at 0x7fa468771910>, <keras.engine.topology.Node object at 0x7fa468771f50>]\n",
      "265 batch_normalization_232 [<keras.engine.topology.Node object at 0x7fa46871d310>]\n",
      "266 activation_198 [<keras.engine.topology.Node object at 0x7fa4687e9f10>]\n",
      "267 conv2d_196 [<keras.engine.topology.Node object at 0x7fa48d4187d0>]\n",
      "268 batch_normalization_233 [<keras.engine.topology.Node object at 0x7fa4686acbd0>]\n",
      "269 activation_199 [<keras.engine.topology.Node object at 0x7fa4687086d0>]\n",
      "270 conv2d_197 [<keras.engine.topology.Node object at 0x7fa48d418a50>]\n",
      "271 concatenate_95 [<keras.engine.topology.Node object at 0x7fa46861f950>, <keras.engine.topology.Node object at 0x7fa46861ff90>]\n",
      "272 batch_normalization_234 [<keras.engine.topology.Node object at 0x7fa4685ca350>]\n",
      "273 activation_200 [<keras.engine.topology.Node object at 0x7fa468670850>]\n",
      "274 conv2d_198 [<keras.engine.topology.Node object at 0x7fa48d418d50>]\n",
      "275 batch_normalization_235 [<keras.engine.topology.Node object at 0x7fa468556c10>]\n",
      "276 activation_201 [<keras.engine.topology.Node object at 0x7fa4685b3710>]\n",
      "277 conv2d_199 [<keras.engine.topology.Node object at 0x7fa48d418fd0>]\n",
      "278 concatenate_96 [<keras.engine.topology.Node object at 0x7fa4684cd990>, <keras.engine.topology.Node object at 0x7fa4684cdfd0>]\n",
      "279 batch_normalization_236 [<keras.engine.topology.Node object at 0x7fa468477390>]\n",
      "280 activation_202 [<keras.engine.topology.Node object at 0x7fa4685caa90>]\n",
      "281 conv2d_200 [<keras.engine.topology.Node object at 0x7fa48d423310>]\n",
      "282 batch_normalization_237 [<keras.engine.topology.Node object at 0x7fa468403c50>]\n",
      "283 activation_203 [<keras.engine.topology.Node object at 0x7fa4684e07d0>]\n",
      "284 conv2d_201 [<keras.engine.topology.Node object at 0x7fa48d423590>]\n",
      "285 concatenate_97 [<keras.engine.topology.Node object at 0x7fa468375ed0>, <keras.engine.topology.Node object at 0x7fa468403a50>]\n",
      "286 batch_normalization_238 [<keras.engine.topology.Node object at 0x7fa4683a33d0>]\n",
      "287 activation_204 [<keras.engine.topology.Node object at 0x7fa468477ad0>]\n",
      "288 conv2d_202 [<keras.engine.topology.Node object at 0x7fa48d423890>]\n",
      "289 batch_normalization_239 [<keras.engine.topology.Node object at 0x7fa468331c90>]\n",
      "290 activation_205 [<keras.engine.topology.Node object at 0x7fa46838e6d0>]\n",
      "291 conv2d_203 [<keras.engine.topology.Node object at 0x7fa48d423b10>]\n",
      "292 concatenate_98 [<keras.engine.topology.Node object at 0x7fa4682a3f10>, <keras.engine.topology.Node object at 0x7fa468331050>]\n",
      "293 batch_normalization_240 [<keras.engine.topology.Node object at 0x7fa468251410>]\n",
      "294 activation_206 [<keras.engine.topology.Node object at 0x7fa4683a3b10>]\n",
      "295 conv2d_204 [<keras.engine.topology.Node object at 0x7fa48d423e10>]\n",
      "296 batch_normalization_241 [<keras.engine.topology.Node object at 0x7fa4681ddcd0>]\n",
      "297 activation_207 [<keras.engine.topology.Node object at 0x7fa4682a3e90>]\n",
      "298 conv2d_205 [<keras.engine.topology.Node object at 0x7fa48d4300d0>]\n",
      "299 concatenate_99 [<keras.engine.topology.Node object at 0x7fa468150f50>, <keras.engine.topology.Node object at 0x7fa468174450>]\n",
      "300 batch_normalization_242 [<keras.engine.topology.Node object at 0x7fa4680fc450>]\n",
      "301 activation_208 [<keras.engine.topology.Node object at 0x7fa468174710>]\n",
      "302 conv2d_206 [<keras.engine.topology.Node object at 0x7fa48d4303d0>]\n",
      "303 batch_normalization_243 [<keras.engine.topology.Node object at 0x7fa468088d10>]\n",
      "304 activation_209 [<keras.engine.topology.Node object at 0x7fa4680880d0>]\n",
      "305 conv2d_207 [<keras.engine.topology.Node object at 0x7fa48d430650>]\n",
      "306 concatenate_100 [<keras.engine.topology.Node object at 0x7fa4680a0750>, <keras.engine.topology.Node object at 0x7fa46803af50>]\n",
      "307 batch_normalization_244 [<keras.engine.topology.Node object at 0x7fa468029450>]\n",
      "308 activation_210 [<keras.engine.topology.Node object at 0x7fa4680fcb90>]\n",
      "309 conv2d_208 [<keras.engine.topology.Node object at 0x7fa48d430950>]\n",
      "310 average_pooling2d_6 [<keras.engine.topology.Node object at 0x7fa467f87e90>]\n",
      "311 input_3 [<keras.engine.topology.Node object at 0x7fa48248d490>]\n",
      "312 lambda_1 [<keras.engine.topology.Node object at 0x7fa467fa2850>]\n",
      "313 input_4 [<keras.engine.topology.Node object at 0x7fa48248d690>]\n",
      "314 input_5 [<keras.engine.topology.Node object at 0x7fa48248d850>]\n",
      "315 lambda_2 [<keras.engine.topology.Node object at 0x7fa468029bd0>, <keras.engine.topology.Node object at 0x7fa467f34450>]\n",
      "316 lambda_3 [<keras.engine.topology.Node object at 0x7fa467f34cd0>, <keras.engine.topology.Node object at 0x7fa467f34e50>]\n",
      "317 lambda_4 [<keras.engine.topology.Node object at 0x7fa467f347d0>, <keras.engine.topology.Node object at 0x7fa467f4db50>]\n",
      "318 input_6 [<keras.engine.topology.Node object at 0x7fa48248da10>]\n",
      "319 batch_normalization_123 [<keras.engine.topology.Node object at 0x7fa467efb410>, <keras.engine.topology.Node object at 0x7fa467f6ca90>, <keras.engine.topology.Node object at 0x7fa467f2db50>]\n",
      "320 input_7 [<keras.engine.topology.Node object at 0x7fa48248dbd0>]\n",
      "321 input_8 [<keras.engine.topology.Node object at 0x7fa48248dd90>]\n",
      "322 lambda_5 [<keras.engine.topology.Node object at 0x7fa467ea5290>, <keras.engine.topology.Node object at 0x7fa467f5c6d0>]\n",
      "323 lambda_6 [<keras.engine.topology.Node object at 0x7fa467f4d810>, <keras.engine.topology.Node object at 0x7fa467ec7450>]\n",
      "324 lambda_7 [<keras.engine.topology.Node object at 0x7fa467e859d0>, <keras.engine.topology.Node object at 0x7fa467e85710>]\n",
      "325 activation_211 [<keras.engine.topology.Node object at 0x7fa467e2d950>, <keras.engine.topology.Node object at 0x7fa467e2db10>, <keras.engine.topology.Node object at 0x7fa467e2dc10>]\n",
      "326 lambda_8 [<keras.engine.topology.Node object at 0x7fa468016810>]\n",
      "327 lambda_9 [<keras.engine.topology.Node object at 0x7fa467dbe810>]\n",
      "328 lambda_10 [<keras.engine.topology.Node object at 0x7fa467dbef90>]\n",
      "329 input_9 [<keras.engine.topology.Node object at 0x7fa483fcd190>]\n",
      "330 conv2d_209 [<keras.engine.topology.Node object at 0x7fa48d430cd0>, <keras.engine.topology.Node object at 0x7fa467dcd9d0>, <keras.engine.topology.Node object at 0x7fa467dcd690>]\n",
      "331 input_10 [<keras.engine.topology.Node object at 0x7fa483fcd350>]\n",
      "332 input_11 [<keras.engine.topology.Node object at 0x7fa483fcd550>]\n",
      "333 lambda_11 [<keras.engine.topology.Node object at 0x7fa4664cb910>, <keras.engine.topology.Node object at 0x7fa4664cb250>]\n",
      "334 lambda_12 [<keras.engine.topology.Node object at 0x7fa4664db410>, <keras.engine.topology.Node object at 0x7fa467dbe9d0>]\n",
      "335 lambda_13 [<keras.engine.topology.Node object at 0x7fa4664db110>, <keras.engine.topology.Node object at 0x7fa4664dbc50>]\n",
      "336 input_12 [<keras.engine.topology.Node object at 0x7fa483fcd750>]\n",
      "337 batch_normalization_124 [<keras.engine.topology.Node object at 0x7fa4664a84d0>, <keras.engine.topology.Node object at 0x7fa466498bd0>, <keras.engine.topology.Node object at 0x7fa466458c90>]\n",
      "338 input_13 [<keras.engine.topology.Node object at 0x7fa483fcd950>]\n",
      "339 input_14 [<keras.engine.topology.Node object at 0x7fa483fcdb50>]\n",
      "340 lambda_14 [<keras.engine.topology.Node object at 0x7fa4663ce3d0>, <keras.engine.topology.Node object at 0x7fa4664739d0>]\n",
      "341 lambda_15 [<keras.engine.topology.Node object at 0x7fa4664dbc90>, <keras.engine.topology.Node object at 0x7fa4663f0590>]\n",
      "342 lambda_16 [<keras.engine.topology.Node object at 0x7fa4663b4b10>, <keras.engine.topology.Node object at 0x7fa4663b4850>]\n",
      "343 activation_212 [<keras.engine.topology.Node object at 0x7fa466358a90>, <keras.engine.topology.Node object at 0x7fa466368c10>, <keras.engine.topology.Node object at 0x7fa467e66550>]\n",
      "344 lambda_17 [<keras.engine.topology.Node object at 0x7fa466358c50>]\n",
      "345 lambda_18 [<keras.engine.topology.Node object at 0x7fa4662cbc50>]\n",
      "346 lambda_19 [<keras.engine.topology.Node object at 0x7fa466368950>]\n",
      "347 input_15 [<keras.engine.topology.Node object at 0x7fa483fd90d0>]\n",
      "348 conv2d_210 [<keras.engine.topology.Node object at 0x7fa48d43c410>, <keras.engine.topology.Node object at 0x7fa4662f8b10>, <keras.engine.topology.Node object at 0x7fa4662f8810>]\n",
      "349 input_16 [<keras.engine.topology.Node object at 0x7fa483fd9290>]\n",
      "350 input_17 [<keras.engine.topology.Node object at 0x7fa483fd9490>]\n",
      "351 lambda_20 [<keras.engine.topology.Node object at 0x7fa4662a2f50>, <keras.engine.topology.Node object at 0x7fa4662a2bd0>]\n",
      "352 lambda_21 [<keras.engine.topology.Node object at 0x7fa466238d50>, <keras.engine.topology.Node object at 0x7fa466248710>]\n",
      "353 lambda_22 [<keras.engine.topology.Node object at 0x7fa466248c90>, <keras.engine.topology.Node object at 0x7fa466248b10>]\n",
      "354 concatenate_101 [<keras.engine.topology.Node object at 0x7fa46625cd50>, <keras.engine.topology.Node object at 0x7fa46625cb90>, <keras.engine.topology.Node object at 0x7fa4661f0d10>]\n",
      "355 input_18 [<keras.engine.topology.Node object at 0x7fa483fd9690>]\n",
      "356 input_19 [<keras.engine.topology.Node object at 0x7fa483fd98d0>]\n",
      "357 input_20 [<keras.engine.topology.Node object at 0x7fa483fd9ad0>]\n",
      "358 lambda_23 [<keras.engine.topology.Node object at 0x7fa4661f0c10>, <keras.engine.topology.Node object at 0x7fa4661f0a50>]\n",
      "359 lambda_24 [<keras.engine.topology.Node object at 0x7fa466201a90>, <keras.engine.topology.Node object at 0x7fa46620f910>]\n",
      "360 lambda_25 [<keras.engine.topology.Node object at 0x7fa46620fc50>, <keras.engine.topology.Node object at 0x7fa466201490>]\n",
      "361 input_21 [<keras.engine.topology.Node object at 0x7fa483fd9d10>]\n",
      "362 batch_normalization_125 [<keras.engine.topology.Node object at 0x7fa4661c3510>, <keras.engine.topology.Node object at 0x7fa4662018d0>, <keras.engine.topology.Node object at 0x7fa466174c50>]\n",
      "363 input_22 [<keras.engine.topology.Node object at 0x7fa483fd9e90>]\n",
      "364 input_23 [<keras.engine.topology.Node object at 0x7fa4824ae0d0>]\n",
      "365 lambda_26 [<keras.engine.topology.Node object at 0x7fa466150ad0>, <keras.engine.topology.Node object at 0x7fa4661b6b50>]\n",
      "366 lambda_27 [<keras.engine.topology.Node object at 0x7fa466201610>, <keras.engine.topology.Node object at 0x7fa46618d550>]\n",
      "367 lambda_28 [<keras.engine.topology.Node object at 0x7fa46616b410>, <keras.engine.topology.Node object at 0x7fa46616b350>]\n",
      "368 activation_213 [<keras.engine.topology.Node object at 0x7fa466074cd0>, <keras.engine.topology.Node object at 0x7fa466074b10>, <keras.engine.topology.Node object at 0x7fa466083c90>]\n",
      "369 lambda_29 [<keras.engine.topology.Node object at 0x7fa465972f10>]\n",
      "370 lambda_30 [<keras.engine.topology.Node object at 0x7fa465205e50>]\n",
      "371 lambda_31 [<keras.engine.topology.Node object at 0x7fa464a9be50>]\n",
      "372 input_24 [<keras.engine.topology.Node object at 0x7fa4824ae790>]\n",
      "373 conv2d_211 [<keras.engine.topology.Node object at 0x7fa48d43c810>, <keras.engine.topology.Node object at 0x7fa4660839d0>, <keras.engine.topology.Node object at 0x7fa466094850>]\n",
      "374 input_25 [<keras.engine.topology.Node object at 0x7fa4824ae950>]\n",
      "375 input_26 [<keras.engine.topology.Node object at 0x7fa4824aeb50>]\n",
      "376 lambda_32 [<keras.engine.topology.Node object at 0x7fa466094b90>, <keras.engine.topology.Node object at 0x7fa46466df50>]\n",
      "377 lambda_33 [<keras.engine.topology.Node object at 0x7fa46467eb50>, <keras.engine.topology.Node object at 0x7fa46467e8d0>]\n",
      "378 lambda_34 [<keras.engine.topology.Node object at 0x7fa46467eb10>, <keras.engine.topology.Node object at 0x7fa464691b10>]\n",
      "379 input_27 [<keras.engine.topology.Node object at 0x7fa4824aed50>]\n",
      "380 batch_normalization_126 [<keras.engine.topology.Node object at 0x7fa4646473d0>, <keras.engine.topology.Node object at 0x7fa464639a50>, <keras.engine.topology.Node object at 0x7fa4645f8b10>]\n",
      "381 input_28 [<keras.engine.topology.Node object at 0x7fa4824aef50>]\n",
      "382 input_29 [<keras.engine.topology.Node object at 0x7fa4824c0190>]\n",
      "383 lambda_35 [<keras.engine.topology.Node object at 0x7fa464571250>, <keras.engine.topology.Node object at 0x7fa464647850>]\n",
      "384 lambda_36 [<keras.engine.topology.Node object at 0x7fa4645d46d0>, <keras.engine.topology.Node object at 0x7fa464563e50>]\n",
      "385 lambda_37 [<keras.engine.topology.Node object at 0x7fa464535f90>, <keras.engine.topology.Node object at 0x7fa4645d4990>]\n",
      "386 activation_214 [<keras.engine.topology.Node object at 0x7fa4644fdad0>, <keras.engine.topology.Node object at 0x7fa4644fd910>, <keras.engine.topology.Node object at 0x7fa46450ba90>]\n",
      "387 lambda_38 [<keras.engine.topology.Node object at 0x7fa466358d50>]\n",
      "388 lambda_39 [<keras.engine.topology.Node object at 0x7fa464480e90>]\n",
      "389 lambda_40 [<keras.engine.topology.Node object at 0x7fa46450b7d0>]\n",
      "390 input_30 [<keras.engine.topology.Node object at 0x7fa4824c06d0>]\n",
      "391 conv2d_212 [<keras.engine.topology.Node object at 0x7fa48d43cf10>, <keras.engine.topology.Node object at 0x7fa4644d8390>, <keras.engine.topology.Node object at 0x7fa46451c990>]\n",
      "392 input_31 [<keras.engine.topology.Node object at 0x7fa4824c0890>]\n",
      "393 input_32 [<keras.engine.topology.Node object at 0x7fa4824c0a90>]\n",
      "394 lambda_41 [<keras.engine.topology.Node object at 0x7fa46451c750>, <keras.engine.topology.Node object at 0x7fa46450be90>]\n",
      "395 lambda_42 [<keras.engine.topology.Node object at 0x7fa464441a50>, <keras.engine.topology.Node object at 0x7fa464441dd0>]\n",
      "396 lambda_43 [<keras.engine.topology.Node object at 0x7fa464457f10>, <keras.engine.topology.Node object at 0x7fa464467b10>]\n",
      "397 concatenate_102 [<keras.engine.topology.Node object at 0x7fa4643fca10>, <keras.engine.topology.Node object at 0x7fa464410b90>, <keras.engine.topology.Node object at 0x7fa4646917d0>]\n",
      "398 input_33 [<keras.engine.topology.Node object at 0x7fa4824c0c90>]\n",
      "399 input_34 [<keras.engine.topology.Node object at 0x7fa4824c0e90>]\n",
      "400 input_35 [<keras.engine.topology.Node object at 0x7fa4856c00d0>]\n",
      "401 lambda_44 [<keras.engine.topology.Node object at 0x7fa4644108d0>, <keras.engine.topology.Node object at 0x7fa464410a90>]\n",
      "402 lambda_45 [<keras.engine.topology.Node object at 0x7fa464420950>, <keras.engine.topology.Node object at 0x7fa4644204d0>]\n",
      "403 lambda_46 [<keras.engine.topology.Node object at 0x7fa464420c10>, <keras.engine.topology.Node object at 0x7fa464420350>]\n",
      "404 input_36 [<keras.engine.topology.Node object at 0x7fa4856c02d0>]\n",
      "405 batch_normalization_127 [<keras.engine.topology.Node object at 0x7fa4643e3390>, <keras.engine.topology.Node object at 0x7fa4643d29d0>, <keras.engine.topology.Node object at 0x7fa464393ad0>]\n",
      "406 input_37 [<keras.engine.topology.Node object at 0x7fa4856c04d0>]\n",
      "407 input_38 [<keras.engine.topology.Node object at 0x7fa4856c06d0>]\n",
      "408 lambda_47 [<keras.engine.topology.Node object at 0x7fa46430a210>, <keras.engine.topology.Node object at 0x7fa4643b2b10>]\n",
      "409 lambda_48 [<keras.engine.topology.Node object at 0x7fa4643e3810>, <keras.engine.topology.Node object at 0x7fa4642cf4d0>]\n",
      "410 lambda_49 [<keras.engine.topology.Node object at 0x7fa4642f1690>, <keras.engine.topology.Node object at 0x7fa4642f1950>]\n",
      "411 activation_215 [<keras.engine.topology.Node object at 0x7fa464294a90>, <keras.engine.topology.Node object at 0x7fa4642948d0>, <keras.engine.topology.Node object at 0x7fa464294b90>]\n",
      "412 lambda_50 [<keras.engine.topology.Node object at 0x7fa463b13cd0>]\n",
      "413 lambda_51 [<keras.engine.topology.Node object at 0x7fa4633a5cd0>]\n",
      "414 lambda_52 [<keras.engine.topology.Node object at 0x7fa46375f8d0>]\n",
      "415 input_39 [<keras.engine.topology.Node object at 0x7fa4856c0d90>]\n",
      "416 conv2d_213 [<keras.engine.topology.Node object at 0x7fa48d454350>, <keras.engine.topology.Node object at 0x7fa462874f10>, <keras.engine.topology.Node object at 0x7fa4642a1ed0>]\n",
      "417 input_40 [<keras.engine.topology.Node object at 0x7fa4856c0f50>]\n",
      "418 input_41 [<keras.engine.topology.Node object at 0x7fa4856e2190>]\n",
      "419 lambda_53 [<keras.engine.topology.Node object at 0x7fa4642a1950>, <keras.engine.topology.Node object at 0x7fa462888dd0>]\n",
      "420 lambda_54 [<keras.engine.topology.Node object at 0x7fa46289b3d0>, <keras.engine.topology.Node object at 0x7fa46289b790>]\n",
      "421 lambda_55 [<keras.engine.topology.Node object at 0x7fa46289b9d0>, <keras.engine.topology.Node object at 0x7fa4628329d0>]\n",
      "422 input_42 [<keras.engine.topology.Node object at 0x7fa4856e2390>]\n",
      "423 batch_normalization_128 [<keras.engine.topology.Node object at 0x7fa4627e9250>, <keras.engine.topology.Node object at 0x7fa4628578d0>, <keras.engine.topology.Node object at 0x7fa462819990>]\n",
      "424 input_43 [<keras.engine.topology.Node object at 0x7fa4856e2590>]\n",
      "425 input_44 [<keras.engine.topology.Node object at 0x7fa4856e2790>]\n",
      "426 lambda_56 [<keras.engine.topology.Node object at 0x7fa4627940d0>, <keras.engine.topology.Node object at 0x7fa462832b50>]\n",
      "427 lambda_57 [<keras.engine.topology.Node object at 0x7fa4627e96d0>, <keras.engine.topology.Node object at 0x7fa462754390>]\n",
      "428 lambda_58 [<keras.engine.topology.Node object at 0x7fa462776550>, <keras.engine.topology.Node object at 0x7fa462776810>]\n",
      "429 activation_216 [<keras.engine.topology.Node object at 0x7fa46271b790>, <keras.engine.topology.Node object at 0x7fa46271be50>, <keras.engine.topology.Node object at 0x7fa4626ab950>]\n",
      "430 lambda_59 [<keras.engine.topology.Node object at 0x7fa46271b950>]\n",
      "431 lambda_60 [<keras.engine.topology.Node object at 0x7fa46427ee50>]\n",
      "432 lambda_61 [<keras.engine.topology.Node object at 0x7fa4626abd10>]\n",
      "433 input_45 [<keras.engine.topology.Node object at 0x7fa4856e2cd0>]\n",
      "434 conv2d_214 [<keras.engine.topology.Node object at 0x7fa48d454a50>, <keras.engine.topology.Node object at 0x7fa4626a2dd0>, <keras.engine.topology.Node object at 0x7fa4626b8810>]\n",
      "435 input_46 [<keras.engine.topology.Node object at 0x7fa4856e2e90>]\n",
      "436 input_47 [<keras.engine.topology.Node object at 0x7fa485636090>]\n",
      "437 lambda_62 [<keras.engine.topology.Node object at 0x7fa4626b8510>, <keras.engine.topology.Node object at 0x7fa4624fea50>]\n",
      "438 lambda_63 [<keras.engine.topology.Node object at 0x7fa4624fefd0>, <keras.engine.topology.Node object at 0x7fa4624fec10>]\n",
      "439 lambda_64 [<keras.engine.topology.Node object at 0x7fa46250f0d0>, <keras.engine.topology.Node object at 0x7fa46250f810>]\n",
      "440 concatenate_103 [<keras.engine.topology.Node object at 0x7fa4625248d0>, <keras.engine.topology.Node object at 0x7fa462524b90>, <keras.engine.topology.Node object at 0x7fa4624b3f50>]\n",
      "441 input_48 [<keras.engine.topology.Node object at 0x7fa4856362d0>]\n",
      "442 input_49 [<keras.engine.topology.Node object at 0x7fa4856364d0>]\n",
      "443 input_50 [<keras.engine.topology.Node object at 0x7fa4856366d0>]\n",
      "444 lambda_65 [<keras.engine.topology.Node object at 0x7fa46250f990>, <keras.engine.topology.Node object at 0x7fa462524a90>]\n",
      "445 lambda_66 [<keras.engine.topology.Node object at 0x7fa4624b3a50>, <keras.engine.topology.Node object at 0x7fa4624c2650>]\n",
      "446 lambda_67 [<keras.engine.topology.Node object at 0x7fa4624c2b10>, <keras.engine.topology.Node object at 0x7fa4624c2810>]\n",
      "447 input_51 [<keras.engine.topology.Node object at 0x7fa4856368d0>]\n",
      "448 batch_normalization_129 [<keras.engine.topology.Node object at 0x7fa462483210>, <keras.engine.topology.Node object at 0x7fa462473850>, <keras.engine.topology.Node object at 0x7fa462432950>]\n",
      "449 input_52 [<keras.engine.topology.Node object at 0x7fa485636ad0>]\n",
      "450 input_53 [<keras.engine.topology.Node object at 0x7fa485636cd0>]\n",
      "451 lambda_68 [<keras.engine.topology.Node object at 0x7fa4623ad090>, <keras.engine.topology.Node object at 0x7fa4624e2c90>]\n",
      "452 lambda_69 [<keras.engine.topology.Node object at 0x7fa462483690>, <keras.engine.topology.Node object at 0x7fa46236d350>]\n",
      "453 lambda_70 [<keras.engine.topology.Node object at 0x7fa462411510>, <keras.engine.topology.Node object at 0x7fa4624117d0>]\n",
      "454 activation_217 [<keras.engine.topology.Node object at 0x7fa462339910>, <keras.engine.topology.Node object at 0x7fa462339750>, <keras.engine.topology.Node object at 0x7fa462339e90>]\n",
      "455 lambda_71 [<keras.engine.topology.Node object at 0x7fa46183fb50>]\n",
      "456 lambda_72 [<keras.engine.topology.Node object at 0x7fa46149cf10>]\n",
      "457 lambda_73 [<keras.engine.topology.Node object at 0x7fa460ce0b90>]\n",
      "458 input_54 [<keras.engine.topology.Node object at 0x7fa4856533d0>]\n",
      "459 conv2d_215 [<keras.engine.topology.Node object at 0x7fa48d454e50>, <keras.engine.topology.Node object at 0x7fa460d0de50>, <keras.engine.topology.Node object at 0x7fa461096790>]\n",
      "460 input_55 [<keras.engine.topology.Node object at 0x7fa485653590>]\n",
      "461 input_56 [<keras.engine.topology.Node object at 0x7fa485653750>]\n",
      "462 lambda_74 [<keras.engine.topology.Node object at 0x7fa461c0bf50>, <keras.engine.topology.Node object at 0x7fa46092dc50>]\n",
      "463 lambda_75 [<keras.engine.topology.Node object at 0x7fa46092df90>, <keras.engine.topology.Node object at 0x7fa460941850>]\n",
      "464 lambda_76 [<keras.engine.topology.Node object at 0x7fa460941dd0>, <keras.engine.topology.Node object at 0x7fa460941c50>]\n",
      "465 input_57 [<keras.engine.topology.Node object at 0x7fa485653950>]\n",
      "466 batch_normalization_130 [<keras.engine.topology.Node object at 0x7fa46090b0d0>, <keras.engine.topology.Node object at 0x7fa4608fb750>, <keras.engine.topology.Node object at 0x7fa4608d8150>]\n",
      "467 input_58 [<keras.engine.topology.Node object at 0x7fa485653b50>]\n",
      "468 input_59 [<keras.engine.topology.Node object at 0x7fa485653d50>]\n",
      "469 lambda_77 [<keras.engine.topology.Node object at 0x7fa4608bafd0>, <keras.engine.topology.Node object at 0x7fa46090b550>]\n",
      "470 lambda_78 [<keras.engine.topology.Node object at 0x7fa4608ebb90>, <keras.engine.topology.Node object at 0x7fa460898690>]\n",
      "471 lambda_79 [<keras.engine.topology.Node object at 0x7fa460898f10>, <keras.engine.topology.Node object at 0x7fa4608983d0>]\n",
      "472 activation_218 [<keras.engine.topology.Node object at 0x7fa4607bbcd0>, <keras.engine.topology.Node object at 0x7fa4607bb8d0>, <keras.engine.topology.Node object at 0x7fa4607c9790>]\n",
      "473 lambda_80 [<keras.engine.topology.Node object at 0x7fa4607bbf10>]\n",
      "474 lambda_81 [<keras.engine.topology.Node object at 0x7fa4607c9b90>]\n",
      "475 lambda_82 [<keras.engine.topology.Node object at 0x7fa460559cd0>]\n",
      "476 input_60 [<keras.engine.topology.Node object at 0x7fa485673310>]\n",
      "477 conv2d_216 [<keras.engine.topology.Node object at 0x7fa48d463590>, <keras.engine.topology.Node object at 0x7fa460799050>, <keras.engine.topology.Node object at 0x7fa460302750>]\n",
      "478 input_61 [<keras.engine.topology.Node object at 0x7fa4856734d0>]\n",
      "479 input_62 [<keras.engine.topology.Node object at 0x7fa485673690>]\n",
      "480 lambda_83 [<keras.engine.topology.Node object at 0x7fa4607c9dd0>, <keras.engine.topology.Node object at 0x7fa4607da6d0>]\n",
      "481 lambda_84 [<keras.engine.topology.Node object at 0x7fa46031ce10>, <keras.engine.topology.Node object at 0x7fa46031ced0>]\n",
      "482 lambda_85 [<keras.engine.topology.Node object at 0x7fa46031ca90>, <keras.engine.topology.Node object at 0x7fa4626abf50>]\n",
      "483 concatenate_104 [<keras.engine.topology.Node object at 0x7fa4601c0e90>, <keras.engine.topology.Node object at 0x7fa4601d0890>, <keras.engine.topology.Node object at 0x7fa4607a7e90>]\n",
      "484 input_63 [<keras.engine.topology.Node object at 0x7fa485673890>]\n",
      "485 input_64 [<keras.engine.topology.Node object at 0x7fa485673a90>]\n",
      "486 input_65 [<keras.engine.topology.Node object at 0x7fa485673c90>]\n",
      "487 lambda_86 [<keras.engine.topology.Node object at 0x7fa4601d0d90>, <keras.engine.topology.Node object at 0x7fa4601d0f10>]\n",
      "488 lambda_87 [<keras.engine.topology.Node object at 0x7fa4601dfc90>, <keras.engine.topology.Node object at 0x7fa4601df4d0>]\n",
      "489 lambda_88 [<keras.engine.topology.Node object at 0x7fa4601df610>, <keras.engine.topology.Node object at 0x7fa460175510>]\n",
      "490 input_66 [<keras.engine.topology.Node object at 0x7fa485673e90>]\n",
      "491 batch_normalization_131 [<keras.engine.topology.Node object at 0x7fa460125090>, <keras.engine.topology.Node object at 0x7fa460175f10>, <keras.engine.topology.Node object at 0x7fa4600f0110>]\n",
      "492 input_67 [<keras.engine.topology.Node object at 0x7fa4856820d0>]\n",
      "493 input_68 [<keras.engine.topology.Node object at 0x7fa4856822d0>]\n",
      "494 lambda_89 [<keras.engine.topology.Node object at 0x7fa460152f90>, <keras.engine.topology.Node object at 0x7fa460125510>]\n",
      "495 lambda_90 [<keras.engine.topology.Node object at 0x7fa460175e10>, <keras.engine.topology.Node object at 0x7fa4600b2650>]\n",
      "496 lambda_91 [<keras.engine.topology.Node object at 0x7fa4600b2ed0>, <keras.engine.topology.Node object at 0x7fa4600b2390>]\n",
      "497 activation_219 [<keras.engine.topology.Node object at 0x7fa460054d90>, <keras.engine.topology.Node object at 0x7fa460054890>, <keras.engine.topology.Node object at 0x7fa45ffe3e90>]\n",
      "498 lambda_92 [<keras.engine.topology.Node object at 0x7fa45f8ede90>]\n",
      "499 lambda_93 [<keras.engine.topology.Node object at 0x7fa45ffe3b50>]\n",
      "500 lambda_94 [<keras.engine.topology.Node object at 0x7fa45df36e90>]\n",
      "501 input_69 [<keras.engine.topology.Node object at 0x7fa4856829d0>]\n",
      "502 conv2d_217 [<keras.engine.topology.Node object at 0x7fa48d463990>, <keras.engine.topology.Node object at 0x7fa45ffe3d90>, <keras.engine.topology.Node object at 0x7fa45fff4650>]\n",
      "503 input_70 [<keras.engine.topology.Node object at 0x7fa485682b90>]\n",
      "504 input_71 [<keras.engine.topology.Node object at 0x7fa485682d90>]\n",
      "505 lambda_95 [<keras.engine.topology.Node object at 0x7fa45df62690>, <keras.engine.topology.Node object at 0x7fa45df62b50>]\n",
      "506 lambda_96 [<keras.engine.topology.Node object at 0x7fa45df62e50>, <keras.engine.topology.Node object at 0x7fa45def9710>]\n",
      "507 lambda_97 [<keras.engine.topology.Node object at 0x7fa45def9350>, <keras.engine.topology.Node object at 0x7fa4601ac050>]\n",
      "508 input_72 [<keras.engine.topology.Node object at 0x7fa485682f90>]\n",
      "509 batch_normalization_132 [<keras.engine.topology.Node object at 0x7fa45dec0090>, <keras.engine.topology.Node object at 0x7fa45df2f610>, <keras.engine.topology.Node object at 0x7fa45dec03d0>]\n",
      "510 input_73 [<keras.engine.topology.Node object at 0x7fa4856971d0>]\n",
      "511 input_74 [<keras.engine.topology.Node object at 0x7fa485697390>]\n",
      "512 lambda_98 [<keras.engine.topology.Node object at 0x7fa45deeff50>, <keras.engine.topology.Node object at 0x7fa45def9c90>]\n",
      "513 lambda_99 [<keras.engine.topology.Node object at 0x7fa45df0af90>, <keras.engine.topology.Node object at 0x7fa45de4f510>]\n",
      "514 lambda_100 [<keras.engine.topology.Node object at 0x7fa45de4fd90>, <keras.engine.topology.Node object at 0x7fa45de4f250>]\n",
      "515 activation_220 [<keras.engine.topology.Node object at 0x7fa45ddf1c50>, <keras.engine.topology.Node object at 0x7fa45ddf1dd0>, <keras.engine.topology.Node object at 0x7fa45ddf1750>]\n",
      "516 lambda_101 [<keras.engine.topology.Node object at 0x7fa45dd7fe90>]\n",
      "517 lambda_102 [<keras.engine.topology.Node object at 0x7fa46003fe90>]\n",
      "518 lambda_103 [<keras.engine.topology.Node object at 0x7fa45dd921d0>]\n",
      "519 input_75 [<keras.engine.topology.Node object at 0x7fa485697910>]\n",
      "520 conv2d_218 [<keras.engine.topology.Node object at 0x7fa48d463e90>, <keras.engine.topology.Node object at 0x7fa45dcf8e90>, <keras.engine.topology.Node object at 0x7fa45dd7fd10>]\n",
      "521 input_76 [<keras.engine.topology.Node object at 0x7fa485697ad0>]\n",
      "522 input_77 [<keras.engine.topology.Node object at 0x7fa485697c90>]\n",
      "523 lambda_104 [<keras.engine.topology.Node object at 0x7fa45dd35f10>, <keras.engine.topology.Node object at 0x7fa45dacef50>]\n",
      "524 lambda_105 [<keras.engine.topology.Node object at 0x7fa45dab6e50>, <keras.engine.topology.Node object at 0x7fa45dab6fd0>]\n",
      "525 lambda_106 [<keras.engine.topology.Node object at 0x7fa45dadf0d0>, <keras.engine.topology.Node object at 0x7fa45dadfad0>]\n",
      "526 concatenate_105 [<keras.engine.topology.Node object at 0x7fa45da73850>, <keras.engine.topology.Node object at 0x7fa45da73f10>, <keras.engine.topology.Node object at 0x7fa45da84ad0>]\n",
      "527 input_78 [<keras.engine.topology.Node object at 0x7fa485697e90>]\n",
      "528 input_79 [<keras.engine.topology.Node object at 0x7fa482451110>]\n",
      "529 input_80 [<keras.engine.topology.Node object at 0x7fa482451310>]\n",
      "530 lambda_107 [<keras.engine.topology.Node object at 0x7fa45dddded0>, <keras.engine.topology.Node object at 0x7fa45da84f50>]\n",
      "531 lambda_108 [<keras.engine.topology.Node object at 0x7fa45da93fd0>, <keras.engine.topology.Node object at 0x7fa45da93610>]\n",
      "532 lambda_109 [<keras.engine.topology.Node object at 0x7fa45da93e50>, <keras.engine.topology.Node object at 0x7fa45daa7810>]\n",
      "533 input_81 [<keras.engine.topology.Node object at 0x7fa482451510>]\n",
      "534 batch_normalization_133 [<keras.engine.topology.Node object at 0x7fa45da5b0d0>, <keras.engine.topology.Node object at 0x7fa45da93090>, <keras.engine.topology.Node object at 0x7fa45da5b410>]\n",
      "535 input_82 [<keras.engine.topology.Node object at 0x7fa48d652050>]\n",
      "536 input_83 [<keras.engine.topology.Node object at 0x7fa48d642c90>]\n",
      "537 lambda_110 [<keras.engine.topology.Node object at 0x7fa45da0bf90>, <keras.engine.topology.Node object at 0x7fa45da36b50>]\n",
      "538 lambda_111 [<keras.engine.topology.Node object at 0x7fa45d9e6310>, <keras.engine.topology.Node object at 0x7fa45d9e6e50>]\n",
      "539 lambda_112 [<keras.engine.topology.Node object at 0x7fa45d947d90>, <keras.engine.topology.Node object at 0x7fa45da36cd0>]\n",
      "540 activation_221 [<keras.engine.topology.Node object at 0x7fa45d8f5dd0>, <keras.engine.topology.Node object at 0x7fa45d908fd0>, <keras.engine.topology.Node object at 0x7fa45d9e65d0>]\n",
      "541 lambda_113 [<keras.engine.topology.Node object at 0x7fa45d0a2ed0>]\n",
      "542 lambda_114 [<keras.engine.topology.Node object at 0x7fa45da73c90>]\n",
      "543 lambda_115 [<keras.engine.topology.Node object at 0x7fa45d908590>]\n",
      "544 input_84 [<keras.engine.topology.Node object at 0x7fa482451a10>]\n",
      "545 conv2d_219 [<keras.engine.topology.Node object at 0x7fa48d4754d0>, <keras.engine.topology.Node object at 0x7fa45baeaf50>, <keras.engine.topology.Node object at 0x7fa45d919ed0>]\n",
      "546 input_85 [<keras.engine.topology.Node object at 0x7fa482451bd0>]\n",
      "547 input_86 [<keras.engine.topology.Node object at 0x7fa482451dd0>]\n",
      "548 lambda_116 [<keras.engine.topology.Node object at 0x7fa45d919f10>, <keras.engine.topology.Node object at 0x7fa45b70de50>]\n",
      "549 lambda_117 [<keras.engine.topology.Node object at 0x7fa45b720ed0>, <keras.engine.topology.Node object at 0x7fa45b720810>]\n",
      "550 lambda_118 [<keras.engine.topology.Node object at 0x7fa45b720d90>, <keras.engine.topology.Node object at 0x7fa45b733f10>]\n",
      "551 input_87 [<keras.engine.topology.Node object at 0x7fa48d657050>]\n",
      "552 batch_normalization_134 [<keras.engine.topology.Node object at 0x7fa45b6ec210>, <keras.engine.topology.Node object at 0x7fa45b6d7890>, <keras.engine.topology.Node object at 0x7fa45b69a950>]\n",
      "553 input_88 [<keras.engine.topology.Node object at 0x7fa48d657210>]\n",
      "554 input_89 [<keras.engine.topology.Node object at 0x7fa48d657410>]\n",
      "555 lambda_119 [<keras.engine.topology.Node object at 0x7fa45b614090>, <keras.engine.topology.Node object at 0x7fa45b6c8d90>]\n",
      "556 lambda_120 [<keras.engine.topology.Node object at 0x7fa45b6b5250>, <keras.engine.topology.Node object at 0x7fa45b6ec690>]\n",
      "557 lambda_121 [<keras.engine.topology.Node object at 0x7fa45b67a7d0>, <keras.engine.topology.Node object at 0x7fa45b67a510>]\n",
      "558 activation_222 [<keras.engine.topology.Node object at 0x7fa45b59e850>, <keras.engine.topology.Node object at 0x7fa45b59ef10>, <keras.engine.topology.Node object at 0x7fa45d908990>]\n",
      "559 lambda_122 [<keras.engine.topology.Node object at 0x7fa45b59ec50>]\n",
      "560 lambda_123 [<keras.engine.topology.Node object at 0x7fa45b5d7f50>]\n",
      "561 lambda_124 [<keras.engine.topology.Node object at 0x7fa45d947110>]\n",
      "562 input_90 [<keras.engine.topology.Node object at 0x7fa48d657910>]\n",
      "563 conv2d_220 [<keras.engine.topology.Node object at 0x7fa48d475bd0>, <keras.engine.topology.Node object at 0x7fa45b422e10>, <keras.engine.topology.Node object at 0x7fa45b5bc250>]\n",
      "564 input_91 [<keras.engine.topology.Node object at 0x7fa48d657ad0>]\n",
      "565 input_92 [<keras.engine.topology.Node object at 0x7fa48d657cd0>]\n",
      "566 lambda_125 [<keras.engine.topology.Node object at 0x7fa45b5bc610>, <keras.engine.topology.Node object at 0x7fa45b1e3a50>]\n",
      "567 lambda_126 [<keras.engine.topology.Node object at 0x7fa45b1faed0>, <keras.engine.topology.Node object at 0x7fa45b1fab90>]\n",
      "568 lambda_127 [<keras.engine.topology.Node object at 0x7fa45af8de10>, <keras.engine.topology.Node object at 0x7fa45af8d0d0>]\n",
      "569 concatenate_106 [<keras.engine.topology.Node object at 0x7fa45afa0b90>, <keras.engine.topology.Node object at 0x7fa45afa0a10>, <keras.engine.topology.Node object at 0x7fa45b1e3a10>]\n",
      "570 input_93 [<keras.engine.topology.Node object at 0x7fa48d657ed0>]\n",
      "571 input_94 [<keras.engine.topology.Node object at 0x7fa482469150>]\n",
      "572 input_95 [<keras.engine.topology.Node object at 0x7fa482469350>]\n",
      "573 lambda_128 [<keras.engine.topology.Node object at 0x7fa45afb3f50>, <keras.engine.topology.Node object at 0x7fa45afb3c90>]\n",
      "574 lambda_129 [<keras.engine.topology.Node object at 0x7fa45af44810>, <keras.engine.topology.Node object at 0x7fa45af44210>]\n",
      "575 lambda_130 [<keras.engine.topology.Node object at 0x7fa45af44b10>, <keras.engine.topology.Node object at 0x7fa45af44650>]\n",
      "576 input_96 [<keras.engine.topology.Node object at 0x7fa482469550>]\n",
      "577 batch_normalization_135 [<keras.engine.topology.Node object at 0x7fa45af071d0>, <keras.engine.topology.Node object at 0x7fa45af59e90>, <keras.engine.topology.Node object at 0x7fa45af37910>]\n",
      "578 input_97 [<keras.engine.topology.Node object at 0x7fa482469750>]\n",
      "579 input_98 [<keras.engine.topology.Node object at 0x7fa482469950>]\n",
      "580 lambda_131 [<keras.engine.topology.Node object at 0x7fa45aeb1050>, <keras.engine.topology.Node object at 0x7fa45af59b10>]\n",
      "581 lambda_132 [<keras.engine.topology.Node object at 0x7fa45aed1210>, <keras.engine.topology.Node object at 0x7fa45af07650>]\n",
      "582 lambda_133 [<keras.engine.topology.Node object at 0x7fa45ae91790>, <keras.engine.topology.Node object at 0x7fa45af77810>]\n",
      "583 activation_223 [<keras.engine.topology.Node object at 0x7fa45ae20fd0>, <keras.engine.topology.Node object at 0x7fa45ae70310>, <keras.engine.topology.Node object at 0x7fa45ae38e10>]\n",
      "584 lambda_134 [<keras.engine.topology.Node object at 0x7fa45b5f6090>]\n",
      "585 lambda_135 [<keras.engine.topology.Node object at 0x7fa45ae38750>]\n",
      "586 lambda_136 [<keras.engine.topology.Node object at 0x7fa45adc7f10>]\n",
      "587 input_99 [<keras.engine.topology.Node object at 0x7fa48247a050>]\n",
      "588 conv2d_221 [<keras.engine.topology.Node object at 0x7fa48d475fd0>, <keras.engine.topology.Node object at 0x7fa45add4110>, <keras.engine.topology.Node object at 0x7fa45add46d0>]\n",
      "589 input_100 [<keras.engine.topology.Node object at 0x7fa48247a210>]\n",
      "590 input_101 [<keras.engine.topology.Node object at 0x7fa48247a3d0>]\n",
      "591 lambda_137 [<keras.engine.topology.Node object at 0x7fa4589c1fd0>, <keras.engine.topology.Node object at 0x7fa4589c18d0>]\n",
      "592 lambda_138 [<keras.engine.topology.Node object at 0x7fa4589d5a10>, <keras.engine.topology.Node object at 0x7fa4589d5c10>]\n",
      "593 lambda_139 [<keras.engine.topology.Node object at 0x7fa4589d5c50>, <keras.engine.topology.Node object at 0x7fa4589c1210>]\n",
      "594 input_102 [<keras.engine.topology.Node object at 0x7fa48247a5d0>]\n",
      "595 batch_normalization_136 [<keras.engine.topology.Node object at 0x7fa458922450>, <keras.engine.topology.Node object at 0x7fa458993a90>, <keras.engine.topology.Node object at 0x7fa458956b90>]\n",
      "596 input_103 [<keras.engine.topology.Node object at 0x7fa48247a7d0>]\n",
      "597 input_104 [<keras.engine.topology.Node object at 0x7fa48247a9d0>]\n",
      "598 lambda_140 [<keras.engine.topology.Node object at 0x7fa4588cd2d0>, <keras.engine.topology.Node object at 0x7fa458982c10>]\n",
      "599 lambda_141 [<keras.engine.topology.Node object at 0x7fa4589228d0>, <keras.engine.topology.Node object at 0x7fa458890590>]\n",
      "600 lambda_142 [<keras.engine.topology.Node object at 0x7fa4588b0a10>, <keras.engine.topology.Node object at 0x7fa4588b0750>]\n",
      "601 activation_224 [<keras.engine.topology.Node object at 0x7fa45882c210>, <keras.engine.topology.Node object at 0x7fa4588549d0>, <keras.engine.topology.Node object at 0x7fa458854b50>]\n",
      "602 lambda_143 [<keras.engine.topology.Node object at 0x7fa45ae914d0>]\n",
      "603 lambda_144 [<keras.engine.topology.Node object at 0x7fa4587e5850>]\n",
      "604 lambda_145 [<keras.engine.topology.Node object at 0x7fa4587f6950>]\n",
      "605 input_105 [<keras.engine.topology.Node object at 0x7fa48247af50>]\n",
      "606 conv2d_222 [<keras.engine.topology.Node object at 0x7fa482510710>, <keras.engine.topology.Node object at 0x7fa4587f6390>, <keras.engine.topology.Node object at 0x7fa45879cf10>]\n",
      "607 input_106 [<keras.engine.topology.Node object at 0x7fa482412150>]\n",
      "608 input_107 [<keras.engine.topology.Node object at 0x7fa482412310>]\n",
      "609 lambda_146 [<keras.engine.topology.Node object at 0x7fa458533f90>, <keras.engine.topology.Node object at 0x7fa45851cc90>]\n",
      "610 lambda_147 [<keras.engine.topology.Node object at 0x7fa458533dd0>, <keras.engine.topology.Node object at 0x7fa458544790>]\n",
      "611 lambda_148 [<keras.engine.topology.Node object at 0x7fa458544ed0>, <keras.engine.topology.Node object at 0x7fa4585447d0>]\n",
      "612 concatenate_107 [<keras.engine.topology.Node object at 0x7fa458557c50>, <keras.engine.topology.Node object at 0x7fa458557dd0>, <keras.engine.topology.Node object at 0x7fa458557750>]\n",
      "613 input_108 [<keras.engine.topology.Node object at 0x7fa482412510>]\n",
      "614 input_109 [<keras.engine.topology.Node object at 0x7fa482412750>]\n",
      "615 input_110 [<keras.engine.topology.Node object at 0x7fa482412950>]\n",
      "616 lambda_149 [<keras.engine.topology.Node object at 0x7fa4584ebc50>, <keras.engine.topology.Node object at 0x7fa4584ebad0>]\n",
      "617 lambda_150 [<keras.engine.topology.Node object at 0x7fa4584fba50>, <keras.engine.topology.Node object at 0x7fa4588f0490>]\n",
      "618 lambda_151 [<keras.engine.topology.Node object at 0x7fa45850cbd0>, <keras.engine.topology.Node object at 0x7fa4584fb450>]\n",
      "619 input_111 [<keras.engine.topology.Node object at 0x7fa482412b50>]\n",
      "620 batch_normalization_137 [<keras.engine.topology.Node object at 0x7fa4584be410>, <keras.engine.topology.Node object at 0x7fa4584fb890>, <keras.engine.topology.Node object at 0x7fa45846eb50>]\n",
      "621 input_112 [<keras.engine.topology.Node object at 0x7fa482412d50>]\n",
      "622 input_113 [<keras.engine.topology.Node object at 0x7fa482412f50>]\n",
      "623 lambda_152 [<keras.engine.topology.Node object at 0x7fa4583e6290>, <keras.engine.topology.Node object at 0x7fa4584fb5d0>]\n",
      "624 lambda_153 [<keras.engine.topology.Node object at 0x7fa4584be890>, <keras.engine.topology.Node object at 0x7fa45844d710>]\n",
      "625 lambda_154 [<keras.engine.topology.Node object at 0x7fa4583c61d0>, <keras.engine.topology.Node object at 0x7fa45844d9d0>]\n",
      "626 activation_225 [<keras.engine.topology.Node object at 0x7fa458372990>, <keras.engine.topology.Node object at 0x7fa458372b10>, <keras.engine.topology.Node object at 0x7fa458372c10>]\n",
      "627 lambda_155 [<keras.engine.topology.Node object at 0x7fa458383810>]\n",
      "628 lambda_156 [<keras.engine.topology.Node object at 0x7fa458394910>]\n",
      "629 lambda_157 [<keras.engine.topology.Node object at 0x7fa458383990>]\n",
      "630 input_114 [<keras.engine.topology.Node object at 0x7fa48242c650>]\n",
      "631 conv2d_223 [<keras.engine.topology.Node object at 0x7fa482510b10>, <keras.engine.topology.Node object at 0x7fa4562df6d0>, <keras.engine.topology.Node object at 0x7fa458394350>]\n",
      "632 input_115 [<keras.engine.topology.Node object at 0x7fa48242c810>]\n",
      "633 input_116 [<keras.engine.topology.Node object at 0x7fa48242ca10>]\n",
      "634 lambda_158 [<keras.engine.topology.Node object at 0x7fa457c1fbd0>, <keras.engine.topology.Node object at 0x7fa457c06e90>]\n",
      "635 lambda_159 [<keras.engine.topology.Node object at 0x7fa455f12f10>, <keras.engine.topology.Node object at 0x7fa455f12310>]\n",
      "636 lambda_160 [<keras.engine.topology.Node object at 0x7fa455f12c90>, <keras.engine.topology.Node object at 0x7fa455f26f90>]\n",
      "637 input_117 [<keras.engine.topology.Node object at 0x7fa48242cbd0>]\n",
      "638 batch_normalization_138 [<keras.engine.topology.Node object at 0x7fa455ede690>, <keras.engine.topology.Node object at 0x7fa455ecfd10>, <keras.engine.topology.Node object at 0x7fa455e8ddd0>]\n",
      "639 input_118 [<keras.engine.topology.Node object at 0x7fa48242cdd0>]\n",
      "640 input_119 [<keras.engine.topology.Node object at 0x7fa482442110>]\n",
      "641 lambda_161 [<keras.engine.topology.Node object at 0x7fa455e06510>, <keras.engine.topology.Node object at 0x7fa455d7af10>]\n",
      "642 lambda_162 [<keras.engine.topology.Node object at 0x7fa455ea86d0>, <keras.engine.topology.Node object at 0x7fa455edeb10>]\n",
      "643 lambda_163 [<keras.engine.topology.Node object at 0x7fa455e6bc50>, <keras.engine.topology.Node object at 0x7fa455e6b990>]\n",
      "644 activation_226 [<keras.engine.topology.Node object at 0x7fa455d8fd90>, <keras.engine.topology.Node object at 0x7fa455d8fc10>, <keras.engine.topology.Node object at 0x7fa455d9fe90>]\n",
      "645 lambda_164 [<keras.engine.topology.Node object at 0x7fa455d8fe90>]\n",
      "646 lambda_165 [<keras.engine.topology.Node object at 0x7fa455de53d0>]\n",
      "647 lambda_166 [<keras.engine.topology.Node object at 0x7fa455d9fa90>]\n",
      "648 input_120 [<keras.engine.topology.Node object at 0x7fa482442590>]\n",
      "649 conv2d_224 [<keras.engine.topology.Node object at 0x7fa482524250>, <keras.engine.topology.Node object at 0x7fa455d31450>, <keras.engine.topology.Node object at 0x7fa455d31b90>]\n",
      "650 input_121 [<keras.engine.topology.Node object at 0x7fa482442750>]\n",
      "651 input_122 [<keras.engine.topology.Node object at 0x7fa482442950>]\n",
      "652 lambda_167 [<keras.engine.topology.Node object at 0x7fa455bece50>, <keras.engine.topology.Node object at 0x7fa455beced0>]\n",
      "653 lambda_168 [<keras.engine.topology.Node object at 0x7fa455bd5e90>, <keras.engine.topology.Node object at 0x7fa45597e9d0>]\n",
      "654 lambda_169 [<keras.engine.topology.Node object at 0x7fa45597e550>, <keras.engine.topology.Node object at 0x7fa45597e8d0>]\n",
      "655 concatenate_108 [<keras.engine.topology.Node object at 0x7fa455990b10>, <keras.engine.topology.Node object at 0x7fa455990e90>, <keras.engine.topology.Node object at 0x7fa455990e10>]\n",
      "656 input_123 [<keras.engine.topology.Node object at 0x7fa482442b50>]\n",
      "657 input_124 [<keras.engine.topology.Node object at 0x7fa482442d50>]\n",
      "658 input_125 [<keras.engine.topology.Node object at 0x7fa482442f50>]\n",
      "659 lambda_170 [<keras.engine.topology.Node object at 0x7fa455bd5ed0>, <keras.engine.topology.Node object at 0x7fa4559a5d50>]\n",
      "660 lambda_171 [<keras.engine.topology.Node object at 0x7fa455935b50>, <keras.engine.topology.Node object at 0x7fa455948fd0>]\n",
      "661 lambda_172 [<keras.engine.topology.Node object at 0x7fa455935fd0>, <keras.engine.topology.Node object at 0x7fa455935890>]\n",
      "662 input_126 [<keras.engine.topology.Node object at 0x7fa47c72a190>]\n",
      "663 batch_normalization_139 [<keras.engine.topology.Node object at 0x7fa4558fb650>, <keras.engine.topology.Node object at 0x7fa455935cd0>, <keras.engine.topology.Node object at 0x7fa455928d90>]\n",
      "664 input_127 [<keras.engine.topology.Node object at 0x7fa47c72a390>]\n",
      "665 input_128 [<keras.engine.topology.Node object at 0x7fa47c72a590>]\n",
      "666 lambda_173 [<keras.engine.topology.Node object at 0x7fa4558a44d0>, <keras.engine.topology.Node object at 0x7fa455815ed0>]\n",
      "667 lambda_174 [<keras.engine.topology.Node object at 0x7fa4558c1690>, <keras.engine.topology.Node object at 0x7fa4558fbad0>]\n",
      "668 lambda_175 [<keras.engine.topology.Node object at 0x7fa455888950>, <keras.engine.topology.Node object at 0x7fa455888c10>]\n",
      "669 activation_227 [<keras.engine.topology.Node object at 0x7fa45582bd50>, <keras.engine.topology.Node object at 0x7fa45582bbd0>, <keras.engine.topology.Node object at 0x7fa4557bbe50>]\n",
      "670 lambda_176 [<keras.engine.topology.Node object at 0x7fa45597e990>]\n",
      "671 lambda_177 [<keras.engine.topology.Node object at 0x7fa4559356d0>]\n",
      "672 lambda_178 [<keras.engine.topology.Node object at 0x7fa4557bba50>]\n",
      "673 input_129 [<keras.engine.topology.Node object at 0x7fa47c72ac50>]\n",
      "674 conv2d_225 [<keras.engine.topology.Node object at 0x7fa482524650>, <keras.engine.topology.Node object at 0x7fa4533a0950>, <keras.engine.topology.Node object at 0x7fa4557cb590>]\n",
      "675 input_130 [<keras.engine.topology.Node object at 0x7fa47c72ae10>]\n",
      "676 input_131 [<keras.engine.topology.Node object at 0x7fa47c739050>]\n",
      "677 lambda_179 [<keras.engine.topology.Node object at 0x7fa4557cb910>, <keras.engine.topology.Node object at 0x7fa45334ac90>]\n",
      "678 lambda_180 [<keras.engine.topology.Node object at 0x7fa45334acd0>, <keras.engine.topology.Node object at 0x7fa4557bbbd0>]\n",
      "679 lambda_181 [<keras.engine.topology.Node object at 0x7fa45334ae90>, <keras.engine.topology.Node object at 0x7fa45334a310>]\n",
      "680 input_132 [<keras.engine.topology.Node object at 0x7fa47c739250>]\n",
      "681 batch_normalization_140 [<keras.engine.topology.Node object at 0x7fa45332e310>, <keras.engine.topology.Node object at 0x7fa453385f50>, <keras.engine.topology.Node object at 0x7fa453347f50>]\n",
      "682 input_133 [<keras.engine.topology.Node object at 0x7fa47c739450>]\n",
      "683 input_134 [<keras.engine.topology.Node object at 0x7fa47c739650>]\n",
      "684 lambda_182 [<keras.engine.topology.Node object at 0x7fa4532be750>, <keras.engine.topology.Node object at 0x7fa453375c90>]\n",
      "685 lambda_183 [<keras.engine.topology.Node object at 0x7fa4532df910>, <keras.engine.topology.Node object at 0x7fa453316d50>]\n",
      "686 lambda_184 [<keras.engine.topology.Node object at 0x7fa4532a5e90>, <keras.engine.topology.Node object at 0x7fa4532a5bd0>]\n",
      "687 activation_228 [<keras.engine.topology.Node object at 0x7fa4531cae50>, <keras.engine.topology.Node object at 0x7fa4531d9810>, <keras.engine.topology.Node object at 0x7fa45334a550>]\n",
      "688 lambda_185 [<keras.engine.topology.Node object at 0x7fa4531cab10>]\n",
      "689 lambda_186 [<keras.engine.topology.Node object at 0x7fa4531d9d10>]\n",
      "690 lambda_187 [<keras.engine.topology.Node object at 0x7fa4531d9e90>]\n",
      "691 input_135 [<keras.engine.topology.Node object at 0x7fa47c739c50>]\n",
      "692 conv2d_226 [<keras.engine.topology.Node object at 0x7fa482524d50>, <keras.engine.topology.Node object at 0x7fa4531e9c50>, <keras.engine.topology.Node object at 0x7fa4531e9850>]\n",
      "693 input_136 [<keras.engine.topology.Node object at 0x7fa47c739d90>]\n",
      "694 input_137 [<keras.engine.topology.Node object at 0x7fa47c739f50>]\n",
      "695 lambda_188 [<keras.engine.topology.Node object at 0x7fa4531e9b50>, <keras.engine.topology.Node object at 0x7fa452e24910>]\n",
      "696 lambda_189 [<keras.engine.topology.Node object at 0x7fa452e24fd0>, <keras.engine.topology.Node object at 0x7fa452e39bd0>]\n",
      "697 lambda_190 [<keras.engine.topology.Node object at 0x7fa452e39c10>, <keras.engine.topology.Node object at 0x7fa452e24790>]\n",
      "698 concatenate_109 [<keras.engine.topology.Node object at 0x7fa452e49d50>, <keras.engine.topology.Node object at 0x7fa452cdef50>, <keras.engine.topology.Node object at 0x7fa452e39590>]\n",
      "699 input_138 [<keras.engine.topology.Node object at 0x7fa47c752190>]\n",
      "700 input_139 [<keras.engine.topology.Node object at 0x7fa47c752350>]\n",
      "701 input_140 [<keras.engine.topology.Node object at 0x7fa47c752590>]\n",
      "702 lambda_191 [<keras.engine.topology.Node object at 0x7fa452cdebd0>, <keras.engine.topology.Node object at 0x7fa452cdea90>]\n",
      "703 lambda_192 [<keras.engine.topology.Node object at 0x7fa452cefed0>, <keras.engine.topology.Node object at 0x7fa452cef8d0>]\n",
      "704 lambda_193 [<keras.engine.topology.Node object at 0x7fa452cffb10>, <keras.engine.topology.Node object at 0x7fa452cefa90>]\n",
      "705 input_141 [<keras.engine.topology.Node object at 0x7fa47c752790>]\n",
      "706 batch_normalization_141 [<keras.engine.topology.Node object at 0x7fa452cb1890>, <keras.engine.topology.Node object at 0x7fa452ca3ed0>, <keras.engine.topology.Node object at 0x7fa452c62fd0>]\n",
      "707 input_142 [<keras.engine.topology.Node object at 0x7fa47c752990>]\n",
      "708 input_143 [<keras.engine.topology.Node object at 0x7fa47c752b90>]\n",
      "709 lambda_194 [<keras.engine.topology.Node object at 0x7fa452bd9710>, <keras.engine.topology.Node object at 0x7fa452c91e10>]\n",
      "710 lambda_195 [<keras.engine.topology.Node object at 0x7fa452cb1d10>, <keras.engine.topology.Node object at 0x7fa452b9c9d0>]\n",
      "711 lambda_196 [<keras.engine.topology.Node object at 0x7fa452c40b90>, <keras.engine.topology.Node object at 0x7fa452c40e50>]\n",
      "712 activation_229 [<keras.engine.topology.Node object at 0x7fa452b66f90>, <keras.engine.topology.Node object at 0x7fa452b66e10>, <keras.engine.topology.Node object at 0x7fa452b767d0>]\n",
      "713 lambda_197 [<keras.engine.topology.Node object at 0x7fa452b66950>]\n",
      "714 lambda_198 [<keras.engine.topology.Node object at 0x7fa452b86d90>]\n",
      "715 lambda_199 [<keras.engine.topology.Node object at 0x7fa452b86b50>]\n",
      "716 input_144 [<keras.engine.topology.Node object at 0x7fa47c6eb290>]\n",
      "717 conv2d_227 [<keras.engine.topology.Node object at 0x7fa482534190>, <keras.engine.topology.Node object at 0x7fa450548250>, <keras.engine.topology.Node object at 0x7fa452b86a50>]\n",
      "718 input_145 [<keras.engine.topology.Node object at 0x7fa47c6eb450>]\n",
      "719 input_146 [<keras.engine.topology.Node object at 0x7fa47c6eb650>]\n",
      "720 lambda_200 [<keras.engine.topology.Node object at 0x7fa452b76c90>, <keras.engine.topology.Node object at 0x7fa45055e550>]\n",
      "721 lambda_201 [<keras.engine.topology.Node object at 0x7fa45055ee90>, <keras.engine.topology.Node object at 0x7fa45055edd0>]\n",
      "722 lambda_202 [<keras.engine.topology.Node object at 0x7fa450576190>, <keras.engine.topology.Node object at 0x7fa450576b50>]\n",
      "723 input_147 [<keras.engine.topology.Node object at 0x7fa47c6eb810>]\n",
      "724 batch_normalization_142 [<keras.engine.topology.Node object at 0x7fa4504c0550>, <keras.engine.topology.Node object at 0x7fa45051bb50>, <keras.engine.topology.Node object at 0x7fa450529fd0>]\n",
      "725 input_148 [<keras.engine.topology.Node object at 0x7fa47c6eba10>]\n",
      "726 input_149 [<keras.engine.topology.Node object at 0x7fa47c6ebc50>]\n",
      "727 lambda_203 [<keras.engine.topology.Node object at 0x7fa45044c990>, <keras.engine.topology.Node object at 0x7fa4504ecb50>]\n",
      "728 lambda_204 [<keras.engine.topology.Node object at 0x7fa45050b8d0>, <keras.engine.topology.Node object at 0x7fa450417c50>]\n",
      "729 lambda_205 [<keras.engine.topology.Node object at 0x7fa4504b6e10>, <keras.engine.topology.Node object at 0x7fa4504b6f50>]\n",
      "730 activation_230 [<keras.engine.topology.Node object at 0x7fa4503dbb90>, <keras.engine.topology.Node object at 0x7fa4503dbd10>, <keras.engine.topology.Node object at 0x7fa4503eef10>]\n",
      "731 lambda_206 [<keras.engine.topology.Node object at 0x7fa452cefa50>]\n",
      "732 lambda_207 [<keras.engine.topology.Node object at 0x7fa45037fcd0>]\n",
      "733 lambda_208 [<keras.engine.topology.Node object at 0x7fa4503eeb90>]\n",
      "734 input_150 [<keras.engine.topology.Node object at 0x7fa47c70d1d0>]\n",
      "735 conv2d_228 [<keras.engine.topology.Node object at 0x7fa482534890>, <keras.engine.topology.Node object at 0x7fa45037fdd0>, <keras.engine.topology.Node object at 0x7fa4503b8d90>]\n",
      "736 input_151 [<keras.engine.topology.Node object at 0x7fa47c70d450>]\n",
      "737 input_152 [<keras.engine.topology.Node object at 0x7fa47c70d590>]\n",
      "738 lambda_209 [<keras.engine.topology.Node object at 0x7fa450036b50>, <keras.engine.topology.Node object at 0x7fa4500369d0>]\n",
      "739 lambda_210 [<keras.engine.topology.Node object at 0x7fa450036ed0>, <keras.engine.topology.Node object at 0x7fa44fdcdad0>]\n",
      "740 lambda_211 [<keras.engine.topology.Node object at 0x7fa45037f890>, <keras.engine.topology.Node object at 0x7fa44fdcde50>]\n",
      "741 concatenate_110 [<keras.engine.topology.Node object at 0x7fa44fddbe10>, <keras.engine.topology.Node object at 0x7fa44fddbf90>, <keras.engine.topology.Node object at 0x7fa450036790>]\n",
      "742 input_153 [<keras.engine.topology.Node object at 0x7fa47c70d850>]\n",
      "743 input_154 [<keras.engine.topology.Node object at 0x7fa47c70d990>]\n",
      "744 input_155 [<keras.engine.topology.Node object at 0x7fa47c70db90>]\n",
      "745 lambda_212 [<keras.engine.topology.Node object at 0x7fa44fdf2e50>, <keras.engine.topology.Node object at 0x7fa44fdf2a10>]\n",
      "746 lambda_213 [<keras.engine.topology.Node object at 0x7fa44fd82cd0>, <keras.engine.topology.Node object at 0x7fa44fd82f50>]\n",
      "747 lambda_214 [<keras.engine.topology.Node object at 0x7fa44fd82c50>, <keras.engine.topology.Node object at 0x7fa44fd90950>]\n",
      "748 input_156 [<keras.engine.topology.Node object at 0x7fa47c70dd90>]\n",
      "749 batch_normalization_143 [<keras.engine.topology.Node object at 0x7fa44fd45ad0>, <keras.engine.topology.Node object at 0x7fa44fd45f50>, <keras.engine.topology.Node object at 0x7fa44fd71f50>]\n",
      "750 input_157 [<keras.engine.topology.Node object at 0x7fa47c70df90>]\n",
      "751 input_158 [<keras.engine.topology.Node object at 0x7fa47c69c1d0>]\n",
      "752 lambda_215 [<keras.engine.topology.Node object at 0x7fa44fce7950>, <keras.engine.topology.Node object at 0x7fa44fdb5650>]\n",
      "753 lambda_216 [<keras.engine.topology.Node object at 0x7fa44fd5a090>, <keras.engine.topology.Node object at 0x7fa44fcadc10>]\n",
      "754 lambda_217 [<keras.engine.topology.Node object at 0x7fa44fccfdd0>, <keras.engine.topology.Node object at 0x7fa44fccffd0>]\n",
      "755 activation_231 [<keras.engine.topology.Node object at 0x7fa44fc72910>, <keras.engine.topology.Node object at 0x7fa44fc72d10>, <keras.engine.topology.Node object at 0x7fa44fc08ed0>]\n",
      "756 lambda_218 [<keras.engine.topology.Node object at 0x7fa44fdcd7d0>]\n",
      "757 lambda_219 [<keras.engine.topology.Node object at 0x7fa44fc08a10>]\n",
      "758 lambda_220 [<keras.engine.topology.Node object at 0x7fa44d718dd0>]\n",
      "759 input_159 [<keras.engine.topology.Node object at 0x7fa47c69c890>]\n",
      "760 conv2d_229 [<keras.engine.topology.Node object at 0x7fa482534c90>, <keras.engine.topology.Node object at 0x7fa44fc17a10>, <keras.engine.topology.Node object at 0x7fa44fc17d90>]\n",
      "761 input_160 [<keras.engine.topology.Node object at 0x7fa47c69ca50>]\n",
      "762 input_161 [<keras.engine.topology.Node object at 0x7fa47c69cc50>]\n",
      "763 lambda_221 [<keras.engine.topology.Node object at 0x7fa44d4af790>, <keras.engine.topology.Node object at 0x7fa44d4af9d0>]\n",
      "764 lambda_222 [<keras.engine.topology.Node object at 0x7fa44d4afcd0>, <keras.engine.topology.Node object at 0x7fa44d4affd0>]\n",
      "765 lambda_223 [<keras.engine.topology.Node object at 0x7fa44d4c6590>, <keras.engine.topology.Node object at 0x7fa44d4d7bd0>]\n",
      "766 input_162 [<keras.engine.topology.Node object at 0x7fa47c69ce50>]\n",
      "767 batch_normalization_144 [<keras.engine.topology.Node object at 0x7fa44d47bd50>, <keras.engine.topology.Node object at 0x7fa44d46bfd0>, <keras.engine.topology.Node object at 0x7fa44d48d210>]\n",
      "768 input_163 [<keras.engine.topology.Node object at 0x7fa47c6af090>]\n",
      "769 input_164 [<keras.engine.topology.Node object at 0x7fa47c6af290>]\n",
      "770 lambda_224 [<keras.engine.topology.Node object at 0x7fa44d43ed90>, <keras.engine.topology.Node object at 0x7fa44d4c6dd0>]\n",
      "771 lambda_225 [<keras.engine.topology.Node object at 0x7fa44d4c65d0>, <keras.engine.topology.Node object at 0x7fa44d41c350>]\n",
      "772 lambda_226 [<keras.engine.topology.Node object at 0x7fa44d41c050>, <keras.engine.topology.Node object at 0x7fa44d3a6f90>]\n",
      "773 activation_232 [<keras.engine.topology.Node object at 0x7fa44d41cbd0>, <keras.engine.topology.Node object at 0x7fa44d37ab10>, <keras.engine.topology.Node object at 0x7fa44d3e0e10>]\n",
      "774 lambda_227 [<keras.engine.topology.Node object at 0x7fa44fd0a250>]\n",
      "775 lambda_228 [<keras.engine.topology.Node object at 0x7fa44d33ca10>]\n",
      "776 lambda_229 [<keras.engine.topology.Node object at 0x7fa44d33ce10>]\n",
      "777 input_165 [<keras.engine.topology.Node object at 0x7fa47c6af790>]\n",
      "778 conv2d_230 [<keras.engine.topology.Node object at 0x7fa4825473d0>, <keras.engine.topology.Node object at 0x7fa44d34df10>, <keras.engine.topology.Node object at 0x7fa44d34dc90>]\n",
      "779 input_166 [<keras.engine.topology.Node object at 0x7fa47c6af990>]\n",
      "780 input_167 [<keras.engine.topology.Node object at 0x7fa47c6afb50>]\n",
      "781 lambda_230 [<keras.engine.topology.Node object at 0x7fa44d099f90>, <keras.engine.topology.Node object at 0x7fa44d099c10>]\n",
      "782 lambda_231 [<keras.engine.topology.Node object at 0x7fa44d34dad0>, <keras.engine.topology.Node object at 0x7fa44d084bd0>]\n",
      "783 lambda_232 [<keras.engine.topology.Node object at 0x7fa44d0845d0>, <keras.engine.topology.Node object at 0x7fa44d099a10>]\n",
      "784 concatenate_111 [<keras.engine.topology.Node object at 0x7fa44cf2add0>, <keras.engine.topology.Node object at 0x7fa44cf43dd0>, <keras.engine.topology.Node object at 0x7fa44cf43ed0>]\n",
      "785 input_168 [<keras.engine.topology.Node object at 0x7fa47c6afe50>]\n",
      "786 input_169 [<keras.engine.topology.Node object at 0x7fa47c6aff90>]\n",
      "787 input_170 [<keras.engine.topology.Node object at 0x7fa47c6ca1d0>]\n",
      "788 lambda_233 [<keras.engine.topology.Node object at 0x7fa44d084d50>, <keras.engine.topology.Node object at 0x7fa44d084e50>]\n",
      "789 lambda_234 [<keras.engine.topology.Node object at 0x7fa44cf54d50>, <keras.engine.topology.Node object at 0x7fa44cf54ed0>]\n",
      "790 lambda_235 [<keras.engine.topology.Node object at 0x7fa44cf63d10>, <keras.engine.topology.Node object at 0x7fa44cef7e10>]\n",
      "791 input_171 [<keras.engine.topology.Node object at 0x7fa47c6ca3d0>]\n",
      "792 batch_normalization_145 [<keras.engine.topology.Node object at 0x7fa44cf16d10>, <keras.engine.topology.Node object at 0x7fa44cf05f50>, <keras.engine.topology.Node object at 0x7fa44cf291d0>]\n",
      "793 input_172 [<keras.engine.topology.Node object at 0x7fa47c6ca5d0>]\n",
      "794 input_173 [<keras.engine.topology.Node object at 0x7fa47c6ca7d0>]\n",
      "795 lambda_236 [<keras.engine.topology.Node object at 0x7fa44cea2ed0>, <keras.engine.topology.Node object at 0x7fa44ced8d50>]\n",
      "796 lambda_237 [<keras.engine.topology.Node object at 0x7fa44cf63b90>, <keras.engine.topology.Node object at 0x7fa44cdfde50>]\n",
      "797 lambda_238 [<keras.engine.topology.Node object at 0x7fa44ce38b90>, <keras.engine.topology.Node object at 0x7fa44ce38310>]\n",
      "798 activation_233 [<keras.engine.topology.Node object at 0x7fa44cdc2f10>, <keras.engine.topology.Node object at 0x7fa44cdc2d90>, <keras.engine.topology.Node object at 0x7fa44cf63f90>]\n",
      "799 lambda_239 [<keras.engine.topology.Node object at 0x7fa44cca2ad0>]\n",
      "800 lambda_240 [<keras.engine.topology.Node object at 0x7fa44b682e10>]\n",
      "801 lambda_241 [<keras.engine.topology.Node object at 0x7fa44aa4ffd0>]\n",
      "802 input_174 [<keras.engine.topology.Node object at 0x7fa47c6cae90>]\n",
      "803 conv2d_231 [<keras.engine.topology.Node object at 0x7fa4825477d0>, <keras.engine.topology.Node object at 0x7fa44cde8ed0>, <keras.engine.topology.Node object at 0x7fa44cde8fd0>]\n",
      "804 input_175 [<keras.engine.topology.Node object at 0x7fa47c675090>]\n",
      "805 input_176 [<keras.engine.topology.Node object at 0x7fa47c675250>]\n",
      "806 lambda_242 [<keras.engine.topology.Node object at 0x7fa44a43f710>, <keras.engine.topology.Node object at 0x7fa44a43fc50>]\n",
      "807 lambda_243 [<keras.engine.topology.Node object at 0x7fa44a43ff50>, <keras.engine.topology.Node object at 0x7fa44a457810>]\n",
      "808 lambda_244 [<keras.engine.topology.Node object at 0x7fa44a457f50>, <keras.engine.topology.Node object at 0x7fa44a3e97d0>]\n",
      "809 input_177 [<keras.engine.topology.Node object at 0x7fa47c675450>]\n",
      "810 batch_normalization_146 [<keras.engine.topology.Node object at 0x7fa44a3a00d0>, <keras.engine.topology.Node object at 0x7fa44a4577d0>, <keras.engine.topology.Node object at 0x7fa44a36a050>]\n",
      "811 input_178 [<keras.engine.topology.Node object at 0x7fa47c675690>]\n",
      "812 input_179 [<keras.engine.topology.Node object at 0x7fa47c675850>]\n",
      "813 lambda_245 [<keras.engine.topology.Node object at 0x7fa44a3cffd0>, <keras.engine.topology.Node object at 0x7fa44a3a0450>]\n",
      "814 lambda_246 [<keras.engine.topology.Node object at 0x7fa44a32e2d0>, <keras.engine.topology.Node object at 0x7fa44a32ee10>]\n",
      "815 lambda_247 [<keras.engine.topology.Node object at 0x7fa44a309d50>, <keras.engine.topology.Node object at 0x7fa44a3fcb50>]\n",
      "816 activation_234 [<keras.engine.topology.Node object at 0x7fa44a2cd550>, <keras.engine.topology.Node object at 0x7fa44a32e590>, <keras.engine.topology.Node object at 0x7fa44a2cded0>]\n",
      "817 lambda_248 [<keras.engine.topology.Node object at 0x7fa44a25fed0>]\n",
      "818 lambda_249 [<keras.engine.topology.Node object at 0x7fa44ce16ad0>]\n",
      "819 lambda_250 [<keras.engine.topology.Node object at 0x7fa44a283bd0>]\n",
      "820 input_180 [<keras.engine.topology.Node object at 0x7fa47c675e90>]\n",
      "821 conv2d_232 [<keras.engine.topology.Node object at 0x7fa482547ed0>, <keras.engine.topology.Node object at 0x7fa44a258bd0>, <keras.engine.topology.Node object at 0x7fa44a25fd10>]\n",
      "822 input_181 [<keras.engine.topology.Node object at 0x7fa47c671050>]\n",
      "823 input_182 [<keras.engine.topology.Node object at 0x7fa47c6711d0>]\n",
      "824 lambda_251 [<keras.engine.topology.Node object at 0x7fa44a293b50>, <keras.engine.topology.Node object at 0x7fa449daee50>]\n",
      "825 lambda_252 [<keras.engine.topology.Node object at 0x7fa449daeed0>, <keras.engine.topology.Node object at 0x7fa449daef50>]\n",
      "826 lambda_253 [<keras.engine.topology.Node object at 0x7fa449dbd750>, <keras.engine.topology.Node object at 0x7fa449dbd050>]\n",
      "827 concatenate_112 [<keras.engine.topology.Node object at 0x7fa449dd2950>, <keras.engine.topology.Node object at 0x7fa44a015fd0>, <keras.engine.topology.Node object at 0x7fa449dd27d0>]\n",
      "828 input_183 [<keras.engine.topology.Node object at 0x7fa47c6713d0>]\n",
      "829 input_184 [<keras.engine.topology.Node object at 0x7fa47c6715d0>]\n",
      "830 input_185 [<keras.engine.topology.Node object at 0x7fa47c671790>]\n",
      "831 lambda_254 [<keras.engine.topology.Node object at 0x7fa449dd2e50>, <keras.engine.topology.Node object at 0x7fa449d63650>]\n",
      "832 lambda_255 [<keras.engine.topology.Node object at 0x7fa449d74f50>, <keras.engine.topology.Node object at 0x7fa449d745d0>]\n",
      "833 lambda_256 [<keras.engine.topology.Node object at 0x7fa449d74dd0>, <keras.engine.topology.Node object at 0x7fa449d748d0>]\n",
      "834 input_186 [<keras.engine.topology.Node object at 0x7fa47c671990>]\n",
      "835 batch_normalization_147 [<keras.engine.topology.Node object at 0x7fa449d38090>, <keras.engine.topology.Node object at 0x7fa449d86c50>, <keras.engine.topology.Node object at 0x7fa449d38410>]\n",
      "836 input_187 [<keras.engine.topology.Node object at 0x7fa47c671b90>]\n",
      "837 input_188 [<keras.engine.topology.Node object at 0x7fa47c671d90>]\n",
      "838 lambda_257 [<keras.engine.topology.Node object at 0x7fa449ce9f90>, <keras.engine.topology.Node object at 0x7fa449d86750>]\n",
      "839 lambda_258 [<keras.engine.topology.Node object at 0x7fa449cc5290>, <keras.engine.topology.Node object at 0x7fa449d96ad0>]\n",
      "840 lambda_259 [<keras.engine.topology.Node object at 0x7fa449cc5550>, <keras.engine.topology.Node object at 0x7fa449c55d50>]\n",
      "841 activation_235 [<keras.engine.topology.Node object at 0x7fa449c23d10>, <keras.engine.topology.Node object at 0x7fa449bebe50>, <keras.engine.topology.Node object at 0x7fa449cc5dd0>]\n",
      "842 lambda_260 [<keras.engine.topology.Node object at 0x7fa448e52b50>]\n",
      "843 lambda_261 [<keras.engine.topology.Node object at 0x7fa449bebb90>]\n",
      "844 lambda_262 [<keras.engine.topology.Node object at 0x7fa449bebfd0>]\n",
      "845 input_189 [<keras.engine.topology.Node object at 0x7fa47c6934d0>]\n",
      "846 conv2d_233 [<keras.engine.topology.Node object at 0x7fa4824d9310>, <keras.engine.topology.Node object at 0x7fa449bfae90>, <keras.engine.topology.Node object at 0x7fa449bfae50>]\n",
      "847 input_190 [<keras.engine.topology.Node object at 0x7fa47c693690>]\n",
      "848 input_191 [<keras.engine.topology.Node object at 0x7fa47c693890>]\n",
      "849 lambda_263 [<keras.engine.topology.Node object at 0x7fa449c09150>, <keras.engine.topology.Node object at 0x7fa447211e50>]\n",
      "850 lambda_264 [<keras.engine.topology.Node object at 0x7fa447225e90>, <keras.engine.topology.Node object at 0x7fa44723ab50>]\n",
      "851 lambda_265 [<keras.engine.topology.Node object at 0x7fa44723aed0>, <keras.engine.topology.Node object at 0x7fa447225d50>]\n",
      "852 input_192 [<keras.engine.topology.Node object at 0x7fa47c693a90>]\n",
      "853 batch_normalization_148 [<keras.engine.topology.Node object at 0x7fa4471ee210>, <keras.engine.topology.Node object at 0x7fa4472257d0>, <keras.engine.topology.Node object at 0x7fa4471a0950>]\n",
      "854 input_193 [<keras.engine.topology.Node object at 0x7fa47c693c90>]\n",
      "855 input_194 [<keras.engine.topology.Node object at 0x7fa47c693e90>]\n",
      "856 lambda_266 [<keras.engine.topology.Node object at 0x7fa44711a090>, <keras.engine.topology.Node object at 0x7fa4472259d0>]\n",
      "857 lambda_267 [<keras.engine.topology.Node object at 0x7fa4471ee690>, <keras.engine.topology.Node object at 0x7fa44717c510>]\n",
      "858 lambda_268 [<keras.engine.topology.Node object at 0x7fa44717c7d0>, <keras.engine.topology.Node object at 0x7fa44708cfd0>]\n",
      "859 activation_236 [<keras.engine.topology.Node object at 0x7fa4470d9f90>, <keras.engine.topology.Node object at 0x7fa4470a3790>, <keras.engine.topology.Node object at 0x7fa4470a3e90>]\n",
      "860 lambda_269 [<keras.engine.topology.Node object at 0x7fa4470d9350>]\n",
      "861 lambda_270 [<keras.engine.topology.Node object at 0x7fa4470b2cd0>]\n",
      "862 lambda_271 [<keras.engine.topology.Node object at 0x7fa4471bb250>]\n",
      "863 input_195 [<keras.engine.topology.Node object at 0x7fa47c628410>]\n",
      "864 conv2d_234 [<keras.engine.topology.Node object at 0x7fa4824d9a10>, <keras.engine.topology.Node object at 0x7fa446e27d90>, <keras.engine.topology.Node object at 0x7fa4470c1050>]\n",
      "865 input_196 [<keras.engine.topology.Node object at 0x7fa47c6285d0>]\n",
      "866 input_197 [<keras.engine.topology.Node object at 0x7fa47c628790>]\n",
      "867 lambda_272 [<keras.engine.topology.Node object at 0x7fa4470c1710>, <keras.engine.topology.Node object at 0x7fa446be78d0>]\n",
      "868 lambda_273 [<keras.engine.topology.Node object at 0x7fa446bffed0>, <keras.engine.topology.Node object at 0x7fa446bffb90>]\n",
      "869 lambda_274 [<keras.engine.topology.Node object at 0x7fa446a91590>, <keras.engine.topology.Node object at 0x7fa446a91c90>]\n",
      "870 concatenate_113 [<keras.engine.topology.Node object at 0x7fa446aa1a10>, <keras.engine.topology.Node object at 0x7fa446be7810>, <keras.engine.topology.Node object at 0x7fa446aa1b90>]\n",
      "871 input_198 [<keras.engine.topology.Node object at 0x7fa47c628990>]\n",
      "872 input_199 [<keras.engine.topology.Node object at 0x7fa47c628bd0>]\n",
      "873 input_200 [<keras.engine.topology.Node object at 0x7fa47c628dd0>]\n",
      "874 lambda_275 [<keras.engine.topology.Node object at 0x7fa446aa1e10>, <keras.engine.topology.Node object at 0x7fa446ab5f10>]\n",
      "875 lambda_276 [<keras.engine.topology.Node object at 0x7fa446ac4810>, <keras.engine.topology.Node object at 0x7fa446ab5890>]\n",
      "876 lambda_277 [<keras.engine.topology.Node object at 0x7fa446ac4210>, <keras.engine.topology.Node object at 0x7fa446a5a990>]\n",
      "877 input_201 [<keras.engine.topology.Node object at 0x7fa47c640050>]\n",
      "878 batch_normalization_149 [<keras.engine.topology.Node object at 0x7fa446a0c1d0>, <keras.engine.topology.Node object at 0x7fa446a79810>, <keras.engine.topology.Node object at 0x7fa446a39910>]\n",
      "879 input_202 [<keras.engine.topology.Node object at 0x7fa47c640210>]\n",
      "880 input_203 [<keras.engine.topology.Node object at 0x7fa47c640410>]\n",
      "881 lambda_278 [<keras.engine.topology.Node object at 0x7fa4469b5050>, <keras.engine.topology.Node object at 0x7fa446a69d10>]\n",
      "882 lambda_279 [<keras.engine.topology.Node object at 0x7fa446a0c650>, <keras.engine.topology.Node object at 0x7fa4469974d0>]\n",
      "883 lambda_280 [<keras.engine.topology.Node object at 0x7fa446972f50>, <keras.engine.topology.Node object at 0x7fa4469d4210>]\n",
      "884 activation_237 [<keras.engine.topology.Node object at 0x7fa446926f90>, <keras.engine.topology.Node object at 0x7fa446997790>, <keras.engine.topology.Node object at 0x7fa44693ae10>]\n",
      "885 lambda_281 [<keras.engine.topology.Node object at 0x7fa446a91d90>]\n",
      "886 lambda_282 [<keras.engine.topology.Node object at 0x7fa4468caf10>]\n",
      "887 lambda_283 [<keras.engine.topology.Node object at 0x7fa4468cac90>]\n",
      "888 input_204 [<keras.engine.topology.Node object at 0x7fa47c640ad0>]\n",
      "889 conv2d_235 [<keras.engine.topology.Node object at 0x7fa4824d9e10>, <keras.engine.topology.Node object at 0x7fa4468da110>, <keras.engine.topology.Node object at 0x7fa445812a10>]\n",
      "890 input_205 [<keras.engine.topology.Node object at 0x7fa47c640c90>]\n",
      "891 input_206 [<keras.engine.topology.Node object at 0x7fa47c640e90>]\n",
      "892 lambda_284 [<keras.engine.topology.Node object at 0x7fa4440cbfd0>, <keras.engine.topology.Node object at 0x7fa4440cb8d0>]\n",
      "893 lambda_285 [<keras.engine.topology.Node object at 0x7fa4440daa10>, <keras.engine.topology.Node object at 0x7fa4440dac10>]\n",
      "894 lambda_286 [<keras.engine.topology.Node object at 0x7fa4440dac50>, <keras.engine.topology.Node object at 0x7fa4440cb210>]\n",
      "895 input_207 [<keras.engine.topology.Node object at 0x7fa47c6570d0>]\n",
      "896 batch_normalization_150 [<keras.engine.topology.Node object at 0x7fa443d7d450>, <keras.engine.topology.Node object at 0x7fa443deea90>, <keras.engine.topology.Node object at 0x7fa443dafb90>]\n",
      "897 input_208 [<keras.engine.topology.Node object at 0x7fa47c6572d0>]\n",
      "898 input_209 [<keras.engine.topology.Node object at 0x7fa47c6574d0>]\n",
      "899 lambda_287 [<keras.engine.topology.Node object at 0x7fa443d262d0>, <keras.engine.topology.Node object at 0x7fa443ddfc10>]\n",
      "900 lambda_288 [<keras.engine.topology.Node object at 0x7fa443d7d8d0>, <keras.engine.topology.Node object at 0x7fa443ce8590>]\n",
      "901 lambda_289 [<keras.engine.topology.Node object at 0x7fa443d0a750>, <keras.engine.topology.Node object at 0x7fa443d0aa10>]\n",
      "902 activation_238 [<keras.engine.topology.Node object at 0x7fa443cb2b50>, <keras.engine.topology.Node object at 0x7fa443cb29d0>, <keras.engine.topology.Node object at 0x7fa443c42c50>]\n",
      "903 lambda_290 [<keras.engine.topology.Node object at 0x7fa443cb2dd0>]\n",
      "904 lambda_291 [<keras.engine.topology.Node object at 0x7fa443c52310>]\n",
      "905 lambda_292 [<keras.engine.topology.Node object at 0x7fa443c42f10>]\n",
      "906 input_210 [<keras.engine.topology.Node object at 0x7fa47c657a10>]\n",
      "907 conv2d_236 [<keras.engine.topology.Node object at 0x7fa4824e9550>, <keras.engine.topology.Node object at 0x7fa443c52950>, <keras.engine.topology.Node object at 0x7fa443c79f10>]\n",
      "908 input_211 [<keras.engine.topology.Node object at 0x7fa47c657bd0>]\n",
      "909 input_212 [<keras.engine.topology.Node object at 0x7fa47c657d90>]\n",
      "910 lambda_293 [<keras.engine.topology.Node object at 0x7fa443af9c90>, <keras.engine.topology.Node object at 0x7fa443af9c50>]\n",
      "911 lambda_294 [<keras.engine.topology.Node object at 0x7fa44388fdd0>, <keras.engine.topology.Node object at 0x7fa44389f790>]\n",
      "912 lambda_295 [<keras.engine.topology.Node object at 0x7fa44389fed0>, <keras.engine.topology.Node object at 0x7fa44389f7d0>]\n",
      "913 concatenate_114 [<keras.engine.topology.Node object at 0x7fa4438b2dd0>, <keras.engine.topology.Node object at 0x7fa4438b2c50>, <keras.engine.topology.Node object at 0x7fa443844ed0>]\n",
      "914 input_213 [<keras.engine.topology.Node object at 0x7fa47c657f90>]\n",
      "915 input_214 [<keras.engine.topology.Node object at 0x7fa46e5821d0>]\n",
      "916 input_215 [<keras.engine.topology.Node object at 0x7fa46e5823d0>]\n",
      "917 lambda_296 [<keras.engine.topology.Node object at 0x7fa443844c50>, <keras.engine.topology.Node object at 0x7fa443844ad0>]\n",
      "918 lambda_297 [<keras.engine.topology.Node object at 0x7fa443855d50>, <keras.engine.topology.Node object at 0x7fa4438555d0>]\n",
      "919 lambda_298 [<keras.engine.topology.Node object at 0x7fa443855890>, <keras.engine.topology.Node object at 0x7fa443868c10>]\n",
      "920 input_216 [<keras.engine.topology.Node object at 0x7fa46e5825d0>]\n",
      "921 batch_normalization_151 [<keras.engine.topology.Node object at 0x7fa443819410>, <keras.engine.topology.Node object at 0x7fa44380ba90>, <keras.engine.topology.Node object at 0x7fa4437cab50>]\n",
      "922 input_217 [<keras.engine.topology.Node object at 0x7fa46e5827d0>]\n",
      "923 input_218 [<keras.engine.topology.Node object at 0x7fa46e5829d0>]\n",
      "924 lambda_299 [<keras.engine.topology.Node object at 0x7fa443741290>, <keras.engine.topology.Node object at 0x7fa443868d90>]\n",
      "925 lambda_300 [<keras.engine.topology.Node object at 0x7fa443819890>, <keras.engine.topology.Node object at 0x7fa443705550>]\n",
      "926 lambda_301 [<keras.engine.topology.Node object at 0x7fa4437a7710>, <keras.engine.topology.Node object at 0x7fa4437a79d0>]\n",
      "927 activation_239 [<keras.engine.topology.Node object at 0x7fa4436cb990>, <keras.engine.topology.Node object at 0x7fa4437231d0>, <keras.engine.topology.Node object at 0x7fa4436dbed0>]\n",
      "928 lambda_302 [<keras.engine.topology.Node object at 0x7fa4436cbb10>]\n",
      "929 lambda_303 [<keras.engine.topology.Node object at 0x7fa446972310>]\n",
      "930 lambda_304 [<keras.engine.topology.Node object at 0x7fa4436ec910>]\n",
      "931 input_219 [<keras.engine.topology.Node object at 0x7fa46e598110>]\n",
      "932 conv2d_237 [<keras.engine.topology.Node object at 0x7fa4824e9950>, <keras.engine.topology.Node object at 0x7fa44112c6d0>, <keras.engine.topology.Node object at 0x7fa4428dabd0>]\n",
      "933 input_220 [<keras.engine.topology.Node object at 0x7fa46e5982d0>]\n",
      "934 input_221 [<keras.engine.topology.Node object at 0x7fa46e5984d0>]\n",
      "935 lambda_305 [<keras.engine.topology.Node object at 0x7fa441e9cd50>, <keras.engine.topology.Node object at 0x7fa440a83f50>]\n",
      "936 lambda_306 [<keras.engine.topology.Node object at 0x7fa440a83fd0>, <keras.engine.topology.Node object at 0x7fa4436ec710>]\n",
      "937 lambda_307 [<keras.engine.topology.Node object at 0x7fa440a98fd0>, <keras.engine.topology.Node object at 0x7fa440a98dd0>]\n",
      "938 input_222 [<keras.engine.topology.Node object at 0x7fa46e5986d0>]\n",
      "939 batch_normalization_152 [<keras.engine.topology.Node object at 0x7fa440a50650>, <keras.engine.topology.Node object at 0x7fa440a83390>, <keras.engine.topology.Node object at 0x7fa4409fddd0>]\n",
      "940 input_223 [<keras.engine.topology.Node object at 0x7fa46e5988d0>]\n",
      "941 input_224 [<keras.engine.topology.Node object at 0x7fa46e598ad0>]\n",
      "942 lambda_308 [<keras.engine.topology.Node object at 0x7fa440978510>, <keras.engine.topology.Node object at 0x7fa4408ecf10>]\n",
      "943 lambda_309 [<keras.engine.topology.Node object at 0x7fa440a3ed50>, <keras.engine.topology.Node object at 0x7fa440a176d0>]\n",
      "944 lambda_310 [<keras.engine.topology.Node object at 0x7fa4409dfc50>, <keras.engine.topology.Node object at 0x7fa4409df990>]\n",
      "945 activation_240 [<keras.engine.topology.Node object at 0x7fa440902c10>, <keras.engine.topology.Node object at 0x7fa440913e90>, <keras.engine.topology.Node object at 0x7fa4436cbd90>]\n",
      "946 lambda_311 [<keras.engine.topology.Node object at 0x7fa440902d90>]\n",
      "947 lambda_312 [<keras.engine.topology.Node object at 0x7fa440913a90>]\n",
      "948 lambda_313 [<keras.engine.topology.Node object at 0x7fa440913c10>]\n",
      "949 input_225 [<keras.engine.topology.Node object at 0x7fa46cfb3050>]\n",
      "950 conv2d_238 [<keras.engine.topology.Node object at 0x7fa4824e9e50>, <keras.engine.topology.Node object at 0x7fa440922590>, <keras.engine.topology.Node object at 0x7fa440922890>]\n",
      "951 input_226 [<keras.engine.topology.Node object at 0x7fa46cfb3210>]\n",
      "952 input_227 [<keras.engine.topology.Node object at 0x7fa46cfb3410>]\n",
      "953 lambda_314 [<keras.engine.topology.Node object at 0x7fa44045ee50>, <keras.engine.topology.Node object at 0x7fa44045eed0>]\n",
      "954 lambda_315 [<keras.engine.topology.Node object at 0x7fa440447e90>, <keras.engine.topology.Node object at 0x7fa440447ed0>]\n",
      "955 lambda_316 [<keras.engine.topology.Node object at 0x7fa4402f18d0>, <keras.engine.topology.Node object at 0x7fa440303e90>]\n",
      "956 concatenate_115 [<keras.engine.topology.Node object at 0x7fa440303b10>, <keras.engine.topology.Node object at 0x7fa440319810>, <keras.engine.topology.Node object at 0x7fa4402f1550>]\n",
      "957 input_228 [<keras.engine.topology.Node object at 0x7fa46cfb3610>]\n",
      "958 input_229 [<keras.engine.topology.Node object at 0x7fa46cfb3810>]\n",
      "959 input_230 [<keras.engine.topology.Node object at 0x7fa46cfb3a10>]\n",
      "960 lambda_317 [<keras.engine.topology.Node object at 0x7fa440319d10>, <keras.engine.topology.Node object at 0x7fa440319e90>]\n",
      "961 lambda_318 [<keras.engine.topology.Node object at 0x7fa440329c90>, <keras.engine.topology.Node object at 0x7fa4402bcb90>]\n",
      "962 lambda_319 [<keras.engine.topology.Node object at 0x7fa4402bce50>, <keras.engine.topology.Node object at 0x7fa440329690>]\n",
      "963 input_231 [<keras.engine.topology.Node object at 0x7fa46cfb3c10>]\n",
      "964 batch_normalization_153 [<keras.engine.topology.Node object at 0x7fa44026b650>, <keras.engine.topology.Node object at 0x7fa440329ad0>, <keras.engine.topology.Node object at 0x7fa44029ad90>]\n",
      "965 input_232 [<keras.engine.topology.Node object at 0x7fa46cfb3e10>]\n",
      "966 input_233 [<keras.engine.topology.Node object at 0x7fa46cfcc050>]\n",
      "967 lambda_320 [<keras.engine.topology.Node object at 0x7fa44020e590>, <keras.engine.topology.Node object at 0x7fa440183f90>]\n",
      "968 lambda_321 [<keras.engine.topology.Node object at 0x7fa440232650>, <keras.engine.topology.Node object at 0x7fa44026bad0>]\n",
      "969 lambda_322 [<keras.engine.topology.Node object at 0x7fa4401f5cd0>, <keras.engine.topology.Node object at 0x7fa4401f5a10>]\n",
      "970 activation_241 [<keras.engine.topology.Node object at 0x7fa44019bc90>, <keras.engine.topology.Node object at 0x7fa44012ef10>, <keras.engine.topology.Node object at 0x7fa44016f4d0>]\n",
      "971 lambda_323 [<keras.engine.topology.Node object at 0x7fa44019b7d0>]\n",
      "972 lambda_324 [<keras.engine.topology.Node object at 0x7fa440902e90>]\n",
      "973 lambda_325 [<keras.engine.topology.Node object at 0x7fa44013cc10>]\n",
      "974 input_234 [<keras.engine.topology.Node object at 0x7fa46cfcc710>]\n",
      "975 conv2d_239 [<keras.engine.topology.Node object at 0x7fa4824fc490>, <keras.engine.topology.Node object at 0x7fa43d6fd910>, <keras.engine.topology.Node object at 0x7fa44013c650>]\n",
      "976 input_235 [<keras.engine.topology.Node object at 0x7fa46cfcc8d0>]\n",
      "977 input_236 [<keras.engine.topology.Node object at 0x7fa46cfcca90>]\n",
      "978 lambda_326 [<keras.engine.topology.Node object at 0x7fa43f2f3e50>, <keras.engine.topology.Node object at 0x7fa44012eb10>]\n",
      "979 lambda_327 [<keras.engine.topology.Node object at 0x7fa43d724c90>, <keras.engine.topology.Node object at 0x7fa43d3abf90>]\n",
      "980 lambda_328 [<keras.engine.topology.Node object at 0x7fa43d724cd0>, <keras.engine.topology.Node object at 0x7fa43d3c1c90>]\n",
      "981 input_237 [<keras.engine.topology.Node object at 0x7fa46cfccc90>]\n",
      "982 batch_normalization_154 [<keras.engine.topology.Node object at 0x7fa43d376310>, <keras.engine.topology.Node object at 0x7fa43d3d0f10>, <keras.engine.topology.Node object at 0x7fa43d38ff50>]\n",
      "983 input_238 [<keras.engine.topology.Node object at 0x7fa46cfcce90>]\n",
      "984 input_239 [<keras.engine.topology.Node object at 0x7fa46cfe2110>]\n",
      "985 lambda_329 [<keras.engine.topology.Node object at 0x7fa43d306750>, <keras.engine.topology.Node object at 0x7fa43d724310>]\n",
      "986 lambda_330 [<keras.engine.topology.Node object at 0x7fa43d361d50>, <keras.engine.topology.Node object at 0x7fa43d2caa90>]\n",
      "987 lambda_331 [<keras.engine.topology.Node object at 0x7fa43d2edbd0>, <keras.engine.topology.Node object at 0x7fa4402dac90>]\n",
      "988 activation_242 [<keras.engine.topology.Node object at 0x7fa43d2909d0>, <keras.engine.topology.Node object at 0x7fa43d290b50>, <keras.engine.topology.Node object at 0x7fa43d224850>]\n",
      "989 lambda_332 [<keras.engine.topology.Node object at 0x7fa43d234890>]\n",
      "990 lambda_333 [<keras.engine.topology.Node object at 0x7fa43d224ed0>]\n",
      "991 lambda_334 [<keras.engine.topology.Node object at 0x7fa43d224d50>]\n",
      "992 input_240 [<keras.engine.topology.Node object at 0x7fa46cfe2650>]\n",
      "993 conv2d_240 [<keras.engine.topology.Node object at 0x7fa4824fcb90>, <keras.engine.topology.Node object at 0x7fa43d234e50>, <keras.engine.topology.Node object at 0x7fa43d329910>]\n",
      "994 input_241 [<keras.engine.topology.Node object at 0x7fa46cfe2810>]\n",
      "995 input_242 [<keras.engine.topology.Node object at 0x7fa46cfe2a10>]\n",
      "996 lambda_335 [<keras.engine.topology.Node object at 0x7fa43cd6b8d0>, <keras.engine.topology.Node object at 0x7fa43cd6b750>]\n",
      "997 lambda_336 [<keras.engine.topology.Node object at 0x7fa43cd6bc90>, <keras.engine.topology.Node object at 0x7fa43cd81c10>]\n",
      "998 lambda_337 [<keras.engine.topology.Node object at 0x7fa43cd81c50>, <keras.engine.topology.Node object at 0x7fa43cd815d0>]\n",
      "999 input_243 [<keras.engine.topology.Node object at 0x7fa46cfe2c10>]\n",
      "1000 concatenate_116 [<keras.engine.topology.Node object at 0x7fa43cd92c10>, <keras.engine.topology.Node object at 0x7fa43cd6b110>, <keras.engine.topology.Node object at 0x7fa43d262710>]\n",
      "1001 input_244 [<keras.engine.topology.Node object at 0x7fa46cfe2e10>]\n",
      "1002 input_245 [<keras.engine.topology.Node object at 0x7fa46b65c050>]\n",
      "1003 lambda_338 [<keras.engine.topology.Node object at 0x7fa43cd29a90>, <keras.engine.topology.Node object at 0x7fa43cd92d90>]\n",
      "1004 lambda_339 [<keras.engine.topology.Node object at 0x7fa43cd3bf50>, <keras.engine.topology.Node object at 0x7fa43cd29c10>]\n",
      "1005 lambda_340 [<keras.engine.topology.Node object at 0x7fa43cd3bad0>, <keras.engine.topology.Node object at 0x7fa43cd4af90>]\n",
      "1006 input_246 [<keras.engine.topology.Node object at 0x7fa46b65c250>]\n",
      "1007 batch_normalization_155 [<keras.engine.topology.Node object at 0x7fa43ccfc890>, <keras.engine.topology.Node object at 0x7fa43cd3ba90>, <keras.engine.topology.Node object at 0x7fa43cca9fd0>]\n",
      "1008 input_247 [<keras.engine.topology.Node object at 0x7fa46b65c450>]\n",
      "1009 input_248 [<keras.engine.topology.Node object at 0x7fa46b65c650>]\n",
      "1010 lambda_341 [<keras.engine.topology.Node object at 0x7fa43cc20710>, <keras.engine.topology.Node object at 0x7fa43ccecf10>]\n",
      "1011 lambda_342 [<keras.engine.topology.Node object at 0x7fa43cd3bd90>, <keras.engine.topology.Node object at 0x7fa43ccfcd10>]\n",
      "1012 lambda_343 [<keras.engine.topology.Node object at 0x7fa43cc86b90>, <keras.engine.topology.Node object at 0x7fa43ccc58d0>]\n",
      "1013 input_249 [<keras.engine.topology.Node object at 0x7fa46b65c850>]\n",
      "1014 activation_243 [<keras.engine.topology.Node object at 0x7fa43cbe69d0>, <keras.engine.topology.Node object at 0x7fa43cbade10>, <keras.engine.topology.Node object at 0x7fa43cbadf90>]\n",
      "1015 input_250 [<keras.engine.topology.Node object at 0x7fa46b65ca50>]\n",
      "1016 input_251 [<keras.engine.topology.Node object at 0x7fa46b65cc50>]\n",
      "1017 lambda_344 [<keras.engine.topology.Node object at 0x7fa43cbbee10>, <keras.engine.topology.Node object at 0x7fa43cd818d0>]\n",
      "1018 lambda_345 [<keras.engine.topology.Node object at 0x7fa43cbced90>, <keras.engine.topology.Node object at 0x7fa43cbbec90>]\n",
      "1019 lambda_346 [<keras.engine.topology.Node object at 0x7fa43cbce790>, <keras.engine.topology.Node object at 0x7fa43cbcea50>]\n",
      "1020 global_average_pooling2d_2 [<keras.engine.topology.Node object at 0x7fa43cbce610>, <keras.engine.topology.Node object at 0x7fa43cb5ecd0>, <keras.engine.topology.Node object at 0x7fa43cb5eb50>]\n",
      "1021 lambda_347 [<keras.engine.topology.Node object at 0x7fa43cbceb50>]\n",
      "1022 lambda_348 [<keras.engine.topology.Node object at 0x7fa43cb6f9d0>]\n",
      "1023 lambda_349 [<keras.engine.topology.Node object at 0x7fa43cb6fb50>]\n",
      "1024 input_252 [<keras.engine.topology.Node object at 0x7fa46b68b350>]\n",
      "1025 dense_3 [<keras.engine.topology.Node object at 0x7fa4824fced0>, <keras.engine.topology.Node object at 0x7fa43cb7f9d0>, <keras.engine.topology.Node object at 0x7fa43cb7fe50>]\n",
      "1026 input_253 [<keras.engine.topology.Node object at 0x7fa46b68b510>]\n",
      "1027 input_254 [<keras.engine.topology.Node object at 0x7fa46b68b710>]\n",
      "1028 lambda_350 [<keras.engine.topology.Node object at 0x7fa43c810c10>, <keras.engine.topology.Node object at 0x7fa43cb7fc50>]\n",
      "1029 lambda_351 [<keras.engine.topology.Node object at 0x7fa43c810590>, <keras.engine.topology.Node object at 0x7fa43c810cd0>]\n",
      "1030 lambda_352 [<keras.engine.topology.Node object at 0x7fa43c810610>, <keras.engine.topology.Node object at 0x7fa43c8109d0>]\n",
      "1031 input_255 [<keras.engine.topology.Node object at 0x7fa46b68b910>]\n",
      "1032 batch_normalization_156 [<keras.engine.topology.Node object at 0x7fa43c765650>, <keras.engine.topology.Node object at 0x7fa43c7ced10>, <keras.engine.topology.Node object at 0x7fa43c794a90>]\n",
      "1033 input_256 [<keras.engine.topology.Node object at 0x7fa46b68bad0>]\n",
      "1034 input_257 [<keras.engine.topology.Node object at 0x7fa46b68bcd0>]\n",
      "1035 lambda_353 [<keras.engine.topology.Node object at 0x7fa43c6e0f90>, <keras.engine.topology.Node object at 0x7fa43c810f90>]\n",
      "1036 lambda_354 [<keras.engine.topology.Node object at 0x7fa43c7bce10>, <keras.engine.topology.Node object at 0x7fa43c765ad0>]\n",
      "1037 lambda_355 [<keras.engine.topology.Node object at 0x7fa43c6f9b10>, <keras.engine.topology.Node object at 0x7fa43c72d390>]\n",
      "1038 activation_244 [<keras.engine.topology.Node object at 0x7fa43c6f9290>, <keras.engine.topology.Node object at 0x7fa43c590dd0>, <keras.engine.topology.Node object at 0x7fa43cc86e50>]\n",
      "1039 lambda_356 [<keras.engine.topology.Node object at 0x7fa43c577fd0>]\n",
      "1040 lambda_357 [<keras.engine.topology.Node object at 0x7fa43c590a10>]\n",
      "1041 lambda_358 [<keras.engine.topology.Node object at 0x7fa43c523c50>]\n",
      "1042 input_258 [<keras.engine.topology.Node object at 0x7fa46b68a150>]\n",
      "1043 input_259 [<keras.engine.topology.Node object at 0x7fa46b68a410>]\n",
      "1044 dense_4 [<keras.engine.topology.Node object at 0x7fa48248d190>, <keras.engine.topology.Node object at 0x7fa43c523910>, <keras.engine.topology.Node object at 0x7fa43c54ce90>]\n",
      "1045 input_260 [<keras.engine.topology.Node object at 0x7fa46b68a550>]\n",
      "1046 input_261 [<keras.engine.topology.Node object at 0x7fa46b68a810>]\n",
      "1047 input_262 [<keras.engine.topology.Node object at 0x7fa46b68a950>]\n",
      "1048 input_263 [<keras.engine.topology.Node object at 0x7fa46b68ac10>]\n",
      "1049 lambda_359 [<keras.engine.topology.Node object at 0x7fa43c3d9dd0>, <keras.engine.topology.Node object at 0x7fa43c523b50>]\n",
      "1050 lambda_360 [<keras.engine.topology.Node object at 0x7fa43c3d9790>, <keras.engine.topology.Node object at 0x7fa43c1eafd0>]\n",
      "1051 lambda_361 [<keras.engine.topology.Node object at 0x7fa43c3d9810>, <keras.engine.topology.Node object at 0x7fa43c3d9e90>]\n",
      "1052 concatenate_117 [<keras.engine.topology.Node object at 0x7fa43c36fb90>]\n"
     ]
    }
   ],
   "source": [
    "for l in range(len(model.layers)):\n",
    "    print l, model.layers[l].name , model.layers[l].inbound_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69464, 4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[373].get_config()['kernel_regularizer']['config']['idx'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69464"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "544*86+540*42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " array([126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 127, 127, 127,\n",
       "        127, 127, 127, 127, 127, 127, 127, 126, 126, 126, 126, 126, 126,\n",
       "        126, 126, 126, 126, 127, 127, 127, 127, 127, 127, 127, 127, 127,\n",
       "        127, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 127, 127,\n",
       "        127, 127, 127, 127, 127, 127, 127, 127, 126, 126, 126, 126, 126,\n",
       "        126, 126, 126, 126, 126, 127, 127, 127, 127, 127, 127, 127, 127,\n",
       "        127, 127, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 127,\n",
       "        127, 127, 127, 127, 127, 127, 127, 127, 127, 126, 126, 126, 126,\n",
       "        126, 126, 126, 126, 126, 126, 127, 127, 127, 127, 127, 127, 127,\n",
       "        127, 127, 127, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126,\n",
       "        127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 126, 126, 126,\n",
       "        126, 126, 126, 126, 126, 126, 126, 127, 127, 127, 127, 127, 127,\n",
       "        127, 127, 127, 127, 126, 126, 126, 126, 126, 126, 126, 126, 126,\n",
       "        126, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127]),\n",
       " array([22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 22, 23, 24, 25, 26, 27, 28,\n",
       "        29, 30, 31, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 22, 23, 24, 25,\n",
       "        26, 27, 28, 29, 30, 31, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 22,\n",
       "        23, 24, 25, 26, 27, 28, 29, 30, 31, 22, 23, 24, 25, 26, 27, 28, 29,\n",
       "        30, 31, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 22, 23, 24, 25, 26,\n",
       "        27, 28, 29, 30, 31, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 22, 23,\n",
       "        24, 25, 26, 27, 28, 29, 30, 31, 22, 23, 24, 25, 26, 27, 28, 29, 30,\n",
       "        31, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 22, 23, 24, 25, 26, 27,\n",
       "        28, 29, 30, 31, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 22, 23, 24,\n",
       "        25, 26, 27, 28, 29, 30, 31, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31,\n",
       "        22, 23, 24, 25, 26, 27, 28, 29, 30, 31]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# base.layers[313].get_weights()[0] == model.layers[330].get_weights()[0]\n",
    "np.where((base.layers[316].get_weights()[0] == model.layers[348].get_weights()[0]) == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-cdc2b40d3ef4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m407\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "mask = K.eval(model.layers[407].output)\n",
    "print mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "test = Model(model.input, model.layers[315].get_output_at(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = test.predict(batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.07746678  0.03892235 -0.29267743 -0.16763251 -0.05023682  0.27832225\n",
      " -0.04552224 -0.06889057  0.11723467  0.01508243 -0.02710598 -0.00265778\n",
      " -0.30692452 -0.05516909 -0.33545771 -0.02623741 -0.03484739 -0.12409534\n",
      " -0.00236316 -0.04012705  0.00843214 -0.09832784 -0.15111145  0.00150553\n",
      " -0.08948306  0.04169369 -0.04982105  0.13740708  0.20242715 -0.00952799\n",
      "  0.04728628 -0.16585818 -0.01196199  0.07630756 -0.1673052  -0.12377773\n",
      " -0.07157809 -0.10489716 -0.17138386  0.20442382  0.22646485 -0.18388368\n",
      "  0.02258735 -0.1545774  -0.00307694 -0.24631692  0.12341008  0.00148524\n",
      " -0.07614261 -0.08126058 -0.10060959 -0.1489829  -0.12980224  0.02608747\n",
      "  0.08379327 -0.08551815 -0.15059206 -0.13624468  0.09929171 -0.15585487\n",
      "  0.0218808   0.09968207  0.00425958  0.04219953 -0.00980009 -0.0823416\n",
      " -0.23268668  0.05433373 -0.21483356 -0.09520058 -0.06844777 -0.1345122\n",
      "  0.05583371  0.06064228  0.07048739  0.14887771 -0.17295152 -0.20265609\n",
      " -0.08049185  0.03223233 -0.05294409 -0.03872973 -0.13010779 -0.12838367\n",
      " -0.16990894  0.01470247 -0.09667439 -0.06700698  0.0433118   0.17399314\n",
      "  0.02494591  0.14485581 -0.00584794 -0.04749376 -0.12511104  0.01390111\n",
      " -0.00392236 -0.12221988 -0.05311856 -0.06413949  0.07142502 -0.17216808\n",
      " -0.10185573  0.22693668  0.16594456  0.08454254  0.07701363  0.09021863\n",
      " -0.13630226 -0.0090152   0.13542481  0.07148545 -0.02570711 -0.09834176\n",
      " -0.19147015  0.05772133 -0.27730808 -0.03931759  0.08346343 -0.16418798\n",
      "  0.08278975  0.02536259  0.01889275  0.10022554  0.13877508 -0.0117112\n",
      " -0.02440053 -0.11352977 -0.10977319 -0.01014006 -0.07217853 -0.04996271\n",
      " -0.06602997 -0.05819209  0.05586596 -0.20802414 -0.175611    0.01524428\n",
      " -0.14790413  0.00581949  0.02685605 -0.31087315  0.03021924  0.03074397\n",
      " -0.02698101 -0.04042635  0.01216142 -0.23113675  0.06852326  0.00574885\n",
      "  0.09079081 -0.12481996 -0.01676879  0.04600849 -0.02950494 -0.0559994\n",
      "  0.08887694  0.03138744  0.13488576  0.0897881  -0.01587065  0.0180984\n",
      " -0.13479984 -0.16009869  0.03630414 -0.07928306 -0.03589137 -0.01699505\n",
      "  0.10679706 -0.07957318 -0.00371895  0.         -0.         -0.          0.\n",
      " -0.          0.         -0.          0.         -0.          0.         -0.\n",
      " -0.          0.          0.         -0.         -0.         -0.          0.\n",
      " -0.         -0.         -0.         -0.          0.         -0.         -0.\n",
      "  0.          0.         -0.          0.          0.         -0.          0.\n",
      " -0.          0.         -0.         -0.         -0.         -0.         -0.\n",
      " -0.          0.         -0.         -0.         -0.         -0.          0.\n",
      " -0.         -0.         -0.         -0.          0.         -0.          0.\n",
      " -0.         -0.         -0.         -0.          0.          0.         -0.\n",
      "  0.         -0.         -0.          0.         -0.         -0.         -0.\n",
      "  0.         -0.         -0.         -0.          0.          0.         -0.\n",
      " -0.         -0.          0.         -0.          0.         -0.         -0.\n",
      "  0.         -0.         -0.          0.          0.         -0.         -0.\n",
      " -0.          0.          0.          0.         -0.         -0.          0.\n",
      " -0.          0.         -0.          0.         -0.         -0.         -0.\n",
      " -0.          0.          0.          0.          0.          0.          0.\n",
      "  0.         -0.         -0.         -0.          0.         -0.         -0.\n",
      "  0.         -0.         -0.         -0.         -0.          0.         -0.\n",
      " -0.         -0.         -0.          0.         -0.         -0.         -0.\n",
      "  0.          0.         -0.         -0.         -0.          0.         -0.\n",
      " -0.          0.         -0.         -0.         -0.         -0.         -0.\n",
      "  0.         -0.          0.         -0.         -0.         -0.         -0.\n",
      " -0.         -0.         -0.         -0.          0.         -0.         -0.\n",
      "  0.         -0.          0.          0.         -0.          0.         -0.\n",
      "  0.          0.          0.         -0.         -0.          0.          0.\n",
      "  0.         -0.         -0.         -0.          0.          0.          0.\n",
      " -0.          0.         -0.          0.         -0.          0.         -0.\n",
      " -0.         -0.         -0.          0.         -0.         -0.          0.\n",
      "  0.         -0.         -0.         -0.         -0.          0.         -0.\n",
      " -0.         -0.         -0.         -0.         -0.         -0.         -0.\n",
      "  0.         -0.          0.         -0.          0.         -0.         -0.\n",
      " -0.         -0.          0.          0.         -0.         -0.          0.\n",
      " -0.         -0.          0.         -0.          0.          0.         -0.\n",
      "  0.         -0.         -0.         -0.         -0.         -0.         -0.\n",
      "  0.         -0.          0.         -0.         -0.          0.         -0.\n",
      " -0.          0.         -0.          0.         -0.         -0.          0.\n",
      " -0.          0.          0.          0.         -0.          0.         -0.\n",
      "  0.          0.         -0.         -0.         -0.         -0.         -0.\n",
      " -0.         -0.         -0.          0.         -0.         -0.          0.\n",
      " -0.          0.          0.         -0.         -0.         -0.         -0.\n",
      " -0.         -0.          0.         -0.          0.         -0.         -0.\n",
      " -0.          0.         -0.         -0.          0.          0.         -0.\n",
      "  0.         -0.         -0.         -0.         -0.         -0.         -0.\n",
      " -0.         -0.         -0.         -0.          0.          0.          0.\n",
      " -0.         -0.         -0.          0.         -0.          0.         -0.\n",
      " -0.          0.          0.          0.         -0.          0.         -0.\n",
      " -0.          0.         -0.         -0.          0.         -0.          0.\n",
      "  0.         -0.         -0.         -0.          0.         -0.         -0.\n",
      " -0.          0.         -0.          0.          0.          0.         -0.\n",
      "  0.        ]\n"
     ]
    }
   ],
   "source": [
    "print x[0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1, 0, 1, 2, 3]\n",
      "l_start 310\n",
      "fill_masks [array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  0.,  0.])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fill_masks [array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fill_masks [array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  0.,  0.])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fill_masks [array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fill_masks [array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  0.,  0.])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fill_masks [array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fill_masks [array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        0.,  0.])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fill_masks [array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fill_masks [array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fill_masks [array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,\n",
      "        0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  0.,  0.])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fill_masks [array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,\n",
      "        0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fill_masks [array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,\n",
      "        0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  0.,  0.])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fill_masks [array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,\n",
      "        0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fill_masks [array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,\n",
      "        0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  0.,  0.])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fill_masks [array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,\n",
      "        0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fill_masks [array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.]), array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,\n",
      "        0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        1.,  1.,  0.,  0.])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1, 0, 1, 2, 3]\n",
      "idx [65452, 4]\n",
      "gather [65452]\n",
      "idx [69464, 4]\n",
      "gather [69464]\n",
      "idx [73476, 4]\n",
      "gather [73476]\n",
      "idx [77488, 4]\n",
      "gather [77488]\n",
      "idx [81500, 4]\n",
      "gather [81500]\n",
      "idx [85512, 4]\n",
      "gather [85512]\n",
      "idx [89524, 4]\n",
      "gather [89524]\n",
      "idx [93536, 4]\n",
      "gather [93536]\n",
      "idx [97548, 4]\n",
      "gather [97548]\n",
      "idx [101560, 4]\n",
      "gather [101560]\n",
      "idx [105572, 4]\n",
      "gather [105572]\n",
      "idx [109584, 4]\n",
      "gather [109584]\n",
      "idx [113596, 4]\n",
      "gather [113596]\n",
      "idx [117608, 4]\n",
      "gather [117608]\n",
      "idx [121620, 4]\n",
      "gather [121620]\n",
      "idx [125632, 4]\n",
      "gather [125632]\n",
      "n_add 0\n",
      "n_add2 1\n",
      "n_add3 1\n",
      "name ['l_326']\n",
      "l_326\n",
      "name ['l_327']\n",
      "l_327\n",
      "name ['l_328']\n",
      "l_328\n",
      "name ['l_344']\n",
      "l_344\n",
      "name ['l_345']\n",
      "l_345\n",
      "name ['l_346']\n",
      "l_346\n",
      "name ['l_369']\n",
      "l_369\n",
      "name ['l_370']\n",
      "l_370\n",
      "name ['l_371']\n",
      "l_371\n",
      "name ['l_387']\n",
      "l_387\n",
      "name ['l_388']\n",
      "l_388\n",
      "name ['l_389']\n",
      "l_389\n",
      "name ['l_412']\n",
      "l_412\n",
      "name ['l_413']\n",
      "l_413\n",
      "name ['l_414']\n",
      "l_414\n",
      "name ['l_430']\n",
      "l_430\n",
      "name ['l_431']\n",
      "l_431\n",
      "name ['l_432']\n",
      "l_432\n",
      "name ['l_455']\n",
      "l_455\n",
      "name ['l_456']\n",
      "l_456\n",
      "name ['l_457']\n",
      "l_457\n",
      "name ['l_473']\n",
      "l_473\n",
      "name ['l_474']\n",
      "l_474\n",
      "name ['l_475']\n",
      "l_475\n",
      "name ['l_498']\n",
      "l_498\n",
      "name ['l_499']\n",
      "l_499\n",
      "name ['l_500']\n",
      "l_500\n",
      "name ['l_516']\n",
      "l_516\n",
      "name ['l_517']\n",
      "l_517\n",
      "name ['l_518']\n",
      "l_518\n",
      "name ['l_541']\n",
      "l_541\n",
      "name ['l_542']\n",
      "l_542\n",
      "name ['l_543']\n",
      "l_543\n",
      "name ['l_559']\n",
      "l_559\n",
      "name ['l_560']\n",
      "l_560\n",
      "name ['l_561']\n",
      "l_561\n",
      "name ['l_584']\n",
      "l_584\n",
      "name ['l_585']\n",
      "l_585\n",
      "name ['l_586']\n",
      "l_586\n",
      "name ['l_602']\n",
      "l_602\n",
      "name ['l_603']\n",
      "l_603\n",
      "name ['l_604']\n",
      "l_604\n",
      "name ['l_627']\n",
      "l_627\n",
      "name ['l_628']\n",
      "l_628\n",
      "name ['l_629']\n",
      "l_629\n",
      "name ['l_645']\n",
      "l_645\n",
      "name ['l_646']\n",
      "l_646\n",
      "name ['l_647']\n",
      "l_647\n",
      "name ['l_670']\n",
      "l_670\n",
      "name ['l_671']\n",
      "l_671\n",
      "name ['l_672']\n",
      "l_672\n",
      "name ['l_688']\n",
      "l_688\n",
      "name ['l_689']\n",
      "l_689\n",
      "name ['l_690']\n",
      "l_690\n",
      "name ['l_713']\n",
      "l_713\n",
      "name ['l_714']\n",
      "l_714\n",
      "name ['l_715']\n",
      "l_715\n",
      "name ['l_731']\n",
      "l_731\n",
      "name ['l_732']\n",
      "l_732\n",
      "name ['l_733']\n",
      "l_733\n",
      "name ['l_756']\n",
      "l_756\n",
      "name ['l_757']\n",
      "l_757\n",
      "name ['l_758']\n",
      "l_758\n",
      "name ['l_774']\n",
      "l_774\n",
      "name ['l_775']\n",
      "l_775\n",
      "name ['l_776']\n",
      "l_776\n",
      "name ['l_799']\n",
      "l_799\n",
      "name ['l_800']\n",
      "l_800\n",
      "name ['l_801']\n",
      "l_801\n",
      "name ['l_817']\n",
      "l_817\n",
      "name ['l_818']\n",
      "l_818\n",
      "name ['l_819']\n",
      "l_819\n",
      "name ['l_842']\n",
      "l_842\n",
      "name ['l_843']\n",
      "l_843\n",
      "name ['l_844']\n",
      "l_844\n",
      "name ['l_860']\n",
      "l_860\n",
      "name ['l_861']\n",
      "l_861\n",
      "name ['l_862']\n",
      "l_862\n",
      "name ['l_885']\n",
      "l_885\n",
      "name ['l_886']\n",
      "l_886\n",
      "name ['l_887']\n",
      "l_887\n",
      "name ['l_903']\n",
      "l_903\n",
      "name ['l_904']\n",
      "l_904\n",
      "name ['l_905']\n",
      "l_905\n",
      "name ['l_928']\n",
      "l_928\n",
      "name ['l_929']\n",
      "l_929\n",
      "name ['l_930']\n",
      "l_930\n",
      "name ['l_946']\n",
      "l_946\n",
      "name ['l_947']\n",
      "l_947\n",
      "name ['l_948']\n",
      "l_948\n",
      "name ['l_971']\n",
      "l_971\n",
      "name ['l_972']\n",
      "l_972\n",
      "name ['l_973']\n",
      "l_973\n",
      "name ['l_989']\n",
      "l_989\n",
      "name ['l_990']\n",
      "l_990\n",
      "name ['l_991']\n",
      "l_991\n",
      "name ['l_1021']\n",
      "l_1021\n",
      "name ['l_1022']\n",
      "l_1022\n",
      "name ['l_1023']\n",
      "l_1023\n",
      "name ['l_1039']\n",
      "l_1039\n",
      "name ['l_1040']\n",
      "l_1040\n",
      "name ['l_1041']\n",
      "l_1041\n",
      "conv2d_481 [[<tf.Tensor 'input_266_2:0' shape=(?, 256, 128, 3) dtype=float32>]]\n",
      "batch_normalization_523 [[<tf.Tensor 'conv2d_481_1/convolution:0' shape=(?, 128, 64, 64) dtype=float32>]]\n",
      "activation_489 [[<tf.Tensor 'batch_normalization_523_1/cond/Merge:0' shape=(?, 128, 64, 64) dtype=float32>]]\n",
      "max_pooling2d_5 [[<tf.Tensor 'activation_489_1/Relu:0' shape=(?, 128, 64, 64) dtype=float32>]]\n",
      "batch_normalization_524 [[<tf.Tensor 'max_pooling2d_5_1/MaxPool:0' shape=(?, 64, 32, 64) dtype=float32>]]\n",
      "activation_490 [[<tf.Tensor 'batch_normalization_524_1/cond/Merge:0' shape=(?, 64, 32, 64) dtype=float32>]]\n",
      "conv2d_482 [[<tf.Tensor 'activation_490_1/Relu:0' shape=(?, 64, 32, 64) dtype=float32>]]\n",
      "batch_normalization_525 [[<tf.Tensor 'conv2d_482_1/convolution:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "activation_491 [[<tf.Tensor 'batch_normalization_525_1/cond/Merge:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "conv2d_483 [[<tf.Tensor 'activation_491_1/Relu:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "concatenate_234 [[<tf.Tensor 'max_pooling2d_5_1/MaxPool:0' shape=(?, 64, 32, 64) dtype=float32>, <tf.Tensor 'conv2d_483_1/convolution:0' shape=(?, 64, 32, 32) dtype=float32>]]\n",
      "[None, 64, 32, 96]\n",
      "batch_normalization_526 [[<tf.Tensor 'concatenate_234_2/concat:0' shape=(?, 64, 32, 96) dtype=float32>]]\n",
      "activation_492 [[<tf.Tensor 'batch_normalization_526_1/cond/Merge:0' shape=(?, 64, 32, 96) dtype=float32>]]\n",
      "conv2d_484 [[<tf.Tensor 'activation_492_1/Relu:0' shape=(?, 64, 32, 96) dtype=float32>]]\n",
      "batch_normalization_527 [[<tf.Tensor 'conv2d_484_1/convolution:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "activation_493 [[<tf.Tensor 'batch_normalization_527_1/cond/Merge:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "conv2d_485 [[<tf.Tensor 'activation_493_1/Relu:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "concatenate_235 [[<tf.Tensor 'concatenate_234_2/concat:0' shape=(?, 64, 32, 96) dtype=float32>, <tf.Tensor 'conv2d_485_1/convolution:0' shape=(?, 64, 32, 32) dtype=float32>]]\n",
      "[None, 64, 32, 128]\n",
      "batch_normalization_528 [[<tf.Tensor 'concatenate_235_2/concat:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "activation_494 [[<tf.Tensor 'batch_normalization_528_1/cond/Merge:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "conv2d_486 [[<tf.Tensor 'activation_494_1/Relu:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "batch_normalization_529 [[<tf.Tensor 'conv2d_486_1/convolution:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "activation_495 [[<tf.Tensor 'batch_normalization_529_1/cond/Merge:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "conv2d_487 [[<tf.Tensor 'activation_495_1/Relu:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "concatenate_236 [[<tf.Tensor 'concatenate_235_2/concat:0' shape=(?, 64, 32, 128) dtype=float32>, <tf.Tensor 'conv2d_487_1/convolution:0' shape=(?, 64, 32, 32) dtype=float32>]]\n",
      "[None, 64, 32, 160]\n",
      "batch_normalization_530 [[<tf.Tensor 'concatenate_236_2/concat:0' shape=(?, 64, 32, 160) dtype=float32>]]\n",
      "activation_496 [[<tf.Tensor 'batch_normalization_530_1/cond/Merge:0' shape=(?, 64, 32, 160) dtype=float32>]]\n",
      "conv2d_488 [[<tf.Tensor 'activation_496_1/Relu:0' shape=(?, 64, 32, 160) dtype=float32>]]\n",
      "batch_normalization_531 [[<tf.Tensor 'conv2d_488_1/convolution:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "activation_497 [[<tf.Tensor 'batch_normalization_531_1/cond/Merge:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "conv2d_489 [[<tf.Tensor 'activation_497_1/Relu:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "concatenate_237 [[<tf.Tensor 'concatenate_236_2/concat:0' shape=(?, 64, 32, 160) dtype=float32>, <tf.Tensor 'conv2d_489_1/convolution:0' shape=(?, 64, 32, 32) dtype=float32>]]\n",
      "[None, 64, 32, 192]\n",
      "batch_normalization_532 [[<tf.Tensor 'concatenate_237_2/concat:0' shape=(?, 64, 32, 192) dtype=float32>]]\n",
      "activation_498 [[<tf.Tensor 'batch_normalization_532_1/cond/Merge:0' shape=(?, 64, 32, 192) dtype=float32>]]\n",
      "conv2d_490 [[<tf.Tensor 'activation_498_1/Relu:0' shape=(?, 64, 32, 192) dtype=float32>]]\n",
      "batch_normalization_533 [[<tf.Tensor 'conv2d_490_1/convolution:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "activation_499 [[<tf.Tensor 'batch_normalization_533_1/cond/Merge:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "conv2d_491 [[<tf.Tensor 'activation_499_1/Relu:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "concatenate_238 [[<tf.Tensor 'concatenate_237_2/concat:0' shape=(?, 64, 32, 192) dtype=float32>, <tf.Tensor 'conv2d_491_1/convolution:0' shape=(?, 64, 32, 32) dtype=float32>]]\n",
      "[None, 64, 32, 224]\n",
      "batch_normalization_534 [[<tf.Tensor 'concatenate_238_2/concat:0' shape=(?, 64, 32, 224) dtype=float32>]]\n",
      "activation_500 [[<tf.Tensor 'batch_normalization_534_1/cond/Merge:0' shape=(?, 64, 32, 224) dtype=float32>]]\n",
      "conv2d_492 [[<tf.Tensor 'activation_500_1/Relu:0' shape=(?, 64, 32, 224) dtype=float32>]]\n",
      "batch_normalization_535 [[<tf.Tensor 'conv2d_492_1/convolution:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "activation_501 [[<tf.Tensor 'batch_normalization_535_1/cond/Merge:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "conv2d_493 [[<tf.Tensor 'activation_501_1/Relu:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "concatenate_239 [[<tf.Tensor 'concatenate_238_2/concat:0' shape=(?, 64, 32, 224) dtype=float32>, <tf.Tensor 'conv2d_493_1/convolution:0' shape=(?, 64, 32, 32) dtype=float32>]]\n",
      "[None, 64, 32, 256]\n",
      "batch_normalization_536 [[<tf.Tensor 'concatenate_239_2/concat:0' shape=(?, 64, 32, 256) dtype=float32>]]\n",
      "activation_502 [[<tf.Tensor 'batch_normalization_536_1/cond/Merge:0' shape=(?, 64, 32, 256) dtype=float32>]]\n",
      "conv2d_494 [[<tf.Tensor 'activation_502_1/Relu:0' shape=(?, 64, 32, 256) dtype=float32>]]\n",
      "average_pooling2d_13 [[<tf.Tensor 'conv2d_494_1/convolution:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "batch_normalization_537 [[<tf.Tensor 'average_pooling2d_13_1/AvgPool:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "activation_503 [[<tf.Tensor 'batch_normalization_537_1/cond/Merge:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "conv2d_495 [[<tf.Tensor 'activation_503_1/Relu:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "batch_normalization_538 [[<tf.Tensor 'conv2d_495_1/convolution:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "activation_504 [[<tf.Tensor 'batch_normalization_538_1/cond/Merge:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "conv2d_496 [[<tf.Tensor 'activation_504_1/Relu:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "concatenate_240 [[<tf.Tensor 'average_pooling2d_13_1/AvgPool:0' shape=(?, 32, 16, 128) dtype=float32>, <tf.Tensor 'conv2d_496_1/convolution:0' shape=(?, 32, 16, 32) dtype=float32>]]\n",
      "[None, 32, 16, 160]\n",
      "batch_normalization_539 [[<tf.Tensor 'concatenate_240_2/concat:0' shape=(?, 32, 16, 160) dtype=float32>]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation_505 [[<tf.Tensor 'batch_normalization_539_1/cond/Merge:0' shape=(?, 32, 16, 160) dtype=float32>]]\n",
      "conv2d_497 [[<tf.Tensor 'activation_505_1/Relu:0' shape=(?, 32, 16, 160) dtype=float32>]]\n",
      "batch_normalization_540 [[<tf.Tensor 'conv2d_497_1/convolution:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "activation_506 [[<tf.Tensor 'batch_normalization_540_1/cond/Merge:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "conv2d_498 [[<tf.Tensor 'activation_506_1/Relu:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "concatenate_241 [[<tf.Tensor 'concatenate_240_2/concat:0' shape=(?, 32, 16, 160) dtype=float32>, <tf.Tensor 'conv2d_498_1/convolution:0' shape=(?, 32, 16, 32) dtype=float32>]]\n",
      "[None, 32, 16, 192]\n",
      "batch_normalization_541 [[<tf.Tensor 'concatenate_241_2/concat:0' shape=(?, 32, 16, 192) dtype=float32>]]\n",
      "activation_507 [[<tf.Tensor 'batch_normalization_541_1/cond/Merge:0' shape=(?, 32, 16, 192) dtype=float32>]]\n",
      "conv2d_499 [[<tf.Tensor 'activation_507_1/Relu:0' shape=(?, 32, 16, 192) dtype=float32>]]\n",
      "batch_normalization_542 [[<tf.Tensor 'conv2d_499_1/convolution:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "activation_508 [[<tf.Tensor 'batch_normalization_542_1/cond/Merge:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "conv2d_500 [[<tf.Tensor 'activation_508_1/Relu:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "concatenate_242 [[<tf.Tensor 'concatenate_241_2/concat:0' shape=(?, 32, 16, 192) dtype=float32>, <tf.Tensor 'conv2d_500_1/convolution:0' shape=(?, 32, 16, 32) dtype=float32>]]\n",
      "[None, 32, 16, 224]\n",
      "batch_normalization_543 [[<tf.Tensor 'concatenate_242_2/concat:0' shape=(?, 32, 16, 224) dtype=float32>]]\n",
      "activation_509 [[<tf.Tensor 'batch_normalization_543_1/cond/Merge:0' shape=(?, 32, 16, 224) dtype=float32>]]\n",
      "conv2d_501 [[<tf.Tensor 'activation_509_1/Relu:0' shape=(?, 32, 16, 224) dtype=float32>]]\n",
      "batch_normalization_544 [[<tf.Tensor 'conv2d_501_1/convolution:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "activation_510 [[<tf.Tensor 'batch_normalization_544_1/cond/Merge:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "conv2d_502 [[<tf.Tensor 'activation_510_1/Relu:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "concatenate_243 [[<tf.Tensor 'concatenate_242_2/concat:0' shape=(?, 32, 16, 224) dtype=float32>, <tf.Tensor 'conv2d_502_1/convolution:0' shape=(?, 32, 16, 32) dtype=float32>]]\n",
      "[None, 32, 16, 256]\n",
      "batch_normalization_545 [[<tf.Tensor 'concatenate_243_2/concat:0' shape=(?, 32, 16, 256) dtype=float32>]]\n",
      "activation_511 [[<tf.Tensor 'batch_normalization_545_1/cond/Merge:0' shape=(?, 32, 16, 256) dtype=float32>]]\n",
      "conv2d_503 [[<tf.Tensor 'activation_511_1/Relu:0' shape=(?, 32, 16, 256) dtype=float32>]]\n",
      "batch_normalization_546 [[<tf.Tensor 'conv2d_503_1/convolution:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "activation_512 [[<tf.Tensor 'batch_normalization_546_1/cond/Merge:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "conv2d_504 [[<tf.Tensor 'activation_512_1/Relu:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "concatenate_244 [[<tf.Tensor 'concatenate_243_2/concat:0' shape=(?, 32, 16, 256) dtype=float32>, <tf.Tensor 'conv2d_504_1/convolution:0' shape=(?, 32, 16, 32) dtype=float32>]]\n",
      "[None, 32, 16, 288]\n",
      "batch_normalization_547 [[<tf.Tensor 'concatenate_244_2/concat:0' shape=(?, 32, 16, 288) dtype=float32>]]\n",
      "activation_513 [[<tf.Tensor 'batch_normalization_547_1/cond/Merge:0' shape=(?, 32, 16, 288) dtype=float32>]]\n",
      "conv2d_505 [[<tf.Tensor 'activation_513_1/Relu:0' shape=(?, 32, 16, 288) dtype=float32>]]\n",
      "batch_normalization_548 [[<tf.Tensor 'conv2d_505_1/convolution:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "activation_514 [[<tf.Tensor 'batch_normalization_548_1/cond/Merge:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "conv2d_506 [[<tf.Tensor 'activation_514_1/Relu:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "concatenate_245 [[<tf.Tensor 'concatenate_244_2/concat:0' shape=(?, 32, 16, 288) dtype=float32>, <tf.Tensor 'conv2d_506_1/convolution:0' shape=(?, 32, 16, 32) dtype=float32>]]\n",
      "[None, 32, 16, 320]\n",
      "batch_normalization_549 [[<tf.Tensor 'concatenate_245_2/concat:0' shape=(?, 32, 16, 320) dtype=float32>]]\n",
      "activation_515 [[<tf.Tensor 'batch_normalization_549_1/cond/Merge:0' shape=(?, 32, 16, 320) dtype=float32>]]\n",
      "conv2d_507 [[<tf.Tensor 'activation_515_1/Relu:0' shape=(?, 32, 16, 320) dtype=float32>]]\n",
      "batch_normalization_550 [[<tf.Tensor 'conv2d_507_1/convolution:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "activation_516 [[<tf.Tensor 'batch_normalization_550_1/cond/Merge:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "conv2d_508 [[<tf.Tensor 'activation_516_1/Relu:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "concatenate_246 [[<tf.Tensor 'concatenate_245_2/concat:0' shape=(?, 32, 16, 320) dtype=float32>, <tf.Tensor 'conv2d_508_1/convolution:0' shape=(?, 32, 16, 32) dtype=float32>]]\n",
      "[None, 32, 16, 352]\n",
      "batch_normalization_551 [[<tf.Tensor 'concatenate_246_2/concat:0' shape=(?, 32, 16, 352) dtype=float32>]]\n",
      "activation_517 [[<tf.Tensor 'batch_normalization_551_1/cond/Merge:0' shape=(?, 32, 16, 352) dtype=float32>]]\n",
      "conv2d_509 [[<tf.Tensor 'activation_517_1/Relu:0' shape=(?, 32, 16, 352) dtype=float32>]]\n",
      "batch_normalization_552 [[<tf.Tensor 'conv2d_509_1/convolution:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "activation_518 [[<tf.Tensor 'batch_normalization_552_1/cond/Merge:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "conv2d_510 [[<tf.Tensor 'activation_518_1/Relu:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "concatenate_247 [[<tf.Tensor 'concatenate_246_2/concat:0' shape=(?, 32, 16, 352) dtype=float32>, <tf.Tensor 'conv2d_510_1/convolution:0' shape=(?, 32, 16, 32) dtype=float32>]]\n",
      "[None, 32, 16, 384]\n",
      "batch_normalization_553 [[<tf.Tensor 'concatenate_247_2/concat:0' shape=(?, 32, 16, 384) dtype=float32>]]\n",
      "activation_519 [[<tf.Tensor 'batch_normalization_553_1/cond/Merge:0' shape=(?, 32, 16, 384) dtype=float32>]]\n",
      "conv2d_511 [[<tf.Tensor 'activation_519_1/Relu:0' shape=(?, 32, 16, 384) dtype=float32>]]\n",
      "batch_normalization_554 [[<tf.Tensor 'conv2d_511_1/convolution:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "activation_520 [[<tf.Tensor 'batch_normalization_554_1/cond/Merge:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "conv2d_512 [[<tf.Tensor 'activation_520_1/Relu:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "concatenate_248 [[<tf.Tensor 'concatenate_247_2/concat:0' shape=(?, 32, 16, 384) dtype=float32>, <tf.Tensor 'conv2d_512_1/convolution:0' shape=(?, 32, 16, 32) dtype=float32>]]\n",
      "[None, 32, 16, 416]\n",
      "batch_normalization_555 [[<tf.Tensor 'concatenate_248_2/concat:0' shape=(?, 32, 16, 416) dtype=float32>]]\n",
      "activation_521 [[<tf.Tensor 'batch_normalization_555_1/cond/Merge:0' shape=(?, 32, 16, 416) dtype=float32>]]\n",
      "conv2d_513 [[<tf.Tensor 'activation_521_1/Relu:0' shape=(?, 32, 16, 416) dtype=float32>]]\n",
      "batch_normalization_556 [[<tf.Tensor 'conv2d_513_1/convolution:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "activation_522 [[<tf.Tensor 'batch_normalization_556_1/cond/Merge:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "conv2d_514 [[<tf.Tensor 'activation_522_1/Relu:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "concatenate_249 [[<tf.Tensor 'concatenate_248_2/concat:0' shape=(?, 32, 16, 416) dtype=float32>, <tf.Tensor 'conv2d_514_1/convolution:0' shape=(?, 32, 16, 32) dtype=float32>]]\n",
      "[None, 32, 16, 448]\n",
      "batch_normalization_557 [[<tf.Tensor 'concatenate_249_2/concat:0' shape=(?, 32, 16, 448) dtype=float32>]]\n",
      "activation_523 [[<tf.Tensor 'batch_normalization_557_1/cond/Merge:0' shape=(?, 32, 16, 448) dtype=float32>]]\n",
      "conv2d_515 [[<tf.Tensor 'activation_523_1/Relu:0' shape=(?, 32, 16, 448) dtype=float32>]]\n",
      "batch_normalization_558 [[<tf.Tensor 'conv2d_515_1/convolution:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "activation_524 [[<tf.Tensor 'batch_normalization_558_1/cond/Merge:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "conv2d_516 [[<tf.Tensor 'activation_524_1/Relu:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "concatenate_250 [[<tf.Tensor 'concatenate_249_2/concat:0' shape=(?, 32, 16, 448) dtype=float32>, <tf.Tensor 'conv2d_516_1/convolution:0' shape=(?, 32, 16, 32) dtype=float32>]]\n",
      "[None, 32, 16, 480]\n",
      "batch_normalization_559 [[<tf.Tensor 'concatenate_250_2/concat:0' shape=(?, 32, 16, 480) dtype=float32>]]\n",
      "activation_525 [[<tf.Tensor 'batch_normalization_559_1/cond/Merge:0' shape=(?, 32, 16, 480) dtype=float32>]]\n",
      "conv2d_517 [[<tf.Tensor 'activation_525_1/Relu:0' shape=(?, 32, 16, 480) dtype=float32>]]\n",
      "batch_normalization_560 [[<tf.Tensor 'conv2d_517_1/convolution:0' shape=(?, 32, 16, 128) dtype=float32>]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation_526 [[<tf.Tensor 'batch_normalization_560_1/cond/Merge:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "conv2d_518 [[<tf.Tensor 'activation_526_1/Relu:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "concatenate_251 [[<tf.Tensor 'concatenate_250_2/concat:0' shape=(?, 32, 16, 480) dtype=float32>, <tf.Tensor 'conv2d_518_1/convolution:0' shape=(?, 32, 16, 32) dtype=float32>]]\n",
      "[None, 32, 16, 512]\n",
      "batch_normalization_561 [[<tf.Tensor 'concatenate_251_2/concat:0' shape=(?, 32, 16, 512) dtype=float32>]]\n",
      "activation_527 [[<tf.Tensor 'batch_normalization_561_1/cond/Merge:0' shape=(?, 32, 16, 512) dtype=float32>]]\n",
      "conv2d_519 [[<tf.Tensor 'activation_527_1/Relu:0' shape=(?, 32, 16, 512) dtype=float32>]]\n",
      "average_pooling2d_14 [[<tf.Tensor 'conv2d_519_1/convolution:0' shape=(?, 32, 16, 256) dtype=float32>]]\n",
      "batch_normalization_562 [[<tf.Tensor 'average_pooling2d_14_1/AvgPool:0' shape=(?, 16, 8, 256) dtype=float32>]]\n",
      "activation_528 [[<tf.Tensor 'batch_normalization_562_1/cond/Merge:0' shape=(?, 16, 8, 256) dtype=float32>]]\n",
      "conv2d_520 [[<tf.Tensor 'activation_528_1/Relu:0' shape=(?, 16, 8, 256) dtype=float32>]]\n",
      "batch_normalization_563 [[<tf.Tensor 'conv2d_520_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "activation_529 [[<tf.Tensor 'batch_normalization_563_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_521 [[<tf.Tensor 'activation_529_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_252 [[<tf.Tensor 'average_pooling2d_14_1/AvgPool:0' shape=(?, 16, 8, 256) dtype=float32>, <tf.Tensor 'conv2d_521_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 288]\n",
      "batch_normalization_564 [[<tf.Tensor 'concatenate_252_2/concat:0' shape=(?, 16, 8, 288) dtype=float32>]]\n",
      "activation_530 [[<tf.Tensor 'batch_normalization_564_1/cond/Merge:0' shape=(?, 16, 8, 288) dtype=float32>]]\n",
      "conv2d_522 [[<tf.Tensor 'activation_530_1/Relu:0' shape=(?, 16, 8, 288) dtype=float32>]]\n",
      "batch_normalization_565 [[<tf.Tensor 'conv2d_522_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "activation_531 [[<tf.Tensor 'batch_normalization_565_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_523 [[<tf.Tensor 'activation_531_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_253 [[<tf.Tensor 'concatenate_252_2/concat:0' shape=(?, 16, 8, 288) dtype=float32>, <tf.Tensor 'conv2d_523_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 320]\n",
      "batch_normalization_566 [[<tf.Tensor 'concatenate_253_2/concat:0' shape=(?, 16, 8, 320) dtype=float32>]]\n",
      "activation_532 [[<tf.Tensor 'batch_normalization_566_1/cond/Merge:0' shape=(?, 16, 8, 320) dtype=float32>]]\n",
      "conv2d_524 [[<tf.Tensor 'activation_532_1/Relu:0' shape=(?, 16, 8, 320) dtype=float32>]]\n",
      "batch_normalization_567 [[<tf.Tensor 'conv2d_524_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "activation_533 [[<tf.Tensor 'batch_normalization_567_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_525 [[<tf.Tensor 'activation_533_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_254 [[<tf.Tensor 'concatenate_253_2/concat:0' shape=(?, 16, 8, 320) dtype=float32>, <tf.Tensor 'conv2d_525_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 352]\n",
      "batch_normalization_568 [[<tf.Tensor 'concatenate_254_2/concat:0' shape=(?, 16, 8, 352) dtype=float32>]]\n",
      "activation_534 [[<tf.Tensor 'batch_normalization_568_1/cond/Merge:0' shape=(?, 16, 8, 352) dtype=float32>]]\n",
      "conv2d_526 [[<tf.Tensor 'activation_534_1/Relu:0' shape=(?, 16, 8, 352) dtype=float32>]]\n",
      "batch_normalization_569 [[<tf.Tensor 'conv2d_526_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "activation_535 [[<tf.Tensor 'batch_normalization_569_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_527 [[<tf.Tensor 'activation_535_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_255 [[<tf.Tensor 'concatenate_254_2/concat:0' shape=(?, 16, 8, 352) dtype=float32>, <tf.Tensor 'conv2d_527_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 384]\n",
      "batch_normalization_570 [[<tf.Tensor 'concatenate_255_2/concat:0' shape=(?, 16, 8, 384) dtype=float32>]]\n",
      "activation_536 [[<tf.Tensor 'batch_normalization_570_1/cond/Merge:0' shape=(?, 16, 8, 384) dtype=float32>]]\n",
      "conv2d_528 [[<tf.Tensor 'activation_536_1/Relu:0' shape=(?, 16, 8, 384) dtype=float32>]]\n",
      "batch_normalization_571 [[<tf.Tensor 'conv2d_528_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "activation_537 [[<tf.Tensor 'batch_normalization_571_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_529 [[<tf.Tensor 'activation_537_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_256 [[<tf.Tensor 'concatenate_255_2/concat:0' shape=(?, 16, 8, 384) dtype=float32>, <tf.Tensor 'conv2d_529_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 416]\n",
      "batch_normalization_572 [[<tf.Tensor 'concatenate_256_2/concat:0' shape=(?, 16, 8, 416) dtype=float32>]]\n",
      "activation_538 [[<tf.Tensor 'batch_normalization_572_1/cond/Merge:0' shape=(?, 16, 8, 416) dtype=float32>]]\n",
      "conv2d_530 [[<tf.Tensor 'activation_538_1/Relu:0' shape=(?, 16, 8, 416) dtype=float32>]]\n",
      "batch_normalization_573 [[<tf.Tensor 'conv2d_530_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "activation_539 [[<tf.Tensor 'batch_normalization_573_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_531 [[<tf.Tensor 'activation_539_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_257 [[<tf.Tensor 'concatenate_256_2/concat:0' shape=(?, 16, 8, 416) dtype=float32>, <tf.Tensor 'conv2d_531_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 448]\n",
      "batch_normalization_574 [[<tf.Tensor 'concatenate_257_2/concat:0' shape=(?, 16, 8, 448) dtype=float32>]]\n",
      "activation_540 [[<tf.Tensor 'batch_normalization_574_1/cond/Merge:0' shape=(?, 16, 8, 448) dtype=float32>]]\n",
      "conv2d_532 [[<tf.Tensor 'activation_540_1/Relu:0' shape=(?, 16, 8, 448) dtype=float32>]]\n",
      "batch_normalization_575 [[<tf.Tensor 'conv2d_532_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "activation_541 [[<tf.Tensor 'batch_normalization_575_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_533 [[<tf.Tensor 'activation_541_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_258 [[<tf.Tensor 'concatenate_257_2/concat:0' shape=(?, 16, 8, 448) dtype=float32>, <tf.Tensor 'conv2d_533_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 480]\n",
      "batch_normalization_576 [[<tf.Tensor 'concatenate_258_2/concat:0' shape=(?, 16, 8, 480) dtype=float32>]]\n",
      "activation_542 [[<tf.Tensor 'batch_normalization_576_1/cond/Merge:0' shape=(?, 16, 8, 480) dtype=float32>]]\n",
      "conv2d_534 [[<tf.Tensor 'activation_542_1/Relu:0' shape=(?, 16, 8, 480) dtype=float32>]]\n",
      "batch_normalization_577 [[<tf.Tensor 'conv2d_534_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "activation_543 [[<tf.Tensor 'batch_normalization_577_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_535 [[<tf.Tensor 'activation_543_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_259 [[<tf.Tensor 'concatenate_258_2/concat:0' shape=(?, 16, 8, 480) dtype=float32>, <tf.Tensor 'conv2d_535_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 512]\n",
      "batch_normalization_578 [[<tf.Tensor 'concatenate_259_2/concat:0' shape=(?, 16, 8, 512) dtype=float32>]]\n",
      "activation_544 [[<tf.Tensor 'batch_normalization_578_1/cond/Merge:0' shape=(?, 16, 8, 512) dtype=float32>]]\n",
      "conv2d_536 [[<tf.Tensor 'activation_544_1/Relu:0' shape=(?, 16, 8, 512) dtype=float32>]]\n",
      "batch_normalization_579 [[<tf.Tensor 'conv2d_536_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "activation_545 [[<tf.Tensor 'batch_normalization_579_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_537 [[<tf.Tensor 'activation_545_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_260 [[<tf.Tensor 'concatenate_259_2/concat:0' shape=(?, 16, 8, 512) dtype=float32>, <tf.Tensor 'conv2d_537_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 544]\n",
      "batch_normalization_580 [[<tf.Tensor 'concatenate_260_2/concat:0' shape=(?, 16, 8, 544) dtype=float32>]]\n",
      "activation_546 [[<tf.Tensor 'batch_normalization_580_1/cond/Merge:0' shape=(?, 16, 8, 544) dtype=float32>]]\n",
      "conv2d_538 [[<tf.Tensor 'activation_546_1/Relu:0' shape=(?, 16, 8, 544) dtype=float32>]]\n",
      "batch_normalization_581 [[<tf.Tensor 'conv2d_538_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation_547 [[<tf.Tensor 'batch_normalization_581_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_539 [[<tf.Tensor 'activation_547_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_261 [[<tf.Tensor 'concatenate_260_2/concat:0' shape=(?, 16, 8, 544) dtype=float32>, <tf.Tensor 'conv2d_539_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 576]\n",
      "batch_normalization_582 [[<tf.Tensor 'concatenate_261_2/concat:0' shape=(?, 16, 8, 576) dtype=float32>]]\n",
      "activation_548 [[<tf.Tensor 'batch_normalization_582_1/cond/Merge:0' shape=(?, 16, 8, 576) dtype=float32>]]\n",
      "conv2d_540 [[<tf.Tensor 'activation_548_1/Relu:0' shape=(?, 16, 8, 576) dtype=float32>]]\n",
      "batch_normalization_583 [[<tf.Tensor 'conv2d_540_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "activation_549 [[<tf.Tensor 'batch_normalization_583_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_541 [[<tf.Tensor 'activation_549_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_262 [[<tf.Tensor 'concatenate_261_2/concat:0' shape=(?, 16, 8, 576) dtype=float32>, <tf.Tensor 'conv2d_541_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 608]\n",
      "batch_normalization_584 [[<tf.Tensor 'concatenate_262_2/concat:0' shape=(?, 16, 8, 608) dtype=float32>]]\n",
      "activation_550 [[<tf.Tensor 'batch_normalization_584_1/cond/Merge:0' shape=(?, 16, 8, 608) dtype=float32>]]\n",
      "conv2d_542 [[<tf.Tensor 'activation_550_1/Relu:0' shape=(?, 16, 8, 608) dtype=float32>]]\n",
      "batch_normalization_585 [[<tf.Tensor 'conv2d_542_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "activation_551 [[<tf.Tensor 'batch_normalization_585_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_543 [[<tf.Tensor 'activation_551_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_263 [[<tf.Tensor 'concatenate_262_2/concat:0' shape=(?, 16, 8, 608) dtype=float32>, <tf.Tensor 'conv2d_543_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 640]\n",
      "batch_normalization_586 [[<tf.Tensor 'concatenate_263_2/concat:0' shape=(?, 16, 8, 640) dtype=float32>]]\n",
      "activation_552 [[<tf.Tensor 'batch_normalization_586_1/cond/Merge:0' shape=(?, 16, 8, 640) dtype=float32>]]\n",
      "conv2d_544 [[<tf.Tensor 'activation_552_1/Relu:0' shape=(?, 16, 8, 640) dtype=float32>]]\n",
      "batch_normalization_587 [[<tf.Tensor 'conv2d_544_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "activation_553 [[<tf.Tensor 'batch_normalization_587_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_545 [[<tf.Tensor 'activation_553_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_264 [[<tf.Tensor 'concatenate_263_2/concat:0' shape=(?, 16, 8, 640) dtype=float32>, <tf.Tensor 'conv2d_545_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 672]\n",
      "batch_normalization_588 [[<tf.Tensor 'concatenate_264_2/concat:0' shape=(?, 16, 8, 672) dtype=float32>]]\n",
      "activation_554 [[<tf.Tensor 'batch_normalization_588_1/cond/Merge:0' shape=(?, 16, 8, 672) dtype=float32>]]\n",
      "conv2d_546 [[<tf.Tensor 'activation_554_1/Relu:0' shape=(?, 16, 8, 672) dtype=float32>]]\n",
      "batch_normalization_589 [[<tf.Tensor 'conv2d_546_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "activation_555 [[<tf.Tensor 'batch_normalization_589_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_547 [[<tf.Tensor 'activation_555_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_265 [[<tf.Tensor 'concatenate_264_2/concat:0' shape=(?, 16, 8, 672) dtype=float32>, <tf.Tensor 'conv2d_547_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 704]\n",
      "batch_normalization_590 [[<tf.Tensor 'concatenate_265_2/concat:0' shape=(?, 16, 8, 704) dtype=float32>]]\n",
      "activation_556 [[<tf.Tensor 'batch_normalization_590_1/cond/Merge:0' shape=(?, 16, 8, 704) dtype=float32>]]\n",
      "conv2d_548 [[<tf.Tensor 'activation_556_1/Relu:0' shape=(?, 16, 8, 704) dtype=float32>]]\n",
      "batch_normalization_591 [[<tf.Tensor 'conv2d_548_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "activation_557 [[<tf.Tensor 'batch_normalization_591_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_549 [[<tf.Tensor 'activation_557_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_266 [[<tf.Tensor 'concatenate_265_2/concat:0' shape=(?, 16, 8, 704) dtype=float32>, <tf.Tensor 'conv2d_549_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 736]\n",
      "batch_normalization_592 [[<tf.Tensor 'concatenate_266_2/concat:0' shape=(?, 16, 8, 736) dtype=float32>]]\n",
      "activation_558 [[<tf.Tensor 'batch_normalization_592_1/cond/Merge:0' shape=(?, 16, 8, 736) dtype=float32>]]\n",
      "conv2d_550 [[<tf.Tensor 'activation_558_1/Relu:0' shape=(?, 16, 8, 736) dtype=float32>]]\n",
      "batch_normalization_593 [[<tf.Tensor 'conv2d_550_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "activation_559 [[<tf.Tensor 'batch_normalization_593_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_551 [[<tf.Tensor 'activation_559_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_267 [[<tf.Tensor 'concatenate_266_2/concat:0' shape=(?, 16, 8, 736) dtype=float32>, <tf.Tensor 'conv2d_551_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 768]\n",
      "batch_normalization_594 [[<tf.Tensor 'concatenate_267_2/concat:0' shape=(?, 16, 8, 768) dtype=float32>]]\n",
      "activation_560 [[<tf.Tensor 'batch_normalization_594_1/cond/Merge:0' shape=(?, 16, 8, 768) dtype=float32>]]\n",
      "conv2d_552 [[<tf.Tensor 'activation_560_1/Relu:0' shape=(?, 16, 8, 768) dtype=float32>]]\n",
      "batch_normalization_595 [[<tf.Tensor 'conv2d_552_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "activation_561 [[<tf.Tensor 'batch_normalization_595_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_553 [[<tf.Tensor 'activation_561_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_268 [[<tf.Tensor 'concatenate_267_2/concat:0' shape=(?, 16, 8, 768) dtype=float32>, <tf.Tensor 'conv2d_553_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 800]\n",
      "batch_normalization_596 [[<tf.Tensor 'concatenate_268_2/concat:0' shape=(?, 16, 8, 800) dtype=float32>]]\n",
      "activation_562 [[<tf.Tensor 'batch_normalization_596_1/cond/Merge:0' shape=(?, 16, 8, 800) dtype=float32>]]\n",
      "conv2d_554 [[<tf.Tensor 'activation_562_1/Relu:0' shape=(?, 16, 8, 800) dtype=float32>]]\n",
      "batch_normalization_597 [[<tf.Tensor 'conv2d_554_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "activation_563 [[<tf.Tensor 'batch_normalization_597_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_555 [[<tf.Tensor 'activation_563_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_269 [[<tf.Tensor 'concatenate_268_2/concat:0' shape=(?, 16, 8, 800) dtype=float32>, <tf.Tensor 'conv2d_555_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 832]\n",
      "batch_normalization_598 [[<tf.Tensor 'concatenate_269_2/concat:0' shape=(?, 16, 8, 832) dtype=float32>]]\n",
      "activation_564 [[<tf.Tensor 'batch_normalization_598_1/cond/Merge:0' shape=(?, 16, 8, 832) dtype=float32>]]\n",
      "conv2d_556 [[<tf.Tensor 'activation_564_1/Relu:0' shape=(?, 16, 8, 832) dtype=float32>]]\n",
      "batch_normalization_599 [[<tf.Tensor 'conv2d_556_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "activation_565 [[<tf.Tensor 'batch_normalization_599_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_557 [[<tf.Tensor 'activation_565_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_270 [[<tf.Tensor 'concatenate_269_2/concat:0' shape=(?, 16, 8, 832) dtype=float32>, <tf.Tensor 'conv2d_557_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 864]\n",
      "batch_normalization_600 [[<tf.Tensor 'concatenate_270_2/concat:0' shape=(?, 16, 8, 864) dtype=float32>]]\n",
      "activation_566 [[<tf.Tensor 'batch_normalization_600_1/cond/Merge:0' shape=(?, 16, 8, 864) dtype=float32>]]\n",
      "conv2d_558 [[<tf.Tensor 'activation_566_1/Relu:0' shape=(?, 16, 8, 864) dtype=float32>]]\n",
      "batch_normalization_601 [[<tf.Tensor 'conv2d_558_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "activation_567 [[<tf.Tensor 'batch_normalization_601_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_559 [[<tf.Tensor 'activation_567_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_271 [[<tf.Tensor 'concatenate_270_2/concat:0' shape=(?, 16, 8, 864) dtype=float32>, <tf.Tensor 'conv2d_559_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 896]\n",
      "batch_normalization_602 [[<tf.Tensor 'concatenate_271_2/concat:0' shape=(?, 16, 8, 896) dtype=float32>]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation_568 [[<tf.Tensor 'batch_normalization_602_1/cond/Merge:0' shape=(?, 16, 8, 896) dtype=float32>]]\n",
      "conv2d_560 [[<tf.Tensor 'activation_568_1/Relu:0' shape=(?, 16, 8, 896) dtype=float32>]]\n",
      "batch_normalization_603 [[<tf.Tensor 'conv2d_560_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "activation_569 [[<tf.Tensor 'batch_normalization_603_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_561 [[<tf.Tensor 'activation_569_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_272 [[<tf.Tensor 'concatenate_271_2/concat:0' shape=(?, 16, 8, 896) dtype=float32>, <tf.Tensor 'conv2d_561_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 928]\n",
      "batch_normalization_604 [[<tf.Tensor 'concatenate_272_2/concat:0' shape=(?, 16, 8, 928) dtype=float32>]]\n",
      "activation_570 [[<tf.Tensor 'batch_normalization_604_1/cond/Merge:0' shape=(?, 16, 8, 928) dtype=float32>]]\n",
      "conv2d_562 [[<tf.Tensor 'activation_570_1/Relu:0' shape=(?, 16, 8, 928) dtype=float32>]]\n",
      "batch_normalization_605 [[<tf.Tensor 'conv2d_562_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "activation_571 [[<tf.Tensor 'batch_normalization_605_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_563 [[<tf.Tensor 'activation_571_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_273 [[<tf.Tensor 'concatenate_272_2/concat:0' shape=(?, 16, 8, 928) dtype=float32>, <tf.Tensor 'conv2d_563_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 960]\n",
      "batch_normalization_606 [[<tf.Tensor 'concatenate_273_2/concat:0' shape=(?, 16, 8, 960) dtype=float32>]]\n",
      "activation_572 [[<tf.Tensor 'batch_normalization_606_1/cond/Merge:0' shape=(?, 16, 8, 960) dtype=float32>]]\n",
      "conv2d_564 [[<tf.Tensor 'activation_572_1/Relu:0' shape=(?, 16, 8, 960) dtype=float32>]]\n",
      "batch_normalization_607 [[<tf.Tensor 'conv2d_564_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "activation_573 [[<tf.Tensor 'batch_normalization_607_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_565 [[<tf.Tensor 'activation_573_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_274 [[<tf.Tensor 'concatenate_273_2/concat:0' shape=(?, 16, 8, 960) dtype=float32>, <tf.Tensor 'conv2d_565_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 992]\n",
      "batch_normalization_608 [[<tf.Tensor 'concatenate_274_2/concat:0' shape=(?, 16, 8, 992) dtype=float32>]]\n",
      "activation_574 [[<tf.Tensor 'batch_normalization_608_1/cond/Merge:0' shape=(?, 16, 8, 992) dtype=float32>]]\n",
      "conv2d_566 [[<tf.Tensor 'activation_574_1/Relu:0' shape=(?, 16, 8, 992) dtype=float32>]]\n",
      "batch_normalization_609 [[<tf.Tensor 'conv2d_566_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "activation_575 [[<tf.Tensor 'batch_normalization_609_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_567 [[<tf.Tensor 'activation_575_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_275 [[<tf.Tensor 'concatenate_274_2/concat:0' shape=(?, 16, 8, 992) dtype=float32>, <tf.Tensor 'conv2d_567_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 1024]\n",
      "batch_normalization_610 [[<tf.Tensor 'concatenate_275_2/concat:0' shape=(?, 16, 8, 1024) dtype=float32>]]\n",
      "activation_576 [[<tf.Tensor 'batch_normalization_610_1/cond/Merge:0' shape=(?, 16, 8, 1024) dtype=float32>]]\n",
      "conv2d_568 [[<tf.Tensor 'activation_576_1/Relu:0' shape=(?, 16, 8, 1024) dtype=float32>]]\n",
      "average_pooling2d_15 [[<tf.Tensor 'conv2d_568_1/convolution:0' shape=(?, 16, 8, 512) dtype=float32>]]\n",
      "reshape_311 [[<tf.Tensor 'average_pooling2d_15_1/AvgPool:0' shape=(?, 8, 4, 512) dtype=float32>]]\n",
      "m_312 [[]]\n",
      "lmda_313 [[<tf.Tensor 'Const_261:0' shape=(512,) dtype=float32>, <tf.Tensor 'lambda_362/Reshape:0' shape=(1, 8, 4, 512) dtype=float32>]]\n",
      "[1, 8, 4, 512]\n",
      "m_314 [[]]\n",
      "lmda_315 [[<tf.Tensor 'Const_262:0' shape=(512,) dtype=float32>, <tf.Tensor 'lambda_362/Reshape:0' shape=(1, 8, 4, 512) dtype=float32>]]\n",
      "[1, 8, 4, 512]\n",
      "m_316 [[]]\n",
      "lmda_317 [[<tf.Tensor 'Const_263:0' shape=(512,) dtype=float32>, <tf.Tensor 'lambda_362/Reshape:0' shape=(1, 8, 4, 512) dtype=float32>]]\n",
      "[1, 8, 4, 512]\n",
      "batch_normalization_489 [[<tf.Tensor 'lambda_363_1/Mul:0' shape=(1, 8, 4, 512) dtype=float32>], [<tf.Tensor 'lambda_364_1/Mul:0' shape=(1, 8, 4, 512) dtype=float32>], [<tf.Tensor 'lambda_365_1/Mul:0' shape=(1, 8, 4, 512) dtype=float32>]]\n",
      "m_319 [[]]\n",
      "lmda_320 [[<tf.Tensor 'Const_264:0' shape=(512,) dtype=float32>, <tf.Tensor 'batch_normalization_489_1/cond/Merge:0' shape=(1, 8, 4, 512) dtype=float32>]]\n",
      "[1, 8, 4, 512]\n",
      "m_321 [[]]\n",
      "lmda_322 [[<tf.Tensor 'Const_265:0' shape=(512,) dtype=float32>, <tf.Tensor 'batch_normalization_489_2/cond/Merge:0' shape=(1, 8, 4, 512) dtype=float32>]]\n",
      "[1, 8, 4, 512]\n",
      "m_323 [[]]\n",
      "lmda_324 [[<tf.Tensor 'Const_266:0' shape=(512,) dtype=float32>, <tf.Tensor 'batch_normalization_489_3/cond/Merge:0' shape=(1, 8, 4, 512) dtype=float32>]]\n",
      "[1, 8, 4, 512]\n",
      "activation_577 [[<tf.Tensor 'lambda_366_1/Mul:0' shape=(1, 8, 4, 512) dtype=float32>], [<tf.Tensor 'lambda_367_1/Mul:0' shape=(1, 8, 4, 512) dtype=float32>], [<tf.Tensor 'lambda_368_1/Mul:0' shape=(1, 8, 4, 512) dtype=float32>]]\n",
      "l_326 [[<tf.Tensor 'activation_577_1/Relu:0' shape=(1, 8, 4, 512) dtype=float32>]]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "l_327 [[<tf.Tensor 'activation_577_2/Relu:0' shape=(1, 8, 4, 512) dtype=float32>]]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "l_328 [[<tf.Tensor 'activation_577_3/Relu:0' shape=(1, 8, 4, 512) dtype=float32>]]\n",
      "1 [5440]\n",
      "2 [1, 8, 4, 1, 170]\n",
      "3 [1, 8, 4, 1, 510]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "1 [5440]\n",
      "2 [1, 8, 4, 1, 170]\n",
      "3 [1, 8, 4, 1, 510]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "conv2d_569 [[<tf.Tensor 'lambda_369/Reshape_1:0' shape=(1, 8, 4, 512) dtype=float32>], [<tf.Tensor 'lambda_370/Reshape_1:0' shape=(1, 8, 4, 512) dtype=float32>], [<tf.Tensor 'lambda_371/Reshape_1:0' shape=(1, 8, 4, 512) dtype=float32>]]\n",
      "idx [65452, 4]\n",
      "gather [65452]\n",
      "m_330 [[]]\n",
      "lmda_331 [[<tf.Tensor 'Const_267:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_569_1/convolution:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_332 [[]]\n",
      "lmda_333 [[<tf.Tensor 'Const_268:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_569_2/convolution:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_334 [[]]\n",
      "lmda_335 [[<tf.Tensor 'Const_269:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_569_3/convolution:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "batch_normalization_490 [[<tf.Tensor 'lambda_372_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_373_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_374_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "m_337 [[]]\n",
      "lmda_338 [[<tf.Tensor 'Const_270:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_490_1/cond/Merge:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_339 [[]]\n",
      "lmda_340 [[<tf.Tensor 'Const_271:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_490_2/cond/Merge:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_341 [[]]\n",
      "lmda_342 [[<tf.Tensor 'Const_272:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_490_3/cond/Merge:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "activation_578 [[<tf.Tensor 'lambda_375_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_376_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_377_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "l_344 [[<tf.Tensor 'activation_578_1/Relu:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "l_345 [[<tf.Tensor 'activation_578_2/Relu:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "l_346 [[<tf.Tensor 'activation_578_3/Relu:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "1 [1344]\n",
      "2 [1, 8, 4, 1, 42]\n",
      "3 [1, 8, 4, 1, 126]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "1 [1344]\n",
      "2 [1, 8, 4, 1, 42]\n",
      "3 [1, 8, 4, 1, 126]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "conv2d_570 [[<tf.Tensor 'lambda_378/Reshape_1:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_379/Reshape_1:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_380/Reshape_1:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "m_348 [[]]\n",
      "lmda_349 [[<tf.Tensor 'Const_273:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_570_1/convolution:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "[1, 8, 4, 32]\n",
      "m_350 [[]]\n",
      "lmda_351 [[<tf.Tensor 'Const_274:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_570_2/convolution:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "[1, 8, 4, 32]\n",
      "m_352 [[]]\n",
      "lmda_353 [[<tf.Tensor 'Const_275:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_570_3/convolution:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "[1, 8, 4, 32]\n",
      "concatenate_276 [[<tf.Tensor 'lambda_363_1/Mul:0' shape=(1, 8, 4, 512) dtype=float32>, <tf.Tensor 'lambda_381_1/Mul:0' shape=(1, 8, 4, 32) dtype=float32>], [<tf.Tensor 'lambda_364_1/Mul:0' shape=(1, 8, 4, 512) dtype=float32>, <tf.Tensor 'lambda_382_1/Mul:0' shape=(1, 8, 4, 32) dtype=float32>], [<tf.Tensor 'lambda_365_1/Mul:0' shape=(1, 8, 4, 512) dtype=float32>, <tf.Tensor 'lambda_383_1/Mul:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "m_355 [[]]\n",
      "lmda_356 [[<tf.Tensor 'Const_276:0' shape=(544,) dtype=float32>, <tf.Tensor 'concatenate_276_1/concat:0' shape=(1, 8, 4, 544) dtype=float32>]]\n",
      "[1, 8, 4, 544]\n",
      "m_357 [[]]\n",
      "lmda_358 [[<tf.Tensor 'Const_277:0' shape=(544,) dtype=float32>, <tf.Tensor 'concatenate_276_2/concat:0' shape=(1, 8, 4, 544) dtype=float32>]]\n",
      "[1, 8, 4, 544]\n",
      "m_359 [[]]\n",
      "lmda_360 [[<tf.Tensor 'Const_278:0' shape=(544,) dtype=float32>, <tf.Tensor 'concatenate_276_3/concat:0' shape=(1, 8, 4, 544) dtype=float32>]]\n",
      "[1, 8, 4, 544]\n",
      "batch_normalization_491 [[<tf.Tensor 'lambda_384_1/Mul:0' shape=(1, 8, 4, 544) dtype=float32>], [<tf.Tensor 'lambda_385_1/Mul:0' shape=(1, 8, 4, 544) dtype=float32>], [<tf.Tensor 'lambda_386_1/Mul:0' shape=(1, 8, 4, 544) dtype=float32>]]\n",
      "m_362 [[]]\n",
      "lmda_363 [[<tf.Tensor 'Const_279:0' shape=(544,) dtype=float32>, <tf.Tensor 'batch_normalization_491_1/cond/Merge:0' shape=(1, 8, 4, 544) dtype=float32>]]\n",
      "[1, 8, 4, 544]\n",
      "m_364 [[]]\n",
      "lmda_365 [[<tf.Tensor 'Const_280:0' shape=(544,) dtype=float32>, <tf.Tensor 'batch_normalization_491_2/cond/Merge:0' shape=(1, 8, 4, 544) dtype=float32>]]\n",
      "[1, 8, 4, 544]\n",
      "m_366 [[]]\n",
      "lmda_367 [[<tf.Tensor 'Const_281:0' shape=(544,) dtype=float32>, <tf.Tensor 'batch_normalization_491_3/cond/Merge:0' shape=(1, 8, 4, 544) dtype=float32>]]\n",
      "[1, 8, 4, 544]\n",
      "activation_579 [[<tf.Tensor 'lambda_387_1/Mul:0' shape=(1, 8, 4, 544) dtype=float32>], [<tf.Tensor 'lambda_388_1/Mul:0' shape=(1, 8, 4, 544) dtype=float32>], [<tf.Tensor 'lambda_389_1/Mul:0' shape=(1, 8, 4, 544) dtype=float32>]]\n",
      "l_369 [[<tf.Tensor 'activation_579_1/Relu:0' shape=(1, 8, 4, 544) dtype=float32>]]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [352]\n",
      "6 [1, 8, 4, 1, 11]\n",
      "7 [1, 8, 4, 1, 32]\n",
      "8 [1, 8, 4, 1, 32]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [352]\n",
      "6 [1, 8, 4, 1, 11]\n",
      "7 [1, 8, 4, 1, 32]\n",
      "8 [1, 8, 4, 1, 32]\n",
      "l_370 [[<tf.Tensor 'activation_579_2/Relu:0' shape=(1, 8, 4, 544) dtype=float32>]]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 [352]\n",
      "6 [1, 8, 4, 1, 11]\n",
      "7 [1, 8, 4, 1, 32]\n",
      "8 [1, 8, 4, 1, 32]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [352]\n",
      "6 [1, 8, 4, 1, 11]\n",
      "7 [1, 8, 4, 1, 32]\n",
      "8 [1, 8, 4, 1, 32]\n",
      "l_371 [[<tf.Tensor 'activation_579_3/Relu:0' shape=(1, 8, 4, 544) dtype=float32>]]\n",
      "1 [5440]\n",
      "2 [1, 8, 4, 1, 170]\n",
      "3 [1, 8, 4, 1, 510]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [320]\n",
      "6 [1, 8, 4, 1, 10]\n",
      "7 [1, 8, 4, 1, 30]\n",
      "8 [1, 8, 4, 1, 32]\n",
      "1 [5440]\n",
      "2 [1, 8, 4, 1, 170]\n",
      "3 [1, 8, 4, 1, 510]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [320]\n",
      "6 [1, 8, 4, 1, 10]\n",
      "7 [1, 8, 4, 1, 30]\n",
      "8 [1, 8, 4, 1, 32]\n",
      "conv2d_571 [[<tf.Tensor 'lambda_390/Reshape_4:0' shape=(1, 8, 4, 544) dtype=float32>], [<tf.Tensor 'lambda_391/Reshape_4:0' shape=(1, 8, 4, 544) dtype=float32>], [<tf.Tensor 'lambda_392/Reshape_4:0' shape=(1, 8, 4, 544) dtype=float32>]]\n",
      "idx [69464, 4]\n",
      "gather [69464]\n",
      "m_373 [[]]\n",
      "lmda_374 [[<tf.Tensor 'Const_282:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_571_1/convolution:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_375 [[]]\n",
      "lmda_376 [[<tf.Tensor 'Const_283:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_571_2/convolution:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_377 [[]]\n",
      "lmda_378 [[<tf.Tensor 'Const_284:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_571_3/convolution:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "batch_normalization_492 [[<tf.Tensor 'lambda_393_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_394_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_395_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "m_380 [[]]\n",
      "lmda_381 [[<tf.Tensor 'Const_285:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_492_1/cond/Merge:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_382 [[]]\n",
      "lmda_383 [[<tf.Tensor 'Const_286:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_492_2/cond/Merge:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_384 [[]]\n",
      "lmda_385 [[<tf.Tensor 'Const_287:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_492_3/cond/Merge:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "activation_580 [[<tf.Tensor 'lambda_396_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_397_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_398_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "l_387 [[<tf.Tensor 'activation_580_1/Relu:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "l_388 [[<tf.Tensor 'activation_580_2/Relu:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "l_389 [[<tf.Tensor 'activation_580_3/Relu:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "1 [1344]\n",
      "2 [1, 8, 4, 1, 42]\n",
      "3 [1, 8, 4, 1, 126]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "1 [1344]\n",
      "2 [1, 8, 4, 1, 42]\n",
      "3 [1, 8, 4, 1, 126]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "conv2d_572 [[<tf.Tensor 'lambda_399/Reshape_1:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_400/Reshape_1:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_401/Reshape_1:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "m_391 [[]]\n",
      "lmda_392 [[<tf.Tensor 'Const_288:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_572_1/convolution:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "[1, 8, 4, 32]\n",
      "m_393 [[]]\n",
      "lmda_394 [[<tf.Tensor 'Const_289:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_572_2/convolution:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "[1, 8, 4, 32]\n",
      "m_395 [[]]\n",
      "lmda_396 [[<tf.Tensor 'Const_290:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_572_3/convolution:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "[1, 8, 4, 32]\n",
      "concatenate_277 [[<tf.Tensor 'concatenate_276_1/concat:0' shape=(1, 8, 4, 544) dtype=float32>, <tf.Tensor 'lambda_402_1/Mul:0' shape=(1, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_276_2/concat:0' shape=(1, 8, 4, 544) dtype=float32>, <tf.Tensor 'lambda_403_1/Mul:0' shape=(1, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_276_3/concat:0' shape=(1, 8, 4, 544) dtype=float32>, <tf.Tensor 'lambda_404_1/Mul:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "m_398 [[]]\n",
      "lmda_399 [[<tf.Tensor 'Const_291:0' shape=(576,) dtype=float32>, <tf.Tensor 'concatenate_277_1/concat:0' shape=(1, 8, 4, 576) dtype=float32>]]\n",
      "[1, 8, 4, 576]\n",
      "m_400 [[]]\n",
      "lmda_401 [[<tf.Tensor 'Const_292:0' shape=(576,) dtype=float32>, <tf.Tensor 'concatenate_277_2/concat:0' shape=(1, 8, 4, 576) dtype=float32>]]\n",
      "[1, 8, 4, 576]\n",
      "m_402 [[]]\n",
      "lmda_403 [[<tf.Tensor 'Const_293:0' shape=(576,) dtype=float32>, <tf.Tensor 'concatenate_277_3/concat:0' shape=(1, 8, 4, 576) dtype=float32>]]\n",
      "[1, 8, 4, 576]\n",
      "batch_normalization_493 [[<tf.Tensor 'lambda_405_1/Mul:0' shape=(1, 8, 4, 576) dtype=float32>], [<tf.Tensor 'lambda_406_1/Mul:0' shape=(1, 8, 4, 576) dtype=float32>], [<tf.Tensor 'lambda_407_1/Mul:0' shape=(1, 8, 4, 576) dtype=float32>]]\n",
      "m_405 [[]]\n",
      "lmda_406 [[<tf.Tensor 'Const_294:0' shape=(576,) dtype=float32>, <tf.Tensor 'batch_normalization_493_1/cond/Merge:0' shape=(1, 8, 4, 576) dtype=float32>]]\n",
      "[1, 8, 4, 576]\n",
      "m_407 [[]]\n",
      "lmda_408 [[<tf.Tensor 'Const_295:0' shape=(576,) dtype=float32>, <tf.Tensor 'batch_normalization_493_2/cond/Merge:0' shape=(1, 8, 4, 576) dtype=float32>]]\n",
      "[1, 8, 4, 576]\n",
      "m_409 [[]]\n",
      "lmda_410 [[<tf.Tensor 'Const_296:0' shape=(576,) dtype=float32>, <tf.Tensor 'batch_normalization_493_3/cond/Merge:0' shape=(1, 8, 4, 576) dtype=float32>]]\n",
      "[1, 8, 4, 576]\n",
      "activation_581 [[<tf.Tensor 'lambda_408_1/Mul:0' shape=(1, 8, 4, 576) dtype=float32>], [<tf.Tensor 'lambda_409_1/Mul:0' shape=(1, 8, 4, 576) dtype=float32>], [<tf.Tensor 'lambda_410_1/Mul:0' shape=(1, 8, 4, 576) dtype=float32>]]\n",
      "l_412 [[<tf.Tensor 'activation_581_1/Relu:0' shape=(1, 8, 4, 576) dtype=float32>]]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [704]\n",
      "6 [1, 8, 4, 2, 11]\n",
      "7 [1, 8, 4, 2, 32]\n",
      "8 [1, 8, 4, 2, 32]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [704]\n",
      "6 [1, 8, 4, 2, 11]\n",
      "7 [1, 8, 4, 2, 32]\n",
      "8 [1, 8, 4, 2, 32]\n",
      "l_413 [[<tf.Tensor 'activation_581_2/Relu:0' shape=(1, 8, 4, 576) dtype=float32>]]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [704]\n",
      "6 [1, 8, 4, 2, 11]\n",
      "7 [1, 8, 4, 2, 32]\n",
      "8 [1, 8, 4, 2, 32]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [704]\n",
      "6 [1, 8, 4, 2, 11]\n",
      "7 [1, 8, 4, 2, 32]\n",
      "8 [1, 8, 4, 2, 32]\n",
      "l_414 [[<tf.Tensor 'activation_581_3/Relu:0' shape=(1, 8, 4, 576) dtype=float32>]]\n",
      "1 [5440]\n",
      "2 [1, 8, 4, 1, 170]\n",
      "3 [1, 8, 4, 1, 510]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [640]\n",
      "6 [1, 8, 4, 2, 10]\n",
      "7 [1, 8, 4, 2, 30]\n",
      "8 [1, 8, 4, 2, 32]\n",
      "1 [5440]\n",
      "2 [1, 8, 4, 1, 170]\n",
      "3 [1, 8, 4, 1, 510]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [640]\n",
      "6 [1, 8, 4, 2, 10]\n",
      "7 [1, 8, 4, 2, 30]\n",
      "8 [1, 8, 4, 2, 32]\n",
      "conv2d_573 [[<tf.Tensor 'lambda_411/Reshape_4:0' shape=(1, 8, 4, 576) dtype=float32>], [<tf.Tensor 'lambda_412/Reshape_4:0' shape=(1, 8, 4, 576) dtype=float32>], [<tf.Tensor 'lambda_413/Reshape_4:0' shape=(1, 8, 4, 576) dtype=float32>]]\n",
      "idx [73476, 4]\n",
      "gather [73476]\n",
      "m_416 [[]]\n",
      "lmda_417 [[<tf.Tensor 'Const_297:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_573_1/convolution:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_418 [[]]\n",
      "lmda_419 [[<tf.Tensor 'Const_298:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_573_2/convolution:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_420 [[]]\n",
      "lmda_421 [[<tf.Tensor 'Const_299:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_573_3/convolution:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "batch_normalization_494 [[<tf.Tensor 'lambda_414_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_415_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_416_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "m_423 [[]]\n",
      "lmda_424 [[<tf.Tensor 'Const_300:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_494_1/cond/Merge:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_425 [[]]\n",
      "lmda_426 [[<tf.Tensor 'Const_301:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_494_2/cond/Merge:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_427 [[]]\n",
      "lmda_428 [[<tf.Tensor 'Const_302:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_494_3/cond/Merge:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "activation_582 [[<tf.Tensor 'lambda_417_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_418_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_419_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "l_430 [[<tf.Tensor 'activation_582_1/Relu:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "1 [1376]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "l_431 [[<tf.Tensor 'activation_582_2/Relu:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "l_432 [[<tf.Tensor 'activation_582_3/Relu:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "1 [1344]\n",
      "2 [1, 8, 4, 1, 42]\n",
      "3 [1, 8, 4, 1, 126]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "1 [1344]\n",
      "2 [1, 8, 4, 1, 42]\n",
      "3 [1, 8, 4, 1, 126]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "conv2d_574 [[<tf.Tensor 'lambda_420/Reshape_1:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_421/Reshape_1:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_422/Reshape_1:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "m_434 [[]]\n",
      "lmda_435 [[<tf.Tensor 'Const_303:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_574_1/convolution:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "[1, 8, 4, 32]\n",
      "m_436 [[]]\n",
      "lmda_437 [[<tf.Tensor 'Const_304:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_574_2/convolution:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "[1, 8, 4, 32]\n",
      "m_438 [[]]\n",
      "lmda_439 [[<tf.Tensor 'Const_305:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_574_3/convolution:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "[1, 8, 4, 32]\n",
      "concatenate_278 [[<tf.Tensor 'concatenate_277_1/concat:0' shape=(1, 8, 4, 576) dtype=float32>, <tf.Tensor 'lambda_423_1/Mul:0' shape=(1, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_277_2/concat:0' shape=(1, 8, 4, 576) dtype=float32>, <tf.Tensor 'lambda_424_1/Mul:0' shape=(1, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_277_3/concat:0' shape=(1, 8, 4, 576) dtype=float32>, <tf.Tensor 'lambda_425_1/Mul:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "m_441 [[]]\n",
      "lmda_442 [[<tf.Tensor 'Const_306:0' shape=(608,) dtype=float32>, <tf.Tensor 'concatenate_278_1/concat:0' shape=(1, 8, 4, 608) dtype=float32>]]\n",
      "[1, 8, 4, 608]\n",
      "m_443 [[]]\n",
      "lmda_444 [[<tf.Tensor 'Const_307:0' shape=(608,) dtype=float32>, <tf.Tensor 'concatenate_278_2/concat:0' shape=(1, 8, 4, 608) dtype=float32>]]\n",
      "[1, 8, 4, 608]\n",
      "m_445 [[]]\n",
      "lmda_446 [[<tf.Tensor 'Const_308:0' shape=(608,) dtype=float32>, <tf.Tensor 'concatenate_278_3/concat:0' shape=(1, 8, 4, 608) dtype=float32>]]\n",
      "[1, 8, 4, 608]\n",
      "batch_normalization_495 [[<tf.Tensor 'lambda_426_1/Mul:0' shape=(1, 8, 4, 608) dtype=float32>], [<tf.Tensor 'lambda_427_1/Mul:0' shape=(1, 8, 4, 608) dtype=float32>], [<tf.Tensor 'lambda_428_1/Mul:0' shape=(1, 8, 4, 608) dtype=float32>]]\n",
      "m_448 [[]]\n",
      "lmda_449 [[<tf.Tensor 'Const_309:0' shape=(608,) dtype=float32>, <tf.Tensor 'batch_normalization_495_1/cond/Merge:0' shape=(1, 8, 4, 608) dtype=float32>]]\n",
      "[1, 8, 4, 608]\n",
      "m_450 [[]]\n",
      "lmda_451 [[<tf.Tensor 'Const_310:0' shape=(608,) dtype=float32>, <tf.Tensor 'batch_normalization_495_2/cond/Merge:0' shape=(1, 8, 4, 608) dtype=float32>]]\n",
      "[1, 8, 4, 608]\n",
      "m_452 [[]]\n",
      "lmda_453 [[<tf.Tensor 'Const_311:0' shape=(608,) dtype=float32>, <tf.Tensor 'batch_normalization_495_3/cond/Merge:0' shape=(1, 8, 4, 608) dtype=float32>]]\n",
      "[1, 8, 4, 608]\n",
      "activation_583 [[<tf.Tensor 'lambda_429_1/Mul:0' shape=(1, 8, 4, 608) dtype=float32>], [<tf.Tensor 'lambda_430_1/Mul:0' shape=(1, 8, 4, 608) dtype=float32>], [<tf.Tensor 'lambda_431_1/Mul:0' shape=(1, 8, 4, 608) dtype=float32>]]\n",
      "l_455 [[<tf.Tensor 'activation_583_1/Relu:0' shape=(1, 8, 4, 608) dtype=float32>]]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [1056]\n",
      "6 [1, 8, 4, 3, 11]\n",
      "7 [1, 8, 4, 3, 32]\n",
      "8 [1, 8, 4, 3, 32]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [1056]\n",
      "6 [1, 8, 4, 3, 11]\n",
      "7 [1, 8, 4, 3, 32]\n",
      "8 [1, 8, 4, 3, 32]\n",
      "l_456 [[<tf.Tensor 'activation_583_2/Relu:0' shape=(1, 8, 4, 608) dtype=float32>]]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [1056]\n",
      "6 [1, 8, 4, 3, 11]\n",
      "7 [1, 8, 4, 3, 32]\n",
      "8 [1, 8, 4, 3, 32]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [1056]\n",
      "6 [1, 8, 4, 3, 11]\n",
      "7 [1, 8, 4, 3, 32]\n",
      "8 [1, 8, 4, 3, 32]\n",
      "l_457 [[<tf.Tensor 'activation_583_3/Relu:0' shape=(1, 8, 4, 608) dtype=float32>]]\n",
      "1 [5440]\n",
      "2 [1, 8, 4, 1, 170]\n",
      "3 [1, 8, 4, 1, 510]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [960]\n",
      "6 [1, 8, 4, 3, 10]\n",
      "7 [1, 8, 4, 3, 30]\n",
      "8 [1, 8, 4, 3, 32]\n",
      "1 [5440]\n",
      "2 [1, 8, 4, 1, 170]\n",
      "3 [1, 8, 4, 1, 510]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [960]\n",
      "6 [1, 8, 4, 3, 10]\n",
      "7 [1, 8, 4, 3, 30]\n",
      "8 [1, 8, 4, 3, 32]\n",
      "conv2d_575 [[<tf.Tensor 'lambda_432/Reshape_4:0' shape=(1, 8, 4, 608) dtype=float32>], [<tf.Tensor 'lambda_433/Reshape_4:0' shape=(1, 8, 4, 608) dtype=float32>], [<tf.Tensor 'lambda_434/Reshape_4:0' shape=(1, 8, 4, 608) dtype=float32>]]\n",
      "idx [77488, 4]\n",
      "gather [77488]\n",
      "m_459 [[]]\n",
      "lmda_460 [[<tf.Tensor 'Const_312:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_575_1/convolution:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_461 [[]]\n",
      "lmda_462 [[<tf.Tensor 'Const_313:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_575_2/convolution:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_463 [[]]\n",
      "lmda_464 [[<tf.Tensor 'Const_314:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_575_3/convolution:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "batch_normalization_496 [[<tf.Tensor 'lambda_435_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_436_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_437_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "m_466 [[]]\n",
      "lmda_467 [[<tf.Tensor 'Const_315:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_496_1/cond/Merge:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_468 [[]]\n",
      "lmda_469 [[<tf.Tensor 'Const_316:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_496_2/cond/Merge:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_470 [[]]\n",
      "lmda_471 [[<tf.Tensor 'Const_317:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_496_3/cond/Merge:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "activation_584 [[<tf.Tensor 'lambda_438_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_439_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_440_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "l_473 [[<tf.Tensor 'activation_584_1/Relu:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "l_474 [[<tf.Tensor 'activation_584_2/Relu:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "l_475 [[<tf.Tensor 'activation_584_3/Relu:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "1 [1344]\n",
      "2 [1, 8, 4, 1, 42]\n",
      "3 [1, 8, 4, 1, 126]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "1 [1344]\n",
      "2 [1, 8, 4, 1, 42]\n",
      "3 [1, 8, 4, 1, 126]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "conv2d_576 [[<tf.Tensor 'lambda_441/Reshape_1:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_442/Reshape_1:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_443/Reshape_1:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "m_477 [[]]\n",
      "lmda_478 [[<tf.Tensor 'Const_318:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_576_1/convolution:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "[1, 8, 4, 32]\n",
      "m_479 [[]]\n",
      "lmda_480 [[<tf.Tensor 'Const_319:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_576_2/convolution:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "[1, 8, 4, 32]\n",
      "m_481 [[]]\n",
      "lmda_482 [[<tf.Tensor 'Const_320:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_576_3/convolution:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "[1, 8, 4, 32]\n",
      "concatenate_279 [[<tf.Tensor 'concatenate_278_1/concat:0' shape=(1, 8, 4, 608) dtype=float32>, <tf.Tensor 'lambda_444_1/Mul:0' shape=(1, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_278_2/concat:0' shape=(1, 8, 4, 608) dtype=float32>, <tf.Tensor 'lambda_445_1/Mul:0' shape=(1, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_278_3/concat:0' shape=(1, 8, 4, 608) dtype=float32>, <tf.Tensor 'lambda_446_1/Mul:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "m_484 [[]]\n",
      "lmda_485 [[<tf.Tensor 'Const_321:0' shape=(640,) dtype=float32>, <tf.Tensor 'concatenate_279_1/concat:0' shape=(1, 8, 4, 640) dtype=float32>]]\n",
      "[1, 8, 4, 640]\n",
      "m_486 [[]]\n",
      "lmda_487 [[<tf.Tensor 'Const_322:0' shape=(640,) dtype=float32>, <tf.Tensor 'concatenate_279_2/concat:0' shape=(1, 8, 4, 640) dtype=float32>]]\n",
      "[1, 8, 4, 640]\n",
      "m_488 [[]]\n",
      "lmda_489 [[<tf.Tensor 'Const_323:0' shape=(640,) dtype=float32>, <tf.Tensor 'concatenate_279_3/concat:0' shape=(1, 8, 4, 640) dtype=float32>]]\n",
      "[1, 8, 4, 640]\n",
      "batch_normalization_497 [[<tf.Tensor 'lambda_447_1/Mul:0' shape=(1, 8, 4, 640) dtype=float32>], [<tf.Tensor 'lambda_448_1/Mul:0' shape=(1, 8, 4, 640) dtype=float32>], [<tf.Tensor 'lambda_449_1/Mul:0' shape=(1, 8, 4, 640) dtype=float32>]]\n",
      "m_491 [[]]\n",
      "lmda_492 [[<tf.Tensor 'Const_324:0' shape=(640,) dtype=float32>, <tf.Tensor 'batch_normalization_497_1/cond/Merge:0' shape=(1, 8, 4, 640) dtype=float32>]]\n",
      "[1, 8, 4, 640]\n",
      "m_493 [[]]\n",
      "lmda_494 [[<tf.Tensor 'Const_325:0' shape=(640,) dtype=float32>, <tf.Tensor 'batch_normalization_497_2/cond/Merge:0' shape=(1, 8, 4, 640) dtype=float32>]]\n",
      "[1, 8, 4, 640]\n",
      "m_495 [[]]\n",
      "lmda_496 [[<tf.Tensor 'Const_326:0' shape=(640,) dtype=float32>, <tf.Tensor 'batch_normalization_497_3/cond/Merge:0' shape=(1, 8, 4, 640) dtype=float32>]]\n",
      "[1, 8, 4, 640]\n",
      "activation_585 [[<tf.Tensor 'lambda_450_1/Mul:0' shape=(1, 8, 4, 640) dtype=float32>], [<tf.Tensor 'lambda_451_1/Mul:0' shape=(1, 8, 4, 640) dtype=float32>], [<tf.Tensor 'lambda_452_1/Mul:0' shape=(1, 8, 4, 640) dtype=float32>]]\n",
      "l_498 [[<tf.Tensor 'activation_585_1/Relu:0' shape=(1, 8, 4, 640) dtype=float32>]]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [1408]\n",
      "6 [1, 8, 4, 4, 11]\n",
      "7 [1, 8, 4, 4, 32]\n",
      "8 [1, 8, 4, 4, 32]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [1408]\n",
      "6 [1, 8, 4, 4, 11]\n",
      "7 [1, 8, 4, 4, 32]\n",
      "8 [1, 8, 4, 4, 32]\n",
      "l_499 [[<tf.Tensor 'activation_585_2/Relu:0' shape=(1, 8, 4, 640) dtype=float32>]]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [1408]\n",
      "6 [1, 8, 4, 4, 11]\n",
      "7 [1, 8, 4, 4, 32]\n",
      "8 [1, 8, 4, 4, 32]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [1408]\n",
      "6 [1, 8, 4, 4, 11]\n",
      "7 [1, 8, 4, 4, 32]\n",
      "8 [1, 8, 4, 4, 32]\n",
      "l_500 [[<tf.Tensor 'activation_585_3/Relu:0' shape=(1, 8, 4, 640) dtype=float32>]]\n",
      "1 [5440]\n",
      "2 [1, 8, 4, 1, 170]\n",
      "3 [1, 8, 4, 1, 510]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [1280]\n",
      "6 [1, 8, 4, 4, 10]\n",
      "7 [1, 8, 4, 4, 30]\n",
      "8 [1, 8, 4, 4, 32]\n",
      "1 [5440]\n",
      "2 [1, 8, 4, 1, 170]\n",
      "3 [1, 8, 4, 1, 510]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [1280]\n",
      "6 [1, 8, 4, 4, 10]\n",
      "7 [1, 8, 4, 4, 30]\n",
      "8 [1, 8, 4, 4, 32]\n",
      "conv2d_577 [[<tf.Tensor 'lambda_453/Reshape_4:0' shape=(1, 8, 4, 640) dtype=float32>], [<tf.Tensor 'lambda_454/Reshape_4:0' shape=(1, 8, 4, 640) dtype=float32>], [<tf.Tensor 'lambda_455/Reshape_4:0' shape=(1, 8, 4, 640) dtype=float32>]]\n",
      "idx [81500, 4]\n",
      "gather [81500]\n",
      "m_502 [[]]\n",
      "lmda_503 [[<tf.Tensor 'Const_327:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_577_1/convolution:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_504 [[]]\n",
      "lmda_505 [[<tf.Tensor 'Const_328:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_577_2/convolution:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_506 [[]]\n",
      "lmda_507 [[<tf.Tensor 'Const_329:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_577_3/convolution:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "batch_normalization_498 [[<tf.Tensor 'lambda_456_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_457_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_458_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m_509 [[]]\n",
      "lmda_510 [[<tf.Tensor 'Const_330:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_498_1/cond/Merge:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_511 [[]]\n",
      "lmda_512 [[<tf.Tensor 'Const_331:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_498_2/cond/Merge:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_513 [[]]\n",
      "lmda_514 [[<tf.Tensor 'Const_332:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_498_3/cond/Merge:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "activation_586 [[<tf.Tensor 'lambda_459_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_460_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_461_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "l_516 [[<tf.Tensor 'activation_586_1/Relu:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "l_517 [[<tf.Tensor 'activation_586_2/Relu:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "l_518 [[<tf.Tensor 'activation_586_3/Relu:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "1 [1344]\n",
      "2 [1, 8, 4, 1, 42]\n",
      "3 [1, 8, 4, 1, 126]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "1 [1344]\n",
      "2 [1, 8, 4, 1, 42]\n",
      "3 [1, 8, 4, 1, 126]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "conv2d_578 [[<tf.Tensor 'lambda_462/Reshape_1:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_463/Reshape_1:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_464/Reshape_1:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "m_520 [[]]\n",
      "lmda_521 [[<tf.Tensor 'Const_333:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_578_1/convolution:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "[1, 8, 4, 32]\n",
      "m_522 [[]]\n",
      "lmda_523 [[<tf.Tensor 'Const_334:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_578_2/convolution:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "[1, 8, 4, 32]\n",
      "m_524 [[]]\n",
      "lmda_525 [[<tf.Tensor 'Const_335:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_578_3/convolution:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "[1, 8, 4, 32]\n",
      "concatenate_280 [[<tf.Tensor 'concatenate_279_1/concat:0' shape=(1, 8, 4, 640) dtype=float32>, <tf.Tensor 'lambda_465_1/Mul:0' shape=(1, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_279_2/concat:0' shape=(1, 8, 4, 640) dtype=float32>, <tf.Tensor 'lambda_466_1/Mul:0' shape=(1, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_279_3/concat:0' shape=(1, 8, 4, 640) dtype=float32>, <tf.Tensor 'lambda_467_1/Mul:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "m_527 [[]]\n",
      "lmda_528 [[<tf.Tensor 'Const_336:0' shape=(672,) dtype=float32>, <tf.Tensor 'concatenate_280_1/concat:0' shape=(1, 8, 4, 672) dtype=float32>]]\n",
      "[1, 8, 4, 672]\n",
      "m_529 [[]]\n",
      "lmda_530 [[<tf.Tensor 'Const_337:0' shape=(672,) dtype=float32>, <tf.Tensor 'concatenate_280_2/concat:0' shape=(1, 8, 4, 672) dtype=float32>]]\n",
      "[1, 8, 4, 672]\n",
      "m_531 [[]]\n",
      "lmda_532 [[<tf.Tensor 'Const_338:0' shape=(672,) dtype=float32>, <tf.Tensor 'concatenate_280_3/concat:0' shape=(1, 8, 4, 672) dtype=float32>]]\n",
      "[1, 8, 4, 672]\n",
      "batch_normalization_499 [[<tf.Tensor 'lambda_468_1/Mul:0' shape=(1, 8, 4, 672) dtype=float32>], [<tf.Tensor 'lambda_469_1/Mul:0' shape=(1, 8, 4, 672) dtype=float32>], [<tf.Tensor 'lambda_470_1/Mul:0' shape=(1, 8, 4, 672) dtype=float32>]]\n",
      "m_534 [[]]\n",
      "lmda_535 [[<tf.Tensor 'Const_339:0' shape=(672,) dtype=float32>, <tf.Tensor 'batch_normalization_499_1/cond/Merge:0' shape=(1, 8, 4, 672) dtype=float32>]]\n",
      "[1, 8, 4, 672]\n",
      "m_536 [[]]\n",
      "lmda_537 [[<tf.Tensor 'Const_340:0' shape=(672,) dtype=float32>, <tf.Tensor 'batch_normalization_499_2/cond/Merge:0' shape=(1, 8, 4, 672) dtype=float32>]]\n",
      "[1, 8, 4, 672]\n",
      "m_538 [[]]\n",
      "lmda_539 [[<tf.Tensor 'Const_341:0' shape=(672,) dtype=float32>, <tf.Tensor 'batch_normalization_499_3/cond/Merge:0' shape=(1, 8, 4, 672) dtype=float32>]]\n",
      "[1, 8, 4, 672]\n",
      "activation_587 [[<tf.Tensor 'lambda_471_1/Mul:0' shape=(1, 8, 4, 672) dtype=float32>], [<tf.Tensor 'lambda_472_1/Mul:0' shape=(1, 8, 4, 672) dtype=float32>], [<tf.Tensor 'lambda_473_1/Mul:0' shape=(1, 8, 4, 672) dtype=float32>]]\n",
      "l_541 [[<tf.Tensor 'activation_587_1/Relu:0' shape=(1, 8, 4, 672) dtype=float32>]]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [1760]\n",
      "6 [1, 8, 4, 5, 11]\n",
      "7 [1, 8, 4, 5, 32]\n",
      "8 [1, 8, 4, 5, 32]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [1760]\n",
      "6 [1, 8, 4, 5, 11]\n",
      "7 [1, 8, 4, 5, 32]\n",
      "8 [1, 8, 4, 5, 32]\n",
      "l_542 [[<tf.Tensor 'activation_587_2/Relu:0' shape=(1, 8, 4, 672) dtype=float32>]]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [1760]\n",
      "6 [1, 8, 4, 5, 11]\n",
      "7 [1, 8, 4, 5, 32]\n",
      "8 [1, 8, 4, 5, 32]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [1760]\n",
      "6 [1, 8, 4, 5, 11]\n",
      "7 [1, 8, 4, 5, 32]\n",
      "8 [1, 8, 4, 5, 32]\n",
      "l_543 [[<tf.Tensor 'activation_587_3/Relu:0' shape=(1, 8, 4, 672) dtype=float32>]]\n",
      "1 [5440]\n",
      "2 [1, 8, 4, 1, 170]\n",
      "3 [1, 8, 4, 1, 510]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [1600]\n",
      "6 [1, 8, 4, 5, 10]\n",
      "7 [1, 8, 4, 5, 30]\n",
      "8 [1, 8, 4, 5, 32]\n",
      "1 [5440]\n",
      "2 [1, 8, 4, 1, 170]\n",
      "3 [1, 8, 4, 1, 510]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [1600]\n",
      "6 [1, 8, 4, 5, 10]\n",
      "7 [1, 8, 4, 5, 30]\n",
      "8 [1, 8, 4, 5, 32]\n",
      "conv2d_579 [[<tf.Tensor 'lambda_474/Reshape_4:0' shape=(1, 8, 4, 672) dtype=float32>], [<tf.Tensor 'lambda_475/Reshape_4:0' shape=(1, 8, 4, 672) dtype=float32>], [<tf.Tensor 'lambda_476/Reshape_4:0' shape=(1, 8, 4, 672) dtype=float32>]]\n",
      "idx [85512, 4]\n",
      "gather [85512]\n",
      "m_545 [[]]\n",
      "lmda_546 [[<tf.Tensor 'Const_342:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_579_1/convolution:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_547 [[]]\n",
      "lmda_548 [[<tf.Tensor 'Const_343:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_579_2/convolution:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_549 [[]]\n",
      "lmda_550 [[<tf.Tensor 'Const_344:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_579_3/convolution:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "batch_normalization_500 [[<tf.Tensor 'lambda_477_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_478_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_479_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "m_552 [[]]\n",
      "lmda_553 [[<tf.Tensor 'Const_345:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_500_1/cond/Merge:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_554 [[]]\n",
      "lmda_555 [[<tf.Tensor 'Const_346:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_500_2/cond/Merge:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_556 [[]]\n",
      "lmda_557 [[<tf.Tensor 'Const_347:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_500_3/cond/Merge:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "activation_588 [[<tf.Tensor 'lambda_480_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_481_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_482_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "l_559 [[<tf.Tensor 'activation_588_1/Relu:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "l_560 [[<tf.Tensor 'activation_588_2/Relu:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "l_561 [[<tf.Tensor 'activation_588_3/Relu:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "1 [1344]\n",
      "2 [1, 8, 4, 1, 42]\n",
      "3 [1, 8, 4, 1, 126]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "1 [1344]\n",
      "2 [1, 8, 4, 1, 42]\n",
      "3 [1, 8, 4, 1, 126]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "conv2d_580 [[<tf.Tensor 'lambda_483/Reshape_1:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_484/Reshape_1:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_485/Reshape_1:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "m_563 [[]]\n",
      "lmda_564 [[<tf.Tensor 'Const_348:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_580_1/convolution:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "[1, 8, 4, 32]\n",
      "m_565 [[]]\n",
      "lmda_566 [[<tf.Tensor 'Const_349:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_580_2/convolution:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "[1, 8, 4, 32]\n",
      "m_567 [[]]\n",
      "lmda_568 [[<tf.Tensor 'Const_350:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_580_3/convolution:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "[1, 8, 4, 32]\n",
      "concatenate_281 [[<tf.Tensor 'concatenate_280_1/concat:0' shape=(1, 8, 4, 672) dtype=float32>, <tf.Tensor 'lambda_486_1/Mul:0' shape=(1, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_280_2/concat:0' shape=(1, 8, 4, 672) dtype=float32>, <tf.Tensor 'lambda_487_1/Mul:0' shape=(1, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_280_3/concat:0' shape=(1, 8, 4, 672) dtype=float32>, <tf.Tensor 'lambda_488_1/Mul:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "m_570 [[]]\n",
      "lmda_571 [[<tf.Tensor 'Const_351:0' shape=(704,) dtype=float32>, <tf.Tensor 'concatenate_281_1/concat:0' shape=(1, 8, 4, 704) dtype=float32>]]\n",
      "[1, 8, 4, 704]\n",
      "m_572 [[]]\n",
      "lmda_573 [[<tf.Tensor 'Const_352:0' shape=(704,) dtype=float32>, <tf.Tensor 'concatenate_281_2/concat:0' shape=(1, 8, 4, 704) dtype=float32>]]\n",
      "[1, 8, 4, 704]\n",
      "m_574 [[]]\n",
      "lmda_575 [[<tf.Tensor 'Const_353:0' shape=(704,) dtype=float32>, <tf.Tensor 'concatenate_281_3/concat:0' shape=(1, 8, 4, 704) dtype=float32>]]\n",
      "[1, 8, 4, 704]\n",
      "batch_normalization_501 [[<tf.Tensor 'lambda_489_1/Mul:0' shape=(1, 8, 4, 704) dtype=float32>], [<tf.Tensor 'lambda_490_1/Mul:0' shape=(1, 8, 4, 704) dtype=float32>], [<tf.Tensor 'lambda_491_1/Mul:0' shape=(1, 8, 4, 704) dtype=float32>]]\n",
      "m_577 [[]]\n",
      "lmda_578 [[<tf.Tensor 'Const_354:0' shape=(704,) dtype=float32>, <tf.Tensor 'batch_normalization_501_1/cond/Merge:0' shape=(1, 8, 4, 704) dtype=float32>]]\n",
      "[1, 8, 4, 704]\n",
      "m_579 [[]]\n",
      "lmda_580 [[<tf.Tensor 'Const_355:0' shape=(704,) dtype=float32>, <tf.Tensor 'batch_normalization_501_2/cond/Merge:0' shape=(1, 8, 4, 704) dtype=float32>]]\n",
      "[1, 8, 4, 704]\n",
      "m_581 [[]]\n",
      "lmda_582 [[<tf.Tensor 'Const_356:0' shape=(704,) dtype=float32>, <tf.Tensor 'batch_normalization_501_3/cond/Merge:0' shape=(1, 8, 4, 704) dtype=float32>]]\n",
      "[1, 8, 4, 704]\n",
      "activation_589 [[<tf.Tensor 'lambda_492_1/Mul:0' shape=(1, 8, 4, 704) dtype=float32>], [<tf.Tensor 'lambda_493_1/Mul:0' shape=(1, 8, 4, 704) dtype=float32>], [<tf.Tensor 'lambda_494_1/Mul:0' shape=(1, 8, 4, 704) dtype=float32>]]\n",
      "l_584 [[<tf.Tensor 'activation_589_1/Relu:0' shape=(1, 8, 4, 704) dtype=float32>]]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [2112]\n",
      "6 [1, 8, 4, 6, 11]\n",
      "7 [1, 8, 4, 6, 32]\n",
      "8 [1, 8, 4, 6, 32]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [2112]\n",
      "6 [1, 8, 4, 6, 11]\n",
      "7 [1, 8, 4, 6, 32]\n",
      "8 [1, 8, 4, 6, 32]\n",
      "l_585 [[<tf.Tensor 'activation_589_2/Relu:0' shape=(1, 8, 4, 704) dtype=float32>]]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [2112]\n",
      "6 [1, 8, 4, 6, 11]\n",
      "7 [1, 8, 4, 6, 32]\n",
      "8 [1, 8, 4, 6, 32]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [2112]\n",
      "6 [1, 8, 4, 6, 11]\n",
      "7 [1, 8, 4, 6, 32]\n",
      "8 [1, 8, 4, 6, 32]\n",
      "l_586 [[<tf.Tensor 'activation_589_3/Relu:0' shape=(1, 8, 4, 704) dtype=float32>]]\n",
      "1 [5440]\n",
      "2 [1, 8, 4, 1, 170]\n",
      "3 [1, 8, 4, 1, 510]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [1920]\n",
      "6 [1, 8, 4, 6, 10]\n",
      "7 [1, 8, 4, 6, 30]\n",
      "8 [1, 8, 4, 6, 32]\n",
      "1 [5440]\n",
      "2 [1, 8, 4, 1, 170]\n",
      "3 [1, 8, 4, 1, 510]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [1920]\n",
      "6 [1, 8, 4, 6, 10]\n",
      "7 [1, 8, 4, 6, 30]\n",
      "8 [1, 8, 4, 6, 32]\n",
      "conv2d_581 [[<tf.Tensor 'lambda_495/Reshape_4:0' shape=(1, 8, 4, 704) dtype=float32>], [<tf.Tensor 'lambda_496/Reshape_4:0' shape=(1, 8, 4, 704) dtype=float32>], [<tf.Tensor 'lambda_497/Reshape_4:0' shape=(1, 8, 4, 704) dtype=float32>]]\n",
      "idx [89524, 4]\n",
      "gather [89524]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m_588 [[]]\n",
      "lmda_589 [[<tf.Tensor 'Const_357:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_581_1/convolution:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_590 [[]]\n",
      "lmda_591 [[<tf.Tensor 'Const_358:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_581_2/convolution:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_592 [[]]\n",
      "lmda_593 [[<tf.Tensor 'Const_359:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_581_3/convolution:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "batch_normalization_502 [[<tf.Tensor 'lambda_498_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_499_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_500_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "m_595 [[]]\n",
      "lmda_596 [[<tf.Tensor 'Const_360:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_502_1/cond/Merge:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_597 [[]]\n",
      "lmda_598 [[<tf.Tensor 'Const_361:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_502_2/cond/Merge:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_599 [[]]\n",
      "lmda_600 [[<tf.Tensor 'Const_362:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_502_3/cond/Merge:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "activation_590 [[<tf.Tensor 'lambda_501_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_502_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_503_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "l_602 [[<tf.Tensor 'activation_590_1/Relu:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "l_603 [[<tf.Tensor 'activation_590_2/Relu:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "l_604 [[<tf.Tensor 'activation_590_3/Relu:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "1 [1344]\n",
      "2 [1, 8, 4, 1, 42]\n",
      "3 [1, 8, 4, 1, 126]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "1 [1344]\n",
      "2 [1, 8, 4, 1, 42]\n",
      "3 [1, 8, 4, 1, 126]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "conv2d_582 [[<tf.Tensor 'lambda_504/Reshape_1:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_505/Reshape_1:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_506/Reshape_1:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "m_606 [[]]\n",
      "lmda_607 [[<tf.Tensor 'Const_363:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_582_1/convolution:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "[1, 8, 4, 32]\n",
      "m_608 [[]]\n",
      "lmda_609 [[<tf.Tensor 'Const_364:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_582_2/convolution:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "[1, 8, 4, 32]\n",
      "m_610 [[]]\n",
      "lmda_611 [[<tf.Tensor 'Const_365:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_582_3/convolution:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "[1, 8, 4, 32]\n",
      "concatenate_282 [[<tf.Tensor 'concatenate_281_1/concat:0' shape=(1, 8, 4, 704) dtype=float32>, <tf.Tensor 'lambda_507_1/Mul:0' shape=(1, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_281_2/concat:0' shape=(1, 8, 4, 704) dtype=float32>, <tf.Tensor 'lambda_508_1/Mul:0' shape=(1, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_281_3/concat:0' shape=(1, 8, 4, 704) dtype=float32>, <tf.Tensor 'lambda_509_1/Mul:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "m_613 [[]]\n",
      "lmda_614 [[<tf.Tensor 'Const_366:0' shape=(736,) dtype=float32>, <tf.Tensor 'concatenate_282_1/concat:0' shape=(1, 8, 4, 736) dtype=float32>]]\n",
      "[1, 8, 4, 736]\n",
      "m_615 [[]]\n",
      "lmda_616 [[<tf.Tensor 'Const_367:0' shape=(736,) dtype=float32>, <tf.Tensor 'concatenate_282_2/concat:0' shape=(1, 8, 4, 736) dtype=float32>]]\n",
      "[1, 8, 4, 736]\n",
      "m_617 [[]]\n",
      "lmda_618 [[<tf.Tensor 'Const_368:0' shape=(736,) dtype=float32>, <tf.Tensor 'concatenate_282_3/concat:0' shape=(1, 8, 4, 736) dtype=float32>]]\n",
      "[1, 8, 4, 736]\n",
      "batch_normalization_503 [[<tf.Tensor 'lambda_510_1/Mul:0' shape=(1, 8, 4, 736) dtype=float32>], [<tf.Tensor 'lambda_511_1/Mul:0' shape=(1, 8, 4, 736) dtype=float32>], [<tf.Tensor 'lambda_512_1/Mul:0' shape=(1, 8, 4, 736) dtype=float32>]]\n",
      "m_620 [[]]\n",
      "lmda_621 [[<tf.Tensor 'Const_369:0' shape=(736,) dtype=float32>, <tf.Tensor 'batch_normalization_503_1/cond/Merge:0' shape=(1, 8, 4, 736) dtype=float32>]]\n",
      "[1, 8, 4, 736]\n",
      "m_622 [[]]\n",
      "lmda_623 [[<tf.Tensor 'Const_370:0' shape=(736,) dtype=float32>, <tf.Tensor 'batch_normalization_503_2/cond/Merge:0' shape=(1, 8, 4, 736) dtype=float32>]]\n",
      "[1, 8, 4, 736]\n",
      "m_624 [[]]\n",
      "lmda_625 [[<tf.Tensor 'Const_371:0' shape=(736,) dtype=float32>, <tf.Tensor 'batch_normalization_503_3/cond/Merge:0' shape=(1, 8, 4, 736) dtype=float32>]]\n",
      "[1, 8, 4, 736]\n",
      "activation_591 [[<tf.Tensor 'lambda_513_1/Mul:0' shape=(1, 8, 4, 736) dtype=float32>], [<tf.Tensor 'lambda_514_1/Mul:0' shape=(1, 8, 4, 736) dtype=float32>], [<tf.Tensor 'lambda_515_1/Mul:0' shape=(1, 8, 4, 736) dtype=float32>]]\n",
      "l_627 [[<tf.Tensor 'activation_591_1/Relu:0' shape=(1, 8, 4, 736) dtype=float32>]]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [2464]\n",
      "6 [1, 8, 4, 7, 11]\n",
      "7 [1, 8, 4, 7, 32]\n",
      "8 [1, 8, 4, 7, 32]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [2464]\n",
      "6 [1, 8, 4, 7, 11]\n",
      "7 [1, 8, 4, 7, 32]\n",
      "8 [1, 8, 4, 7, 32]\n",
      "l_628 [[<tf.Tensor 'activation_591_2/Relu:0' shape=(1, 8, 4, 736) dtype=float32>]]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [2464]\n",
      "6 [1, 8, 4, 7, 11]\n",
      "7 [1, 8, 4, 7, 32]\n",
      "8 [1, 8, 4, 7, 32]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [2464]\n",
      "6 [1, 8, 4, 7, 11]\n",
      "7 [1, 8, 4, 7, 32]\n",
      "8 [1, 8, 4, 7, 32]\n",
      "l_629 [[<tf.Tensor 'activation_591_3/Relu:0' shape=(1, 8, 4, 736) dtype=float32>]]\n",
      "1 [5440]\n",
      "2 [1, 8, 4, 1, 170]\n",
      "3 [1, 8, 4, 1, 510]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [2240]\n",
      "6 [1, 8, 4, 7, 10]\n",
      "7 [1, 8, 4, 7, 30]\n",
      "8 [1, 8, 4, 7, 32]\n",
      "1 [5440]\n",
      "2 [1, 8, 4, 1, 170]\n",
      "3 [1, 8, 4, 1, 510]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [2240]\n",
      "6 [1, 8, 4, 7, 10]\n",
      "7 [1, 8, 4, 7, 30]\n",
      "8 [1, 8, 4, 7, 32]\n",
      "conv2d_583 [[<tf.Tensor 'lambda_516/Reshape_4:0' shape=(1, 8, 4, 736) dtype=float32>], [<tf.Tensor 'lambda_517/Reshape_4:0' shape=(1, 8, 4, 736) dtype=float32>], [<tf.Tensor 'lambda_518/Reshape_4:0' shape=(1, 8, 4, 736) dtype=float32>]]\n",
      "idx [93536, 4]\n",
      "gather [93536]\n",
      "m_631 [[]]\n",
      "lmda_632 [[<tf.Tensor 'Const_372:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_583_1/convolution:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_633 [[]]\n",
      "lmda_634 [[<tf.Tensor 'Const_373:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_583_2/convolution:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_635 [[]]\n",
      "lmda_636 [[<tf.Tensor 'Const_374:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_583_3/convolution:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "batch_normalization_504 [[<tf.Tensor 'lambda_519_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_520_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_521_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "m_638 [[]]\n",
      "lmda_639 [[<tf.Tensor 'Const_375:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_504_1/cond/Merge:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_640 [[]]\n",
      "lmda_641 [[<tf.Tensor 'Const_376:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_504_2/cond/Merge:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_642 [[]]\n",
      "lmda_643 [[<tf.Tensor 'Const_377:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_504_3/cond/Merge:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "activation_592 [[<tf.Tensor 'lambda_522_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_523_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_524_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "l_645 [[<tf.Tensor 'activation_592_1/Relu:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "l_646 [[<tf.Tensor 'activation_592_2/Relu:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "l_647 [[<tf.Tensor 'activation_592_3/Relu:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "1 [1344]\n",
      "2 [1, 8, 4, 1, 42]\n",
      "3 [1, 8, 4, 1, 126]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "1 [1344]\n",
      "2 [1, 8, 4, 1, 42]\n",
      "3 [1, 8, 4, 1, 126]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "conv2d_584 [[<tf.Tensor 'lambda_525/Reshape_1:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_526/Reshape_1:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_527/Reshape_1:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "m_649 [[]]\n",
      "lmda_650 [[<tf.Tensor 'Const_378:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_584_1/convolution:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "[1, 8, 4, 32]\n",
      "m_651 [[]]\n",
      "lmda_652 [[<tf.Tensor 'Const_379:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_584_2/convolution:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "[1, 8, 4, 32]\n",
      "m_653 [[]]\n",
      "lmda_654 [[<tf.Tensor 'Const_380:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_584_3/convolution:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "[1, 8, 4, 32]\n",
      "concatenate_283 [[<tf.Tensor 'concatenate_282_1/concat:0' shape=(1, 8, 4, 736) dtype=float32>, <tf.Tensor 'lambda_528_1/Mul:0' shape=(1, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_282_2/concat:0' shape=(1, 8, 4, 736) dtype=float32>, <tf.Tensor 'lambda_529_1/Mul:0' shape=(1, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_282_3/concat:0' shape=(1, 8, 4, 736) dtype=float32>, <tf.Tensor 'lambda_530_1/Mul:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "m_656 [[]]\n",
      "lmda_657 [[<tf.Tensor 'Const_381:0' shape=(768,) dtype=float32>, <tf.Tensor 'concatenate_283_1/concat:0' shape=(1, 8, 4, 768) dtype=float32>]]\n",
      "[1, 8, 4, 768]\n",
      "m_658 [[]]\n",
      "lmda_659 [[<tf.Tensor 'Const_382:0' shape=(768,) dtype=float32>, <tf.Tensor 'concatenate_283_2/concat:0' shape=(1, 8, 4, 768) dtype=float32>]]\n",
      "[1, 8, 4, 768]\n",
      "m_660 [[]]\n",
      "lmda_661 [[<tf.Tensor 'Const_383:0' shape=(768,) dtype=float32>, <tf.Tensor 'concatenate_283_3/concat:0' shape=(1, 8, 4, 768) dtype=float32>]]\n",
      "[1, 8, 4, 768]\n",
      "batch_normalization_505 [[<tf.Tensor 'lambda_531_1/Mul:0' shape=(1, 8, 4, 768) dtype=float32>], [<tf.Tensor 'lambda_532_1/Mul:0' shape=(1, 8, 4, 768) dtype=float32>], [<tf.Tensor 'lambda_533_1/Mul:0' shape=(1, 8, 4, 768) dtype=float32>]]\n",
      "m_663 [[]]\n",
      "lmda_664 [[<tf.Tensor 'Const_384:0' shape=(768,) dtype=float32>, <tf.Tensor 'batch_normalization_505_1/cond/Merge:0' shape=(1, 8, 4, 768) dtype=float32>]]\n",
      "[1, 8, 4, 768]\n",
      "m_665 [[]]\n",
      "lmda_666 [[<tf.Tensor 'Const_385:0' shape=(768,) dtype=float32>, <tf.Tensor 'batch_normalization_505_2/cond/Merge:0' shape=(1, 8, 4, 768) dtype=float32>]]\n",
      "[1, 8, 4, 768]\n",
      "m_667 [[]]\n",
      "lmda_668 [[<tf.Tensor 'Const_386:0' shape=(768,) dtype=float32>, <tf.Tensor 'batch_normalization_505_3/cond/Merge:0' shape=(1, 8, 4, 768) dtype=float32>]]\n",
      "[1, 8, 4, 768]\n",
      "activation_593 [[<tf.Tensor 'lambda_534_1/Mul:0' shape=(1, 8, 4, 768) dtype=float32>], [<tf.Tensor 'lambda_535_1/Mul:0' shape=(1, 8, 4, 768) dtype=float32>], [<tf.Tensor 'lambda_536_1/Mul:0' shape=(1, 8, 4, 768) dtype=float32>]]\n",
      "l_670 [[<tf.Tensor 'activation_593_1/Relu:0' shape=(1, 8, 4, 768) dtype=float32>]]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [2816]\n",
      "6 [1, 8, 4, 8, 11]\n",
      "7 [1, 8, 4, 8, 32]\n",
      "8 [1, 8, 4, 8, 32]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [2816]\n",
      "6 [1, 8, 4, 8, 11]\n",
      "7 [1, 8, 4, 8, 32]\n",
      "8 [1, 8, 4, 8, 32]\n",
      "l_671 [[<tf.Tensor 'activation_593_2/Relu:0' shape=(1, 8, 4, 768) dtype=float32>]]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [2816]\n",
      "6 [1, 8, 4, 8, 11]\n",
      "7 [1, 8, 4, 8, 32]\n",
      "8 [1, 8, 4, 8, 32]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 [1, 8, 4, 1, 512]\n",
      "5 [2816]\n",
      "6 [1, 8, 4, 8, 11]\n",
      "7 [1, 8, 4, 8, 32]\n",
      "8 [1, 8, 4, 8, 32]\n",
      "l_672 [[<tf.Tensor 'activation_593_3/Relu:0' shape=(1, 8, 4, 768) dtype=float32>]]\n",
      "1 [5440]\n",
      "2 [1, 8, 4, 1, 170]\n",
      "3 [1, 8, 4, 1, 510]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [2560]\n",
      "6 [1, 8, 4, 8, 10]\n",
      "7 [1, 8, 4, 8, 30]\n",
      "8 [1, 8, 4, 8, 32]\n",
      "1 [5440]\n",
      "2 [1, 8, 4, 1, 170]\n",
      "3 [1, 8, 4, 1, 510]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [2560]\n",
      "6 [1, 8, 4, 8, 10]\n",
      "7 [1, 8, 4, 8, 30]\n",
      "8 [1, 8, 4, 8, 32]\n",
      "conv2d_585 [[<tf.Tensor 'lambda_537/Reshape_4:0' shape=(1, 8, 4, 768) dtype=float32>], [<tf.Tensor 'lambda_538/Reshape_4:0' shape=(1, 8, 4, 768) dtype=float32>], [<tf.Tensor 'lambda_539/Reshape_4:0' shape=(1, 8, 4, 768) dtype=float32>]]\n",
      "idx [97548, 4]\n",
      "gather [97548]\n",
      "m_674 [[]]\n",
      "lmda_675 [[<tf.Tensor 'Const_387:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_585_1/convolution:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_676 [[]]\n",
      "lmda_677 [[<tf.Tensor 'Const_388:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_585_2/convolution:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_678 [[]]\n",
      "lmda_679 [[<tf.Tensor 'Const_389:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_585_3/convolution:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "batch_normalization_506 [[<tf.Tensor 'lambda_540_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_541_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_542_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "m_681 [[]]\n",
      "lmda_682 [[<tf.Tensor 'Const_390:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_506_1/cond/Merge:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_683 [[]]\n",
      "lmda_684 [[<tf.Tensor 'Const_391:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_506_2/cond/Merge:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_685 [[]]\n",
      "lmda_686 [[<tf.Tensor 'Const_392:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_506_3/cond/Merge:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "activation_594 [[<tf.Tensor 'lambda_543_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_544_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_545_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "l_688 [[<tf.Tensor 'activation_594_1/Relu:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "l_689 [[<tf.Tensor 'activation_594_2/Relu:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "l_690 [[<tf.Tensor 'activation_594_3/Relu:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "1 [1344]\n",
      "2 [1, 8, 4, 1, 42]\n",
      "3 [1, 8, 4, 1, 126]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "1 [1344]\n",
      "2 [1, 8, 4, 1, 42]\n",
      "3 [1, 8, 4, 1, 126]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "conv2d_586 [[<tf.Tensor 'lambda_546/Reshape_1:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_547/Reshape_1:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_548/Reshape_1:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "m_692 [[]]\n",
      "lmda_693 [[<tf.Tensor 'Const_393:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_586_1/convolution:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "[1, 8, 4, 32]\n",
      "m_694 [[]]\n",
      "lmda_695 [[<tf.Tensor 'Const_394:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_586_2/convolution:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "[1, 8, 4, 32]\n",
      "m_696 [[]]\n",
      "lmda_697 [[<tf.Tensor 'Const_395:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_586_3/convolution:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "[1, 8, 4, 32]\n",
      "concatenate_284 [[<tf.Tensor 'concatenate_283_1/concat:0' shape=(1, 8, 4, 768) dtype=float32>, <tf.Tensor 'lambda_549_1/Mul:0' shape=(1, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_283_2/concat:0' shape=(1, 8, 4, 768) dtype=float32>, <tf.Tensor 'lambda_550_1/Mul:0' shape=(1, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_283_3/concat:0' shape=(1, 8, 4, 768) dtype=float32>, <tf.Tensor 'lambda_551_1/Mul:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "m_699 [[]]\n",
      "lmda_700 [[<tf.Tensor 'Const_396:0' shape=(800,) dtype=float32>, <tf.Tensor 'concatenate_284_1/concat:0' shape=(1, 8, 4, 800) dtype=float32>]]\n",
      "[1, 8, 4, 800]\n",
      "m_701 [[]]\n",
      "lmda_702 [[<tf.Tensor 'Const_397:0' shape=(800,) dtype=float32>, <tf.Tensor 'concatenate_284_2/concat:0' shape=(1, 8, 4, 800) dtype=float32>]]\n",
      "[1, 8, 4, 800]\n",
      "m_703 [[]]\n",
      "lmda_704 [[<tf.Tensor 'Const_398:0' shape=(800,) dtype=float32>, <tf.Tensor 'concatenate_284_3/concat:0' shape=(1, 8, 4, 800) dtype=float32>]]\n",
      "[1, 8, 4, 800]\n",
      "batch_normalization_507 [[<tf.Tensor 'lambda_552_1/Mul:0' shape=(1, 8, 4, 800) dtype=float32>], [<tf.Tensor 'lambda_553_1/Mul:0' shape=(1, 8, 4, 800) dtype=float32>], [<tf.Tensor 'lambda_554_1/Mul:0' shape=(1, 8, 4, 800) dtype=float32>]]\n",
      "m_706 [[]]\n",
      "lmda_707 [[<tf.Tensor 'Const_399:0' shape=(800,) dtype=float32>, <tf.Tensor 'batch_normalization_507_1/cond/Merge:0' shape=(1, 8, 4, 800) dtype=float32>]]\n",
      "[1, 8, 4, 800]\n",
      "m_708 [[]]\n",
      "lmda_709 [[<tf.Tensor 'Const_400:0' shape=(800,) dtype=float32>, <tf.Tensor 'batch_normalization_507_2/cond/Merge:0' shape=(1, 8, 4, 800) dtype=float32>]]\n",
      "[1, 8, 4, 800]\n",
      "m_710 [[]]\n",
      "lmda_711 [[<tf.Tensor 'Const_401:0' shape=(800,) dtype=float32>, <tf.Tensor 'batch_normalization_507_3/cond/Merge:0' shape=(1, 8, 4, 800) dtype=float32>]]\n",
      "[1, 8, 4, 800]\n",
      "activation_595 [[<tf.Tensor 'lambda_555_1/Mul:0' shape=(1, 8, 4, 800) dtype=float32>], [<tf.Tensor 'lambda_556_1/Mul:0' shape=(1, 8, 4, 800) dtype=float32>], [<tf.Tensor 'lambda_557_1/Mul:0' shape=(1, 8, 4, 800) dtype=float32>]]\n",
      "l_713 [[<tf.Tensor 'activation_595_1/Relu:0' shape=(1, 8, 4, 800) dtype=float32>]]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [3168]\n",
      "6 [1, 8, 4, 9, 11]\n",
      "7 [1, 8, 4, 9, 32]\n",
      "8 [1, 8, 4, 9, 32]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [3168]\n",
      "6 [1, 8, 4, 9, 11]\n",
      "7 [1, 8, 4, 9, 32]\n",
      "8 [1, 8, 4, 9, 32]\n",
      "l_714 [[<tf.Tensor 'activation_595_2/Relu:0' shape=(1, 8, 4, 800) dtype=float32>]]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [3168]\n",
      "6 [1, 8, 4, 9, 11]\n",
      "7 [1, 8, 4, 9, 32]\n",
      "8 [1, 8, 4, 9, 32]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [3168]\n",
      "6 [1, 8, 4, 9, 11]\n",
      "7 [1, 8, 4, 9, 32]\n",
      "8 [1, 8, 4, 9, 32]\n",
      "l_715 [[<tf.Tensor 'activation_595_3/Relu:0' shape=(1, 8, 4, 800) dtype=float32>]]\n",
      "1 [5440]\n",
      "2 [1, 8, 4, 1, 170]\n",
      "3 [1, 8, 4, 1, 510]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [2880]\n",
      "6 [1, 8, 4, 9, 10]\n",
      "7 [1, 8, 4, 9, 30]\n",
      "8 [1, 8, 4, 9, 32]\n",
      "1 [5440]\n",
      "2 [1, 8, 4, 1, 170]\n",
      "3 [1, 8, 4, 1, 510]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [2880]\n",
      "6 [1, 8, 4, 9, 10]\n",
      "7 [1, 8, 4, 9, 30]\n",
      "8 [1, 8, 4, 9, 32]\n",
      "conv2d_587 [[<tf.Tensor 'lambda_558/Reshape_4:0' shape=(1, 8, 4, 800) dtype=float32>], [<tf.Tensor 'lambda_559/Reshape_4:0' shape=(1, 8, 4, 800) dtype=float32>], [<tf.Tensor 'lambda_560/Reshape_4:0' shape=(1, 8, 4, 800) dtype=float32>]]\n",
      "idx [101560, 4]\n",
      "gather [101560]\n",
      "m_717 [[]]\n",
      "lmda_718 [[<tf.Tensor 'Const_402:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_587_1/convolution:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_719 [[]]\n",
      "lmda_720 [[<tf.Tensor 'Const_403:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_587_2/convolution:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_721 [[]]\n",
      "lmda_722 [[<tf.Tensor 'Const_404:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_587_3/convolution:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "batch_normalization_508 [[<tf.Tensor 'lambda_561_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_562_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_563_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "m_724 [[]]\n",
      "lmda_725 [[<tf.Tensor 'Const_405:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_508_1/cond/Merge:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_726 [[]]\n",
      "lmda_727 [[<tf.Tensor 'Const_406:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_508_2/cond/Merge:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_728 [[]]\n",
      "lmda_729 [[<tf.Tensor 'Const_407:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_508_3/cond/Merge:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "activation_596 [[<tf.Tensor 'lambda_564_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_565_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_566_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "l_731 [[<tf.Tensor 'activation_596_1/Relu:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "l_732 [[<tf.Tensor 'activation_596_2/Relu:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "l_733 [[<tf.Tensor 'activation_596_3/Relu:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "1 [1344]\n",
      "2 [1, 8, 4, 1, 42]\n",
      "3 [1, 8, 4, 1, 126]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "1 [1344]\n",
      "2 [1, 8, 4, 1, 42]\n",
      "3 [1, 8, 4, 1, 126]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "conv2d_588 [[<tf.Tensor 'lambda_567/Reshape_1:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_568/Reshape_1:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_569/Reshape_1:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "m_735 [[]]\n",
      "lmda_736 [[<tf.Tensor 'Const_408:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_588_1/convolution:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "[1, 8, 4, 32]\n",
      "m_737 [[]]\n",
      "lmda_738 [[<tf.Tensor 'Const_409:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_588_2/convolution:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "[1, 8, 4, 32]\n",
      "m_739 [[]]\n",
      "lmda_740 [[<tf.Tensor 'Const_410:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_588_3/convolution:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "[1, 8, 4, 32]\n",
      "concatenate_285 [[<tf.Tensor 'concatenate_284_1/concat:0' shape=(1, 8, 4, 800) dtype=float32>, <tf.Tensor 'lambda_570_1/Mul:0' shape=(1, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_284_2/concat:0' shape=(1, 8, 4, 800) dtype=float32>, <tf.Tensor 'lambda_571_1/Mul:0' shape=(1, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_284_3/concat:0' shape=(1, 8, 4, 800) dtype=float32>, <tf.Tensor 'lambda_572_1/Mul:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "m_742 [[]]\n",
      "lmda_743 [[<tf.Tensor 'Const_411:0' shape=(832,) dtype=float32>, <tf.Tensor 'concatenate_285_1/concat:0' shape=(1, 8, 4, 832) dtype=float32>]]\n",
      "[1, 8, 4, 832]\n",
      "m_744 [[]]\n",
      "lmda_745 [[<tf.Tensor 'Const_412:0' shape=(832,) dtype=float32>, <tf.Tensor 'concatenate_285_2/concat:0' shape=(1, 8, 4, 832) dtype=float32>]]\n",
      "[1, 8, 4, 832]\n",
      "m_746 [[]]\n",
      "lmda_747 [[<tf.Tensor 'Const_413:0' shape=(832,) dtype=float32>, <tf.Tensor 'concatenate_285_3/concat:0' shape=(1, 8, 4, 832) dtype=float32>]]\n",
      "[1, 8, 4, 832]\n",
      "batch_normalization_509 [[<tf.Tensor 'lambda_573_1/Mul:0' shape=(1, 8, 4, 832) dtype=float32>], [<tf.Tensor 'lambda_574_1/Mul:0' shape=(1, 8, 4, 832) dtype=float32>], [<tf.Tensor 'lambda_575_1/Mul:0' shape=(1, 8, 4, 832) dtype=float32>]]\n",
      "m_749 [[]]\n",
      "lmda_750 [[<tf.Tensor 'Const_414:0' shape=(832,) dtype=float32>, <tf.Tensor 'batch_normalization_509_1/cond/Merge:0' shape=(1, 8, 4, 832) dtype=float32>]]\n",
      "[1, 8, 4, 832]\n",
      "m_751 [[]]\n",
      "lmda_752 [[<tf.Tensor 'Const_415:0' shape=(832,) dtype=float32>, <tf.Tensor 'batch_normalization_509_2/cond/Merge:0' shape=(1, 8, 4, 832) dtype=float32>]]\n",
      "[1, 8, 4, 832]\n",
      "m_753 [[]]\n",
      "lmda_754 [[<tf.Tensor 'Const_416:0' shape=(832,) dtype=float32>, <tf.Tensor 'batch_normalization_509_3/cond/Merge:0' shape=(1, 8, 4, 832) dtype=float32>]]\n",
      "[1, 8, 4, 832]\n",
      "activation_597 [[<tf.Tensor 'lambda_576_1/Mul:0' shape=(1, 8, 4, 832) dtype=float32>], [<tf.Tensor 'lambda_577_1/Mul:0' shape=(1, 8, 4, 832) dtype=float32>], [<tf.Tensor 'lambda_578_1/Mul:0' shape=(1, 8, 4, 832) dtype=float32>]]\n",
      "l_756 [[<tf.Tensor 'activation_597_1/Relu:0' shape=(1, 8, 4, 832) dtype=float32>]]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [3520]\n",
      "6 [1, 8, 4, 10, 11]\n",
      "7 [1, 8, 4, 10, 32]\n",
      "8 [1, 8, 4, 10, 32]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [3520]\n",
      "6 [1, 8, 4, 10, 11]\n",
      "7 [1, 8, 4, 10, 32]\n",
      "8 [1, 8, 4, 10, 32]\n",
      "l_757 [[<tf.Tensor 'activation_597_2/Relu:0' shape=(1, 8, 4, 832) dtype=float32>]]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [3520]\n",
      "6 [1, 8, 4, 10, 11]\n",
      "7 [1, 8, 4, 10, 32]\n",
      "8 [1, 8, 4, 10, 32]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [3520]\n",
      "6 [1, 8, 4, 10, 11]\n",
      "7 [1, 8, 4, 10, 32]\n",
      "8 [1, 8, 4, 10, 32]\n",
      "l_758 [[<tf.Tensor 'activation_597_3/Relu:0' shape=(1, 8, 4, 832) dtype=float32>]]\n",
      "1 [5440]\n",
      "2 [1, 8, 4, 1, 170]\n",
      "3 [1, 8, 4, 1, 510]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [3200]\n",
      "6 [1, 8, 4, 10, 10]\n",
      "7 [1, 8, 4, 10, 30]\n",
      "8 [1, 8, 4, 10, 32]\n",
      "1 [5440]\n",
      "2 [1, 8, 4, 1, 170]\n",
      "3 [1, 8, 4, 1, 510]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [3200]\n",
      "6 [1, 8, 4, 10, 10]\n",
      "7 [1, 8, 4, 10, 30]\n",
      "8 [1, 8, 4, 10, 32]\n",
      "conv2d_589 [[<tf.Tensor 'lambda_579/Reshape_4:0' shape=(1, 8, 4, 832) dtype=float32>], [<tf.Tensor 'lambda_580/Reshape_4:0' shape=(1, 8, 4, 832) dtype=float32>], [<tf.Tensor 'lambda_581/Reshape_4:0' shape=(1, 8, 4, 832) dtype=float32>]]\n",
      "idx [105572, 4]\n",
      "gather [105572]\n",
      "m_760 [[]]\n",
      "lmda_761 [[<tf.Tensor 'Const_417:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_589_1/convolution:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_762 [[]]\n",
      "lmda_763 [[<tf.Tensor 'Const_418:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_589_2/convolution:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_764 [[]]\n",
      "lmda_765 [[<tf.Tensor 'Const_419:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_589_3/convolution:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "batch_normalization_510 [[<tf.Tensor 'lambda_582_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_583_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_584_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "m_767 [[]]\n",
      "lmda_768 [[<tf.Tensor 'Const_420:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_510_1/cond/Merge:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_769 [[]]\n",
      "lmda_770 [[<tf.Tensor 'Const_421:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_510_2/cond/Merge:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_771 [[]]\n",
      "lmda_772 [[<tf.Tensor 'Const_422:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_510_3/cond/Merge:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "activation_598 [[<tf.Tensor 'lambda_585_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_586_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_587_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "l_774 [[<tf.Tensor 'activation_598_1/Relu:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "l_775 [[<tf.Tensor 'activation_598_2/Relu:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "l_776 [[<tf.Tensor 'activation_598_3/Relu:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "1 [1344]\n",
      "2 [1, 8, 4, 1, 42]\n",
      "3 [1, 8, 4, 1, 126]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "1 [1344]\n",
      "2 [1, 8, 4, 1, 42]\n",
      "3 [1, 8, 4, 1, 126]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "conv2d_590 [[<tf.Tensor 'lambda_588/Reshape_1:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_589/Reshape_1:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_590/Reshape_1:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "m_778 [[]]\n",
      "lmda_779 [[<tf.Tensor 'Const_423:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_590_1/convolution:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "[1, 8, 4, 32]\n",
      "m_780 [[]]\n",
      "lmda_781 [[<tf.Tensor 'Const_424:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_590_2/convolution:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "[1, 8, 4, 32]\n",
      "m_782 [[]]\n",
      "lmda_783 [[<tf.Tensor 'Const_425:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_590_3/convolution:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "[1, 8, 4, 32]\n",
      "concatenate_286 [[<tf.Tensor 'concatenate_285_1/concat:0' shape=(1, 8, 4, 832) dtype=float32>, <tf.Tensor 'lambda_591_1/Mul:0' shape=(1, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_285_2/concat:0' shape=(1, 8, 4, 832) dtype=float32>, <tf.Tensor 'lambda_592_1/Mul:0' shape=(1, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_285_3/concat:0' shape=(1, 8, 4, 832) dtype=float32>, <tf.Tensor 'lambda_593_1/Mul:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "m_785 [[]]\n",
      "lmda_786 [[<tf.Tensor 'Const_426:0' shape=(864,) dtype=float32>, <tf.Tensor 'concatenate_286_1/concat:0' shape=(1, 8, 4, 864) dtype=float32>]]\n",
      "[1, 8, 4, 864]\n",
      "m_787 [[]]\n",
      "lmda_788 [[<tf.Tensor 'Const_427:0' shape=(864,) dtype=float32>, <tf.Tensor 'concatenate_286_2/concat:0' shape=(1, 8, 4, 864) dtype=float32>]]\n",
      "[1, 8, 4, 864]\n",
      "m_789 [[]]\n",
      "lmda_790 [[<tf.Tensor 'Const_428:0' shape=(864,) dtype=float32>, <tf.Tensor 'concatenate_286_3/concat:0' shape=(1, 8, 4, 864) dtype=float32>]]\n",
      "[1, 8, 4, 864]\n",
      "batch_normalization_511 [[<tf.Tensor 'lambda_594_1/Mul:0' shape=(1, 8, 4, 864) dtype=float32>], [<tf.Tensor 'lambda_595_1/Mul:0' shape=(1, 8, 4, 864) dtype=float32>], [<tf.Tensor 'lambda_596_1/Mul:0' shape=(1, 8, 4, 864) dtype=float32>]]\n",
      "m_792 [[]]\n",
      "lmda_793 [[<tf.Tensor 'Const_429:0' shape=(864,) dtype=float32>, <tf.Tensor 'batch_normalization_511_1/cond/Merge:0' shape=(1, 8, 4, 864) dtype=float32>]]\n",
      "[1, 8, 4, 864]\n",
      "m_794 [[]]\n",
      "lmda_795 [[<tf.Tensor 'Const_430:0' shape=(864,) dtype=float32>, <tf.Tensor 'batch_normalization_511_2/cond/Merge:0' shape=(1, 8, 4, 864) dtype=float32>]]\n",
      "[1, 8, 4, 864]\n",
      "m_796 [[]]\n",
      "lmda_797 [[<tf.Tensor 'Const_431:0' shape=(864,) dtype=float32>, <tf.Tensor 'batch_normalization_511_3/cond/Merge:0' shape=(1, 8, 4, 864) dtype=float32>]]\n",
      "[1, 8, 4, 864]\n",
      "activation_599 [[<tf.Tensor 'lambda_597_1/Mul:0' shape=(1, 8, 4, 864) dtype=float32>], [<tf.Tensor 'lambda_598_1/Mul:0' shape=(1, 8, 4, 864) dtype=float32>], [<tf.Tensor 'lambda_599_1/Mul:0' shape=(1, 8, 4, 864) dtype=float32>]]\n",
      "l_799 [[<tf.Tensor 'activation_599_1/Relu:0' shape=(1, 8, 4, 864) dtype=float32>]]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [3872]\n",
      "6 [1, 8, 4, 11, 11]\n",
      "7 [1, 8, 4, 11, 32]\n",
      "8 [1, 8, 4, 11, 32]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [3872]\n",
      "6 [1, 8, 4, 11, 11]\n",
      "7 [1, 8, 4, 11, 32]\n",
      "8 [1, 8, 4, 11, 32]\n",
      "l_800 [[<tf.Tensor 'activation_599_2/Relu:0' shape=(1, 8, 4, 864) dtype=float32>]]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [3872]\n",
      "6 [1, 8, 4, 11, 11]\n",
      "7 [1, 8, 4, 11, 32]\n",
      "8 [1, 8, 4, 11, 32]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [3872]\n",
      "6 [1, 8, 4, 11, 11]\n",
      "7 [1, 8, 4, 11, 32]\n",
      "8 [1, 8, 4, 11, 32]\n",
      "l_801 [[<tf.Tensor 'activation_599_3/Relu:0' shape=(1, 8, 4, 864) dtype=float32>]]\n",
      "1 [5440]\n",
      "2 [1, 8, 4, 1, 170]\n",
      "3 [1, 8, 4, 1, 510]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [3520]\n",
      "6 [1, 8, 4, 11, 10]\n",
      "7 [1, 8, 4, 11, 30]\n",
      "8 [1, 8, 4, 11, 32]\n",
      "1 [5440]\n",
      "2 [1, 8, 4, 1, 170]\n",
      "3 [1, 8, 4, 1, 510]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [3520]\n",
      "6 [1, 8, 4, 11, 10]\n",
      "7 [1, 8, 4, 11, 30]\n",
      "8 [1, 8, 4, 11, 32]\n",
      "conv2d_591 [[<tf.Tensor 'lambda_600/Reshape_4:0' shape=(1, 8, 4, 864) dtype=float32>], [<tf.Tensor 'lambda_601/Reshape_4:0' shape=(1, 8, 4, 864) dtype=float32>], [<tf.Tensor 'lambda_602/Reshape_4:0' shape=(1, 8, 4, 864) dtype=float32>]]\n",
      "idx [109584, 4]\n",
      "gather [109584]\n",
      "m_803 [[]]\n",
      "lmda_804 [[<tf.Tensor 'Const_432:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_591_1/convolution:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_805 [[]]\n",
      "lmda_806 [[<tf.Tensor 'Const_433:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_591_2/convolution:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_807 [[]]\n",
      "lmda_808 [[<tf.Tensor 'Const_434:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_591_3/convolution:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "batch_normalization_512 [[<tf.Tensor 'lambda_603_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_604_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_605_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "m_810 [[]]\n",
      "lmda_811 [[<tf.Tensor 'Const_435:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_512_1/cond/Merge:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_812 [[]]\n",
      "lmda_813 [[<tf.Tensor 'Const_436:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_512_2/cond/Merge:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_814 [[]]\n",
      "lmda_815 [[<tf.Tensor 'Const_437:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_512_3/cond/Merge:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "activation_600 [[<tf.Tensor 'lambda_606_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_607_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_608_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "l_817 [[<tf.Tensor 'activation_600_1/Relu:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "l_818 [[<tf.Tensor 'activation_600_2/Relu:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "l_819 [[<tf.Tensor 'activation_600_3/Relu:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "1 [1344]\n",
      "2 [1, 8, 4, 1, 42]\n",
      "3 [1, 8, 4, 1, 126]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "1 [1344]\n",
      "2 [1, 8, 4, 1, 42]\n",
      "3 [1, 8, 4, 1, 126]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "conv2d_592 [[<tf.Tensor 'lambda_609/Reshape_1:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_610/Reshape_1:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_611/Reshape_1:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "m_821 [[]]\n",
      "lmda_822 [[<tf.Tensor 'Const_438:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_592_1/convolution:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "[1, 8, 4, 32]\n",
      "m_823 [[]]\n",
      "lmda_824 [[<tf.Tensor 'Const_439:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_592_2/convolution:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "[1, 8, 4, 32]\n",
      "m_825 [[]]\n",
      "lmda_826 [[<tf.Tensor 'Const_440:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_592_3/convolution:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "[1, 8, 4, 32]\n",
      "concatenate_287 [[<tf.Tensor 'concatenate_286_1/concat:0' shape=(1, 8, 4, 864) dtype=float32>, <tf.Tensor 'lambda_612_1/Mul:0' shape=(1, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_286_2/concat:0' shape=(1, 8, 4, 864) dtype=float32>, <tf.Tensor 'lambda_613_1/Mul:0' shape=(1, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_286_3/concat:0' shape=(1, 8, 4, 864) dtype=float32>, <tf.Tensor 'lambda_614_1/Mul:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "m_828 [[]]\n",
      "lmda_829 [[<tf.Tensor 'Const_441:0' shape=(896,) dtype=float32>, <tf.Tensor 'concatenate_287_1/concat:0' shape=(1, 8, 4, 896) dtype=float32>]]\n",
      "[1, 8, 4, 896]\n",
      "m_830 [[]]\n",
      "lmda_831 [[<tf.Tensor 'Const_442:0' shape=(896,) dtype=float32>, <tf.Tensor 'concatenate_287_2/concat:0' shape=(1, 8, 4, 896) dtype=float32>]]\n",
      "[1, 8, 4, 896]\n",
      "m_832 [[]]\n",
      "lmda_833 [[<tf.Tensor 'Const_443:0' shape=(896,) dtype=float32>, <tf.Tensor 'concatenate_287_3/concat:0' shape=(1, 8, 4, 896) dtype=float32>]]\n",
      "[1, 8, 4, 896]\n",
      "batch_normalization_513 [[<tf.Tensor 'lambda_615_1/Mul:0' shape=(1, 8, 4, 896) dtype=float32>], [<tf.Tensor 'lambda_616_1/Mul:0' shape=(1, 8, 4, 896) dtype=float32>], [<tf.Tensor 'lambda_617_1/Mul:0' shape=(1, 8, 4, 896) dtype=float32>]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m_835 [[]]\n",
      "lmda_836 [[<tf.Tensor 'Const_444:0' shape=(896,) dtype=float32>, <tf.Tensor 'batch_normalization_513_1/cond/Merge:0' shape=(1, 8, 4, 896) dtype=float32>]]\n",
      "[1, 8, 4, 896]\n",
      "m_837 [[]]\n",
      "lmda_838 [[<tf.Tensor 'Const_445:0' shape=(896,) dtype=float32>, <tf.Tensor 'batch_normalization_513_2/cond/Merge:0' shape=(1, 8, 4, 896) dtype=float32>]]\n",
      "[1, 8, 4, 896]\n",
      "m_839 [[]]\n",
      "lmda_840 [[<tf.Tensor 'Const_446:0' shape=(896,) dtype=float32>, <tf.Tensor 'batch_normalization_513_3/cond/Merge:0' shape=(1, 8, 4, 896) dtype=float32>]]\n",
      "[1, 8, 4, 896]\n",
      "activation_601 [[<tf.Tensor 'lambda_618_1/Mul:0' shape=(1, 8, 4, 896) dtype=float32>], [<tf.Tensor 'lambda_619_1/Mul:0' shape=(1, 8, 4, 896) dtype=float32>], [<tf.Tensor 'lambda_620_1/Mul:0' shape=(1, 8, 4, 896) dtype=float32>]]\n",
      "l_842 [[<tf.Tensor 'activation_601_1/Relu:0' shape=(1, 8, 4, 896) dtype=float32>]]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [4224]\n",
      "6 [1, 8, 4, 12, 11]\n",
      "7 [1, 8, 4, 12, 32]\n",
      "8 [1, 8, 4, 12, 32]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [4224]\n",
      "6 [1, 8, 4, 12, 11]\n",
      "7 [1, 8, 4, 12, 32]\n",
      "8 [1, 8, 4, 12, 32]\n",
      "l_843 [[<tf.Tensor 'activation_601_2/Relu:0' shape=(1, 8, 4, 896) dtype=float32>]]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [4224]\n",
      "6 [1, 8, 4, 12, 11]\n",
      "7 [1, 8, 4, 12, 32]\n",
      "8 [1, 8, 4, 12, 32]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [4224]\n",
      "6 [1, 8, 4, 12, 11]\n",
      "7 [1, 8, 4, 12, 32]\n",
      "8 [1, 8, 4, 12, 32]\n",
      "l_844 [[<tf.Tensor 'activation_601_3/Relu:0' shape=(1, 8, 4, 896) dtype=float32>]]\n",
      "1 [5440]\n",
      "2 [1, 8, 4, 1, 170]\n",
      "3 [1, 8, 4, 1, 510]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [3840]\n",
      "6 [1, 8, 4, 12, 10]\n",
      "7 [1, 8, 4, 12, 30]\n",
      "8 [1, 8, 4, 12, 32]\n",
      "1 [5440]\n",
      "2 [1, 8, 4, 1, 170]\n",
      "3 [1, 8, 4, 1, 510]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [3840]\n",
      "6 [1, 8, 4, 12, 10]\n",
      "7 [1, 8, 4, 12, 30]\n",
      "8 [1, 8, 4, 12, 32]\n",
      "conv2d_593 [[<tf.Tensor 'lambda_621/Reshape_4:0' shape=(1, 8, 4, 896) dtype=float32>], [<tf.Tensor 'lambda_622/Reshape_4:0' shape=(1, 8, 4, 896) dtype=float32>], [<tf.Tensor 'lambda_623/Reshape_4:0' shape=(1, 8, 4, 896) dtype=float32>]]\n",
      "idx [113596, 4]\n",
      "gather [113596]\n",
      "m_846 [[]]\n",
      "lmda_847 [[<tf.Tensor 'Const_447:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_593_1/convolution:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_848 [[]]\n",
      "lmda_849 [[<tf.Tensor 'Const_448:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_593_2/convolution:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_850 [[]]\n",
      "lmda_851 [[<tf.Tensor 'Const_449:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_593_3/convolution:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "batch_normalization_514 [[<tf.Tensor 'lambda_624_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_625_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_626_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "m_853 [[]]\n",
      "lmda_854 [[<tf.Tensor 'Const_450:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_514_1/cond/Merge:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_855 [[]]\n",
      "lmda_856 [[<tf.Tensor 'Const_451:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_514_2/cond/Merge:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_857 [[]]\n",
      "lmda_858 [[<tf.Tensor 'Const_452:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_514_3/cond/Merge:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "activation_602 [[<tf.Tensor 'lambda_627_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_628_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_629_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "l_860 [[<tf.Tensor 'activation_602_1/Relu:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "l_861 [[<tf.Tensor 'activation_602_2/Relu:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "l_862 [[<tf.Tensor 'activation_602_3/Relu:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "1 [1344]\n",
      "2 [1, 8, 4, 1, 42]\n",
      "3 [1, 8, 4, 1, 126]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "1 [1344]\n",
      "2 [1, 8, 4, 1, 42]\n",
      "3 [1, 8, 4, 1, 126]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "conv2d_594 [[<tf.Tensor 'lambda_630/Reshape_1:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_631/Reshape_1:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_632/Reshape_1:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "m_864 [[]]\n",
      "lmda_865 [[<tf.Tensor 'Const_453:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_594_1/convolution:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "[1, 8, 4, 32]\n",
      "m_866 [[]]\n",
      "lmda_867 [[<tf.Tensor 'Const_454:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_594_2/convolution:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "[1, 8, 4, 32]\n",
      "m_868 [[]]\n",
      "lmda_869 [[<tf.Tensor 'Const_455:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_594_3/convolution:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "[1, 8, 4, 32]\n",
      "concatenate_288 [[<tf.Tensor 'concatenate_287_1/concat:0' shape=(1, 8, 4, 896) dtype=float32>, <tf.Tensor 'lambda_633_1/Mul:0' shape=(1, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_287_2/concat:0' shape=(1, 8, 4, 896) dtype=float32>, <tf.Tensor 'lambda_634_1/Mul:0' shape=(1, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_287_3/concat:0' shape=(1, 8, 4, 896) dtype=float32>, <tf.Tensor 'lambda_635_1/Mul:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "m_871 [[]]\n",
      "lmda_872 [[<tf.Tensor 'Const_456:0' shape=(928,) dtype=float32>, <tf.Tensor 'concatenate_288_1/concat:0' shape=(1, 8, 4, 928) dtype=float32>]]\n",
      "[1, 8, 4, 928]\n",
      "m_873 [[]]\n",
      "lmda_874 [[<tf.Tensor 'Const_457:0' shape=(928,) dtype=float32>, <tf.Tensor 'concatenate_288_2/concat:0' shape=(1, 8, 4, 928) dtype=float32>]]\n",
      "[1, 8, 4, 928]\n",
      "m_875 [[]]\n",
      "lmda_876 [[<tf.Tensor 'Const_458:0' shape=(928,) dtype=float32>, <tf.Tensor 'concatenate_288_3/concat:0' shape=(1, 8, 4, 928) dtype=float32>]]\n",
      "[1, 8, 4, 928]\n",
      "batch_normalization_515 [[<tf.Tensor 'lambda_636_1/Mul:0' shape=(1, 8, 4, 928) dtype=float32>], [<tf.Tensor 'lambda_637_1/Mul:0' shape=(1, 8, 4, 928) dtype=float32>], [<tf.Tensor 'lambda_638_1/Mul:0' shape=(1, 8, 4, 928) dtype=float32>]]\n",
      "m_878 [[]]\n",
      "lmda_879 [[<tf.Tensor 'Const_459:0' shape=(928,) dtype=float32>, <tf.Tensor 'batch_normalization_515_1/cond/Merge:0' shape=(1, 8, 4, 928) dtype=float32>]]\n",
      "[1, 8, 4, 928]\n",
      "m_880 [[]]\n",
      "lmda_881 [[<tf.Tensor 'Const_460:0' shape=(928,) dtype=float32>, <tf.Tensor 'batch_normalization_515_2/cond/Merge:0' shape=(1, 8, 4, 928) dtype=float32>]]\n",
      "[1, 8, 4, 928]\n",
      "m_882 [[]]\n",
      "lmda_883 [[<tf.Tensor 'Const_461:0' shape=(928,) dtype=float32>, <tf.Tensor 'batch_normalization_515_3/cond/Merge:0' shape=(1, 8, 4, 928) dtype=float32>]]\n",
      "[1, 8, 4, 928]\n",
      "activation_603 [[<tf.Tensor 'lambda_639_1/Mul:0' shape=(1, 8, 4, 928) dtype=float32>], [<tf.Tensor 'lambda_640_1/Mul:0' shape=(1, 8, 4, 928) dtype=float32>], [<tf.Tensor 'lambda_641_1/Mul:0' shape=(1, 8, 4, 928) dtype=float32>]]\n",
      "l_885 [[<tf.Tensor 'activation_603_1/Relu:0' shape=(1, 8, 4, 928) dtype=float32>]]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [4576]\n",
      "6 [1, 8, 4, 13, 11]\n",
      "7 [1, 8, 4, 13, 32]\n",
      "8 [1, 8, 4, 13, 32]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [4576]\n",
      "6 [1, 8, 4, 13, 11]\n",
      "7 [1, 8, 4, 13, 32]\n",
      "8 [1, 8, 4, 13, 32]\n",
      "l_886 [[<tf.Tensor 'activation_603_2/Relu:0' shape=(1, 8, 4, 928) dtype=float32>]]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [4576]\n",
      "6 [1, 8, 4, 13, 11]\n",
      "7 [1, 8, 4, 13, 32]\n",
      "8 [1, 8, 4, 13, 32]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [4576]\n",
      "6 [1, 8, 4, 13, 11]\n",
      "7 [1, 8, 4, 13, 32]\n",
      "8 [1, 8, 4, 13, 32]\n",
      "l_887 [[<tf.Tensor 'activation_603_3/Relu:0' shape=(1, 8, 4, 928) dtype=float32>]]\n",
      "1 [5440]\n",
      "2 [1, 8, 4, 1, 170]\n",
      "3 [1, 8, 4, 1, 510]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [4160]\n",
      "6 [1, 8, 4, 13, 10]\n",
      "7 [1, 8, 4, 13, 30]\n",
      "8 [1, 8, 4, 13, 32]\n",
      "1 [5440]\n",
      "2 [1, 8, 4, 1, 170]\n",
      "3 [1, 8, 4, 1, 510]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [4160]\n",
      "6 [1, 8, 4, 13, 10]\n",
      "7 [1, 8, 4, 13, 30]\n",
      "8 [1, 8, 4, 13, 32]\n",
      "conv2d_595 [[<tf.Tensor 'lambda_642/Reshape_4:0' shape=(1, 8, 4, 928) dtype=float32>], [<tf.Tensor 'lambda_643/Reshape_4:0' shape=(1, 8, 4, 928) dtype=float32>], [<tf.Tensor 'lambda_644/Reshape_4:0' shape=(1, 8, 4, 928) dtype=float32>]]\n",
      "idx [117608, 4]\n",
      "gather [117608]\n",
      "m_889 [[]]\n",
      "lmda_890 [[<tf.Tensor 'Const_462:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_595_1/convolution:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_891 [[]]\n",
      "lmda_892 [[<tf.Tensor 'Const_463:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_595_2/convolution:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_893 [[]]\n",
      "lmda_894 [[<tf.Tensor 'Const_464:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_595_3/convolution:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "batch_normalization_516 [[<tf.Tensor 'lambda_645_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_646_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_647_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "m_896 [[]]\n",
      "lmda_897 [[<tf.Tensor 'Const_465:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_516_1/cond/Merge:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_898 [[]]\n",
      "lmda_899 [[<tf.Tensor 'Const_466:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_516_2/cond/Merge:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_900 [[]]\n",
      "lmda_901 [[<tf.Tensor 'Const_467:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_516_3/cond/Merge:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "activation_604 [[<tf.Tensor 'lambda_648_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_649_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_650_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "l_903 [[<tf.Tensor 'activation_604_1/Relu:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "l_904 [[<tf.Tensor 'activation_604_2/Relu:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "l_905 [[<tf.Tensor 'activation_604_3/Relu:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "1 [1344]\n",
      "2 [1, 8, 4, 1, 42]\n",
      "3 [1, 8, 4, 1, 126]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "1 [1344]\n",
      "2 [1, 8, 4, 1, 42]\n",
      "3 [1, 8, 4, 1, 126]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "conv2d_596 [[<tf.Tensor 'lambda_651/Reshape_1:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_652/Reshape_1:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_653/Reshape_1:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "m_907 [[]]\n",
      "lmda_908 [[<tf.Tensor 'Const_468:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_596_1/convolution:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "[1, 8, 4, 32]\n",
      "m_909 [[]]\n",
      "lmda_910 [[<tf.Tensor 'Const_469:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_596_2/convolution:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "[1, 8, 4, 32]\n",
      "m_911 [[]]\n",
      "lmda_912 [[<tf.Tensor 'Const_470:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_596_3/convolution:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "[1, 8, 4, 32]\n",
      "concatenate_289 [[<tf.Tensor 'concatenate_288_1/concat:0' shape=(1, 8, 4, 928) dtype=float32>, <tf.Tensor 'lambda_654_1/Mul:0' shape=(1, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_288_2/concat:0' shape=(1, 8, 4, 928) dtype=float32>, <tf.Tensor 'lambda_655_1/Mul:0' shape=(1, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_288_3/concat:0' shape=(1, 8, 4, 928) dtype=float32>, <tf.Tensor 'lambda_656_1/Mul:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "m_914 [[]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lmda_915 [[<tf.Tensor 'Const_471:0' shape=(960,) dtype=float32>, <tf.Tensor 'concatenate_289_1/concat:0' shape=(1, 8, 4, 960) dtype=float32>]]\n",
      "[1, 8, 4, 960]\n",
      "m_916 [[]]\n",
      "lmda_917 [[<tf.Tensor 'Const_472:0' shape=(960,) dtype=float32>, <tf.Tensor 'concatenate_289_2/concat:0' shape=(1, 8, 4, 960) dtype=float32>]]\n",
      "[1, 8, 4, 960]\n",
      "m_918 [[]]\n",
      "lmda_919 [[<tf.Tensor 'Const_473:0' shape=(960,) dtype=float32>, <tf.Tensor 'concatenate_289_3/concat:0' shape=(1, 8, 4, 960) dtype=float32>]]\n",
      "[1, 8, 4, 960]\n",
      "batch_normalization_517 [[<tf.Tensor 'lambda_657_1/Mul:0' shape=(1, 8, 4, 960) dtype=float32>], [<tf.Tensor 'lambda_658_1/Mul:0' shape=(1, 8, 4, 960) dtype=float32>], [<tf.Tensor 'lambda_659_1/Mul:0' shape=(1, 8, 4, 960) dtype=float32>]]\n",
      "m_921 [[]]\n",
      "lmda_922 [[<tf.Tensor 'Const_474:0' shape=(960,) dtype=float32>, <tf.Tensor 'batch_normalization_517_1/cond/Merge:0' shape=(1, 8, 4, 960) dtype=float32>]]\n",
      "[1, 8, 4, 960]\n",
      "m_923 [[]]\n",
      "lmda_924 [[<tf.Tensor 'Const_475:0' shape=(960,) dtype=float32>, <tf.Tensor 'batch_normalization_517_2/cond/Merge:0' shape=(1, 8, 4, 960) dtype=float32>]]\n",
      "[1, 8, 4, 960]\n",
      "m_925 [[]]\n",
      "lmda_926 [[<tf.Tensor 'Const_476:0' shape=(960,) dtype=float32>, <tf.Tensor 'batch_normalization_517_3/cond/Merge:0' shape=(1, 8, 4, 960) dtype=float32>]]\n",
      "[1, 8, 4, 960]\n",
      "activation_605 [[<tf.Tensor 'lambda_660_1/Mul:0' shape=(1, 8, 4, 960) dtype=float32>], [<tf.Tensor 'lambda_661_1/Mul:0' shape=(1, 8, 4, 960) dtype=float32>], [<tf.Tensor 'lambda_662_1/Mul:0' shape=(1, 8, 4, 960) dtype=float32>]]\n",
      "l_928 [[<tf.Tensor 'activation_605_1/Relu:0' shape=(1, 8, 4, 960) dtype=float32>]]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [4928]\n",
      "6 [1, 8, 4, 14, 11]\n",
      "7 [1, 8, 4, 14, 32]\n",
      "8 [1, 8, 4, 14, 32]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [4928]\n",
      "6 [1, 8, 4, 14, 11]\n",
      "7 [1, 8, 4, 14, 32]\n",
      "8 [1, 8, 4, 14, 32]\n",
      "l_929 [[<tf.Tensor 'activation_605_2/Relu:0' shape=(1, 8, 4, 960) dtype=float32>]]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [4928]\n",
      "6 [1, 8, 4, 14, 11]\n",
      "7 [1, 8, 4, 14, 32]\n",
      "8 [1, 8, 4, 14, 32]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [4928]\n",
      "6 [1, 8, 4, 14, 11]\n",
      "7 [1, 8, 4, 14, 32]\n",
      "8 [1, 8, 4, 14, 32]\n",
      "l_930 [[<tf.Tensor 'activation_605_3/Relu:0' shape=(1, 8, 4, 960) dtype=float32>]]\n",
      "1 [5440]\n",
      "2 [1, 8, 4, 1, 170]\n",
      "3 [1, 8, 4, 1, 510]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [4480]\n",
      "6 [1, 8, 4, 14, 10]\n",
      "7 [1, 8, 4, 14, 30]\n",
      "8 [1, 8, 4, 14, 32]\n",
      "1 [5440]\n",
      "2 [1, 8, 4, 1, 170]\n",
      "3 [1, 8, 4, 1, 510]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [4480]\n",
      "6 [1, 8, 4, 14, 10]\n",
      "7 [1, 8, 4, 14, 30]\n",
      "8 [1, 8, 4, 14, 32]\n",
      "conv2d_597 [[<tf.Tensor 'lambda_663/Reshape_4:0' shape=(1, 8, 4, 960) dtype=float32>], [<tf.Tensor 'lambda_664/Reshape_4:0' shape=(1, 8, 4, 960) dtype=float32>], [<tf.Tensor 'lambda_665/Reshape_4:0' shape=(1, 8, 4, 960) dtype=float32>]]\n",
      "idx [121620, 4]\n",
      "gather [121620]\n",
      "m_932 [[]]\n",
      "lmda_933 [[<tf.Tensor 'Const_477:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_597_1/convolution:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_934 [[]]\n",
      "lmda_935 [[<tf.Tensor 'Const_478:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_597_2/convolution:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_936 [[]]\n",
      "lmda_937 [[<tf.Tensor 'Const_479:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_597_3/convolution:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "batch_normalization_518 [[<tf.Tensor 'lambda_666_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_667_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_668_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "m_939 [[]]\n",
      "lmda_940 [[<tf.Tensor 'Const_480:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_518_1/cond/Merge:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_941 [[]]\n",
      "lmda_942 [[<tf.Tensor 'Const_481:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_518_2/cond/Merge:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_943 [[]]\n",
      "lmda_944 [[<tf.Tensor 'Const_482:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_518_3/cond/Merge:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "activation_606 [[<tf.Tensor 'lambda_669_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_670_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_671_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "l_946 [[<tf.Tensor 'activation_606_1/Relu:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "l_947 [[<tf.Tensor 'activation_606_2/Relu:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "l_948 [[<tf.Tensor 'activation_606_3/Relu:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "1 [1344]\n",
      "2 [1, 8, 4, 1, 42]\n",
      "3 [1, 8, 4, 1, 126]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "1 [1344]\n",
      "2 [1, 8, 4, 1, 42]\n",
      "3 [1, 8, 4, 1, 126]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "conv2d_598 [[<tf.Tensor 'lambda_672/Reshape_1:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_673/Reshape_1:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_674/Reshape_1:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "m_950 [[]]\n",
      "lmda_951 [[<tf.Tensor 'Const_483:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_598_1/convolution:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "[1, 8, 4, 32]\n",
      "m_952 [[]]\n",
      "lmda_953 [[<tf.Tensor 'Const_484:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_598_2/convolution:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "[1, 8, 4, 32]\n",
      "m_954 [[]]\n",
      "lmda_955 [[<tf.Tensor 'Const_485:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_598_3/convolution:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "[1, 8, 4, 32]\n",
      "concatenate_290 [[<tf.Tensor 'concatenate_289_1/concat:0' shape=(1, 8, 4, 960) dtype=float32>, <tf.Tensor 'lambda_675_1/Mul:0' shape=(1, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_289_2/concat:0' shape=(1, 8, 4, 960) dtype=float32>, <tf.Tensor 'lambda_676_1/Mul:0' shape=(1, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_289_3/concat:0' shape=(1, 8, 4, 960) dtype=float32>, <tf.Tensor 'lambda_677_1/Mul:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "m_957 [[]]\n",
      "lmda_958 [[<tf.Tensor 'Const_486:0' shape=(992,) dtype=float32>, <tf.Tensor 'concatenate_290_1/concat:0' shape=(1, 8, 4, 992) dtype=float32>]]\n",
      "[1, 8, 4, 992]\n",
      "m_959 [[]]\n",
      "lmda_960 [[<tf.Tensor 'Const_487:0' shape=(992,) dtype=float32>, <tf.Tensor 'concatenate_290_2/concat:0' shape=(1, 8, 4, 992) dtype=float32>]]\n",
      "[1, 8, 4, 992]\n",
      "m_961 [[]]\n",
      "lmda_962 [[<tf.Tensor 'Const_488:0' shape=(992,) dtype=float32>, <tf.Tensor 'concatenate_290_3/concat:0' shape=(1, 8, 4, 992) dtype=float32>]]\n",
      "[1, 8, 4, 992]\n",
      "batch_normalization_519 [[<tf.Tensor 'lambda_678_1/Mul:0' shape=(1, 8, 4, 992) dtype=float32>], [<tf.Tensor 'lambda_679_1/Mul:0' shape=(1, 8, 4, 992) dtype=float32>], [<tf.Tensor 'lambda_680_1/Mul:0' shape=(1, 8, 4, 992) dtype=float32>]]\n",
      "m_964 [[]]\n",
      "lmda_965 [[<tf.Tensor 'Const_489:0' shape=(992,) dtype=float32>, <tf.Tensor 'batch_normalization_519_1/cond/Merge:0' shape=(1, 8, 4, 992) dtype=float32>]]\n",
      "[1, 8, 4, 992]\n",
      "m_966 [[]]\n",
      "lmda_967 [[<tf.Tensor 'Const_490:0' shape=(992,) dtype=float32>, <tf.Tensor 'batch_normalization_519_2/cond/Merge:0' shape=(1, 8, 4, 992) dtype=float32>]]\n",
      "[1, 8, 4, 992]\n",
      "m_968 [[]]\n",
      "lmda_969 [[<tf.Tensor 'Const_491:0' shape=(992,) dtype=float32>, <tf.Tensor 'batch_normalization_519_3/cond/Merge:0' shape=(1, 8, 4, 992) dtype=float32>]]\n",
      "[1, 8, 4, 992]\n",
      "activation_607 [[<tf.Tensor 'lambda_681_1/Mul:0' shape=(1, 8, 4, 992) dtype=float32>], [<tf.Tensor 'lambda_682_1/Mul:0' shape=(1, 8, 4, 992) dtype=float32>], [<tf.Tensor 'lambda_683_1/Mul:0' shape=(1, 8, 4, 992) dtype=float32>]]\n",
      "l_971 [[<tf.Tensor 'activation_607_1/Relu:0' shape=(1, 8, 4, 992) dtype=float32>]]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [5280]\n",
      "6 [1, 8, 4, 15, 11]\n",
      "7 [1, 8, 4, 15, 32]\n",
      "8 [1, 8, 4, 15, 32]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [5280]\n",
      "6 [1, 8, 4, 15, 11]\n",
      "7 [1, 8, 4, 15, 32]\n",
      "8 [1, 8, 4, 15, 32]\n",
      "l_972 [[<tf.Tensor 'activation_607_2/Relu:0' shape=(1, 8, 4, 992) dtype=float32>]]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 [5280]\n",
      "6 [1, 8, 4, 15, 11]\n",
      "7 [1, 8, 4, 15, 32]\n",
      "8 [1, 8, 4, 15, 32]\n",
      "1 [5472]\n",
      "2 [1, 8, 4, 1, 171]\n",
      "3 [1, 8, 4, 1, 512]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [5280]\n",
      "6 [1, 8, 4, 15, 11]\n",
      "7 [1, 8, 4, 15, 32]\n",
      "8 [1, 8, 4, 15, 32]\n",
      "l_973 [[<tf.Tensor 'activation_607_3/Relu:0' shape=(1, 8, 4, 992) dtype=float32>]]\n",
      "1 [5440]\n",
      "2 [1, 8, 4, 1, 170]\n",
      "3 [1, 8, 4, 1, 510]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [4800]\n",
      "6 [1, 8, 4, 15, 10]\n",
      "7 [1, 8, 4, 15, 30]\n",
      "8 [1, 8, 4, 15, 32]\n",
      "1 [5440]\n",
      "2 [1, 8, 4, 1, 170]\n",
      "3 [1, 8, 4, 1, 510]\n",
      "4 [1, 8, 4, 1, 512]\n",
      "5 [4800]\n",
      "6 [1, 8, 4, 15, 10]\n",
      "7 [1, 8, 4, 15, 30]\n",
      "8 [1, 8, 4, 15, 32]\n",
      "conv2d_599 [[<tf.Tensor 'lambda_684/Reshape_4:0' shape=(1, 8, 4, 992) dtype=float32>], [<tf.Tensor 'lambda_685/Reshape_4:0' shape=(1, 8, 4, 992) dtype=float32>], [<tf.Tensor 'lambda_686/Reshape_4:0' shape=(1, 8, 4, 992) dtype=float32>]]\n",
      "idx [125632, 4]\n",
      "gather [125632]\n",
      "m_975 [[]]\n",
      "lmda_976 [[<tf.Tensor 'Const_492:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_599_1/convolution:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_977 [[]]\n",
      "lmda_978 [[<tf.Tensor 'Const_493:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_599_2/convolution:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_979 [[]]\n",
      "lmda_980 [[<tf.Tensor 'Const_494:0' shape=(128,) dtype=float32>, <tf.Tensor 'conv2d_599_3/convolution:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "batch_normalization_520 [[<tf.Tensor 'lambda_687_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_688_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_689_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "m_982 [[]]\n",
      "lmda_983 [[<tf.Tensor 'Const_495:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_520_1/cond/Merge:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_984 [[]]\n",
      "lmda_985 [[<tf.Tensor 'Const_496:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_520_2/cond/Merge:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "m_986 [[]]\n",
      "lmda_987 [[<tf.Tensor 'Const_497:0' shape=(128,) dtype=float32>, <tf.Tensor 'batch_normalization_520_3/cond/Merge:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "[1, 8, 4, 128]\n",
      "activation_608 [[<tf.Tensor 'lambda_690_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_691_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_692_1/Mul:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "l_989 [[<tf.Tensor 'activation_608_1/Relu:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "l_990 [[<tf.Tensor 'activation_608_2/Relu:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "1 [1376]\n",
      "2 [1, 8, 4, 1, 43]\n",
      "3 [1, 8, 4, 1, 128]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "l_991 [[<tf.Tensor 'activation_608_3/Relu:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "1 [1344]\n",
      "2 [1, 8, 4, 1, 42]\n",
      "3 [1, 8, 4, 1, 126]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "1 [1344]\n",
      "2 [1, 8, 4, 1, 42]\n",
      "3 [1, 8, 4, 1, 126]\n",
      "4 [1, 8, 4, 1, 128]\n",
      "conv2d_600 [[<tf.Tensor 'lambda_693/Reshape_1:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_694/Reshape_1:0' shape=(1, 8, 4, 128) dtype=float32>], [<tf.Tensor 'lambda_695/Reshape_1:0' shape=(1, 8, 4, 128) dtype=float32>]]\n",
      "m_993 [[]]\n",
      "lmda_994 [[<tf.Tensor 'Const_498:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_600_1/convolution:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "[1, 8, 4, 32]\n",
      "m_995 [[]]\n",
      "lmda_996 [[<tf.Tensor 'Const_499:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_600_2/convolution:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "[1, 8, 4, 32]\n",
      "m_997 [[]]\n",
      "lmda_998 [[<tf.Tensor 'Const_500:0' shape=(32,) dtype=float32>, <tf.Tensor 'conv2d_600_3/convolution:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "[1, 8, 4, 32]\n",
      "concatenate_291 [[<tf.Tensor 'concatenate_290_1/concat:0' shape=(1, 8, 4, 992) dtype=float32>, <tf.Tensor 'lambda_696_1/Mul:0' shape=(1, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_290_2/concat:0' shape=(1, 8, 4, 992) dtype=float32>, <tf.Tensor 'lambda_697_1/Mul:0' shape=(1, 8, 4, 32) dtype=float32>], [<tf.Tensor 'concatenate_290_3/concat:0' shape=(1, 8, 4, 992) dtype=float32>, <tf.Tensor 'lambda_698_1/Mul:0' shape=(1, 8, 4, 32) dtype=float32>]]\n",
      "m_1000 [[]]\n",
      "lmda_1001 [[<tf.Tensor 'Const_501:0' shape=(1024,) dtype=float32>, <tf.Tensor 'concatenate_291_1/concat:0' shape=(1, 8, 4, 1024) dtype=float32>]]\n",
      "[1, 8, 4, 1024]\n",
      "m_1002 [[]]\n",
      "lmda_1003 [[<tf.Tensor 'Const_502:0' shape=(1024,) dtype=float32>, <tf.Tensor 'concatenate_291_2/concat:0' shape=(1, 8, 4, 1024) dtype=float32>]]\n",
      "[1, 8, 4, 1024]\n",
      "m_1004 [[]]\n",
      "lmda_1005 [[<tf.Tensor 'Const_503:0' shape=(1024,) dtype=float32>, <tf.Tensor 'concatenate_291_3/concat:0' shape=(1, 8, 4, 1024) dtype=float32>]]\n",
      "[1, 8, 4, 1024]\n",
      "batch_normalization_521 [[<tf.Tensor 'lambda_699_1/Mul:0' shape=(1, 8, 4, 1024) dtype=float32>], [<tf.Tensor 'lambda_700_1/Mul:0' shape=(1, 8, 4, 1024) dtype=float32>], [<tf.Tensor 'lambda_701_1/Mul:0' shape=(1, 8, 4, 1024) dtype=float32>]]\n",
      "m_1007 [[]]\n",
      "lmda_1008 [[<tf.Tensor 'Const_504:0' shape=(1024,) dtype=float32>, <tf.Tensor 'batch_normalization_521_1/cond/Merge:0' shape=(1, 8, 4, 1024) dtype=float32>]]\n",
      "[1, 8, 4, 1024]\n",
      "m_1009 [[]]\n",
      "lmda_1010 [[<tf.Tensor 'Const_505:0' shape=(1024,) dtype=float32>, <tf.Tensor 'batch_normalization_521_2/cond/Merge:0' shape=(1, 8, 4, 1024) dtype=float32>]]\n",
      "[1, 8, 4, 1024]\n",
      "m_1011 [[]]\n",
      "lmda_1012 [[<tf.Tensor 'Const_506:0' shape=(1024,) dtype=float32>, <tf.Tensor 'batch_normalization_521_3/cond/Merge:0' shape=(1, 8, 4, 1024) dtype=float32>]]\n",
      "[1, 8, 4, 1024]\n",
      "activation_609 [[<tf.Tensor 'lambda_702_1/Mul:0' shape=(1, 8, 4, 1024) dtype=float32>], [<tf.Tensor 'lambda_703_1/Mul:0' shape=(1, 8, 4, 1024) dtype=float32>], [<tf.Tensor 'lambda_704_1/Mul:0' shape=(1, 8, 4, 1024) dtype=float32>]]\n",
      "m_1014 [[]]\n",
      "lmda_1015 [[<tf.Tensor 'Const_507:0' shape=(1024,) dtype=float32>, <tf.Tensor 'activation_609_1/Relu:0' shape=(1, 8, 4, 1024) dtype=float32>]]\n",
      "[1, 8, 4, 1024]\n",
      "m_1016 [[]]\n",
      "lmda_1017 [[<tf.Tensor 'Const_508:0' shape=(1024,) dtype=float32>, <tf.Tensor 'activation_609_2/Relu:0' shape=(1, 8, 4, 1024) dtype=float32>]]\n",
      "[1, 8, 4, 1024]\n",
      "m_1018 [[]]\n",
      "lmda_1019 [[<tf.Tensor 'Const_509:0' shape=(1024,) dtype=float32>, <tf.Tensor 'activation_609_3/Relu:0' shape=(1, 8, 4, 1024) dtype=float32>]]\n",
      "[1, 8, 4, 1024]\n",
      "global_average_pooling2d_5 [[<tf.Tensor 'lambda_705_1/Mul:0' shape=(1, 8, 4, 1024) dtype=float32>], [<tf.Tensor 'lambda_706_1/Mul:0' shape=(1, 8, 4, 1024) dtype=float32>], [<tf.Tensor 'lambda_707_1/Mul:0' shape=(1, 8, 4, 1024) dtype=float32>]]\n",
      "l_1021 [[<tf.Tensor 'global_average_pooling2d_5_1/Mean:0' shape=(1, 1024) dtype=float32>]]\n",
      "1 [171]\n",
      "2 [1, 1, 171]\n",
      "3 [1, 1, 512]\n",
      "4 [1, 1, 512]\n",
      "5 [176]\n",
      "6 [1, 16, 11]\n",
      "7 [1, 16, 32]\n",
      "8 [1, 16, 32]\n",
      "1 [171]\n",
      "2 [1, 1, 171]\n",
      "3 [1, 1, 512]\n",
      "4 [1, 1, 512]\n",
      "5 [176]\n",
      "6 [1, 16, 11]\n",
      "7 [1, 16, 32]\n",
      "8 [1, 16, 32]\n",
      "l_1022 [[<tf.Tensor 'global_average_pooling2d_5_2/Mean:0' shape=(1, 1024) dtype=float32>]]\n",
      "1 [171]\n",
      "2 [1, 1, 171]\n",
      "3 [1, 1, 512]\n",
      "4 [1, 1, 512]\n",
      "5 [176]\n",
      "6 [1, 16, 11]\n",
      "7 [1, 16, 32]\n",
      "8 [1, 16, 32]\n",
      "1 [171]\n",
      "2 [1, 1, 171]\n",
      "3 [1, 1, 512]\n",
      "4 [1, 1, 512]\n",
      "5 [176]\n",
      "6 [1, 16, 11]\n",
      "7 [1, 16, 32]\n",
      "8 [1, 16, 32]\n",
      "l_1023 [[<tf.Tensor 'global_average_pooling2d_5_3/Mean:0' shape=(1, 1024) dtype=float32>]]\n",
      "1 [170]\n",
      "2 [1, 1, 170]\n",
      "3 [1, 1, 510]\n",
      "4 [1, 1, 512]\n",
      "5 [160]\n",
      "6 [1, 16, 10]\n",
      "7 [1, 16, 30]\n",
      "8 [1, 16, 32]\n",
      "1 [170]\n",
      "2 [1, 1, 170]\n",
      "3 [1, 1, 510]\n",
      "4 [1, 1, 512]\n",
      "5 [160]\n",
      "6 [1, 16, 10]\n",
      "7 [1, 16, 30]\n",
      "8 [1, 16, 32]\n",
      "dense_9 [[<tf.Tensor 'lambda_708/Reshape_4:0' shape=(1, 1024) dtype=float32>], [<tf.Tensor 'lambda_709/Reshape_4:0' shape=(1, 1024) dtype=float32>], [<tf.Tensor 'lambda_710/Reshape_4:0' shape=(1, 1024) dtype=float32>]]\n",
      "m_1025 [[]]\n",
      "lmda_1026 [[<tf.Tensor 'Const_510:0' shape=(1024,) dtype=float32>, <tf.Tensor 'dense_9_1/BiasAdd:0' shape=(1, 1024) dtype=float32>]]\n",
      "[1, 1024]\n",
      "m_1027 [[]]\n",
      "lmda_1028 [[<tf.Tensor 'Const_511:0' shape=(1024,) dtype=float32>, <tf.Tensor 'dense_9_2/BiasAdd:0' shape=(1, 1024) dtype=float32>]]\n",
      "[1, 1024]\n",
      "m_1029 [[]]\n",
      "lmda_1030 [[<tf.Tensor 'Const_512:0' shape=(1024,) dtype=float32>, <tf.Tensor 'dense_9_3/BiasAdd:0' shape=(1, 1024) dtype=float32>]]\n",
      "[1, 1024]\n",
      "batch_normalization_522 [[<tf.Tensor 'lambda_711_1/Mul:0' shape=(1, 1024) dtype=float32>], [<tf.Tensor 'lambda_712_1/Mul:0' shape=(1, 1024) dtype=float32>], [<tf.Tensor 'lambda_713_1/Mul:0' shape=(1, 1024) dtype=float32>]]\n",
      "m_1032 [[]]\n",
      "lmda_1033 [[<tf.Tensor 'Const_513:0' shape=(1024,) dtype=float32>, <tf.Tensor 'batch_normalization_522_1/cond/Merge:0' shape=(1, 1024) dtype=float32>]]\n",
      "[1, 1024]\n",
      "m_1034 [[]]\n",
      "lmda_1035 [[<tf.Tensor 'Const_514:0' shape=(1024,) dtype=float32>, <tf.Tensor 'batch_normalization_522_2/cond/Merge:0' shape=(1, 1024) dtype=float32>]]\n",
      "[1, 1024]\n",
      "m_1036 [[]]\n",
      "lmda_1037 [[<tf.Tensor 'Const_515:0' shape=(1024,) dtype=float32>, <tf.Tensor 'batch_normalization_522_3/cond/Merge:0' shape=(1, 1024) dtype=float32>]]\n",
      "[1, 1024]\n",
      "activation_610 [[<tf.Tensor 'lambda_714_1/Mul:0' shape=(1, 1024) dtype=float32>], [<tf.Tensor 'lambda_715_1/Mul:0' shape=(1, 1024) dtype=float32>], [<tf.Tensor 'lambda_716_1/Mul:0' shape=(1, 1024) dtype=float32>]]\n",
      "l_1039 [[<tf.Tensor 'activation_610_1/Relu:0' shape=(1, 1024) dtype=float32>]]\n",
      "1 [341]\n",
      "2 [1, 1, 341]\n",
      "3 [1, 1, 1023]\n",
      "4 [1, 1, 1024]\n",
      "1 [341]\n",
      "2 [1, 1, 341]\n",
      "3 [1, 1, 1023]\n",
      "4 [1, 1, 1024]\n",
      "l_1040 [[<tf.Tensor 'activation_610_2/Relu:0' shape=(1, 1024) dtype=float32>]]\n",
      "1 [341]\n",
      "2 [1, 1, 341]\n",
      "3 [1, 1, 1023]\n",
      "4 [1, 1, 1024]\n",
      "1 [341]\n",
      "2 [1, 1, 341]\n",
      "3 [1, 1, 1023]\n",
      "4 [1, 1, 1024]\n",
      "l_1041 [[<tf.Tensor 'activation_610_3/Relu:0' shape=(1, 1024) dtype=float32>]]\n",
      "1 [342]\n",
      "2 [1, 1, 342]\n",
      "3 [1, 1, 1024]\n",
      "4 [1, 1, 1024]\n",
      "1 [342]\n",
      "2 [1, 1, 342]\n",
      "3 [1, 1, 1024]\n",
      "4 [1, 1, 1024]\n",
      "dense_10 [[<tf.Tensor 'lambda_717/Reshape_1:0' shape=(1, 1024) dtype=float32>], [<tf.Tensor 'lambda_718/Reshape_1:0' shape=(1, 1024) dtype=float32>], [<tf.Tensor 'lambda_719/Reshape_1:0' shape=(1, 1024) dtype=float32>]]\n",
      "ip_1043 [[]]\n",
      "ip_1044 [[]]\n",
      "l_1045 [[<tf.Tensor 'Const_516:0' shape=(128, 2) dtype=int32>, <tf.Tensor 'Const_517:0' shape=(1,) dtype=float32>, <tf.Tensor 'dense_10_1/BiasAdd:0' shape=(1, 384) dtype=float32>]]\n",
      "[None, None]\n",
      "ip_1046 [[]]\n",
      "ip_1047 [[]]\n",
      "l_1048 [[<tf.Tensor 'Const_518:0' shape=(128, 2) dtype=int32>, <tf.Tensor 'Const_519:0' shape=(1,) dtype=float32>, <tf.Tensor 'dense_10_2/BiasAdd:0' shape=(1, 384) dtype=float32>]]\n",
      "[None, None]\n",
      "ip_1049 [[]]\n",
      "ip_1050 [[]]\n",
      "l_1051 [[<tf.Tensor 'Const_520:0' shape=(128, 2) dtype=int32>, <tf.Tensor 'Const_521:0' shape=(1,) dtype=float32>, <tf.Tensor 'dense_10_3/BiasAdd:0' shape=(1, 384) dtype=float32>]]\n",
      "[None, None]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'lambda_720_1/Reshape:0' shape=(?, ?) dtype=float32>, <tf.Tensor 'lambda_721_1/Reshape:0' shape=(?, ?) dtype=float32>, <tf.Tensor 'lambda_722_1/Reshape:0' shape=(?, ?) dtype=float32>]\n",
      "0.2\n",
      "[0, 128, 256, 384]\n",
      "(1, 128)\n",
      "(1, 128)\n",
      "(1, 128)\n"
     ]
    }
   ],
   "source": [
    "model_eval = models.DenseNetDrop(blocks=4, tile=True)\n",
    "\n",
    "# model_eval = models_bk2.DenseNet121Drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_2 (InputLayer)             (None, 256, 128, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)              (None, 128, 64, 64)   9408        input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchNo (None, 128, 64, 64)   256         conv2d_121[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_123 (Activation)      (None, 128, 64, 64)   0           batch_normalization_157[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)   (None, 64, 32, 64)    0           activation_123[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchNo (None, 64, 32, 64)    256         max_pooling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_124 (Activation)      (None, 64, 32, 64)    0           batch_normalization_158[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)              (None, 64, 32, 128)   8192        activation_124[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchNo (None, 64, 32, 128)   512         conv2d_122[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_125 (Activation)      (None, 64, 32, 128)   0           batch_normalization_159[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)              (None, 64, 32, 32)    36864       activation_125[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_59 (Concatenate)     (None, 64, 32, 96)    0           max_pooling2d_2[0][0]            \n",
      "                                                                   conv2d_123[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchNo (None, 64, 32, 96)    384         concatenate_59[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_126 (Activation)      (None, 64, 32, 96)    0           batch_normalization_160[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)              (None, 64, 32, 128)   12288       activation_126[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchNo (None, 64, 32, 128)   512         conv2d_124[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_127 (Activation)      (None, 64, 32, 128)   0           batch_normalization_161[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)              (None, 64, 32, 32)    36864       activation_127[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_60 (Concatenate)     (None, 64, 32, 128)   0           concatenate_59[1][0]             \n",
      "                                                                   conv2d_125[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchNo (None, 64, 32, 128)   512         concatenate_60[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_128 (Activation)      (None, 64, 32, 128)   0           batch_normalization_162[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)              (None, 64, 32, 128)   16384       activation_128[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchNo (None, 64, 32, 128)   512         conv2d_126[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_129 (Activation)      (None, 64, 32, 128)   0           batch_normalization_163[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)              (None, 64, 32, 32)    36864       activation_129[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_61 (Concatenate)     (None, 64, 32, 160)   0           concatenate_60[1][0]             \n",
      "                                                                   conv2d_127[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchNo (None, 64, 32, 160)   640         concatenate_61[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_130 (Activation)      (None, 64, 32, 160)   0           batch_normalization_164[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)              (None, 64, 32, 128)   20480       activation_130[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchNo (None, 64, 32, 128)   512         conv2d_128[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_131 (Activation)      (None, 64, 32, 128)   0           batch_normalization_165[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)              (None, 64, 32, 32)    36864       activation_131[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_62 (Concatenate)     (None, 64, 32, 192)   0           concatenate_61[1][0]             \n",
      "                                                                   conv2d_129[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchNo (None, 64, 32, 192)   768         concatenate_62[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_132 (Activation)      (None, 64, 32, 192)   0           batch_normalization_166[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)              (None, 64, 32, 128)   24576       activation_132[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchNo (None, 64, 32, 128)   512         conv2d_130[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_133 (Activation)      (None, 64, 32, 128)   0           batch_normalization_167[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)              (None, 64, 32, 32)    36864       activation_133[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_63 (Concatenate)     (None, 64, 32, 224)   0           concatenate_62[1][0]             \n",
      "                                                                   conv2d_131[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchNo (None, 64, 32, 224)   896         concatenate_63[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_134 (Activation)      (None, 64, 32, 224)   0           batch_normalization_168[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)              (None, 64, 32, 128)   28672       activation_134[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchNo (None, 64, 32, 128)   512         conv2d_132[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_135 (Activation)      (None, 64, 32, 128)   0           batch_normalization_169[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)              (None, 64, 32, 32)    36864       activation_135[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_64 (Concatenate)     (None, 64, 32, 256)   0           concatenate_63[1][0]             \n",
      "                                                                   conv2d_133[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchNo (None, 64, 32, 256)   1024        concatenate_64[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_136 (Activation)      (None, 64, 32, 256)   0           batch_normalization_170[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)              (None, 64, 32, 128)   32768       activation_136[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePool (None, 32, 16, 128)   0           conv2d_134[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchNo (None, 32, 16, 128)   512         average_pooling2d_4[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "activation_137 (Activation)      (None, 32, 16, 128)   0           batch_normalization_171[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)              (None, 32, 16, 128)   16384       activation_137[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchNo (None, 32, 16, 128)   512         conv2d_135[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_138 (Activation)      (None, 32, 16, 128)   0           batch_normalization_172[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)              (None, 32, 16, 32)    36864       activation_138[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_65 (Concatenate)     (None, 32, 16, 160)   0           average_pooling2d_4[0][0]        \n",
      "                                                                   conv2d_136[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchNo (None, 32, 16, 160)   640         concatenate_65[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_139 (Activation)      (None, 32, 16, 160)   0           batch_normalization_173[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)              (None, 32, 16, 128)   20480       activation_139[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchNo (None, 32, 16, 128)   512         conv2d_137[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_140 (Activation)      (None, 32, 16, 128)   0           batch_normalization_174[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)              (None, 32, 16, 32)    36864       activation_140[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_66 (Concatenate)     (None, 32, 16, 192)   0           concatenate_65[1][0]             \n",
      "                                                                   conv2d_138[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchNo (None, 32, 16, 192)   768         concatenate_66[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_141 (Activation)      (None, 32, 16, 192)   0           batch_normalization_175[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)              (None, 32, 16, 128)   24576       activation_141[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchNo (None, 32, 16, 128)   512         conv2d_139[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_142 (Activation)      (None, 32, 16, 128)   0           batch_normalization_176[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)              (None, 32, 16, 32)    36864       activation_142[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_67 (Concatenate)     (None, 32, 16, 224)   0           concatenate_66[1][0]             \n",
      "                                                                   conv2d_140[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchNo (None, 32, 16, 224)   896         concatenate_67[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_143 (Activation)      (None, 32, 16, 224)   0           batch_normalization_177[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)              (None, 32, 16, 128)   28672       activation_143[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchNo (None, 32, 16, 128)   512         conv2d_141[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_144 (Activation)      (None, 32, 16, 128)   0           batch_normalization_178[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)              (None, 32, 16, 32)    36864       activation_144[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_68 (Concatenate)     (None, 32, 16, 256)   0           concatenate_67[1][0]             \n",
      "                                                                   conv2d_142[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchNo (None, 32, 16, 256)   1024        concatenate_68[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_145 (Activation)      (None, 32, 16, 256)   0           batch_normalization_179[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)              (None, 32, 16, 128)   32768       activation_145[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchNo (None, 32, 16, 128)   512         conv2d_143[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_146 (Activation)      (None, 32, 16, 128)   0           batch_normalization_180[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)              (None, 32, 16, 32)    36864       activation_146[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_69 (Concatenate)     (None, 32, 16, 288)   0           concatenate_68[1][0]             \n",
      "                                                                   conv2d_144[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchNo (None, 32, 16, 288)   1152        concatenate_69[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_147 (Activation)      (None, 32, 16, 288)   0           batch_normalization_181[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)              (None, 32, 16, 128)   36864       activation_147[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchNo (None, 32, 16, 128)   512         conv2d_145[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_148 (Activation)      (None, 32, 16, 128)   0           batch_normalization_182[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)              (None, 32, 16, 32)    36864       activation_148[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_70 (Concatenate)     (None, 32, 16, 320)   0           concatenate_69[1][0]             \n",
      "                                                                   conv2d_146[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchNo (None, 32, 16, 320)   1280        concatenate_70[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_149 (Activation)      (None, 32, 16, 320)   0           batch_normalization_183[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)              (None, 32, 16, 128)   40960       activation_149[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchNo (None, 32, 16, 128)   512         conv2d_147[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_150 (Activation)      (None, 32, 16, 128)   0           batch_normalization_184[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)              (None, 32, 16, 32)    36864       activation_150[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_71 (Concatenate)     (None, 32, 16, 352)   0           concatenate_70[1][0]             \n",
      "                                                                   conv2d_148[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchNo (None, 32, 16, 352)   1408        concatenate_71[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_151 (Activation)      (None, 32, 16, 352)   0           batch_normalization_185[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)              (None, 32, 16, 128)   45056       activation_151[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchNo (None, 32, 16, 128)   512         conv2d_149[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_152 (Activation)      (None, 32, 16, 128)   0           batch_normalization_186[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)              (None, 32, 16, 32)    36864       activation_152[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_72 (Concatenate)     (None, 32, 16, 384)   0           concatenate_71[1][0]             \n",
      "                                                                   conv2d_150[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchNo (None, 32, 16, 384)   1536        concatenate_72[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_153 (Activation)      (None, 32, 16, 384)   0           batch_normalization_187[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)              (None, 32, 16, 128)   49152       activation_153[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchNo (None, 32, 16, 128)   512         conv2d_151[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_154 (Activation)      (None, 32, 16, 128)   0           batch_normalization_188[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)              (None, 32, 16, 32)    36864       activation_154[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_73 (Concatenate)     (None, 32, 16, 416)   0           concatenate_72[1][0]             \n",
      "                                                                   conv2d_152[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchNo (None, 32, 16, 416)   1664        concatenate_73[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_155 (Activation)      (None, 32, 16, 416)   0           batch_normalization_189[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)              (None, 32, 16, 128)   53248       activation_155[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchNo (None, 32, 16, 128)   512         conv2d_153[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_156 (Activation)      (None, 32, 16, 128)   0           batch_normalization_190[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)              (None, 32, 16, 32)    36864       activation_156[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_74 (Concatenate)     (None, 32, 16, 448)   0           concatenate_73[1][0]             \n",
      "                                                                   conv2d_154[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchNo (None, 32, 16, 448)   1792        concatenate_74[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_157 (Activation)      (None, 32, 16, 448)   0           batch_normalization_191[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)              (None, 32, 16, 128)   57344       activation_157[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchNo (None, 32, 16, 128)   512         conv2d_155[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_158 (Activation)      (None, 32, 16, 128)   0           batch_normalization_192[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)              (None, 32, 16, 32)    36864       activation_158[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_75 (Concatenate)     (None, 32, 16, 480)   0           concatenate_74[1][0]             \n",
      "                                                                   conv2d_156[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchNo (None, 32, 16, 480)   1920        concatenate_75[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_159 (Activation)      (None, 32, 16, 480)   0           batch_normalization_193[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)              (None, 32, 16, 128)   61440       activation_159[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchNo (None, 32, 16, 128)   512         conv2d_157[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_160 (Activation)      (None, 32, 16, 128)   0           batch_normalization_194[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)              (None, 32, 16, 32)    36864       activation_160[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_76 (Concatenate)     (None, 32, 16, 512)   0           concatenate_75[1][0]             \n",
      "                                                                   conv2d_158[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchNo (None, 32, 16, 512)   2048        concatenate_76[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_161 (Activation)      (None, 32, 16, 512)   0           batch_normalization_195[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)              (None, 32, 16, 256)   131072      activation_161[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePool (None, 16, 8, 256)    0           conv2d_159[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchNo (None, 16, 8, 256)    1024        average_pooling2d_5[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "activation_162 (Activation)      (None, 16, 8, 256)    0           batch_normalization_196[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)              (None, 16, 8, 128)    32768       activation_162[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchNo (None, 16, 8, 128)    512         conv2d_160[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_163 (Activation)      (None, 16, 8, 128)    0           batch_normalization_197[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)              (None, 16, 8, 32)     36864       activation_163[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_77 (Concatenate)     (None, 16, 8, 288)    0           average_pooling2d_5[0][0]        \n",
      "                                                                   conv2d_161[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchNo (None, 16, 8, 288)    1152        concatenate_77[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_164 (Activation)      (None, 16, 8, 288)    0           batch_normalization_198[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)              (None, 16, 8, 128)    36864       activation_164[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchNo (None, 16, 8, 128)    512         conv2d_162[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_165 (Activation)      (None, 16, 8, 128)    0           batch_normalization_199[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)              (None, 16, 8, 32)     36864       activation_165[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_78 (Concatenate)     (None, 16, 8, 320)    0           concatenate_77[1][0]             \n",
      "                                                                   conv2d_163[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchNo (None, 16, 8, 320)    1280        concatenate_78[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_166 (Activation)      (None, 16, 8, 320)    0           batch_normalization_200[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)              (None, 16, 8, 128)    40960       activation_166[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchNo (None, 16, 8, 128)    512         conv2d_164[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_167 (Activation)      (None, 16, 8, 128)    0           batch_normalization_201[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)              (None, 16, 8, 32)     36864       activation_167[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_79 (Concatenate)     (None, 16, 8, 352)    0           concatenate_78[1][0]             \n",
      "                                                                   conv2d_165[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchNo (None, 16, 8, 352)    1408        concatenate_79[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_168 (Activation)      (None, 16, 8, 352)    0           batch_normalization_202[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)              (None, 16, 8, 128)    45056       activation_168[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchNo (None, 16, 8, 128)    512         conv2d_166[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_169 (Activation)      (None, 16, 8, 128)    0           batch_normalization_203[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)              (None, 16, 8, 32)     36864       activation_169[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_80 (Concatenate)     (None, 16, 8, 384)    0           concatenate_79[1][0]             \n",
      "                                                                   conv2d_167[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchNo (None, 16, 8, 384)    1536        concatenate_80[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_170 (Activation)      (None, 16, 8, 384)    0           batch_normalization_204[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)              (None, 16, 8, 128)    49152       activation_170[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchNo (None, 16, 8, 128)    512         conv2d_168[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_171 (Activation)      (None, 16, 8, 128)    0           batch_normalization_205[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)              (None, 16, 8, 32)     36864       activation_171[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_81 (Concatenate)     (None, 16, 8, 416)    0           concatenate_80[1][0]             \n",
      "                                                                   conv2d_169[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchNo (None, 16, 8, 416)    1664        concatenate_81[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_172 (Activation)      (None, 16, 8, 416)    0           batch_normalization_206[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)              (None, 16, 8, 128)    53248       activation_172[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchNo (None, 16, 8, 128)    512         conv2d_170[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_173 (Activation)      (None, 16, 8, 128)    0           batch_normalization_207[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)              (None, 16, 8, 32)     36864       activation_173[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_82 (Concatenate)     (None, 16, 8, 448)    0           concatenate_81[1][0]             \n",
      "                                                                   conv2d_171[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_208 (BatchNo (None, 16, 8, 448)    1792        concatenate_82[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_174 (Activation)      (None, 16, 8, 448)    0           batch_normalization_208[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)              (None, 16, 8, 128)    57344       activation_174[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_209 (BatchNo (None, 16, 8, 128)    512         conv2d_172[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_175 (Activation)      (None, 16, 8, 128)    0           batch_normalization_209[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)              (None, 16, 8, 32)     36864       activation_175[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_83 (Concatenate)     (None, 16, 8, 480)    0           concatenate_82[1][0]             \n",
      "                                                                   conv2d_173[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchNo (None, 16, 8, 480)    1920        concatenate_83[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_176 (Activation)      (None, 16, 8, 480)    0           batch_normalization_210[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)              (None, 16, 8, 128)    61440       activation_176[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchNo (None, 16, 8, 128)    512         conv2d_174[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_177 (Activation)      (None, 16, 8, 128)    0           batch_normalization_211[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)              (None, 16, 8, 32)     36864       activation_177[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_84 (Concatenate)     (None, 16, 8, 512)    0           concatenate_83[1][0]             \n",
      "                                                                   conv2d_175[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_212 (BatchNo (None, 16, 8, 512)    2048        concatenate_84[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_178 (Activation)      (None, 16, 8, 512)    0           batch_normalization_212[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)              (None, 16, 8, 128)    65536       activation_178[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_213 (BatchNo (None, 16, 8, 128)    512         conv2d_176[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_179 (Activation)      (None, 16, 8, 128)    0           batch_normalization_213[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)              (None, 16, 8, 32)     36864       activation_179[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_85 (Concatenate)     (None, 16, 8, 544)    0           concatenate_84[1][0]             \n",
      "                                                                   conv2d_177[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_214 (BatchNo (None, 16, 8, 544)    2176        concatenate_85[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_180 (Activation)      (None, 16, 8, 544)    0           batch_normalization_214[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)              (None, 16, 8, 128)    69632       activation_180[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_215 (BatchNo (None, 16, 8, 128)    512         conv2d_178[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_181 (Activation)      (None, 16, 8, 128)    0           batch_normalization_215[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)              (None, 16, 8, 32)     36864       activation_181[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_86 (Concatenate)     (None, 16, 8, 576)    0           concatenate_85[1][0]             \n",
      "                                                                   conv2d_179[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_216 (BatchNo (None, 16, 8, 576)    2304        concatenate_86[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_182 (Activation)      (None, 16, 8, 576)    0           batch_normalization_216[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)              (None, 16, 8, 128)    73728       activation_182[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_217 (BatchNo (None, 16, 8, 128)    512         conv2d_180[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_183 (Activation)      (None, 16, 8, 128)    0           batch_normalization_217[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)              (None, 16, 8, 32)     36864       activation_183[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_87 (Concatenate)     (None, 16, 8, 608)    0           concatenate_86[1][0]             \n",
      "                                                                   conv2d_181[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_218 (BatchNo (None, 16, 8, 608)    2432        concatenate_87[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_184 (Activation)      (None, 16, 8, 608)    0           batch_normalization_218[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)              (None, 16, 8, 128)    77824       activation_184[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_219 (BatchNo (None, 16, 8, 128)    512         conv2d_182[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_185 (Activation)      (None, 16, 8, 128)    0           batch_normalization_219[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)              (None, 16, 8, 32)     36864       activation_185[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_88 (Concatenate)     (None, 16, 8, 640)    0           concatenate_87[1][0]             \n",
      "                                                                   conv2d_183[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_220 (BatchNo (None, 16, 8, 640)    2560        concatenate_88[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_186 (Activation)      (None, 16, 8, 640)    0           batch_normalization_220[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)              (None, 16, 8, 128)    81920       activation_186[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_221 (BatchNo (None, 16, 8, 128)    512         conv2d_184[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_187 (Activation)      (None, 16, 8, 128)    0           batch_normalization_221[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)              (None, 16, 8, 32)     36864       activation_187[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_89 (Concatenate)     (None, 16, 8, 672)    0           concatenate_88[1][0]             \n",
      "                                                                   conv2d_185[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_222 (BatchNo (None, 16, 8, 672)    2688        concatenate_89[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_188 (Activation)      (None, 16, 8, 672)    0           batch_normalization_222[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)              (None, 16, 8, 128)    86016       activation_188[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_223 (BatchNo (None, 16, 8, 128)    512         conv2d_186[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_189 (Activation)      (None, 16, 8, 128)    0           batch_normalization_223[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)              (None, 16, 8, 32)     36864       activation_189[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_90 (Concatenate)     (None, 16, 8, 704)    0           concatenate_89[1][0]             \n",
      "                                                                   conv2d_187[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_224 (BatchNo (None, 16, 8, 704)    2816        concatenate_90[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_190 (Activation)      (None, 16, 8, 704)    0           batch_normalization_224[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)              (None, 16, 8, 128)    90112       activation_190[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_225 (BatchNo (None, 16, 8, 128)    512         conv2d_188[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_191 (Activation)      (None, 16, 8, 128)    0           batch_normalization_225[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)              (None, 16, 8, 32)     36864       activation_191[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_91 (Concatenate)     (None, 16, 8, 736)    0           concatenate_90[1][0]             \n",
      "                                                                   conv2d_189[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_226 (BatchNo (None, 16, 8, 736)    2944        concatenate_91[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_192 (Activation)      (None, 16, 8, 736)    0           batch_normalization_226[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)              (None, 16, 8, 128)    94208       activation_192[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_227 (BatchNo (None, 16, 8, 128)    512         conv2d_190[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_193 (Activation)      (None, 16, 8, 128)    0           batch_normalization_227[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)              (None, 16, 8, 32)     36864       activation_193[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_92 (Concatenate)     (None, 16, 8, 768)    0           concatenate_91[1][0]             \n",
      "                                                                   conv2d_191[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_228 (BatchNo (None, 16, 8, 768)    3072        concatenate_92[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_194 (Activation)      (None, 16, 8, 768)    0           batch_normalization_228[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)              (None, 16, 8, 128)    98304       activation_194[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_229 (BatchNo (None, 16, 8, 128)    512         conv2d_192[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_195 (Activation)      (None, 16, 8, 128)    0           batch_normalization_229[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)              (None, 16, 8, 32)     36864       activation_195[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_93 (Concatenate)     (None, 16, 8, 800)    0           concatenate_92[1][0]             \n",
      "                                                                   conv2d_193[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_230 (BatchNo (None, 16, 8, 800)    3200        concatenate_93[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_196 (Activation)      (None, 16, 8, 800)    0           batch_normalization_230[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)              (None, 16, 8, 128)    102400      activation_196[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_231 (BatchNo (None, 16, 8, 128)    512         conv2d_194[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_197 (Activation)      (None, 16, 8, 128)    0           batch_normalization_231[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)              (None, 16, 8, 32)     36864       activation_197[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_94 (Concatenate)     (None, 16, 8, 832)    0           concatenate_93[1][0]             \n",
      "                                                                   conv2d_195[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_232 (BatchNo (None, 16, 8, 832)    3328        concatenate_94[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_198 (Activation)      (None, 16, 8, 832)    0           batch_normalization_232[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)              (None, 16, 8, 128)    106496      activation_198[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_233 (BatchNo (None, 16, 8, 128)    512         conv2d_196[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_199 (Activation)      (None, 16, 8, 128)    0           batch_normalization_233[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)              (None, 16, 8, 32)     36864       activation_199[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_95 (Concatenate)     (None, 16, 8, 864)    0           concatenate_94[1][0]             \n",
      "                                                                   conv2d_197[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_234 (BatchNo (None, 16, 8, 864)    3456        concatenate_95[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_200 (Activation)      (None, 16, 8, 864)    0           batch_normalization_234[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)              (None, 16, 8, 128)    110592      activation_200[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_235 (BatchNo (None, 16, 8, 128)    512         conv2d_198[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_201 (Activation)      (None, 16, 8, 128)    0           batch_normalization_235[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)              (None, 16, 8, 32)     36864       activation_201[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_96 (Concatenate)     (None, 16, 8, 896)    0           concatenate_95[1][0]             \n",
      "                                                                   conv2d_199[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_236 (BatchNo (None, 16, 8, 896)    3584        concatenate_96[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_202 (Activation)      (None, 16, 8, 896)    0           batch_normalization_236[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)              (None, 16, 8, 128)    114688      activation_202[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_237 (BatchNo (None, 16, 8, 128)    512         conv2d_200[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_203 (Activation)      (None, 16, 8, 128)    0           batch_normalization_237[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)              (None, 16, 8, 32)     36864       activation_203[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_97 (Concatenate)     (None, 16, 8, 928)    0           concatenate_96[1][0]             \n",
      "                                                                   conv2d_201[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_238 (BatchNo (None, 16, 8, 928)    3712        concatenate_97[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_204 (Activation)      (None, 16, 8, 928)    0           batch_normalization_238[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)              (None, 16, 8, 128)    118784      activation_204[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_239 (BatchNo (None, 16, 8, 128)    512         conv2d_202[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_205 (Activation)      (None, 16, 8, 128)    0           batch_normalization_239[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)              (None, 16, 8, 32)     36864       activation_205[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_98 (Concatenate)     (None, 16, 8, 960)    0           concatenate_97[1][0]             \n",
      "                                                                   conv2d_203[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_240 (BatchNo (None, 16, 8, 960)    3840        concatenate_98[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_206 (Activation)      (None, 16, 8, 960)    0           batch_normalization_240[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)              (None, 16, 8, 128)    122880      activation_206[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_241 (BatchNo (None, 16, 8, 128)    512         conv2d_204[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_207 (Activation)      (None, 16, 8, 128)    0           batch_normalization_241[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)              (None, 16, 8, 32)     36864       activation_207[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_99 (Concatenate)     (None, 16, 8, 992)    0           concatenate_98[1][0]             \n",
      "                                                                   conv2d_205[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_242 (BatchNo (None, 16, 8, 992)    3968        concatenate_99[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_208 (Activation)      (None, 16, 8, 992)    0           batch_normalization_242[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)              (None, 16, 8, 128)    126976      activation_208[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_243 (BatchNo (None, 16, 8, 128)    512         conv2d_206[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_209 (Activation)      (None, 16, 8, 128)    0           batch_normalization_243[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)              (None, 16, 8, 32)     36864       activation_209[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_100 (Concatenate)    (None, 16, 8, 1024)   0           concatenate_99[1][0]             \n",
      "                                                                   conv2d_207[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_244 (BatchNo (None, 16, 8, 1024)   4096        concatenate_100[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_210 (Activation)      (None, 16, 8, 1024)   0           batch_normalization_244[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)              (None, 16, 8, 512)    524288      activation_210[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePool (None, 8, 4, 512)     0           conv2d_208[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_4 (InputLayer)             (512,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)                (20, 8, 4, 512)       0           average_pooling2d_6[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "input_5 (InputLayer)             (512,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_6 (InputLayer)             (512,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)                (20, 8, 4, 512)       0           input_4[0][0]                    \n",
      "                                                                   lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)                (20, 8, 4, 512)       0           input_5[0][0]                    \n",
      "                                                                   lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)                (20, 8, 4, 512)       0           input_6[0][0]                    \n",
      "                                                                   lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "input_7 (InputLayer)             (512,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchNo (20, 8, 4, 512)       2048        lambda_2[1][0]                   \n",
      "                                                                   lambda_3[1][0]                   \n",
      "                                                                   lambda_4[1][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "input_8 (InputLayer)             (512,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_9 (InputLayer)             (512,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)                (20, 8, 4, 512)       0           input_7[0][0]                    \n",
      "                                                                   batch_normalization_123[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)                (20, 8, 4, 512)       0           input_8[0][0]                    \n",
      "                                                                   batch_normalization_123[1][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)                (20, 8, 4, 512)       0           input_9[0][0]                    \n",
      "                                                                   batch_normalization_123[2][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_211 (Activation)      (20, 8, 4, 512)       0           lambda_5[1][0]                   \n",
      "                                                                   lambda_6[1][0]                   \n",
      "                                                                   lambda_7[1][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)                (20, 8, 4, 512)       0           activation_211[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)                (20, 8, 4, 512)       0           activation_211[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)               (20, 8, 4, 512)       0           activation_211[2][0]             \n",
      "____________________________________________________________________________________________________\n",
      "input_10 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)              (20, 8, 4, 128)       65536       lambda_8[0][0]                   \n",
      "                                                                   lambda_9[0][0]                   \n",
      "                                                                   lambda_10[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_11 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_12 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)               (20, 8, 4, 128)       0           input_10[0][0]                   \n",
      "                                                                   conv2d_209[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)               (20, 8, 4, 128)       0           input_11[0][0]                   \n",
      "                                                                   conv2d_209[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)               (20, 8, 4, 128)       0           input_12[0][0]                   \n",
      "                                                                   conv2d_209[2][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_13 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchNo (20, 8, 4, 128)       512         lambda_11[1][0]                  \n",
      "                                                                   lambda_12[1][0]                  \n",
      "                                                                   lambda_13[1][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_14 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_15 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)               (20, 8, 4, 128)       0           input_13[0][0]                   \n",
      "                                                                   batch_normalization_124[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)               (20, 8, 4, 128)       0           input_14[0][0]                   \n",
      "                                                                   batch_normalization_124[1][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)               (20, 8, 4, 128)       0           input_15[0][0]                   \n",
      "                                                                   batch_normalization_124[2][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_212 (Activation)      (20, 8, 4, 128)       0           lambda_14[1][0]                  \n",
      "                                                                   lambda_15[1][0]                  \n",
      "                                                                   lambda_16[1][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)               (20, 8, 4, 128)       0           activation_212[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)               (20, 8, 4, 128)       0           activation_212[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)               (20, 8, 4, 128)       0           activation_212[2][0]             \n",
      "____________________________________________________________________________________________________\n",
      "input_16 (InputLayer)            (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)              (20, 8, 4, 32)        36864       lambda_17[0][0]                  \n",
      "                                                                   lambda_18[0][0]                  \n",
      "                                                                   lambda_19[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_17 (InputLayer)            (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_18 (InputLayer)            (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_20 (Lambda)               (20, 8, 4, 32)        0           input_16[0][0]                   \n",
      "                                                                   conv2d_210[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)               (20, 8, 4, 32)        0           input_17[0][0]                   \n",
      "                                                                   conv2d_210[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)               (20, 8, 4, 32)        0           input_18[0][0]                   \n",
      "                                                                   conv2d_210[2][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_101 (Concatenate)    (20, 8, 4, 544)       0           lambda_2[1][0]                   \n",
      "                                                                   lambda_20[1][0]                  \n",
      "                                                                   lambda_3[1][0]                   \n",
      "                                                                   lambda_21[1][0]                  \n",
      "                                                                   lambda_4[1][0]                   \n",
      "                                                                   lambda_22[1][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_19 (InputLayer)            (544,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_20 (InputLayer)            (544,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_21 (InputLayer)            (544,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)               (20, 8, 4, 544)       0           input_19[0][0]                   \n",
      "                                                                   concatenate_101[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_24 (Lambda)               (20, 8, 4, 544)       0           input_20[0][0]                   \n",
      "                                                                   concatenate_101[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_25 (Lambda)               (20, 8, 4, 544)       0           input_21[0][0]                   \n",
      "                                                                   concatenate_101[2][0]            \n",
      "____________________________________________________________________________________________________\n",
      "input_22 (InputLayer)            (544,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchNo (20, 8, 4, 544)       2176        lambda_23[1][0]                  \n",
      "                                                                   lambda_24[1][0]                  \n",
      "                                                                   lambda_25[1][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_23 (InputLayer)            (544,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_24 (InputLayer)            (544,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_26 (Lambda)               (20, 8, 4, 544)       0           input_22[0][0]                   \n",
      "                                                                   batch_normalization_125[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_27 (Lambda)               (20, 8, 4, 544)       0           input_23[0][0]                   \n",
      "                                                                   batch_normalization_125[1][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_28 (Lambda)               (20, 8, 4, 544)       0           input_24[0][0]                   \n",
      "                                                                   batch_normalization_125[2][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_213 (Activation)      (20, 8, 4, 544)       0           lambda_26[1][0]                  \n",
      "                                                                   lambda_27[1][0]                  \n",
      "                                                                   lambda_28[1][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_29 (Lambda)               (20, 8, 4, 544)       0           activation_213[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_30 (Lambda)               (20, 8, 4, 544)       0           activation_213[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_31 (Lambda)               (20, 8, 4, 544)       0           activation_213[2][0]             \n",
      "____________________________________________________________________________________________________\n",
      "input_25 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)              (20, 8, 4, 128)       69632       lambda_29[0][0]                  \n",
      "                                                                   lambda_30[0][0]                  \n",
      "                                                                   lambda_31[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_26 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_27 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_32 (Lambda)               (20, 8, 4, 128)       0           input_25[0][0]                   \n",
      "                                                                   conv2d_211[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_33 (Lambda)               (20, 8, 4, 128)       0           input_26[0][0]                   \n",
      "                                                                   conv2d_211[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_34 (Lambda)               (20, 8, 4, 128)       0           input_27[0][0]                   \n",
      "                                                                   conv2d_211[2][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_28 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchNo (20, 8, 4, 128)       512         lambda_32[1][0]                  \n",
      "                                                                   lambda_33[1][0]                  \n",
      "                                                                   lambda_34[1][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_29 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_30 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_35 (Lambda)               (20, 8, 4, 128)       0           input_28[0][0]                   \n",
      "                                                                   batch_normalization_126[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_36 (Lambda)               (20, 8, 4, 128)       0           input_29[0][0]                   \n",
      "                                                                   batch_normalization_126[1][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_37 (Lambda)               (20, 8, 4, 128)       0           input_30[0][0]                   \n",
      "                                                                   batch_normalization_126[2][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_214 (Activation)      (20, 8, 4, 128)       0           lambda_35[1][0]                  \n",
      "                                                                   lambda_36[1][0]                  \n",
      "                                                                   lambda_37[1][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_38 (Lambda)               (20, 8, 4, 128)       0           activation_214[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_39 (Lambda)               (20, 8, 4, 128)       0           activation_214[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_40 (Lambda)               (20, 8, 4, 128)       0           activation_214[2][0]             \n",
      "____________________________________________________________________________________________________\n",
      "input_31 (InputLayer)            (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)              (20, 8, 4, 32)        36864       lambda_38[0][0]                  \n",
      "                                                                   lambda_39[0][0]                  \n",
      "                                                                   lambda_40[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_32 (InputLayer)            (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_33 (InputLayer)            (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_41 (Lambda)               (20, 8, 4, 32)        0           input_31[0][0]                   \n",
      "                                                                   conv2d_212[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_42 (Lambda)               (20, 8, 4, 32)        0           input_32[0][0]                   \n",
      "                                                                   conv2d_212[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_43 (Lambda)               (20, 8, 4, 32)        0           input_33[0][0]                   \n",
      "                                                                   conv2d_212[2][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_102 (Concatenate)    (20, 8, 4, 576)       0           concatenate_101[0][0]            \n",
      "                                                                   lambda_41[1][0]                  \n",
      "                                                                   concatenate_101[1][0]            \n",
      "                                                                   lambda_42[1][0]                  \n",
      "                                                                   concatenate_101[2][0]            \n",
      "                                                                   lambda_43[1][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_34 (InputLayer)            (576,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_35 (InputLayer)            (576,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_36 (InputLayer)            (576,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_44 (Lambda)               (20, 8, 4, 576)       0           input_34[0][0]                   \n",
      "                                                                   concatenate_102[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_45 (Lambda)               (20, 8, 4, 576)       0           input_35[0][0]                   \n",
      "                                                                   concatenate_102[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_46 (Lambda)               (20, 8, 4, 576)       0           input_36[0][0]                   \n",
      "                                                                   concatenate_102[2][0]            \n",
      "____________________________________________________________________________________________________\n",
      "input_37 (InputLayer)            (576,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchNo (20, 8, 4, 576)       2304        lambda_44[1][0]                  \n",
      "                                                                   lambda_45[1][0]                  \n",
      "                                                                   lambda_46[1][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_38 (InputLayer)            (576,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_39 (InputLayer)            (576,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_47 (Lambda)               (20, 8, 4, 576)       0           input_37[0][0]                   \n",
      "                                                                   batch_normalization_127[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_48 (Lambda)               (20, 8, 4, 576)       0           input_38[0][0]                   \n",
      "                                                                   batch_normalization_127[1][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_49 (Lambda)               (20, 8, 4, 576)       0           input_39[0][0]                   \n",
      "                                                                   batch_normalization_127[2][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_215 (Activation)      (20, 8, 4, 576)       0           lambda_47[1][0]                  \n",
      "                                                                   lambda_48[1][0]                  \n",
      "                                                                   lambda_49[1][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_50 (Lambda)               (20, 8, 4, 576)       0           activation_215[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_51 (Lambda)               (20, 8, 4, 576)       0           activation_215[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_52 (Lambda)               (20, 8, 4, 576)       0           activation_215[2][0]             \n",
      "____________________________________________________________________________________________________\n",
      "input_40 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)              (20, 8, 4, 128)       73728       lambda_50[0][0]                  \n",
      "                                                                   lambda_51[0][0]                  \n",
      "                                                                   lambda_52[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_41 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_42 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_53 (Lambda)               (20, 8, 4, 128)       0           input_40[0][0]                   \n",
      "                                                                   conv2d_213[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_54 (Lambda)               (20, 8, 4, 128)       0           input_41[0][0]                   \n",
      "                                                                   conv2d_213[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_55 (Lambda)               (20, 8, 4, 128)       0           input_42[0][0]                   \n",
      "                                                                   conv2d_213[2][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_43 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchNo (20, 8, 4, 128)       512         lambda_53[1][0]                  \n",
      "                                                                   lambda_54[1][0]                  \n",
      "                                                                   lambda_55[1][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_44 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_45 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_56 (Lambda)               (20, 8, 4, 128)       0           input_43[0][0]                   \n",
      "                                                                   batch_normalization_128[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_57 (Lambda)               (20, 8, 4, 128)       0           input_44[0][0]                   \n",
      "                                                                   batch_normalization_128[1][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_58 (Lambda)               (20, 8, 4, 128)       0           input_45[0][0]                   \n",
      "                                                                   batch_normalization_128[2][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_216 (Activation)      (20, 8, 4, 128)       0           lambda_56[1][0]                  \n",
      "                                                                   lambda_57[1][0]                  \n",
      "                                                                   lambda_58[1][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_59 (Lambda)               (20, 8, 4, 128)       0           activation_216[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_60 (Lambda)               (20, 8, 4, 128)       0           activation_216[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_61 (Lambda)               (20, 8, 4, 128)       0           activation_216[2][0]             \n",
      "____________________________________________________________________________________________________\n",
      "input_46 (InputLayer)            (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)              (20, 8, 4, 32)        36864       lambda_59[0][0]                  \n",
      "                                                                   lambda_60[0][0]                  \n",
      "                                                                   lambda_61[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_47 (InputLayer)            (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_48 (InputLayer)            (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_62 (Lambda)               (20, 8, 4, 32)        0           input_46[0][0]                   \n",
      "                                                                   conv2d_214[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_63 (Lambda)               (20, 8, 4, 32)        0           input_47[0][0]                   \n",
      "                                                                   conv2d_214[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_64 (Lambda)               (20, 8, 4, 32)        0           input_48[0][0]                   \n",
      "                                                                   conv2d_214[2][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_103 (Concatenate)    (20, 8, 4, 608)       0           concatenate_102[0][0]            \n",
      "                                                                   lambda_62[1][0]                  \n",
      "                                                                   concatenate_102[1][0]            \n",
      "                                                                   lambda_63[1][0]                  \n",
      "                                                                   concatenate_102[2][0]            \n",
      "                                                                   lambda_64[1][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_49 (InputLayer)            (608,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_50 (InputLayer)            (608,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_51 (InputLayer)            (608,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_65 (Lambda)               (20, 8, 4, 608)       0           input_49[0][0]                   \n",
      "                                                                   concatenate_103[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_66 (Lambda)               (20, 8, 4, 608)       0           input_50[0][0]                   \n",
      "                                                                   concatenate_103[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_67 (Lambda)               (20, 8, 4, 608)       0           input_51[0][0]                   \n",
      "                                                                   concatenate_103[2][0]            \n",
      "____________________________________________________________________________________________________\n",
      "input_52 (InputLayer)            (608,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchNo (20, 8, 4, 608)       2432        lambda_65[1][0]                  \n",
      "                                                                   lambda_66[1][0]                  \n",
      "                                                                   lambda_67[1][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_53 (InputLayer)            (608,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_54 (InputLayer)            (608,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_68 (Lambda)               (20, 8, 4, 608)       0           input_52[0][0]                   \n",
      "                                                                   batch_normalization_129[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_69 (Lambda)               (20, 8, 4, 608)       0           input_53[0][0]                   \n",
      "                                                                   batch_normalization_129[1][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_70 (Lambda)               (20, 8, 4, 608)       0           input_54[0][0]                   \n",
      "                                                                   batch_normalization_129[2][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_217 (Activation)      (20, 8, 4, 608)       0           lambda_68[1][0]                  \n",
      "                                                                   lambda_69[1][0]                  \n",
      "                                                                   lambda_70[1][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_71 (Lambda)               (20, 8, 4, 608)       0           activation_217[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_72 (Lambda)               (20, 8, 4, 608)       0           activation_217[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_73 (Lambda)               (20, 8, 4, 608)       0           activation_217[2][0]             \n",
      "____________________________________________________________________________________________________\n",
      "input_55 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)              (20, 8, 4, 128)       77824       lambda_71[0][0]                  \n",
      "                                                                   lambda_72[0][0]                  \n",
      "                                                                   lambda_73[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_56 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_57 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_74 (Lambda)               (20, 8, 4, 128)       0           input_55[0][0]                   \n",
      "                                                                   conv2d_215[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_75 (Lambda)               (20, 8, 4, 128)       0           input_56[0][0]                   \n",
      "                                                                   conv2d_215[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_76 (Lambda)               (20, 8, 4, 128)       0           input_57[0][0]                   \n",
      "                                                                   conv2d_215[2][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_58 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchNo (20, 8, 4, 128)       512         lambda_74[1][0]                  \n",
      "                                                                   lambda_75[1][0]                  \n",
      "                                                                   lambda_76[1][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_59 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_60 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_77 (Lambda)               (20, 8, 4, 128)       0           input_58[0][0]                   \n",
      "                                                                   batch_normalization_130[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_78 (Lambda)               (20, 8, 4, 128)       0           input_59[0][0]                   \n",
      "                                                                   batch_normalization_130[1][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_79 (Lambda)               (20, 8, 4, 128)       0           input_60[0][0]                   \n",
      "                                                                   batch_normalization_130[2][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_218 (Activation)      (20, 8, 4, 128)       0           lambda_77[1][0]                  \n",
      "                                                                   lambda_78[1][0]                  \n",
      "                                                                   lambda_79[1][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_80 (Lambda)               (20, 8, 4, 128)       0           activation_218[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_81 (Lambda)               (20, 8, 4, 128)       0           activation_218[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_82 (Lambda)               (20, 8, 4, 128)       0           activation_218[2][0]             \n",
      "____________________________________________________________________________________________________\n",
      "input_61 (InputLayer)            (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)              (20, 8, 4, 32)        36864       lambda_80[0][0]                  \n",
      "                                                                   lambda_81[0][0]                  \n",
      "                                                                   lambda_82[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_62 (InputLayer)            (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_63 (InputLayer)            (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_83 (Lambda)               (20, 8, 4, 32)        0           input_61[0][0]                   \n",
      "                                                                   conv2d_216[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_84 (Lambda)               (20, 8, 4, 32)        0           input_62[0][0]                   \n",
      "                                                                   conv2d_216[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_85 (Lambda)               (20, 8, 4, 32)        0           input_63[0][0]                   \n",
      "                                                                   conv2d_216[2][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_104 (Concatenate)    (20, 8, 4, 640)       0           concatenate_103[0][0]            \n",
      "                                                                   lambda_83[1][0]                  \n",
      "                                                                   concatenate_103[1][0]            \n",
      "                                                                   lambda_84[1][0]                  \n",
      "                                                                   concatenate_103[2][0]            \n",
      "                                                                   lambda_85[1][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_64 (InputLayer)            (640,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_65 (InputLayer)            (640,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_66 (InputLayer)            (640,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_86 (Lambda)               (20, 8, 4, 640)       0           input_64[0][0]                   \n",
      "                                                                   concatenate_104[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_87 (Lambda)               (20, 8, 4, 640)       0           input_65[0][0]                   \n",
      "                                                                   concatenate_104[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_88 (Lambda)               (20, 8, 4, 640)       0           input_66[0][0]                   \n",
      "                                                                   concatenate_104[2][0]            \n",
      "____________________________________________________________________________________________________\n",
      "input_67 (InputLayer)            (640,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchNo (20, 8, 4, 640)       2560        lambda_86[1][0]                  \n",
      "                                                                   lambda_87[1][0]                  \n",
      "                                                                   lambda_88[1][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_68 (InputLayer)            (640,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_69 (InputLayer)            (640,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_89 (Lambda)               (20, 8, 4, 640)       0           input_67[0][0]                   \n",
      "                                                                   batch_normalization_131[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_90 (Lambda)               (20, 8, 4, 640)       0           input_68[0][0]                   \n",
      "                                                                   batch_normalization_131[1][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_91 (Lambda)               (20, 8, 4, 640)       0           input_69[0][0]                   \n",
      "                                                                   batch_normalization_131[2][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_219 (Activation)      (20, 8, 4, 640)       0           lambda_89[1][0]                  \n",
      "                                                                   lambda_90[1][0]                  \n",
      "                                                                   lambda_91[1][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_92 (Lambda)               (20, 8, 4, 640)       0           activation_219[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_93 (Lambda)               (20, 8, 4, 640)       0           activation_219[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_94 (Lambda)               (20, 8, 4, 640)       0           activation_219[2][0]             \n",
      "____________________________________________________________________________________________________\n",
      "input_70 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_217 (Conv2D)              (20, 8, 4, 128)       81920       lambda_92[0][0]                  \n",
      "                                                                   lambda_93[0][0]                  \n",
      "                                                                   lambda_94[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_71 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_72 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_95 (Lambda)               (20, 8, 4, 128)       0           input_70[0][0]                   \n",
      "                                                                   conv2d_217[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_96 (Lambda)               (20, 8, 4, 128)       0           input_71[0][0]                   \n",
      "                                                                   conv2d_217[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_97 (Lambda)               (20, 8, 4, 128)       0           input_72[0][0]                   \n",
      "                                                                   conv2d_217[2][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_73 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchNo (20, 8, 4, 128)       512         lambda_95[1][0]                  \n",
      "                                                                   lambda_96[1][0]                  \n",
      "                                                                   lambda_97[1][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_74 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_75 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_98 (Lambda)               (20, 8, 4, 128)       0           input_73[0][0]                   \n",
      "                                                                   batch_normalization_132[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_99 (Lambda)               (20, 8, 4, 128)       0           input_74[0][0]                   \n",
      "                                                                   batch_normalization_132[1][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_100 (Lambda)              (20, 8, 4, 128)       0           input_75[0][0]                   \n",
      "                                                                   batch_normalization_132[2][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_220 (Activation)      (20, 8, 4, 128)       0           lambda_98[1][0]                  \n",
      "                                                                   lambda_99[1][0]                  \n",
      "                                                                   lambda_100[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_101 (Lambda)              (20, 8, 4, 128)       0           activation_220[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_102 (Lambda)              (20, 8, 4, 128)       0           activation_220[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_103 (Lambda)              (20, 8, 4, 128)       0           activation_220[2][0]             \n",
      "____________________________________________________________________________________________________\n",
      "input_76 (InputLayer)            (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_218 (Conv2D)              (20, 8, 4, 32)        36864       lambda_101[0][0]                 \n",
      "                                                                   lambda_102[0][0]                 \n",
      "                                                                   lambda_103[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_77 (InputLayer)            (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_78 (InputLayer)            (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_104 (Lambda)              (20, 8, 4, 32)        0           input_76[0][0]                   \n",
      "                                                                   conv2d_218[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_105 (Lambda)              (20, 8, 4, 32)        0           input_77[0][0]                   \n",
      "                                                                   conv2d_218[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_106 (Lambda)              (20, 8, 4, 32)        0           input_78[0][0]                   \n",
      "                                                                   conv2d_218[2][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_105 (Concatenate)    (20, 8, 4, 672)       0           concatenate_104[0][0]            \n",
      "                                                                   lambda_104[1][0]                 \n",
      "                                                                   concatenate_104[1][0]            \n",
      "                                                                   lambda_105[1][0]                 \n",
      "                                                                   concatenate_104[2][0]            \n",
      "                                                                   lambda_106[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_79 (InputLayer)            (672,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_80 (InputLayer)            (672,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_81 (InputLayer)            (672,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_107 (Lambda)              (20, 8, 4, 672)       0           input_79[0][0]                   \n",
      "                                                                   concatenate_105[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_108 (Lambda)              (20, 8, 4, 672)       0           input_80[0][0]                   \n",
      "                                                                   concatenate_105[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_109 (Lambda)              (20, 8, 4, 672)       0           input_81[0][0]                   \n",
      "                                                                   concatenate_105[2][0]            \n",
      "____________________________________________________________________________________________________\n",
      "input_82 (InputLayer)            (672,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchNo (20, 8, 4, 672)       2688        lambda_107[1][0]                 \n",
      "                                                                   lambda_108[1][0]                 \n",
      "                                                                   lambda_109[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_83 (InputLayer)            (672,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_84 (InputLayer)            (672,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_110 (Lambda)              (20, 8, 4, 672)       0           input_82[0][0]                   \n",
      "                                                                   batch_normalization_133[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_111 (Lambda)              (20, 8, 4, 672)       0           input_83[0][0]                   \n",
      "                                                                   batch_normalization_133[1][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_112 (Lambda)              (20, 8, 4, 672)       0           input_84[0][0]                   \n",
      "                                                                   batch_normalization_133[2][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_221 (Activation)      (20, 8, 4, 672)       0           lambda_110[1][0]                 \n",
      "                                                                   lambda_111[1][0]                 \n",
      "                                                                   lambda_112[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_113 (Lambda)              (20, 8, 4, 672)       0           activation_221[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_114 (Lambda)              (20, 8, 4, 672)       0           activation_221[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_115 (Lambda)              (20, 8, 4, 672)       0           activation_221[2][0]             \n",
      "____________________________________________________________________________________________________\n",
      "input_85 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_219 (Conv2D)              (20, 8, 4, 128)       86016       lambda_113[0][0]                 \n",
      "                                                                   lambda_114[0][0]                 \n",
      "                                                                   lambda_115[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_86 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_87 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_116 (Lambda)              (20, 8, 4, 128)       0           input_85[0][0]                   \n",
      "                                                                   conv2d_219[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_117 (Lambda)              (20, 8, 4, 128)       0           input_86[0][0]                   \n",
      "                                                                   conv2d_219[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_118 (Lambda)              (20, 8, 4, 128)       0           input_87[0][0]                   \n",
      "                                                                   conv2d_219[2][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_88 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchNo (20, 8, 4, 128)       512         lambda_116[1][0]                 \n",
      "                                                                   lambda_117[1][0]                 \n",
      "                                                                   lambda_118[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_89 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_90 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_119 (Lambda)              (20, 8, 4, 128)       0           input_88[0][0]                   \n",
      "                                                                   batch_normalization_134[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_120 (Lambda)              (20, 8, 4, 128)       0           input_89[0][0]                   \n",
      "                                                                   batch_normalization_134[1][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_121 (Lambda)              (20, 8, 4, 128)       0           input_90[0][0]                   \n",
      "                                                                   batch_normalization_134[2][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_222 (Activation)      (20, 8, 4, 128)       0           lambda_119[1][0]                 \n",
      "                                                                   lambda_120[1][0]                 \n",
      "                                                                   lambda_121[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_122 (Lambda)              (20, 8, 4, 128)       0           activation_222[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_123 (Lambda)              (20, 8, 4, 128)       0           activation_222[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_124 (Lambda)              (20, 8, 4, 128)       0           activation_222[2][0]             \n",
      "____________________________________________________________________________________________________\n",
      "input_91 (InputLayer)            (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_220 (Conv2D)              (20, 8, 4, 32)        36864       lambda_122[0][0]                 \n",
      "                                                                   lambda_123[0][0]                 \n",
      "                                                                   lambda_124[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_92 (InputLayer)            (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_93 (InputLayer)            (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_125 (Lambda)              (20, 8, 4, 32)        0           input_91[0][0]                   \n",
      "                                                                   conv2d_220[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_126 (Lambda)              (20, 8, 4, 32)        0           input_92[0][0]                   \n",
      "                                                                   conv2d_220[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_127 (Lambda)              (20, 8, 4, 32)        0           input_93[0][0]                   \n",
      "                                                                   conv2d_220[2][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_106 (Concatenate)    (20, 8, 4, 704)       0           concatenate_105[0][0]            \n",
      "                                                                   lambda_125[1][0]                 \n",
      "                                                                   concatenate_105[1][0]            \n",
      "                                                                   lambda_126[1][0]                 \n",
      "                                                                   concatenate_105[2][0]            \n",
      "                                                                   lambda_127[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_94 (InputLayer)            (704,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_95 (InputLayer)            (704,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_96 (InputLayer)            (704,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_128 (Lambda)              (20, 8, 4, 704)       0           input_94[0][0]                   \n",
      "                                                                   concatenate_106[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_129 (Lambda)              (20, 8, 4, 704)       0           input_95[0][0]                   \n",
      "                                                                   concatenate_106[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_130 (Lambda)              (20, 8, 4, 704)       0           input_96[0][0]                   \n",
      "                                                                   concatenate_106[2][0]            \n",
      "____________________________________________________________________________________________________\n",
      "input_97 (InputLayer)            (704,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchNo (20, 8, 4, 704)       2816        lambda_128[1][0]                 \n",
      "                                                                   lambda_129[1][0]                 \n",
      "                                                                   lambda_130[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_98 (InputLayer)            (704,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_99 (InputLayer)            (704,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_131 (Lambda)              (20, 8, 4, 704)       0           input_97[0][0]                   \n",
      "                                                                   batch_normalization_135[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_132 (Lambda)              (20, 8, 4, 704)       0           input_98[0][0]                   \n",
      "                                                                   batch_normalization_135[1][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_133 (Lambda)              (20, 8, 4, 704)       0           input_99[0][0]                   \n",
      "                                                                   batch_normalization_135[2][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_223 (Activation)      (20, 8, 4, 704)       0           lambda_131[1][0]                 \n",
      "                                                                   lambda_132[1][0]                 \n",
      "                                                                   lambda_133[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_134 (Lambda)              (20, 8, 4, 704)       0           activation_223[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_135 (Lambda)              (20, 8, 4, 704)       0           activation_223[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_136 (Lambda)              (20, 8, 4, 704)       0           activation_223[2][0]             \n",
      "____________________________________________________________________________________________________\n",
      "input_100 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_221 (Conv2D)              (20, 8, 4, 128)       90112       lambda_134[0][0]                 \n",
      "                                                                   lambda_135[0][0]                 \n",
      "                                                                   lambda_136[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_101 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_102 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_137 (Lambda)              (20, 8, 4, 128)       0           input_100[0][0]                  \n",
      "                                                                   conv2d_221[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_138 (Lambda)              (20, 8, 4, 128)       0           input_101[0][0]                  \n",
      "                                                                   conv2d_221[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_139 (Lambda)              (20, 8, 4, 128)       0           input_102[0][0]                  \n",
      "                                                                   conv2d_221[2][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_103 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchNo (20, 8, 4, 128)       512         lambda_137[1][0]                 \n",
      "                                                                   lambda_138[1][0]                 \n",
      "                                                                   lambda_139[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_104 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_105 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_140 (Lambda)              (20, 8, 4, 128)       0           input_103[0][0]                  \n",
      "                                                                   batch_normalization_136[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_141 (Lambda)              (20, 8, 4, 128)       0           input_104[0][0]                  \n",
      "                                                                   batch_normalization_136[1][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_142 (Lambda)              (20, 8, 4, 128)       0           input_105[0][0]                  \n",
      "                                                                   batch_normalization_136[2][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_224 (Activation)      (20, 8, 4, 128)       0           lambda_140[1][0]                 \n",
      "                                                                   lambda_141[1][0]                 \n",
      "                                                                   lambda_142[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_143 (Lambda)              (20, 8, 4, 128)       0           activation_224[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_144 (Lambda)              (20, 8, 4, 128)       0           activation_224[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_145 (Lambda)              (20, 8, 4, 128)       0           activation_224[2][0]             \n",
      "____________________________________________________________________________________________________\n",
      "input_106 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_222 (Conv2D)              (20, 8, 4, 32)        36864       lambda_143[0][0]                 \n",
      "                                                                   lambda_144[0][0]                 \n",
      "                                                                   lambda_145[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_107 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_108 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_146 (Lambda)              (20, 8, 4, 32)        0           input_106[0][0]                  \n",
      "                                                                   conv2d_222[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_147 (Lambda)              (20, 8, 4, 32)        0           input_107[0][0]                  \n",
      "                                                                   conv2d_222[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_148 (Lambda)              (20, 8, 4, 32)        0           input_108[0][0]                  \n",
      "                                                                   conv2d_222[2][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_107 (Concatenate)    (20, 8, 4, 736)       0           concatenate_106[0][0]            \n",
      "                                                                   lambda_146[1][0]                 \n",
      "                                                                   concatenate_106[1][0]            \n",
      "                                                                   lambda_147[1][0]                 \n",
      "                                                                   concatenate_106[2][0]            \n",
      "                                                                   lambda_148[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_109 (InputLayer)           (736,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_110 (InputLayer)           (736,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_111 (InputLayer)           (736,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_149 (Lambda)              (20, 8, 4, 736)       0           input_109[0][0]                  \n",
      "                                                                   concatenate_107[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_150 (Lambda)              (20, 8, 4, 736)       0           input_110[0][0]                  \n",
      "                                                                   concatenate_107[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_151 (Lambda)              (20, 8, 4, 736)       0           input_111[0][0]                  \n",
      "                                                                   concatenate_107[2][0]            \n",
      "____________________________________________________________________________________________________\n",
      "input_112 (InputLayer)           (736,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchNo (20, 8, 4, 736)       2944        lambda_149[1][0]                 \n",
      "                                                                   lambda_150[1][0]                 \n",
      "                                                                   lambda_151[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_113 (InputLayer)           (736,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_114 (InputLayer)           (736,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_152 (Lambda)              (20, 8, 4, 736)       0           input_112[0][0]                  \n",
      "                                                                   batch_normalization_137[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_153 (Lambda)              (20, 8, 4, 736)       0           input_113[0][0]                  \n",
      "                                                                   batch_normalization_137[1][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_154 (Lambda)              (20, 8, 4, 736)       0           input_114[0][0]                  \n",
      "                                                                   batch_normalization_137[2][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_225 (Activation)      (20, 8, 4, 736)       0           lambda_152[1][0]                 \n",
      "                                                                   lambda_153[1][0]                 \n",
      "                                                                   lambda_154[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_155 (Lambda)              (20, 8, 4, 736)       0           activation_225[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_156 (Lambda)              (20, 8, 4, 736)       0           activation_225[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_157 (Lambda)              (20, 8, 4, 736)       0           activation_225[2][0]             \n",
      "____________________________________________________________________________________________________\n",
      "input_115 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_223 (Conv2D)              (20, 8, 4, 128)       94208       lambda_155[0][0]                 \n",
      "                                                                   lambda_156[0][0]                 \n",
      "                                                                   lambda_157[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_116 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_117 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_158 (Lambda)              (20, 8, 4, 128)       0           input_115[0][0]                  \n",
      "                                                                   conv2d_223[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_159 (Lambda)              (20, 8, 4, 128)       0           input_116[0][0]                  \n",
      "                                                                   conv2d_223[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_160 (Lambda)              (20, 8, 4, 128)       0           input_117[0][0]                  \n",
      "                                                                   conv2d_223[2][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_118 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchNo (20, 8, 4, 128)       512         lambda_158[1][0]                 \n",
      "                                                                   lambda_159[1][0]                 \n",
      "                                                                   lambda_160[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_119 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_120 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_161 (Lambda)              (20, 8, 4, 128)       0           input_118[0][0]                  \n",
      "                                                                   batch_normalization_138[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_162 (Lambda)              (20, 8, 4, 128)       0           input_119[0][0]                  \n",
      "                                                                   batch_normalization_138[1][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_163 (Lambda)              (20, 8, 4, 128)       0           input_120[0][0]                  \n",
      "                                                                   batch_normalization_138[2][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_226 (Activation)      (20, 8, 4, 128)       0           lambda_161[1][0]                 \n",
      "                                                                   lambda_162[1][0]                 \n",
      "                                                                   lambda_163[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_164 (Lambda)              (20, 8, 4, 128)       0           activation_226[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_165 (Lambda)              (20, 8, 4, 128)       0           activation_226[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_166 (Lambda)              (20, 8, 4, 128)       0           activation_226[2][0]             \n",
      "____________________________________________________________________________________________________\n",
      "input_121 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_224 (Conv2D)              (20, 8, 4, 32)        36864       lambda_164[0][0]                 \n",
      "                                                                   lambda_165[0][0]                 \n",
      "                                                                   lambda_166[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_122 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_123 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_167 (Lambda)              (20, 8, 4, 32)        0           input_121[0][0]                  \n",
      "                                                                   conv2d_224[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_168 (Lambda)              (20, 8, 4, 32)        0           input_122[0][0]                  \n",
      "                                                                   conv2d_224[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_169 (Lambda)              (20, 8, 4, 32)        0           input_123[0][0]                  \n",
      "                                                                   conv2d_224[2][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_108 (Concatenate)    (20, 8, 4, 768)       0           concatenate_107[0][0]            \n",
      "                                                                   lambda_167[1][0]                 \n",
      "                                                                   concatenate_107[1][0]            \n",
      "                                                                   lambda_168[1][0]                 \n",
      "                                                                   concatenate_107[2][0]            \n",
      "                                                                   lambda_169[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_124 (InputLayer)           (768,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_125 (InputLayer)           (768,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_126 (InputLayer)           (768,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_170 (Lambda)              (20, 8, 4, 768)       0           input_124[0][0]                  \n",
      "                                                                   concatenate_108[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_171 (Lambda)              (20, 8, 4, 768)       0           input_125[0][0]                  \n",
      "                                                                   concatenate_108[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_172 (Lambda)              (20, 8, 4, 768)       0           input_126[0][0]                  \n",
      "                                                                   concatenate_108[2][0]            \n",
      "____________________________________________________________________________________________________\n",
      "input_127 (InputLayer)           (768,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchNo (20, 8, 4, 768)       3072        lambda_170[1][0]                 \n",
      "                                                                   lambda_171[1][0]                 \n",
      "                                                                   lambda_172[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_128 (InputLayer)           (768,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_129 (InputLayer)           (768,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_173 (Lambda)              (20, 8, 4, 768)       0           input_127[0][0]                  \n",
      "                                                                   batch_normalization_139[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_174 (Lambda)              (20, 8, 4, 768)       0           input_128[0][0]                  \n",
      "                                                                   batch_normalization_139[1][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_175 (Lambda)              (20, 8, 4, 768)       0           input_129[0][0]                  \n",
      "                                                                   batch_normalization_139[2][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_227 (Activation)      (20, 8, 4, 768)       0           lambda_173[1][0]                 \n",
      "                                                                   lambda_174[1][0]                 \n",
      "                                                                   lambda_175[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_176 (Lambda)              (20, 8, 4, 768)       0           activation_227[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_177 (Lambda)              (20, 8, 4, 768)       0           activation_227[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_178 (Lambda)              (20, 8, 4, 768)       0           activation_227[2][0]             \n",
      "____________________________________________________________________________________________________\n",
      "input_130 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_225 (Conv2D)              (20, 8, 4, 128)       98304       lambda_176[0][0]                 \n",
      "                                                                   lambda_177[0][0]                 \n",
      "                                                                   lambda_178[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_131 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_132 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_179 (Lambda)              (20, 8, 4, 128)       0           input_130[0][0]                  \n",
      "                                                                   conv2d_225[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_180 (Lambda)              (20, 8, 4, 128)       0           input_131[0][0]                  \n",
      "                                                                   conv2d_225[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_181 (Lambda)              (20, 8, 4, 128)       0           input_132[0][0]                  \n",
      "                                                                   conv2d_225[2][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_133 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchNo (20, 8, 4, 128)       512         lambda_179[1][0]                 \n",
      "                                                                   lambda_180[1][0]                 \n",
      "                                                                   lambda_181[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_134 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_135 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_182 (Lambda)              (20, 8, 4, 128)       0           input_133[0][0]                  \n",
      "                                                                   batch_normalization_140[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_183 (Lambda)              (20, 8, 4, 128)       0           input_134[0][0]                  \n",
      "                                                                   batch_normalization_140[1][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_184 (Lambda)              (20, 8, 4, 128)       0           input_135[0][0]                  \n",
      "                                                                   batch_normalization_140[2][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_228 (Activation)      (20, 8, 4, 128)       0           lambda_182[1][0]                 \n",
      "                                                                   lambda_183[1][0]                 \n",
      "                                                                   lambda_184[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_185 (Lambda)              (20, 8, 4, 128)       0           activation_228[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_186 (Lambda)              (20, 8, 4, 128)       0           activation_228[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_187 (Lambda)              (20, 8, 4, 128)       0           activation_228[2][0]             \n",
      "____________________________________________________________________________________________________\n",
      "input_136 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_226 (Conv2D)              (20, 8, 4, 32)        36864       lambda_185[0][0]                 \n",
      "                                                                   lambda_186[0][0]                 \n",
      "                                                                   lambda_187[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_137 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_138 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_188 (Lambda)              (20, 8, 4, 32)        0           input_136[0][0]                  \n",
      "                                                                   conv2d_226[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_189 (Lambda)              (20, 8, 4, 32)        0           input_137[0][0]                  \n",
      "                                                                   conv2d_226[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_190 (Lambda)              (20, 8, 4, 32)        0           input_138[0][0]                  \n",
      "                                                                   conv2d_226[2][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_109 (Concatenate)    (20, 8, 4, 800)       0           concatenate_108[0][0]            \n",
      "                                                                   lambda_188[1][0]                 \n",
      "                                                                   concatenate_108[1][0]            \n",
      "                                                                   lambda_189[1][0]                 \n",
      "                                                                   concatenate_108[2][0]            \n",
      "                                                                   lambda_190[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_139 (InputLayer)           (800,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_140 (InputLayer)           (800,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_141 (InputLayer)           (800,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_191 (Lambda)              (20, 8, 4, 800)       0           input_139[0][0]                  \n",
      "                                                                   concatenate_109[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_192 (Lambda)              (20, 8, 4, 800)       0           input_140[0][0]                  \n",
      "                                                                   concatenate_109[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_193 (Lambda)              (20, 8, 4, 800)       0           input_141[0][0]                  \n",
      "                                                                   concatenate_109[2][0]            \n",
      "____________________________________________________________________________________________________\n",
      "input_142 (InputLayer)           (800,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchNo (20, 8, 4, 800)       3200        lambda_191[1][0]                 \n",
      "                                                                   lambda_192[1][0]                 \n",
      "                                                                   lambda_193[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_143 (InputLayer)           (800,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_144 (InputLayer)           (800,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_194 (Lambda)              (20, 8, 4, 800)       0           input_142[0][0]                  \n",
      "                                                                   batch_normalization_141[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_195 (Lambda)              (20, 8, 4, 800)       0           input_143[0][0]                  \n",
      "                                                                   batch_normalization_141[1][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_196 (Lambda)              (20, 8, 4, 800)       0           input_144[0][0]                  \n",
      "                                                                   batch_normalization_141[2][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_229 (Activation)      (20, 8, 4, 800)       0           lambda_194[1][0]                 \n",
      "                                                                   lambda_195[1][0]                 \n",
      "                                                                   lambda_196[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_197 (Lambda)              (20, 8, 4, 800)       0           activation_229[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_198 (Lambda)              (20, 8, 4, 800)       0           activation_229[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_199 (Lambda)              (20, 8, 4, 800)       0           activation_229[2][0]             \n",
      "____________________________________________________________________________________________________\n",
      "input_145 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_227 (Conv2D)              (20, 8, 4, 128)       102400      lambda_197[0][0]                 \n",
      "                                                                   lambda_198[0][0]                 \n",
      "                                                                   lambda_199[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_146 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_147 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_200 (Lambda)              (20, 8, 4, 128)       0           input_145[0][0]                  \n",
      "                                                                   conv2d_227[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_201 (Lambda)              (20, 8, 4, 128)       0           input_146[0][0]                  \n",
      "                                                                   conv2d_227[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_202 (Lambda)              (20, 8, 4, 128)       0           input_147[0][0]                  \n",
      "                                                                   conv2d_227[2][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_148 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchNo (20, 8, 4, 128)       512         lambda_200[1][0]                 \n",
      "                                                                   lambda_201[1][0]                 \n",
      "                                                                   lambda_202[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_149 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_150 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_203 (Lambda)              (20, 8, 4, 128)       0           input_148[0][0]                  \n",
      "                                                                   batch_normalization_142[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_204 (Lambda)              (20, 8, 4, 128)       0           input_149[0][0]                  \n",
      "                                                                   batch_normalization_142[1][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_205 (Lambda)              (20, 8, 4, 128)       0           input_150[0][0]                  \n",
      "                                                                   batch_normalization_142[2][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_230 (Activation)      (20, 8, 4, 128)       0           lambda_203[1][0]                 \n",
      "                                                                   lambda_204[1][0]                 \n",
      "                                                                   lambda_205[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_206 (Lambda)              (20, 8, 4, 128)       0           activation_230[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_207 (Lambda)              (20, 8, 4, 128)       0           activation_230[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_208 (Lambda)              (20, 8, 4, 128)       0           activation_230[2][0]             \n",
      "____________________________________________________________________________________________________\n",
      "input_151 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_228 (Conv2D)              (20, 8, 4, 32)        36864       lambda_206[0][0]                 \n",
      "                                                                   lambda_207[0][0]                 \n",
      "                                                                   lambda_208[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_152 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_153 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_209 (Lambda)              (20, 8, 4, 32)        0           input_151[0][0]                  \n",
      "                                                                   conv2d_228[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_210 (Lambda)              (20, 8, 4, 32)        0           input_152[0][0]                  \n",
      "                                                                   conv2d_228[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_211 (Lambda)              (20, 8, 4, 32)        0           input_153[0][0]                  \n",
      "                                                                   conv2d_228[2][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_110 (Concatenate)    (20, 8, 4, 832)       0           concatenate_109[0][0]            \n",
      "                                                                   lambda_209[1][0]                 \n",
      "                                                                   concatenate_109[1][0]            \n",
      "                                                                   lambda_210[1][0]                 \n",
      "                                                                   concatenate_109[2][0]            \n",
      "                                                                   lambda_211[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_154 (InputLayer)           (832,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_155 (InputLayer)           (832,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_156 (InputLayer)           (832,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_212 (Lambda)              (20, 8, 4, 832)       0           input_154[0][0]                  \n",
      "                                                                   concatenate_110[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_213 (Lambda)              (20, 8, 4, 832)       0           input_155[0][0]                  \n",
      "                                                                   concatenate_110[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_214 (Lambda)              (20, 8, 4, 832)       0           input_156[0][0]                  \n",
      "                                                                   concatenate_110[2][0]            \n",
      "____________________________________________________________________________________________________\n",
      "input_157 (InputLayer)           (832,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchNo (20, 8, 4, 832)       3328        lambda_212[1][0]                 \n",
      "                                                                   lambda_213[1][0]                 \n",
      "                                                                   lambda_214[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_158 (InputLayer)           (832,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_159 (InputLayer)           (832,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_215 (Lambda)              (20, 8, 4, 832)       0           input_157[0][0]                  \n",
      "                                                                   batch_normalization_143[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_216 (Lambda)              (20, 8, 4, 832)       0           input_158[0][0]                  \n",
      "                                                                   batch_normalization_143[1][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_217 (Lambda)              (20, 8, 4, 832)       0           input_159[0][0]                  \n",
      "                                                                   batch_normalization_143[2][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_231 (Activation)      (20, 8, 4, 832)       0           lambda_215[1][0]                 \n",
      "                                                                   lambda_216[1][0]                 \n",
      "                                                                   lambda_217[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_218 (Lambda)              (20, 8, 4, 832)       0           activation_231[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_219 (Lambda)              (20, 8, 4, 832)       0           activation_231[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_220 (Lambda)              (20, 8, 4, 832)       0           activation_231[2][0]             \n",
      "____________________________________________________________________________________________________\n",
      "input_160 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_229 (Conv2D)              (20, 8, 4, 128)       106496      lambda_218[0][0]                 \n",
      "                                                                   lambda_219[0][0]                 \n",
      "                                                                   lambda_220[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_161 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_162 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_221 (Lambda)              (20, 8, 4, 128)       0           input_160[0][0]                  \n",
      "                                                                   conv2d_229[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_222 (Lambda)              (20, 8, 4, 128)       0           input_161[0][0]                  \n",
      "                                                                   conv2d_229[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_223 (Lambda)              (20, 8, 4, 128)       0           input_162[0][0]                  \n",
      "                                                                   conv2d_229[2][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_163 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchNo (20, 8, 4, 128)       512         lambda_221[1][0]                 \n",
      "                                                                   lambda_222[1][0]                 \n",
      "                                                                   lambda_223[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_164 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_165 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_224 (Lambda)              (20, 8, 4, 128)       0           input_163[0][0]                  \n",
      "                                                                   batch_normalization_144[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_225 (Lambda)              (20, 8, 4, 128)       0           input_164[0][0]                  \n",
      "                                                                   batch_normalization_144[1][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_226 (Lambda)              (20, 8, 4, 128)       0           input_165[0][0]                  \n",
      "                                                                   batch_normalization_144[2][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_232 (Activation)      (20, 8, 4, 128)       0           lambda_224[1][0]                 \n",
      "                                                                   lambda_225[1][0]                 \n",
      "                                                                   lambda_226[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_227 (Lambda)              (20, 8, 4, 128)       0           activation_232[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_228 (Lambda)              (20, 8, 4, 128)       0           activation_232[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_229 (Lambda)              (20, 8, 4, 128)       0           activation_232[2][0]             \n",
      "____________________________________________________________________________________________________\n",
      "input_166 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_230 (Conv2D)              (20, 8, 4, 32)        36864       lambda_227[0][0]                 \n",
      "                                                                   lambda_228[0][0]                 \n",
      "                                                                   lambda_229[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_167 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_168 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_230 (Lambda)              (20, 8, 4, 32)        0           input_166[0][0]                  \n",
      "                                                                   conv2d_230[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_231 (Lambda)              (20, 8, 4, 32)        0           input_167[0][0]                  \n",
      "                                                                   conv2d_230[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_232 (Lambda)              (20, 8, 4, 32)        0           input_168[0][0]                  \n",
      "                                                                   conv2d_230[2][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_111 (Concatenate)    (20, 8, 4, 864)       0           concatenate_110[0][0]            \n",
      "                                                                   lambda_230[1][0]                 \n",
      "                                                                   concatenate_110[1][0]            \n",
      "                                                                   lambda_231[1][0]                 \n",
      "                                                                   concatenate_110[2][0]            \n",
      "                                                                   lambda_232[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_169 (InputLayer)           (864,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_170 (InputLayer)           (864,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_171 (InputLayer)           (864,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_233 (Lambda)              (20, 8, 4, 864)       0           input_169[0][0]                  \n",
      "                                                                   concatenate_111[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_234 (Lambda)              (20, 8, 4, 864)       0           input_170[0][0]                  \n",
      "                                                                   concatenate_111[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_235 (Lambda)              (20, 8, 4, 864)       0           input_171[0][0]                  \n",
      "                                                                   concatenate_111[2][0]            \n",
      "____________________________________________________________________________________________________\n",
      "input_172 (InputLayer)           (864,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchNo (20, 8, 4, 864)       3456        lambda_233[1][0]                 \n",
      "                                                                   lambda_234[1][0]                 \n",
      "                                                                   lambda_235[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_173 (InputLayer)           (864,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_174 (InputLayer)           (864,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_236 (Lambda)              (20, 8, 4, 864)       0           input_172[0][0]                  \n",
      "                                                                   batch_normalization_145[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_237 (Lambda)              (20, 8, 4, 864)       0           input_173[0][0]                  \n",
      "                                                                   batch_normalization_145[1][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_238 (Lambda)              (20, 8, 4, 864)       0           input_174[0][0]                  \n",
      "                                                                   batch_normalization_145[2][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_233 (Activation)      (20, 8, 4, 864)       0           lambda_236[1][0]                 \n",
      "                                                                   lambda_237[1][0]                 \n",
      "                                                                   lambda_238[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_239 (Lambda)              (20, 8, 4, 864)       0           activation_233[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_240 (Lambda)              (20, 8, 4, 864)       0           activation_233[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_241 (Lambda)              (20, 8, 4, 864)       0           activation_233[2][0]             \n",
      "____________________________________________________________________________________________________\n",
      "input_175 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_231 (Conv2D)              (20, 8, 4, 128)       110592      lambda_239[0][0]                 \n",
      "                                                                   lambda_240[0][0]                 \n",
      "                                                                   lambda_241[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_176 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_177 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_242 (Lambda)              (20, 8, 4, 128)       0           input_175[0][0]                  \n",
      "                                                                   conv2d_231[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_243 (Lambda)              (20, 8, 4, 128)       0           input_176[0][0]                  \n",
      "                                                                   conv2d_231[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_244 (Lambda)              (20, 8, 4, 128)       0           input_177[0][0]                  \n",
      "                                                                   conv2d_231[2][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_178 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchNo (20, 8, 4, 128)       512         lambda_242[1][0]                 \n",
      "                                                                   lambda_243[1][0]                 \n",
      "                                                                   lambda_244[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_179 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_180 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_245 (Lambda)              (20, 8, 4, 128)       0           input_178[0][0]                  \n",
      "                                                                   batch_normalization_146[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_246 (Lambda)              (20, 8, 4, 128)       0           input_179[0][0]                  \n",
      "                                                                   batch_normalization_146[1][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_247 (Lambda)              (20, 8, 4, 128)       0           input_180[0][0]                  \n",
      "                                                                   batch_normalization_146[2][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_234 (Activation)      (20, 8, 4, 128)       0           lambda_245[1][0]                 \n",
      "                                                                   lambda_246[1][0]                 \n",
      "                                                                   lambda_247[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_248 (Lambda)              (20, 8, 4, 128)       0           activation_234[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_249 (Lambda)              (20, 8, 4, 128)       0           activation_234[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_250 (Lambda)              (20, 8, 4, 128)       0           activation_234[2][0]             \n",
      "____________________________________________________________________________________________________\n",
      "input_181 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_232 (Conv2D)              (20, 8, 4, 32)        36864       lambda_248[0][0]                 \n",
      "                                                                   lambda_249[0][0]                 \n",
      "                                                                   lambda_250[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_182 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_183 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_251 (Lambda)              (20, 8, 4, 32)        0           input_181[0][0]                  \n",
      "                                                                   conv2d_232[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_252 (Lambda)              (20, 8, 4, 32)        0           input_182[0][0]                  \n",
      "                                                                   conv2d_232[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_253 (Lambda)              (20, 8, 4, 32)        0           input_183[0][0]                  \n",
      "                                                                   conv2d_232[2][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_112 (Concatenate)    (20, 8, 4, 896)       0           concatenate_111[0][0]            \n",
      "                                                                   lambda_251[1][0]                 \n",
      "                                                                   concatenate_111[1][0]            \n",
      "                                                                   lambda_252[1][0]                 \n",
      "                                                                   concatenate_111[2][0]            \n",
      "                                                                   lambda_253[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_184 (InputLayer)           (896,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_185 (InputLayer)           (896,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_186 (InputLayer)           (896,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_254 (Lambda)              (20, 8, 4, 896)       0           input_184[0][0]                  \n",
      "                                                                   concatenate_112[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_255 (Lambda)              (20, 8, 4, 896)       0           input_185[0][0]                  \n",
      "                                                                   concatenate_112[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_256 (Lambda)              (20, 8, 4, 896)       0           input_186[0][0]                  \n",
      "                                                                   concatenate_112[2][0]            \n",
      "____________________________________________________________________________________________________\n",
      "input_187 (InputLayer)           (896,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchNo (20, 8, 4, 896)       3584        lambda_254[1][0]                 \n",
      "                                                                   lambda_255[1][0]                 \n",
      "                                                                   lambda_256[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_188 (InputLayer)           (896,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_189 (InputLayer)           (896,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_257 (Lambda)              (20, 8, 4, 896)       0           input_187[0][0]                  \n",
      "                                                                   batch_normalization_147[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_258 (Lambda)              (20, 8, 4, 896)       0           input_188[0][0]                  \n",
      "                                                                   batch_normalization_147[1][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_259 (Lambda)              (20, 8, 4, 896)       0           input_189[0][0]                  \n",
      "                                                                   batch_normalization_147[2][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_235 (Activation)      (20, 8, 4, 896)       0           lambda_257[1][0]                 \n",
      "                                                                   lambda_258[1][0]                 \n",
      "                                                                   lambda_259[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_260 (Lambda)              (20, 8, 4, 896)       0           activation_235[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_261 (Lambda)              (20, 8, 4, 896)       0           activation_235[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_262 (Lambda)              (20, 8, 4, 896)       0           activation_235[2][0]             \n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_190 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_233 (Conv2D)              (20, 8, 4, 128)       114688      lambda_260[0][0]                 \n",
      "                                                                   lambda_261[0][0]                 \n",
      "                                                                   lambda_262[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_191 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_192 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_263 (Lambda)              (20, 8, 4, 128)       0           input_190[0][0]                  \n",
      "                                                                   conv2d_233[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_264 (Lambda)              (20, 8, 4, 128)       0           input_191[0][0]                  \n",
      "                                                                   conv2d_233[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_265 (Lambda)              (20, 8, 4, 128)       0           input_192[0][0]                  \n",
      "                                                                   conv2d_233[2][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_193 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchNo (20, 8, 4, 128)       512         lambda_263[1][0]                 \n",
      "                                                                   lambda_264[1][0]                 \n",
      "                                                                   lambda_265[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_194 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_195 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_266 (Lambda)              (20, 8, 4, 128)       0           input_193[0][0]                  \n",
      "                                                                   batch_normalization_148[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_267 (Lambda)              (20, 8, 4, 128)       0           input_194[0][0]                  \n",
      "                                                                   batch_normalization_148[1][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_268 (Lambda)              (20, 8, 4, 128)       0           input_195[0][0]                  \n",
      "                                                                   batch_normalization_148[2][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_236 (Activation)      (20, 8, 4, 128)       0           lambda_266[1][0]                 \n",
      "                                                                   lambda_267[1][0]                 \n",
      "                                                                   lambda_268[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_269 (Lambda)              (20, 8, 4, 128)       0           activation_236[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_270 (Lambda)              (20, 8, 4, 128)       0           activation_236[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_271 (Lambda)              (20, 8, 4, 128)       0           activation_236[2][0]             \n",
      "____________________________________________________________________________________________________\n",
      "input_196 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_234 (Conv2D)              (20, 8, 4, 32)        36864       lambda_269[0][0]                 \n",
      "                                                                   lambda_270[0][0]                 \n",
      "                                                                   lambda_271[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_197 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_198 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_272 (Lambda)              (20, 8, 4, 32)        0           input_196[0][0]                  \n",
      "                                                                   conv2d_234[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_273 (Lambda)              (20, 8, 4, 32)        0           input_197[0][0]                  \n",
      "                                                                   conv2d_234[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_274 (Lambda)              (20, 8, 4, 32)        0           input_198[0][0]                  \n",
      "                                                                   conv2d_234[2][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_113 (Concatenate)    (20, 8, 4, 928)       0           concatenate_112[0][0]            \n",
      "                                                                   lambda_272[1][0]                 \n",
      "                                                                   concatenate_112[1][0]            \n",
      "                                                                   lambda_273[1][0]                 \n",
      "                                                                   concatenate_112[2][0]            \n",
      "                                                                   lambda_274[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_199 (InputLayer)           (928,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_200 (InputLayer)           (928,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_201 (InputLayer)           (928,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_275 (Lambda)              (20, 8, 4, 928)       0           input_199[0][0]                  \n",
      "                                                                   concatenate_113[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_276 (Lambda)              (20, 8, 4, 928)       0           input_200[0][0]                  \n",
      "                                                                   concatenate_113[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_277 (Lambda)              (20, 8, 4, 928)       0           input_201[0][0]                  \n",
      "                                                                   concatenate_113[2][0]            \n",
      "____________________________________________________________________________________________________\n",
      "input_202 (InputLayer)           (928,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchNo (20, 8, 4, 928)       3712        lambda_275[1][0]                 \n",
      "                                                                   lambda_276[1][0]                 \n",
      "                                                                   lambda_277[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_203 (InputLayer)           (928,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_204 (InputLayer)           (928,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_278 (Lambda)              (20, 8, 4, 928)       0           input_202[0][0]                  \n",
      "                                                                   batch_normalization_149[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_279 (Lambda)              (20, 8, 4, 928)       0           input_203[0][0]                  \n",
      "                                                                   batch_normalization_149[1][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_280 (Lambda)              (20, 8, 4, 928)       0           input_204[0][0]                  \n",
      "                                                                   batch_normalization_149[2][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_237 (Activation)      (20, 8, 4, 928)       0           lambda_278[1][0]                 \n",
      "                                                                   lambda_279[1][0]                 \n",
      "                                                                   lambda_280[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_281 (Lambda)              (20, 8, 4, 928)       0           activation_237[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_282 (Lambda)              (20, 8, 4, 928)       0           activation_237[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_283 (Lambda)              (20, 8, 4, 928)       0           activation_237[2][0]             \n",
      "____________________________________________________________________________________________________\n",
      "input_205 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_235 (Conv2D)              (20, 8, 4, 128)       118784      lambda_281[0][0]                 \n",
      "                                                                   lambda_282[0][0]                 \n",
      "                                                                   lambda_283[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_206 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_207 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_284 (Lambda)              (20, 8, 4, 128)       0           input_205[0][0]                  \n",
      "                                                                   conv2d_235[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_285 (Lambda)              (20, 8, 4, 128)       0           input_206[0][0]                  \n",
      "                                                                   conv2d_235[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_286 (Lambda)              (20, 8, 4, 128)       0           input_207[0][0]                  \n",
      "                                                                   conv2d_235[2][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_208 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchNo (20, 8, 4, 128)       512         lambda_284[1][0]                 \n",
      "                                                                   lambda_285[1][0]                 \n",
      "                                                                   lambda_286[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_209 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_210 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_287 (Lambda)              (20, 8, 4, 128)       0           input_208[0][0]                  \n",
      "                                                                   batch_normalization_150[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_288 (Lambda)              (20, 8, 4, 128)       0           input_209[0][0]                  \n",
      "                                                                   batch_normalization_150[1][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_289 (Lambda)              (20, 8, 4, 128)       0           input_210[0][0]                  \n",
      "                                                                   batch_normalization_150[2][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_238 (Activation)      (20, 8, 4, 128)       0           lambda_287[1][0]                 \n",
      "                                                                   lambda_288[1][0]                 \n",
      "                                                                   lambda_289[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_290 (Lambda)              (20, 8, 4, 128)       0           activation_238[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_291 (Lambda)              (20, 8, 4, 128)       0           activation_238[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_292 (Lambda)              (20, 8, 4, 128)       0           activation_238[2][0]             \n",
      "____________________________________________________________________________________________________\n",
      "input_211 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_236 (Conv2D)              (20, 8, 4, 32)        36864       lambda_290[0][0]                 \n",
      "                                                                   lambda_291[0][0]                 \n",
      "                                                                   lambda_292[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_212 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_213 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_293 (Lambda)              (20, 8, 4, 32)        0           input_211[0][0]                  \n",
      "                                                                   conv2d_236[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_294 (Lambda)              (20, 8, 4, 32)        0           input_212[0][0]                  \n",
      "                                                                   conv2d_236[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_295 (Lambda)              (20, 8, 4, 32)        0           input_213[0][0]                  \n",
      "                                                                   conv2d_236[2][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_114 (Concatenate)    (20, 8, 4, 960)       0           concatenate_113[0][0]            \n",
      "                                                                   lambda_293[1][0]                 \n",
      "                                                                   concatenate_113[1][0]            \n",
      "                                                                   lambda_294[1][0]                 \n",
      "                                                                   concatenate_113[2][0]            \n",
      "                                                                   lambda_295[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_214 (InputLayer)           (960,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_215 (InputLayer)           (960,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_216 (InputLayer)           (960,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_296 (Lambda)              (20, 8, 4, 960)       0           input_214[0][0]                  \n",
      "                                                                   concatenate_114[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_297 (Lambda)              (20, 8, 4, 960)       0           input_215[0][0]                  \n",
      "                                                                   concatenate_114[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_298 (Lambda)              (20, 8, 4, 960)       0           input_216[0][0]                  \n",
      "                                                                   concatenate_114[2][0]            \n",
      "____________________________________________________________________________________________________\n",
      "input_217 (InputLayer)           (960,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchNo (20, 8, 4, 960)       3840        lambda_296[1][0]                 \n",
      "                                                                   lambda_297[1][0]                 \n",
      "                                                                   lambda_298[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_218 (InputLayer)           (960,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_219 (InputLayer)           (960,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_299 (Lambda)              (20, 8, 4, 960)       0           input_217[0][0]                  \n",
      "                                                                   batch_normalization_151[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_300 (Lambda)              (20, 8, 4, 960)       0           input_218[0][0]                  \n",
      "                                                                   batch_normalization_151[1][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_301 (Lambda)              (20, 8, 4, 960)       0           input_219[0][0]                  \n",
      "                                                                   batch_normalization_151[2][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_239 (Activation)      (20, 8, 4, 960)       0           lambda_299[1][0]                 \n",
      "                                                                   lambda_300[1][0]                 \n",
      "                                                                   lambda_301[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_302 (Lambda)              (20, 8, 4, 960)       0           activation_239[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_303 (Lambda)              (20, 8, 4, 960)       0           activation_239[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_304 (Lambda)              (20, 8, 4, 960)       0           activation_239[2][0]             \n",
      "____________________________________________________________________________________________________\n",
      "input_220 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_237 (Conv2D)              (20, 8, 4, 128)       122880      lambda_302[0][0]                 \n",
      "                                                                   lambda_303[0][0]                 \n",
      "                                                                   lambda_304[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_221 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_222 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_305 (Lambda)              (20, 8, 4, 128)       0           input_220[0][0]                  \n",
      "                                                                   conv2d_237[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_306 (Lambda)              (20, 8, 4, 128)       0           input_221[0][0]                  \n",
      "                                                                   conv2d_237[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_307 (Lambda)              (20, 8, 4, 128)       0           input_222[0][0]                  \n",
      "                                                                   conv2d_237[2][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_223 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchNo (20, 8, 4, 128)       512         lambda_305[1][0]                 \n",
      "                                                                   lambda_306[1][0]                 \n",
      "                                                                   lambda_307[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_224 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_225 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_308 (Lambda)              (20, 8, 4, 128)       0           input_223[0][0]                  \n",
      "                                                                   batch_normalization_152[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_309 (Lambda)              (20, 8, 4, 128)       0           input_224[0][0]                  \n",
      "                                                                   batch_normalization_152[1][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_310 (Lambda)              (20, 8, 4, 128)       0           input_225[0][0]                  \n",
      "                                                                   batch_normalization_152[2][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_240 (Activation)      (20, 8, 4, 128)       0           lambda_308[1][0]                 \n",
      "                                                                   lambda_309[1][0]                 \n",
      "                                                                   lambda_310[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_311 (Lambda)              (20, 8, 4, 128)       0           activation_240[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_312 (Lambda)              (20, 8, 4, 128)       0           activation_240[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_313 (Lambda)              (20, 8, 4, 128)       0           activation_240[2][0]             \n",
      "____________________________________________________________________________________________________\n",
      "input_226 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_238 (Conv2D)              (20, 8, 4, 32)        36864       lambda_311[0][0]                 \n",
      "                                                                   lambda_312[0][0]                 \n",
      "                                                                   lambda_313[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_227 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_228 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_314 (Lambda)              (20, 8, 4, 32)        0           input_226[0][0]                  \n",
      "                                                                   conv2d_238[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_315 (Lambda)              (20, 8, 4, 32)        0           input_227[0][0]                  \n",
      "                                                                   conv2d_238[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_316 (Lambda)              (20, 8, 4, 32)        0           input_228[0][0]                  \n",
      "                                                                   conv2d_238[2][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_115 (Concatenate)    (20, 8, 4, 992)       0           concatenate_114[0][0]            \n",
      "                                                                   lambda_314[1][0]                 \n",
      "                                                                   concatenate_114[1][0]            \n",
      "                                                                   lambda_315[1][0]                 \n",
      "                                                                   concatenate_114[2][0]            \n",
      "                                                                   lambda_316[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_229 (InputLayer)           (992,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_230 (InputLayer)           (992,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_231 (InputLayer)           (992,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_317 (Lambda)              (20, 8, 4, 992)       0           input_229[0][0]                  \n",
      "                                                                   concatenate_115[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_318 (Lambda)              (20, 8, 4, 992)       0           input_230[0][0]                  \n",
      "                                                                   concatenate_115[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_319 (Lambda)              (20, 8, 4, 992)       0           input_231[0][0]                  \n",
      "                                                                   concatenate_115[2][0]            \n",
      "____________________________________________________________________________________________________\n",
      "input_232 (InputLayer)           (992,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchNo (20, 8, 4, 992)       3968        lambda_317[1][0]                 \n",
      "                                                                   lambda_318[1][0]                 \n",
      "                                                                   lambda_319[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_233 (InputLayer)           (992,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_234 (InputLayer)           (992,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_320 (Lambda)              (20, 8, 4, 992)       0           input_232[0][0]                  \n",
      "                                                                   batch_normalization_153[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_321 (Lambda)              (20, 8, 4, 992)       0           input_233[0][0]                  \n",
      "                                                                   batch_normalization_153[1][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_322 (Lambda)              (20, 8, 4, 992)       0           input_234[0][0]                  \n",
      "                                                                   batch_normalization_153[2][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_241 (Activation)      (20, 8, 4, 992)       0           lambda_320[1][0]                 \n",
      "                                                                   lambda_321[1][0]                 \n",
      "                                                                   lambda_322[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_323 (Lambda)              (20, 8, 4, 992)       0           activation_241[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_324 (Lambda)              (20, 8, 4, 992)       0           activation_241[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_325 (Lambda)              (20, 8, 4, 992)       0           activation_241[2][0]             \n",
      "____________________________________________________________________________________________________\n",
      "input_235 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_239 (Conv2D)              (20, 8, 4, 128)       126976      lambda_323[0][0]                 \n",
      "                                                                   lambda_324[0][0]                 \n",
      "                                                                   lambda_325[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_236 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_237 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_326 (Lambda)              (20, 8, 4, 128)       0           input_235[0][0]                  \n",
      "                                                                   conv2d_239[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_327 (Lambda)              (20, 8, 4, 128)       0           input_236[0][0]                  \n",
      "                                                                   conv2d_239[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_328 (Lambda)              (20, 8, 4, 128)       0           input_237[0][0]                  \n",
      "                                                                   conv2d_239[2][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_238 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchNo (20, 8, 4, 128)       512         lambda_326[1][0]                 \n",
      "                                                                   lambda_327[1][0]                 \n",
      "                                                                   lambda_328[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_239 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_240 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_329 (Lambda)              (20, 8, 4, 128)       0           input_238[0][0]                  \n",
      "                                                                   batch_normalization_154[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_330 (Lambda)              (20, 8, 4, 128)       0           input_239[0][0]                  \n",
      "                                                                   batch_normalization_154[1][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_331 (Lambda)              (20, 8, 4, 128)       0           input_240[0][0]                  \n",
      "                                                                   batch_normalization_154[2][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_242 (Activation)      (20, 8, 4, 128)       0           lambda_329[1][0]                 \n",
      "                                                                   lambda_330[1][0]                 \n",
      "                                                                   lambda_331[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_332 (Lambda)              (20, 8, 4, 128)       0           activation_242[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_333 (Lambda)              (20, 8, 4, 128)       0           activation_242[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_334 (Lambda)              (20, 8, 4, 128)       0           activation_242[2][0]             \n",
      "____________________________________________________________________________________________________\n",
      "input_241 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_240 (Conv2D)              (20, 8, 4, 32)        36864       lambda_332[0][0]                 \n",
      "                                                                   lambda_333[0][0]                 \n",
      "                                                                   lambda_334[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_242 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_243 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_335 (Lambda)              (20, 8, 4, 32)        0           input_241[0][0]                  \n",
      "                                                                   conv2d_240[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_336 (Lambda)              (20, 8, 4, 32)        0           input_242[0][0]                  \n",
      "                                                                   conv2d_240[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_337 (Lambda)              (20, 8, 4, 32)        0           input_243[0][0]                  \n",
      "                                                                   conv2d_240[2][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_244 (InputLayer)           (1024,)               0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_116 (Concatenate)    (20, 8, 4, 1024)      0           concatenate_115[0][0]            \n",
      "                                                                   lambda_335[1][0]                 \n",
      "                                                                   concatenate_115[1][0]            \n",
      "                                                                   lambda_336[1][0]                 \n",
      "                                                                   concatenate_115[2][0]            \n",
      "                                                                   lambda_337[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_245 (InputLayer)           (1024,)               0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_246 (InputLayer)           (1024,)               0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_338 (Lambda)              (20, 8, 4, 1024)      0           input_244[0][0]                  \n",
      "                                                                   concatenate_116[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_339 (Lambda)              (20, 8, 4, 1024)      0           input_245[0][0]                  \n",
      "                                                                   concatenate_116[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_340 (Lambda)              (20, 8, 4, 1024)      0           input_246[0][0]                  \n",
      "                                                                   concatenate_116[2][0]            \n",
      "____________________________________________________________________________________________________\n",
      "input_247 (InputLayer)           (1024,)               0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchNo (20, 8, 4, 1024)      4096        lambda_338[1][0]                 \n",
      "                                                                   lambda_339[1][0]                 \n",
      "                                                                   lambda_340[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_248 (InputLayer)           (1024,)               0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_249 (InputLayer)           (1024,)               0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_341 (Lambda)              (20, 8, 4, 1024)      0           input_247[0][0]                  \n",
      "                                                                   batch_normalization_155[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_342 (Lambda)              (20, 8, 4, 1024)      0           input_248[0][0]                  \n",
      "                                                                   batch_normalization_155[1][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_343 (Lambda)              (20, 8, 4, 1024)      0           input_249[0][0]                  \n",
      "                                                                   batch_normalization_155[2][0]    \n",
      "____________________________________________________________________________________________________\n",
      "input_250 (InputLayer)           (1024,)               0                                            \n",
      "____________________________________________________________________________________________________\n",
      "activation_243 (Activation)      (20, 8, 4, 1024)      0           lambda_341[1][0]                 \n",
      "                                                                   lambda_342[1][0]                 \n",
      "                                                                   lambda_343[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_251 (InputLayer)           (1024,)               0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_252 (InputLayer)           (1024,)               0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_344 (Lambda)              (20, 8, 4, 1024)      0           input_250[0][0]                  \n",
      "                                                                   activation_243[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_345 (Lambda)              (20, 8, 4, 1024)      0           input_251[0][0]                  \n",
      "                                                                   activation_243[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_346 (Lambda)              (20, 8, 4, 1024)      0           input_252[0][0]                  \n",
      "                                                                   activation_243[2][0]             \n",
      "____________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glob (20, 1024)            0           lambda_344[1][0]                 \n",
      "                                                                   lambda_345[1][0]                 \n",
      "                                                                   lambda_346[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_347 (Lambda)              (20, 1024)            0           global_average_pooling2d_2[0][0] \n",
      "____________________________________________________________________________________________________\n",
      "lambda_348 (Lambda)              (20, 1024)            0           global_average_pooling2d_2[1][0] \n",
      "____________________________________________________________________________________________________\n",
      "lambda_349 (Lambda)              (20, 1024)            0           global_average_pooling2d_2[2][0] \n",
      "____________________________________________________________________________________________________\n",
      "input_253 (InputLayer)           (1024,)               0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (20, 1024)            1049600     lambda_347[0][0]                 \n",
      "                                                                   lambda_348[0][0]                 \n",
      "                                                                   lambda_349[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_254 (InputLayer)           (1024,)               0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_255 (InputLayer)           (1024,)               0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_350 (Lambda)              (20, 1024)            0           input_253[0][0]                  \n",
      "                                                                   dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_351 (Lambda)              (20, 1024)            0           input_254[0][0]                  \n",
      "                                                                   dense_3[1][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_352 (Lambda)              (20, 1024)            0           input_255[0][0]                  \n",
      "                                                                   dense_3[2][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "input_256 (InputLayer)           (1024,)               0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchNo (20, 1024)            4096        lambda_350[1][0]                 \n",
      "                                                                   lambda_351[1][0]                 \n",
      "                                                                   lambda_352[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_257 (InputLayer)           (1024,)               0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_258 (InputLayer)           (1024,)               0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_353 (Lambda)              (20, 1024)            0           input_256[0][0]                  \n",
      "                                                                   batch_normalization_156[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_354 (Lambda)              (20, 1024)            0           input_257[0][0]                  \n",
      "                                                                   batch_normalization_156[1][0]    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_355 (Lambda)              (20, 1024)            0           input_258[0][0]                  \n",
      "                                                                   batch_normalization_156[2][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_244 (Activation)      (20, 1024)            0           lambda_353[1][0]                 \n",
      "                                                                   lambda_354[1][0]                 \n",
      "                                                                   lambda_355[1][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_356 (Lambda)              (20, 1024)            0           activation_244[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_357 (Lambda)              (20, 1024)            0           activation_244[1][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_358 (Lambda)              (20, 1024)            0           activation_244[2][0]             \n",
      "____________________________________________________________________________________________________\n",
      "input_259 (InputLayer)           (2560, 2)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_260 (InputLayer)           (1,)                  0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (20, 384)             393600      lambda_356[0][0]                 \n",
      "                                                                   lambda_357[0][0]                 \n",
      "                                                                   lambda_358[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_261 (InputLayer)           (2560, 2)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_262 (InputLayer)           (1,)                  0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_263 (InputLayer)           (2560, 2)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_264 (InputLayer)           (1,)                  0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_359 (Lambda)              (None, None)          0           input_259[0][0]                  \n",
      "                                                                   input_260[0][0]                  \n",
      "                                                                   dense_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_360 (Lambda)              (None, None)          0           input_261[0][0]                  \n",
      "                                                                   input_262[0][0]                  \n",
      "                                                                   dense_4[1][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_361 (Lambda)              (None, None)          0           input_263[0][0]                  \n",
      "                                                                   input_264[0][0]                  \n",
      "                                                                   dense_4[2][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_175 (Concatenate)    (None, None)          0           lambda_359[1][0]                 \n",
      "                                                                   lambda_360[1][0]                 \n",
      "                                                                   lambda_361[1][0]                 \n",
      "====================================================================================================\n",
      "Total params: 8,484,800\n",
      "Trainable params: 8,399,104\n",
      "Non-trainable params: 85,696\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "era, 1\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 75s - loss: 1016.6488    \n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 68s - loss: 495.8817    \n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 69s - loss: 351.3887    \n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 69s - loss: 305.9168    \n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 69s - loss: 270.7308    \n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 69s - loss: 261.5215    \n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 69s - loss: 191.7627    \n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 69s - loss: 188.9929    \n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 69s - loss: 182.7648    \n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 69s - loss: 176.4164    \n",
      "1000 34.5601818562\n",
      "2000 65.855932951\n",
      "3000 97.1457998753\n",
      "4000 128.450387955\n",
      "5000 159.742989063\n",
      "6000 191.004456997\n",
      "7000 222.208064079\n",
      "8000 253.41012907\n",
      "9000 284.601912975\n",
      "10000 315.799607038\n",
      "11000 347.154917955\n",
      "12000 378.343257904\n",
      "13000 409.557893991\n",
      "14000 440.711780071\n",
      "15000 471.880003929\n",
      "1000 31.1683690548\n",
      "2000 62.3255541325\n",
      "3000 93.4875011444\n",
      "metric time: 231.228942\n",
      "{'mAP': 0.28820000000000001, 'rank': {'r5': 0.7271, 'r1': 0.4955}, 'loss': [1016.6488415527343, 495.88166463851928, 351.38873281717298, 305.91677303314208, 270.73082312583921, 261.52151771545408, 191.76270014435053, 188.9929261803627, 182.76479943364859, 176.41637956500054]}\n",
      "era, 2\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 69s - loss: 201.9536    \n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 69s - loss: 168.5292    \n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 69s - loss: 126.9429    \n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 69s - loss: 171.2088    \n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 69s - loss: 148.8655    \n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 69s - loss: 149.2430    \n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 69s - loss: 110.5360    \n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 69s - loss: 130.3866    \n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 69s - loss: 125.8909    \n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 69s - loss: 109.9785    \n",
      "1000 31.39184618\n",
      "2000 62.6458339691\n",
      "3000 93.8881900311\n",
      "4000 125.165140152\n",
      "5000 156.433272123\n",
      "6000 187.705049038\n",
      "7000 218.954575062\n",
      "8000 250.204694033\n",
      "9000 281.483335018\n",
      "10000 312.774678946\n",
      "11000 344.019335032\n",
      "12000 375.295236111\n",
      "13000 406.579297066\n",
      "14000 437.827049971\n",
      "15000 469.091447115\n",
      "1000 31.2129631042\n",
      "2000 62.3947761059\n",
      "3000 93.587747097\n",
      "metric time: 238.494437\n",
      "{'mAP': 0.31569999999999998, 'rank': {'r5': 0.7473, 'r1': 0.5276}, 'loss': [201.95361296385528, 168.52915050446987, 126.94293122023345, 171.20876811385153, 148.8654536652565, 149.24301549077035, 110.53603186041117, 130.38660056591033, 125.89087610244751, 109.97851720660925]}\n",
      "era, 3\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 69s - loss: 124.9622    \n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 69s - loss: 105.6151    \n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 69s - loss: 111.8239    \n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 69s - loss: 113.4117    \n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 69s - loss: 116.1575    \n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 69s - loss: 124.7033    \n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 69s - loss: 107.8456    \n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 69s - loss: 93.5082    \n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 69s - loss: 122.4260    \n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 69s - loss: 123.4987    \n",
      "1000 31.3501279354\n",
      "2000 62.6268548965\n",
      "3000 93.8886520863\n",
      "4000 125.145006895\n",
      "5000 156.406224012\n",
      "6000 187.69117403\n",
      "7000 219.08197093\n",
      "8000 250.313441038\n",
      "9000 281.55656004\n",
      "10000 312.805517912\n",
      "11000 344.042002916\n",
      "12000 375.275513887\n",
      "13000 406.510456085\n",
      "14000 437.750313044\n",
      "15000 468.993861914\n",
      "1000 31.6669139862\n",
      "2000 62.9547448158\n",
      "3000 94.2698738575\n",
      "metric time: 240.173653\n",
      "{'mAP': 0.3664, 'rank': {'r5': 0.7841, 'r1': 0.5748}, 'loss': [124.96224213123321, 105.61511815309524, 111.82388550251723, 113.41166938215494, 116.15753116607667, 124.7033106815815, 107.84555785655975, 93.50820706665516, 122.42597412377596, 123.49869455039502]}\n",
      "era, 4\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 69s - loss: 119.6461    \n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 68s - loss: 121.8069    \n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 69s - loss: 99.5228    \n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 68s - loss: 126.2300    \n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 68s - loss: 102.8869    \n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 69s - loss: 89.6655    \n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 69s - loss: 110.7794    \n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 69s - loss: 84.8948    \n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 69s - loss: 106.9458    \n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 69s - loss: 95.1763    \n",
      "1000 31.5135171413\n",
      "2000 62.7517709732\n",
      "3000 94.002259016\n",
      "4000 125.228346109\n",
      "5000 156.431766987\n",
      "6000 187.637128115\n",
      "7000 218.862458944\n",
      "8000 250.103553057\n",
      "9000 281.350331068\n",
      "10000 312.550625086\n",
      "11000 343.770689011\n",
      "12000 374.976042986\n",
      "13000 406.172145128\n",
      "14000 437.395868063\n",
      "15000 468.597146034\n",
      "1000 31.5036180019\n",
      "2000 62.9535689354\n",
      "3000 94.3856449127\n",
      "metric time: 240.043553\n",
      "{'mAP': 0.38940000000000002, 'rank': {'r5': 0.8002, 'r1': 0.5861}, 'loss': [119.64611303895713, 121.80694186478853, 99.52276021778583, 126.2300138220191, 102.88691075086594, 89.665470982491968, 110.77943790555, 84.894841598868368, 106.94575349062681, 95.176275430917741]}\n",
      "era, 5\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 68s - loss: 103.2110    \n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 69s - loss: 104.6836    \n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 69s - loss: 119.2880    \n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 69s - loss: 61.3824    \n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 69s - loss: 76.0892    \n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 69s - loss: 118.2095    \n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 69s - loss: 81.6244    \n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 69s - loss: 93.3838    \n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 69s - loss: 83.0625    \n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 69s - loss: 64.0221    \n",
      "1000 31.3385717869\n",
      "2000 62.5616149902\n",
      "3000 94.234254837\n",
      "4000 125.528512001\n",
      "5000 156.802236795\n",
      "6000 188.082432985\n",
      "7000 219.379310846\n",
      "8000 250.675193787\n",
      "9000 281.919060946\n",
      "10000 313.100907803\n",
      "11000 344.301129818\n",
      "12000 375.486120939\n",
      "13000 406.668452978\n",
      "14000 437.846956968\n",
      "15000 469.042248964\n",
      "1000 31.1995429993\n",
      "2000 62.381362915\n",
      "3000 93.5756211281\n",
      "metric time: 237.936333\n",
      "{'mAP': 0.40029999999999999, 'rank': {'r5': 0.8144, 'r1': 0.5986}, 'loss': [103.21103845626116, 104.68360330611468, 119.28801400601864, 61.382369202971461, 76.089238220155238, 118.20950135856867, 81.624436921775342, 93.383791958093639, 83.062479630112648, 64.022055198252204]}\n",
      "era, 6\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 68s - loss: 73.9954    \n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 69s - loss: 36.7925    \n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 69s - loss: 29.8053    \n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 69s - loss: 37.8814    \n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 69s - loss: 48.7745    \n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 69s - loss: 42.1479    \n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 69s - loss: 36.4410    \n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 69s - loss: 24.3745    \n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 69s - loss: 37.4603    \n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 69s - loss: 21.8192    \n",
      "1000 31.2544701099\n",
      "2000 62.9160659313\n",
      "3000 94.1766929626\n",
      "4000 125.428523064\n",
      "5000 156.697523117\n",
      "6000 188.002146959\n",
      "7000 219.199644089\n",
      "8000 250.397339106\n",
      "9000 281.57319808\n",
      "10000 312.739535093\n",
      "11000 343.906424046\n",
      "12000 375.110922098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13000 406.280687094\n",
      "14000 437.44809103\n",
      "15000 468.633734941\n",
      "1000 31.1743788719\n",
      "2000 62.3441858292\n",
      "3000 93.5153059959\n",
      "metric time: 239.779408\n",
      "{'mAP': 0.47149999999999997, 'rank': {'r5': 0.8542, 'r1': 0.6648}, 'loss': [73.995423495769501, 36.792479295730594, 29.805337127745151, 37.881418126225469, 48.774545888304708, 42.147914637923243, 36.440951166450979, 24.374492235183716, 37.460305206775665, 21.819207957386972]}\n",
      "era, 7\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 68s - loss: 28.9805    \n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 68s - loss: 25.9667    \n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 69s - loss: 23.8568    \n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 69s - loss: 23.5070    \n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 69s - loss: 21.0571    \n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 70s - loss: 17.7867    \n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 69s - loss: 28.6957    \n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 69s - loss: 22.1043    \n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 69s - loss: 21.8387    \n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 69s - loss: 15.4658    \n",
      "1000 31.6381649971\n",
      "2000 62.9345920086\n",
      "3000 94.2174680233\n",
      "4000 125.381630898\n",
      "5000 156.620079994\n",
      "6000 187.973684072\n",
      "7000 219.11275506\n",
      "8000 250.239423037\n",
      "9000 281.408869982\n",
      "10000 312.549570084\n",
      "11000 343.683051109\n",
      "12000 374.818237066\n",
      "13000 405.985282898\n",
      "14000 437.129421949\n",
      "15000 468.254097939\n",
      "1000 31.2006940842\n",
      "2000 62.3821132183\n",
      "3000 93.5700640678\n",
      "metric time: 238.320884\n",
      "{'mAP': 0.51170000000000004, 'rank': {'r5': 0.8741, 'r1': 0.7114}, 'loss': [28.980504613220692, 25.966660374104976, 23.856830355823039, 23.50703762859106, 21.05714834243059, 17.786742664277554, 28.695658814907073, 22.104316873550417, 21.838677775561809, 15.465789198577404]}\n",
      "era, 8\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 69s - loss: 20.1135    \n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 69s - loss: 19.2868    \n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 69s - loss: 14.6140    \n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 69s - loss: 14.8839    \n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 69s - loss: 14.2520    \n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 69s - loss: 15.5404    \n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 69s - loss: 12.4186    \n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 69s - loss: 17.2444    \n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 69s - loss: 5.8451    \n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 69s - loss: 13.1243    \n",
      "1000 31.3894100189\n",
      "2000 62.6764149666\n",
      "3000 93.9219119549\n",
      "4000 125.15662694\n",
      "5000 156.382520914\n",
      "6000 187.655894995\n",
      "7000 218.899544954\n",
      "8000 250.134995937\n",
      "9000 281.384472847\n",
      "10000 312.666301966\n",
      "11000 343.92727685\n",
      "12000 375.173950911\n",
      "13000 406.443430901\n",
      "14000 437.692653894\n",
      "15000 469.038835049\n",
      "1000 31.2602789402\n",
      "2000 62.5349538326\n",
      "3000 93.7894020081\n",
      "metric time: 239.260682\n",
      "{'mAP': 0.52659999999999996, 'rank': {'r5': 0.8729, 'r1': 0.7162}, 'loss': [20.113545983731747, 19.286769683063032, 14.614029074609279, 14.883904176056385, 14.251980192363263, 15.540364079475403, 12.418572627007961, 17.244378107488156, 5.8451214766502382, 13.124263833761216]}\n",
      "era, 9\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 69s - loss: 15.8055    \n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 69s - loss: 19.6036    \n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 69s - loss: 21.8668    \n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 69s - loss: 13.9654    \n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 69s - loss: 11.1127    \n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 69s - loss: 13.3629    \n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 69s - loss: 16.1202    \n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 69s - loss: 7.5329    \n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 69s - loss: 11.3220    \n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 69s - loss: 13.9064    \n",
      "1000 31.2799618244\n",
      "2000 62.5760998726\n",
      "3000 93.8791809082\n",
      "4000 125.156502008\n",
      "5000 156.440779924\n",
      "6000 187.71794486\n",
      "7000 218.911523819\n",
      "8000 250.083840847\n",
      "9000 281.267664909\n",
      "10000 312.459159851\n",
      "11000 343.661003828\n",
      "12000 374.857228041\n",
      "13000 406.054625034\n",
      "14000 437.250249863\n",
      "15000 468.440788984\n",
      "1000 31.1823570728\n",
      "2000 62.3717160225\n",
      "3000 93.5675940514\n",
      "metric time: 238.240039\n",
      "{'mAP': 0.54510000000000003, 'rank': {'r5': 0.8887, 'r1': 0.7248}, 'loss': [15.805482968389988, 19.603594321608544, 21.866814306080343, 13.965420866310597, 11.112684823274613, 13.362906522154809, 16.120154796838762, 7.532948814928532, 11.322017370164394, 13.906370911300183]}\n",
      "era, 10\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 69s - loss: 14.7097    \n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 69s - loss: 9.4364    \n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 69s - loss: 14.1403    \n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 69s - loss: 8.8904    \n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 69s - loss: 16.2949    \n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 69s - loss: 12.8317    \n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 69s - loss: 7.4768    \n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 69s - loss: 11.8446    \n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 69s - loss: 10.8754    \n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 69s - loss: 12.2700    \n",
      "1000 31.2868430614\n",
      "2000 62.5644040108\n",
      "3000 93.7989220619\n",
      "4000 125.037514925\n",
      "5000 156.265901089\n",
      "6000 187.514328003\n",
      "7000 218.74747014\n",
      "8000 250.014183998\n",
      "9000 281.26266098\n",
      "10000 312.504359007\n",
      "11000 343.787374973\n",
      "12000 375.063774109\n",
      "13000 406.313976049\n",
      "14000 437.564381123\n",
      "15000 468.823966026\n",
      "1000 31.2522661686\n",
      "2000 62.4983251095\n",
      "3000 93.77333498\n",
      "metric time: 239.141030\n",
      "{'mAP': 0.55000000000000004, 'rank': {'r5': 0.8913, 'r1': 0.7301}, 'loss': [14.709733839333058, 9.4363932767510406, 14.140301865935326, 8.8903699120879178, 16.29488989830017, 12.831659160554409, 7.4768391746282576, 11.844572715461254, 10.875405928194523, 12.270047457516194]}\n",
      "era, 11\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 68s - loss: 8.6494    \n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 69s - loss: 10.2024    \n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 69s - loss: 10.9442   \n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 69s - loss: 8.4397    \n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 69s - loss: 8.7684    \n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 69s - loss: 4.7389    \n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 69s - loss: 14.1009    \n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 69s - loss: 12.4425    \n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 69s - loss: 8.8521    \n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 69s - loss: 4.8372    \n",
      "1000 31.3861789703\n",
      "2000 62.6452460289\n",
      "3000 93.9029989243\n",
      "4000 125.147417068\n",
      "5000 156.400152922\n",
      "6000 187.665125847\n",
      "7000 218.930111885\n",
      "8000 250.185540915\n",
      "9000 281.464513063\n",
      "10000 312.739872932\n",
      "11000 344.005614042\n",
      "12000 375.287395954\n",
      "13000 406.559921026\n",
      "14000 437.825746059\n",
      "15000 469.091141939\n",
      "1000 31.2677869797\n",
      "2000 62.529086113\n",
      "3000 93.7824189663\n",
      "metric time: 238.241243\n",
      "{'mAP': 0.55420000000000003, 'rank': {'r5': 0.8934, 'r1': 0.7334}, 'loss': [8.6494046404957778, 10.202444123029709, 10.944200631380081, 8.4396585485339166, 8.7683848080039031, 4.738875600099564, 14.100855468213558, 12.442547701597213, 8.8520965385437016, 4.8371853175759316]}\n",
      "era, 12\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 69s - loss: 11.7629    \n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 69s - loss: 8.5524    \n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 68s - loss: 3.5776    \n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 69s - loss: 7.7918    \n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 69s - loss: 9.4744    \n",
      "Epoch 6/10\n",
      " 81/100 [=======================>......] - ETA: 13s - loss: 7.0271"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-9d2c68b24ff4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m                          \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                          \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                          callbacks=[lrate,history])\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mergenet_fill_P5K4_reg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/albert/anaconda2/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/albert/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2040\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2041\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2042\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2044\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/albert/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1760\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1762\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/albert/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2272\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2273\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2274\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2275\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/albert/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/albert/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/albert/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/albert/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/albert/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = History()\n",
    "for era in range(1,16):\n",
    "    iterations = era * epochs * steps_per_epoch\n",
    "    lrate = LearningRateScheduler(training.step_decay_cont(epochs, era))\n",
    "\n",
    "    print 'era, ' + str(era)\n",
    "\n",
    "    model.fit_generator(data.batch_generator(train_dict, P=P_param, K=K_param,\n",
    "                            preprocess=True, shape=(256,128)),\n",
    "                         steps_per_epoch=steps_per_epoch,\n",
    "                         epochs=epochs,\n",
    "                         callbacks=[lrate,history])\n",
    "\n",
    "    path = training.save_weights(model, it=iterations, root='mergenet_fill_P5K4_reg')\n",
    "    model_eval.set_weights(model.get_weights())\n",
    "\n",
    "    print evaluation.get_score(model_eval, hist=history, inputs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
