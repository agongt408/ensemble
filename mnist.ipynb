{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.datasets.mnist as mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vbranch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 784\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_flat = X_train.reshape([-1, input_dim])\n",
    "X_test_flat = X_test.reshape([-1, input_dim])\n",
    "\n",
    "y_train_one_hot = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test_one_hot = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Wrapping all together -> Switch between train and test set using Initializable iterator\n",
    "EPOCHS = 10\n",
    "# create a placeholder to dynamically switch between batch sizes\n",
    "batch_size = tf.placeholder(tf.int64)\n",
    "x = tf.placeholder(tf.float32, shape=[None, input_dim])\n",
    "y = tf.placeholder(tf.float32, shape=[None, num_classes])\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "dataset = dataset.batch(batch_size).repeat().shuffle(buffer_size=400)\n",
    "\n",
    "data_iter = dataset.make_initializable_iterator()\n",
    "inputs, labels_one_hot = data_iter.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = vbranch.models.simple_fcnet(inputs, input_dim, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'fc1_w:0' shape=(784, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'fc1_b:0' shape=(10,) dtype=float32_ref>,\n",
       " <tf.Variable 'fc1_bn_scale:0' shape=(10,) dtype=float32_ref>,\n",
       " <tf.Variable 'fc1_bn_beta:0' shape=(10,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.nn.softmax_cross_entropy_with_logits_v2(labels=labels_one_hot, logits=outputs)\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "n_batches = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9582\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.0764\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.9730\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.9710\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.7177\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8479\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.8558\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9118\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.7203\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.7036\n",
      "Test Loss: 0.581682\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # initialise iterator with train data\n",
    "    sess.run(data_iter.initializer, feed_dict={x: X_train_flat, y: y_train_one_hot, \n",
    "                                               batch_size: BATCH_SIZE})\n",
    "    for e in range(EPOCHS):\n",
    "        print(\"Epoch {}/{}\".format(e + 1, n_batches))\n",
    "        progbar = tf.keras.utils.Progbar(n_batches)\n",
    "        ep_losses = []\n",
    "        for i in range(n_batches):\n",
    "            _, loss_value = sess.run([train_op, loss])\n",
    "            ep_losses.append(loss_value[0])\n",
    "            progbar.update(i + 1, values=[(\"loss\", np.mean(ep_losses)),])\n",
    "        \n",
    "    # initialise iterator with test data\n",
    "    sess.run(data_iter.initializer, feed_dict={ x: X_test_flat, y: y_test_one_hot, \n",
    "                                          batch_size: 1000})\n",
    "    test_loss = sess.run(loss)[0]\n",
    "    print('Test Loss: {:4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
