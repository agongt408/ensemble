{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Omnigot One-Shot with Virtual Branching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import cv2\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vbranch as vb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 1\n",
    "architecture = 'simple'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = vb.datasets.omniglot.load_generator('train')\n",
    "test_generator = vb.datasets.omniglot.load_generator('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = test_generator.next(4, 4, 4, flatten=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(batch[2, 3, 0].squeeze(), cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 90\n",
    "STEPS_PER_EPOCH = 100\n",
    "T_0 = 30\n",
    "\n",
    "NUM_BRANCHES = 3\n",
    "SHARED_FRAC = 0.5\n",
    "model_path = os.path.join('models', 'vb-omniglot-{}-B{:d}-S{:.2f}_{:d}'.format(architecture,\n",
    "    NUM_BRANCHES, SHARED_FRAC, model_id))\n",
    "\n",
    "A, P, K = 4, 8, 4 # triplet batch specs\n",
    "output_dim = 128\n",
    "input_dim = [None, 105, 105, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('./models'):\n",
    "    os.system('mkdir models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_gen(A, P, K):\n",
    "    def func():\n",
    "        while True:\n",
    "            batch = train_generator.next(A, P, K)\n",
    "            batch = batch.astype('float32')\n",
    "            yield batch\n",
    "    return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Placeholder for feeding test images\n",
    "x = tf.placeholder('float32', input_dim, name='x')\n",
    "batch_size = tf.placeholder('int64', name='batch_size')\n",
    "\n",
    "train_datasets = []\n",
    "test_datasets = []\n",
    "inputs = [None] * NUM_BRANCHES\n",
    "train_init_ops = []\n",
    "test_init_ops = []\n",
    "\n",
    "for i in range(NUM_BRANCHES):\n",
    "    train_datasets.append( tf.data.Dataset.from_generator(batch_gen(A, P, K), \n",
    "                                                          'float32', \n",
    "                                                          output_shapes=input_dim))\n",
    "\n",
    "    test_datasets.append(tf.data.Dataset.from_tensor_slices(x).batch(batch_size))\n",
    "    \n",
    "    iterator = tf.data.Iterator.from_structure('float32', input_dim)\n",
    "    inputs[i] = iterator.get_next(name='input_'+str(i+1))    \n",
    "\n",
    "    train_init_ops.append(iterator.make_initializer(train_datasets[i]))\n",
    "    test_init_ops.append(iterator.make_initializer(test_datasets[i], \n",
    "                                                name='test_init_op_'+str(i+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if architecture == 'simple':        \n",
    "    filters = [32, 64, 128, 256]\n",
    "    layers_spec = [([f]*NUM_BRANCHES, int(f*SHARED_FRAC)) for f in filters]\n",
    "\n",
    "    model = vb.vbranch_simple_cnn(inputs, (output_dim, 0), *layers_spec,\n",
    "        branches=NUM_BRANCHES, name='model_' + str(model_id))\n",
    "\n",
    "elif architecture == 'res':\n",
    "    model = vb.res_cnn(inputs, output_dim, 32, 64, 128, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i   Layer name         Output shape                          Num param  Inbound            \n",
      "-------------------------------------------------------------------------------------------\n",
      "    Input              [None,105,105,1]                                                    \n",
      "-------------------------------------------------------------------------------------------\n",
      "    Input              [None,105,105,1]                                                    \n",
      "-------------------------------------------------------------------------------------------\n",
      "    Input              [None,105,105,1]                                                    \n",
      "-------------------------------------------------------------------------------------------\n",
      "0   conv2d_1_1         [None,103,103,16] [None,103,103,16]   640        input              \n",
      "                       [None,103,103,16] [None,103,103,16]                                 \n",
      "                       [None,103,103,16] [None,103,103,16]                                 \n",
      "-------------------------------------------------------------------------------------------\n",
      "1   bn_1_1             [None,103,103,16] [None,103,103,16]   128        conv2d_1_1         \n",
      "                       [None,103,103,16] [None,103,103,16]                                 \n",
      "                       [None,103,103,16] [None,103,103,16]                                 \n",
      "-------------------------------------------------------------------------------------------\n",
      "2   relu_1_1           [None,103,103,16] [None,103,103,16]   0          bn_1_1             \n",
      "                       [None,103,103,16] [None,103,103,16]                                 \n",
      "                       [None,103,103,16] [None,103,103,16]                                 \n",
      "-------------------------------------------------------------------------------------------\n",
      "3   conv2d_1_2         [None,101,101,16] [None,101,101,16]   23200      relu_1_1           \n",
      "                       [None,101,101,16] [None,101,101,16]                                 \n",
      "                       [None,101,101,16] [None,101,101,16]                                 \n",
      "-------------------------------------------------------------------------------------------\n",
      "4   bn_1_2             [None,101,101,16] [None,101,101,16]   128        conv2d_1_2         \n",
      "                       [None,101,101,16] [None,101,101,16]                                 \n",
      "                       [None,101,101,16] [None,101,101,16]                                 \n",
      "-------------------------------------------------------------------------------------------\n",
      "5   relu_1_2           [None,101,101,16] [None,101,101,16]   0          bn_1_2             \n",
      "                       [None,101,101,16] [None,101,101,16]                                 \n",
      "                       [None,101,101,16] [None,101,101,16]                                 \n",
      "-------------------------------------------------------------------------------------------\n",
      "6   avg_pool2d_1       [None,50,50,16] [None,50,50,16]       0          relu_1_2           \n",
      "                       [None,50,50,16] [None,50,50,16]                                     \n",
      "                       [None,50,50,16] [None,50,50,16]                                     \n",
      "-------------------------------------------------------------------------------------------\n",
      "7   conv2d_2_1         [None,48,48,32] [None,48,48,32]       46400      avg_pool2d_1       \n",
      "                       [None,48,48,32] [None,48,48,32]                                     \n",
      "                       [None,48,48,32] [None,48,48,32]                                     \n",
      "-------------------------------------------------------------------------------------------\n",
      "8   bn_2_1             [None,48,48,32] [None,48,48,32]       256        conv2d_2_1         \n",
      "                       [None,48,48,32] [None,48,48,32]                                     \n",
      "                       [None,48,48,32] [None,48,48,32]                                     \n",
      "-------------------------------------------------------------------------------------------\n",
      "9   relu_2_1           [None,48,48,32] [None,48,48,32]       0          bn_2_1             \n",
      "                       [None,48,48,32] [None,48,48,32]                                     \n",
      "                       [None,48,48,32] [None,48,48,32]                                     \n",
      "-------------------------------------------------------------------------------------------\n",
      "10  conv2d_2_2         [None,46,46,32] [None,46,46,32]       92480      relu_2_1           \n",
      "                       [None,46,46,32] [None,46,46,32]                                     \n",
      "                       [None,46,46,32] [None,46,46,32]                                     \n",
      "-------------------------------------------------------------------------------------------\n",
      "11  bn_2_2             [None,46,46,32] [None,46,46,32]       256        conv2d_2_2         \n",
      "                       [None,46,46,32] [None,46,46,32]                                     \n",
      "                       [None,46,46,32] [None,46,46,32]                                     \n",
      "-------------------------------------------------------------------------------------------\n",
      "12  relu_2_2           [None,46,46,32] [None,46,46,32]       0          bn_2_2             \n",
      "                       [None,46,46,32] [None,46,46,32]                                     \n",
      "                       [None,46,46,32] [None,46,46,32]                                     \n",
      "-------------------------------------------------------------------------------------------\n",
      "13  avg_pool2d_2       [None,23,23,32] [None,23,23,32]       0          relu_2_2           \n",
      "                       [None,23,23,32] [None,23,23,32]                                     \n",
      "                       [None,23,23,32] [None,23,23,32]                                     \n",
      "-------------------------------------------------------------------------------------------\n",
      "14  conv2d_3_1         [None,21,21,64] [None,21,21,64]       184960     avg_pool2d_2       \n",
      "                       [None,21,21,64] [None,21,21,64]                                     \n",
      "                       [None,21,21,64] [None,21,21,64]                                     \n",
      "-------------------------------------------------------------------------------------------\n",
      "15  bn_3_1             [None,21,21,64] [None,21,21,64]       512        conv2d_3_1         \n",
      "                       [None,21,21,64] [None,21,21,64]                                     \n",
      "                       [None,21,21,64] [None,21,21,64]                                     \n",
      "-------------------------------------------------------------------------------------------\n",
      "16  relu_3_1           [None,21,21,64] [None,21,21,64]       0          bn_3_1             \n",
      "                       [None,21,21,64] [None,21,21,64]                                     \n",
      "                       [None,21,21,64] [None,21,21,64]                                     \n",
      "-------------------------------------------------------------------------------------------\n",
      "17  conv2d_3_2         [None,19,19,64] [None,19,19,64]       369280     relu_3_1           \n",
      "                       [None,19,19,64] [None,19,19,64]                                     \n",
      "                       [None,19,19,64] [None,19,19,64]                                     \n",
      "-------------------------------------------------------------------------------------------\n",
      "18  bn_3_2             [None,19,19,64] [None,19,19,64]       512        conv2d_3_2         \n",
      "                       [None,19,19,64] [None,19,19,64]                                     \n",
      "                       [None,19,19,64] [None,19,19,64]                                     \n",
      "-------------------------------------------------------------------------------------------\n",
      "19  relu_3_2           [None,19,19,64] [None,19,19,64]       0          bn_3_2             \n",
      "                       [None,19,19,64] [None,19,19,64]                                     \n",
      "                       [None,19,19,64] [None,19,19,64]                                     \n",
      "-------------------------------------------------------------------------------------------\n",
      "20  avg_pool2d_3       [None,9,9,64] [None,9,9,64]           0          relu_3_2           \n",
      "                       [None,9,9,64] [None,9,9,64]                                         \n",
      "                       [None,9,9,64] [None,9,9,64]                                         \n",
      "-------------------------------------------------------------------------------------------\n",
      "21  conv2d_4_1         [None,7,7,128] [None,7,7,128]         738560     avg_pool2d_3       \n",
      "                       [None,7,7,128] [None,7,7,128]                                       \n",
      "                       [None,7,7,128] [None,7,7,128]                                       \n",
      "-------------------------------------------------------------------------------------------\n",
      "22  bn_4_1             [None,7,7,128] [None,7,7,128]         1024       conv2d_4_1         \n",
      "                       [None,7,7,128] [None,7,7,128]                                       \n",
      "                       [None,7,7,128] [None,7,7,128]                                       \n",
      "-------------------------------------------------------------------------------------------\n",
      "23  relu_4_1           [None,7,7,128] [None,7,7,128]         0          bn_4_1             \n",
      "                       [None,7,7,128] [None,7,7,128]                                       \n",
      "                       [None,7,7,128] [None,7,7,128]                                       \n",
      "-------------------------------------------------------------------------------------------\n",
      "24  conv2d_4_2         [None,5,5,128] [None,5,5,128]         1475840    relu_4_1           \n",
      "                       [None,5,5,128] [None,5,5,128]                                       \n",
      "                       [None,5,5,128] [None,5,5,128]                                       \n",
      "-------------------------------------------------------------------------------------------\n",
      "25  bn_4_2             [None,5,5,128] [None,5,5,128]         1024       conv2d_4_2         \n",
      "                       [None,5,5,128] [None,5,5,128]                                       \n",
      "                       [None,5,5,128] [None,5,5,128]                                       \n",
      "-------------------------------------------------------------------------------------------\n",
      "26  relu_4_2           [None,5,5,128] [None,5,5,128]         0          bn_4_2             \n",
      "                       [None,5,5,128] [None,5,5,128]                                       \n",
      "                       [None,5,5,128] [None,5,5,128]                                       \n",
      "-------------------------------------------------------------------------------------------\n",
      "27  global_avg_pool2d  [None,128] [None,128]                 0          relu_4_2           \n",
      "                       [None,128] [None,128]                                               \n",
      "                       [None,128] [None,128]                                               \n",
      "-------------------------------------------------------------------------------------------\n",
      "28  fc1                [None,128] [None,128]                 165120     global_avg_pool2d  \n",
      "                       [None,128] [None,128]                                               \n",
      "                       [None,128] [None,128]                                               \n",
      "-------------------------------------------------------------------------------------------\n",
      "29  bn_fc1             [None,128] [None,128]                 1024       fc1                \n",
      "                       [None,128] [None,128]                                               \n",
      "                       [None,128] [None,128]                                               \n",
      "-------------------------------------------------------------------------------------------\n",
      "30  relu_fc1           [None,128] [None,128]                 0          bn_fc1             \n",
      "                       [None,128] [None,128]                                               \n",
      "                       [None,128] [None,128]                                               \n",
      "-------------------------------------------------------------------------------------------\n",
      "31  output             [None,128]                            98688      relu_fc1           \n",
      "                       [None,128]                                                          \n",
      "                       [None,128]                                                          \n",
      "-------------------------------------------------------------------------------------------\n",
      "Total parameters: 3200032\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_exp_decay_scheduler(init_lr, t0, t1, decay):\n",
    "    \"\"\"NOTE: `episode` starts from 1\"\"\"\n",
    "    def func(episode):\n",
    "        if episode < t0:\n",
    "            return init_lr\n",
    "        lr = init_lr * np.power(decay, (episode - t0) / (t1 - t0))\n",
    "        return lr\n",
    "    return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_scheduler = lr_exp_decay_scheduler(0.001, T_0, EPOCHS, 0.001)\n",
    "lr_steps = [lr_scheduler(e + 1) for e in range(EPOCHS)]\n",
    "plt.plot(lr_steps)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = tf.placeholder('float32', name='lr')\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer, 'triplet_omniglot', A=A, P=P, K=K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'model_1/model_1/output_vb1:0' shape=(?, 128) dtype=float32>, <tf.Tensor 'model_1/model_1/output_vb2:0' shape=(?, 128) dtype=float32>, <tf.Tensor 'model_1/model_1/output_vb3:0' shape=(?, 128) dtype=float32>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90\n",
      "100/100 [==============================] - 180s 2s/step - loss_1: 237.6685 - loss_2: 235.0316 - loss_3: 253.3819 - lr: 0.0010\n",
      "Epoch 2/90\n",
      "100/100 [==============================] - 92s 916ms/step - loss_1: 67.6989 - loss_2: 62.9552 - loss_3: 71.0828 - lr: 0.0010\n",
      "Epoch 3/90\n",
      "100/100 [==============================] - 91s 914ms/step - loss_1: 49.5306 - loss_2: 46.0332 - loss_3: 51.6713 - lr: 0.0010\n",
      "Epoch 4/90\n",
      "100/100 [==============================] - 91s 910ms/step - loss_1: 39.0302 - loss_2: 37.5737 - loss_3: 41.0405 - lr: 0.0010\n",
      "Epoch 5/90\n",
      "100/100 [==============================] - 91s 910ms/step - loss_1: 35.9236 - loss_2: 36.5205 - loss_3: 31.2357 - lr: 0.0010\n",
      "Epoch 6/90\n",
      "100/100 [==============================] - 91s 912ms/step - loss_1: 29.2729 - loss_2: 28.7048 - loss_3: 28.8384 - lr: 0.0010\n",
      "Epoch 7/90\n",
      "100/100 [==============================] - 91s 907ms/step - loss_1: 30.6997 - loss_2: 26.1090 - loss_3: 26.2196 - lr: 0.0010\n",
      "Epoch 8/90\n",
      "100/100 [==============================] - 91s 906ms/step - loss_1: 26.6556 - loss_2: 23.2674 - loss_3: 23.2337 - lr: 0.0010\n",
      "Epoch 9/90\n",
      "100/100 [==============================] - 91s 906ms/step - loss_1: 24.7091 - loss_2: 23.7009 - loss_3: 22.2495 - lr: 0.0010\n",
      "Epoch 10/90\n",
      "100/100 [==============================] - 91s 907ms/step - loss_1: 23.0235 - loss_2: 22.9296 - loss_3: 20.8794 - lr: 0.0010\n",
      "Epoch 11/90\n",
      "100/100 [==============================] - 91s 906ms/step - loss_1: 21.2818 - loss_2: 22.0303 - loss_3: 20.4047 - lr: 0.0010\n",
      "Epoch 12/90\n",
      "100/100 [==============================] - 91s 906ms/step - loss_1: 20.8819 - loss_2: 19.3469 - loss_3: 21.0184 - lr: 0.0010\n",
      "Epoch 13/90\n",
      "100/100 [==============================] - 91s 906ms/step - loss_1: 19.3686 - loss_2: 19.4784 - loss_3: 18.0122 - lr: 0.0010\n",
      "Epoch 14/90\n",
      "100/100 [==============================] - 91s 908ms/step - loss_1: 16.1091 - loss_2: 17.1425 - loss_3: 16.8297 - lr: 0.0010\n",
      "Epoch 15/90\n",
      "100/100 [==============================] - 91s 907ms/step - loss_1: 17.1509 - loss_2: 17.1332 - loss_3: 17.9413 - lr: 0.0010\n",
      "Epoch 16/90\n",
      "100/100 [==============================] - 91s 907ms/step - loss_1: 15.6867 - loss_2: 13.9171 - loss_3: 16.8087 - lr: 0.0010\n",
      "Epoch 17/90\n",
      "100/100 [==============================] - 91s 908ms/step - loss_1: 16.2695 - loss_2: 15.9471 - loss_3: 15.2613 - lr: 0.0010\n",
      "Epoch 18/90\n",
      "100/100 [==============================] - 91s 907ms/step - loss_1: 15.1991 - loss_2: 17.8481 - loss_3: 13.3639 - lr: 0.0010\n",
      "Epoch 19/90\n",
      "100/100 [==============================] - 91s 907ms/step - loss_1: 14.4902 - loss_2: 14.1730 - loss_3: 13.9537 - lr: 0.0010\n",
      "Epoch 20/90\n",
      "100/100 [==============================] - 91s 907ms/step - loss_1: 13.4111 - loss_2: 14.1086 - loss_3: 13.3993 - lr: 0.0010\n",
      "Epoch 21/90\n",
      "100/100 [==============================] - 91s 908ms/step - loss_1: 12.7066 - loss_2: 12.5602 - loss_3: 14.3261 - lr: 0.0010\n",
      "Epoch 22/90\n",
      "100/100 [==============================] - 91s 908ms/step - loss_1: 12.7788 - loss_2: 14.1773 - loss_3: 12.4508 - lr: 0.0010\n",
      "Epoch 23/90\n",
      "100/100 [==============================] - 91s 907ms/step - loss_1: 15.0703 - loss_2: 12.3665 - loss_3: 12.3288 - lr: 0.0010\n",
      "Epoch 24/90\n",
      "100/100 [==============================] - 91s 907ms/step - loss_1: 14.6125 - loss_2: 11.8679 - loss_3: 11.2341 - lr: 0.0010\n",
      "Epoch 25/90\n",
      "100/100 [==============================] - 91s 907ms/step - loss_1: 12.7779 - loss_2: 12.2799 - loss_3: 13.1854 - lr: 0.0010\n",
      "Epoch 26/90\n",
      "100/100 [==============================] - 91s 908ms/step - loss_1: 12.9592 - loss_2: 12.4461 - loss_3: 12.7312 - lr: 0.0010\n",
      "Epoch 27/90\n",
      "100/100 [==============================] - 91s 907ms/step - loss_1: 11.1892 - loss_2: 11.8608 - loss_3: 11.4278 - lr: 0.0010\n",
      "Epoch 28/90\n",
      "100/100 [==============================] - 91s 907ms/step - loss_1: 10.5959 - loss_2: 11.8420 - loss_3: 10.4544 - lr: 0.0010\n",
      "Epoch 29/90\n",
      "100/100 [==============================] - 91s 907ms/step - loss_1: 10.4015 - loss_2: 10.8386 - loss_3: 10.5605 - lr: 0.0010\n",
      "Epoch 30/90\n",
      "100/100 [==============================] - 91s 907ms/step - loss_1: 9.9435 - loss_2: 9.9000 - loss_3: 9.5231 - lr: 0.0010\n",
      "Epoch 31/90\n",
      "100/100 [==============================] - 91s 907ms/step - loss_1: 9.3912 - loss_2: 8.6101 - loss_3: 8.6027 - lr: 8.9125e-04\n",
      "Epoch 32/90\n",
      "100/100 [==============================] - 91s 907ms/step - loss_1: 7.4200 - loss_2: 8.7767 - loss_3: 7.4796 - lr: 7.9433e-04\n",
      "Epoch 33/90\n",
      "100/100 [==============================] - 91s 907ms/step - loss_1: 6.6747 - loss_2: 7.1668 - loss_3: 7.4891 - lr: 7.0795e-04\n",
      "Epoch 34/90\n",
      "100/100 [==============================] - 91s 907ms/step - loss_1: 7.1247 - loss_2: 5.6901 - loss_3: 6.3283 - lr: 6.3096e-04\n",
      "Epoch 35/90\n",
      "100/100 [==============================] - 91s 907ms/step - loss_1: 6.0514 - loss_2: 6.1298 - loss_3: 5.9530 - lr: 5.6234e-04\n",
      "Epoch 36/90\n",
      "100/100 [==============================] - 91s 907ms/step - loss_1: 5.8106 - loss_2: 5.1357 - loss_3: 5.7137 - lr: 5.0119e-04\n",
      "Epoch 37/90\n",
      "100/100 [==============================] - 91s 908ms/step - loss_1: 5.4613 - loss_2: 4.6079 - loss_3: 4.8198 - lr: 4.4668e-04\n",
      "Epoch 38/90\n",
      "100/100 [==============================] - 91s 907ms/step - loss_1: 4.4300 - loss_2: 4.9710 - loss_3: 4.2447 - lr: 3.9811e-04\n",
      "Epoch 39/90\n",
      "100/100 [==============================] - 91s 908ms/step - loss_1: 4.2518 - loss_2: 4.5091 - loss_3: 3.9229 - lr: 3.5481e-04\n",
      "Epoch 40/90\n",
      "100/100 [==============================] - 91s 908ms/step - loss_1: 3.9086 - loss_2: 4.0231 - loss_3: 4.3643 - lr: 3.1623e-04\n",
      "Epoch 41/90\n",
      "100/100 [==============================] - 91s 907ms/step - loss_1: 4.1553 - loss_2: 3.5712 - loss_3: 3.9068 - lr: 2.8184e-04\n",
      "Epoch 42/90\n",
      "100/100 [==============================] - 91s 907ms/step - loss_1: 3.6760 - loss_2: 3.8126 - loss_3: 3.3910 - lr: 2.5119e-04\n",
      "Epoch 43/90\n",
      "100/100 [==============================] - 91s 908ms/step - loss_1: 3.3530 - loss_2: 3.5135 - loss_3: 3.3371 - lr: 2.2387e-04\n",
      "Epoch 44/90\n",
      "100/100 [==============================] - 91s 907ms/step - loss_1: 3.0588 - loss_2: 3.4134 - loss_3: 3.1024 - lr: 1.9953e-04\n",
      "Epoch 45/90\n",
      "100/100 [==============================] - 91s 908ms/step - loss_1: 3.0128 - loss_2: 2.9958 - loss_3: 2.8562 - lr: 1.7783e-04\n",
      "Epoch 46/90\n",
      "100/100 [==============================] - 91s 908ms/step - loss_1: 2.9395 - loss_2: 2.9008 - loss_3: 2.7694 - lr: 1.5849e-04\n",
      "Epoch 47/90\n",
      "100/100 [==============================] - 91s 907ms/step - loss_1: 2.9825 - loss_2: 3.0161 - loss_3: 2.4065 - lr: 1.4125e-04\n",
      "Epoch 48/90\n",
      "100/100 [==============================] - 91s 908ms/step - loss_1: 2.7117 - loss_2: 2.7312 - loss_3: 2.7037 - lr: 1.2589e-04\n",
      "Epoch 49/90\n",
      "100/100 [==============================] - 91s 906ms/step - loss_1: 2.6277 - loss_2: 2.5166 - loss_3: 2.6445 - lr: 1.1220e-04\n",
      "Epoch 50/90\n",
      "100/100 [==============================] - 91s 907ms/step - loss_1: 2.8875 - loss_2: 2.5293 - loss_3: 2.4808 - lr: 1.0000e-04\n",
      "Epoch 51/90\n",
      "100/100 [==============================] - 91s 907ms/step - loss_1: 2.5943 - loss_2: 2.8570 - loss_3: 2.5869 - lr: 8.9125e-05\n",
      "Epoch 52/90\n",
      "100/100 [==============================] - 91s 907ms/step - loss_1: 2.4354 - loss_2: 2.2773 - loss_3: 2.1982 - lr: 7.9433e-05\n",
      "Epoch 53/90\n",
      "100/100 [==============================] - 91s 907ms/step - loss_1: 2.1570 - loss_2: 2.1670 - loss_3: 2.3866 - lr: 7.0795e-05\n",
      "Epoch 54/90\n",
      "100/100 [==============================] - 91s 907ms/step - loss_1: 2.4546 - loss_2: 2.4411 - loss_3: 2.4142 - lr: 6.3096e-05\n",
      "Epoch 55/90\n",
      "100/100 [==============================] - 91s 907ms/step - loss_1: 2.3056 - loss_2: 2.5728 - loss_3: 2.6848 - lr: 5.6234e-05\n",
      "Epoch 56/90\n",
      "100/100 [==============================] - 91s 907ms/step - loss_1: 2.3483 - loss_2: 2.5326 - loss_3: 2.3714 - lr: 5.0119e-05\n",
      "Epoch 57/90\n",
      "100/100 [==============================] - 91s 907ms/step - loss_1: 1.9202 - loss_2: 2.2775 - loss_3: 2.0622 - lr: 4.4668e-05\n",
      "Epoch 58/90\n",
      "100/100 [==============================] - 91s 907ms/step - loss_1: 2.1752 - loss_2: 2.3510 - loss_3: 2.4201 - lr: 3.9811e-05\n",
      "Epoch 59/90\n",
      "100/100 [==============================] - 91s 907ms/step - loss_1: 2.1730 - loss_2: 2.1975 - loss_3: 1.9984 - lr: 3.5481e-05\n",
      "Epoch 60/90\n",
      "100/100 [==============================] - 91s 908ms/step - loss_1: 2.3954 - loss_2: 1.9949 - loss_3: 2.0868 - lr: 3.1623e-05\n",
      "Epoch 61/90\n",
      "100/100 [==============================] - 91s 908ms/step - loss_1: 2.2476 - loss_2: 2.1179 - loss_3: 2.0076 - lr: 2.8184e-05\n",
      "Epoch 62/90\n",
      "100/100 [==============================] - 91s 908ms/step - loss_1: 2.1929 - loss_2: 2.1088 - loss_3: 2.2034 - lr: 2.5119e-05\n",
      "Epoch 63/90\n",
      "100/100 [==============================] - 91s 909ms/step - loss_1: 2.2090 - loss_2: 2.0682 - loss_3: 2.1600 - lr: 2.2387e-05\n",
      "Epoch 64/90\n",
      "100/100 [==============================] - 91s 908ms/step - loss_1: 2.1332 - loss_2: 1.8812 - loss_3: 2.0322 - lr: 1.9953e-05\n",
      "Epoch 65/90\n",
      "100/100 [==============================] - 91s 908ms/step - loss_1: 2.0551 - loss_2: 2.0061 - loss_3: 2.1871 - lr: 1.7783e-05\n",
      "Epoch 66/90\n",
      "100/100 [==============================] - 91s 908ms/step - loss_1: 2.3306 - loss_2: 2.1029 - loss_3: 2.0070 - lr: 1.5849e-05\n",
      "Epoch 67/90\n",
      "100/100 [==============================] - 91s 907ms/step - loss_1: 2.0929 - loss_2: 1.9465 - loss_3: 1.9055 - lr: 1.4125e-05\n",
      "Epoch 68/90\n",
      "100/100 [==============================] - 91s 907ms/step - loss_1: 2.0476 - loss_2: 2.1227 - loss_3: 1.8232 - lr: 1.2589e-05\n",
      "Epoch 69/90\n",
      "100/100 [==============================] - 91s 908ms/step - loss_1: 1.9711 - loss_2: 1.8060 - loss_3: 1.8676 - lr: 1.1220e-05\n",
      "Epoch 70/90\n",
      "100/100 [==============================] - 91s 907ms/step - loss_1: 2.2322 - loss_2: 1.9379 - loss_3: 1.7289 - lr: 1.0000e-05\n",
      "Epoch 71/90\n",
      "100/100 [==============================] - 91s 908ms/step - loss_1: 1.9643 - loss_2: 2.2422 - loss_3: 1.7609 - lr: 8.9125e-06\n",
      "Epoch 72/90\n",
      "100/100 [==============================] - 91s 907ms/step - loss_1: 1.7630 - loss_2: 1.9856 - loss_3: 2.0439 - lr: 7.9433e-06\n",
      "Epoch 73/90\n",
      "100/100 [==============================] - 91s 907ms/step - loss_1: 1.8849 - loss_2: 2.0623 - loss_3: 2.1463 - lr: 7.0795e-06\n",
      "Epoch 74/90\n",
      "100/100 [==============================] - 91s 908ms/step - loss_1: 2.0069 - loss_2: 1.9639 - loss_3: 1.5506 - lr: 6.3096e-06\n",
      "Epoch 75/90\n",
      "100/100 [==============================] - 91s 907ms/step - loss_1: 2.1143 - loss_2: 1.8969 - loss_3: 1.8263 - lr: 5.6234e-06\n",
      "Epoch 76/90\n",
      "100/100 [==============================] - 91s 907ms/step - loss_1: 1.9091 - loss_2: 1.8691 - loss_3: 1.8867 - lr: 5.0119e-06\n",
      "Epoch 77/90\n",
      "100/100 [==============================] - 91s 908ms/step - loss_1: 2.2316 - loss_2: 1.9181 - loss_3: 1.8408 - lr: 4.4668e-06\n",
      "Epoch 78/90\n",
      "100/100 [==============================] - 91s 907ms/step - loss_1: 1.7162 - loss_2: 1.7000 - loss_3: 1.8989 - lr: 3.9811e-06\n",
      "Epoch 79/90\n",
      "100/100 [==============================] - 91s 907ms/step - loss_1: 1.9339 - loss_2: 1.8423 - loss_3: 1.9131 - lr: 3.5481e-06\n",
      "Epoch 80/90\n",
      "100/100 [==============================] - 91s 908ms/step - loss_1: 2.0415 - loss_2: 1.6505 - loss_3: 1.8391 - lr: 3.1623e-06\n",
      "Epoch 81/90\n",
      "100/100 [==============================] - 91s 907ms/step - loss_1: 1.7016 - loss_2: 1.9880 - loss_3: 2.0777 - lr: 2.8184e-06\n",
      "Epoch 82/90\n",
      "100/100 [==============================] - 91s 907ms/step - loss_1: 2.1502 - loss_2: 1.9984 - loss_3: 1.8705 - lr: 2.5119e-06\n",
      "Epoch 83/90\n",
      "100/100 [==============================] - 91s 906ms/step - loss_1: 2.0075 - loss_2: 1.9343 - loss_3: 1.7169 - lr: 2.2387e-06\n",
      "Epoch 84/90\n",
      "100/100 [==============================] - 91s 908ms/step - loss_1: 2.1105 - loss_2: 1.8340 - loss_3: 1.9476 - lr: 1.9953e-06\n",
      "Epoch 85/90\n",
      "100/100 [==============================] - 91s 908ms/step - loss_1: 1.6587 - loss_2: 1.8359 - loss_3: 1.7882 - lr: 1.7783e-06\n",
      "Epoch 86/90\n",
      "100/100 [==============================] - 91s 906ms/step - loss_1: 2.1055 - loss_2: 1.7519 - loss_3: 1.6979 - lr: 1.5849e-06\n",
      "Epoch 87/90\n",
      "100/100 [==============================] - 91s 908ms/step - loss_1: 1.9963 - loss_2: 1.7207 - loss_3: 1.7951 - lr: 1.4125e-06\n",
      "Epoch 88/90\n",
      "100/100 [==============================] - 91s 907ms/step - loss_1: 2.0231 - loss_2: 1.8172 - loss_3: 1.8634 - lr: 1.2589e-06\n",
      "Epoch 89/90\n",
      "100/100 [==============================] - 91s 907ms/step - loss_1: 2.0418 - loss_2: 1.9279 - loss_3: 1.6287 - lr: 1.1220e-06\n",
      "Epoch 90/90\n",
      "100/100 [==============================] - 91s 907ms/step - loss_1: 2.0191 - loss_2: 2.1384 - loss_3: 1.5735 - lr: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(train_init_ops)\n",
    "\n",
    "    for e in range(EPOCHS):\n",
    "        print(\"Epoch {}/{}\".format(e + 1, EPOCHS))\n",
    "        progbar = tf.keras.utils.Progbar(STEPS_PER_EPOCH)\n",
    "        \n",
    "        learning_rate = lr_scheduler(e + 1)\n",
    "        for i in range(STEPS_PER_EPOCH):\n",
    "            _, loss_values = sess.run([model.train_ops, model.losses], feed_dict={lr:learning_rate})\n",
    "            progbar.update(i + 1, values=[('loss_'+str(b+1), loss_values[b]) for b in range(len(loss_values))] \\\n",
    "                           + [('lr', learning_rate),])\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    path = os.path.join(model_path, 'ckpt')\n",
    "    saver.save(sess, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_sess(sess, model_path):\n",
    "    meta_path = os.path.join(model_path, 'ckpt.meta')\n",
    "    ckpt = tf.train.get_checkpoint_state(model_path)\n",
    "\n",
    "    imported_graph = tf.train.import_meta_graph(meta_path)\n",
    "    imported_graph.restore(sess, ckpt.model_checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run(n_run):\n",
    "    all_runs = './omniglot/python/one-shot-classification/all_runs'\n",
    "    \n",
    "    if not os.path.isdir(all_runs):\n",
    "        with zipfile.ZipFile(all_runs + '.zip','r') as zip_ref:\n",
    "            zip_ref.extractall(all_runs)\n",
    "    \n",
    "    run_path = os.path.join(all_runs,'run%02d'%n_run,'class_labels.txt')\n",
    "    with open(run_path) as f:\n",
    "        content = f.read().splitlines()\n",
    "\n",
    "    pairs = [line.split() for line in content]\n",
    "    test_files  = [pair[0] for pair in pairs]\n",
    "    train_files = [pair[1] for pair in pairs]\n",
    "\n",
    "    answers_files = copy.copy(train_files)\n",
    "    test_files.sort()\n",
    "    train_files.sort()\n",
    "    \n",
    "    def f_load(f):\n",
    "        path = os.path.join(all_runs, f)\n",
    "        return cv2.imread(path)[..., 0]\n",
    "\n",
    "    train_imgs = np.stack([f_load(f) for f in train_files]).\\\n",
    "                        astype('float32')[..., np.newaxis]\n",
    "    test_imgs  = np.stack([f_load(f) for f in test_files]).\\\n",
    "                        astype('float32')[..., np.newaxis]\n",
    "\n",
    "    return train_files, test_files, train_imgs, test_imgs, answers_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_one_shot_acc(test_pred, train_pred, train_files, answers_files):\n",
    "    n_test = len(test_pred)\n",
    "    n_train = len(train_pred)\n",
    "    \n",
    "    distM = np.zeros((n_test, n_train))\n",
    "    for i in range(n_test):\n",
    "        for c in range(n_train):\n",
    "            distM[i,c] = distance.euclidean(test_pred[i],train_pred[c])\n",
    "            \n",
    "    YHAT = np.argmin(distM, axis=1)\n",
    "    \n",
    "    # compute the error rate\n",
    "    correct = 0.0\n",
    "    for i in range(n_test):\n",
    "        if train_files[YHAT[i]] == answers_files[i]:\n",
    "            correct += 1.0\n",
    "        \n",
    "    return correct / n_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_init_ops = ['test_init_op_'+str(i+1) for i in range(NUM_BRANCHES)]\n",
    "model_outputs = ['model_1/model_1/output_vb{}:0'.format(i+1) for i in range(NUM_BRANCHES)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/vb-omniglot-simple-B3-S0.50_1/ckpt\n"
     ]
    }
   ],
   "source": [
    "total_runs = 20\n",
    "train_pred_runs = []\n",
    "test_pred_runs = []\n",
    "\n",
    "run_data = [get_run(r+1) for r in range(total_runs)]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    restore_sess(sess, model_path)\n",
    "\n",
    "    for r in range(total_runs):\n",
    "        train_files,test_files,train_imgs,test_imgs,answers_files = run_data[r]\n",
    "\n",
    "        feed_dict = {'x:0':train_imgs, 'batch_size:0':len(train_imgs)}\n",
    "        sess.run(test_init_ops, feed_dict=feed_dict)\n",
    "        train_pred_runs.append(sess.run(model_outputs))\n",
    "\n",
    "        feed_dict = {'x:0':test_imgs, 'batch_size:0':len(test_imgs)}\n",
    "        sess.run(test_init_ops, feed_dict=feed_dict)\n",
    "        test_pred_runs.append(sess.run(model_outputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_acc_runs = []\n",
    "for r in range(total_runs):\n",
    "    test_embed = np.mean(test_pred_runs[r], axis=0)\n",
    "    train_embed = np.mean(train_pred_runs[r], axis=0)\n",
    "    train_files = run_data[r][0]\n",
    "    answers_files = run_data[r][-1]\n",
    "    \n",
    "    acc = compute_one_shot_acc(test_embed, train_embed,train_files, answers_files)\n",
    "    mean_acc_runs.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9, 0.85, 0.85, 0.95, 0.8, 0.95, 0.85, 0.85, 0.7, 0.85, 1.0, 0.75, 0.75, 0.65, 1.0, 1.0, 0.8, 0.9, 0.6, 0.85]\n",
      "0.8425\n"
     ]
    }
   ],
   "source": [
    "print(mean_acc_runs)\n",
    "print(np.mean(mean_acc_runs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_acc_runs = []\n",
    "for r in range(total_runs):\n",
    "    test_embed = np.concatenate(test_pred_runs[r], axis=-1)\n",
    "    train_embed = np.concatenate(train_pred_runs[r], axis=-1)\n",
    "    train_files = run_data[r][0]\n",
    "    answers_files = run_data[r][-1]\n",
    "        \n",
    "    acc = compute_one_shot_acc(test_embed, train_embed,train_files, answers_files)\n",
    "    concat_acc_runs.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8, 0.8, 0.85, 0.9, 0.85, 0.95, 0.9, 0.7, 0.75, 0.85, 1.0, 0.8, 0.6, 0.75, 1.0, 1.0, 0.85, 0.95, 0.65, 0.9]\n",
      "0.8424999999999999\n"
     ]
    }
   ],
   "source": [
    "print(concat_acc_runs)\n",
    "print(np.mean(concat_acc_runs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
