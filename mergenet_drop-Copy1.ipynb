{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(threshold=1000)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.callbacks import LearningRateScheduler, History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/albert/github/tensorflow/pre/pre8/src/')\n",
    "import evaluation,data, training, models\n",
    "# from src.bk import models_bk2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "P_param = 5\n",
    "K_param = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dict, train_files = data.get_data('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0836570262909\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3EAAABpCAYAAACUGaonAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ng8FgMBgMH4IZcQaDwWAwGAwGg8HwIfw/xp9mxe+s0jIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f80642cf210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start = time.time()\n",
    "batch = data.batch_generator(train_dict, P=P_param, K=K_param, preprocess=True,\n",
    "                                    shape=(256,128)).next()\n",
    "print time.time() - start\n",
    "\n",
    "i = 0\n",
    "\n",
    "plt.figure(figsize=(15,2))\n",
    "for j in range(P_param*K_param):\n",
    "    plt.subplot(1,20,j+1)\n",
    "    im = batch[0][i][j].squeeze().astype(np.uint8)\n",
    "#         print im.min(), im.max()\n",
    "    plt.imshow(im)\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7fcc688f50>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAD8CAYAAAC2PJlnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f803dc42710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 10\n",
    "steps_per_epoch = 100\n",
    "\n",
    "lr = []\n",
    "for era in range(1,21):\n",
    "#     exec(step_decay_cont_str % (epochs, era))\n",
    "    for j in range(10):\n",
    "        lr.append(training.step_decay_cont(epochs, era)(j))\n",
    "plt.plot(np.arange(200), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called 0\n",
      "[64]\n",
      "[64]\n",
      "[-1, 0, 1, 2]\n",
      "called 0\n",
      "[64]\n",
      "[64]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[96]\n",
      "[96]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[160]\n",
      "[160]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[192]\n",
      "[192]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[224]\n",
      "[224]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[256]\n",
      "[256]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[160]\n",
      "[160]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[192]\n",
      "[192]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[224]\n",
      "[224]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[256]\n",
      "[256]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[288]\n",
      "[288]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[320]\n",
      "[320]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[352]\n",
      "[352]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[384]\n",
      "[384]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[416]\n",
      "[416]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[448]\n",
      "[448]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[480]\n",
      "[480]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[512]\n",
      "[512]\n",
      "called 0\n",
      "[256]\n",
      "[256]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[288]\n",
      "[288]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[320]\n",
      "[320]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[352]\n",
      "[352]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[384]\n",
      "[384]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[416]\n",
      "[416]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[448]\n",
      "[448]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[480]\n",
      "[480]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[512]\n",
      "[512]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[544]\n",
      "[544]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[576]\n",
      "[576]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[608]\n",
      "[608]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[640]\n",
      "[640]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[672]\n",
      "[672]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[704]\n",
      "[704]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[736]\n",
      "[736]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[768]\n",
      "[768]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[800]\n",
      "[800]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[832]\n",
      "[832]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[864]\n",
      "[864]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[896]\n",
      "[896]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[928]\n",
      "[928]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[960]\n",
      "[960]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[992]\n",
      "[992]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[1024]\n",
      "[1024]\n",
      "called 0\n",
      "[1024]\n",
      "[1024]\n",
      "l_start 138\n",
      "called 0\n",
      "[64]\n",
      "[64]\n",
      "[-1, 0, 1, 2]\n",
      "called 0\n",
      "[64]\n",
      "[64]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[96]\n",
      "[96]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[160]\n",
      "[160]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[192]\n",
      "[192]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[224]\n",
      "[224]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[256]\n",
      "[256]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[160]\n",
      "[160]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[192]\n",
      "[192]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[224]\n",
      "[224]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[256]\n",
      "[256]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[288]\n",
      "[288]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[320]\n",
      "[320]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[352]\n",
      "[352]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[384]\n",
      "[384]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[416]\n",
      "[416]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[448]\n",
      "[448]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[480]\n",
      "[480]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "called 0\n",
      "[512]\n",
      "[512]\n",
      "idx [10922, 4]\n",
      "gather [10922]\n",
      "idx [12288, 4]\n",
      "gather [12288]\n",
      "idx [13654, 4]\n",
      "gather [13654]\n",
      "idx [15020, 4]\n",
      "gather [15020]\n",
      "idx [16386, 4]\n",
      "gather [16386]\n",
      "idx [17752, 4]\n",
      "gather [17752]\n",
      "idx [19118, 4]\n",
      "gather [19118]\n",
      "idx [20484, 4]\n",
      "gather [20484]\n",
      "idx [21850, 4]\n",
      "gather [21850]\n",
      "idx [23216, 4]\n",
      "gather [23216]\n",
      "idx [24582, 4]\n",
      "gather [24582]\n",
      "idx [25948, 4]\n",
      "gather [25948]\n",
      "idx [27314, 4]\n",
      "gather [27314]\n",
      "idx [28680, 4]\n",
      "gather [28680]\n",
      "idx [30046, 4]\n",
      "gather [30046]\n",
      "idx [31412, 4]\n",
      "gather [31412]\n",
      "idx [32778, 4]\n",
      "gather [32778]\n",
      "idx [34144, 4]\n",
      "gather [34144]\n",
      "idx [35510, 4]\n",
      "gather [35510]\n",
      "idx [36876, 4]\n",
      "gather [36876]\n",
      "idx [38242, 4]\n",
      "gather [38242]\n",
      "idx [39608, 4]\n",
      "gather [39608]\n",
      "idx [40974, 4]\n",
      "gather [40974]\n",
      "idx [42340, 4]\n",
      "gather [42340]\n",
      "conv2d_88 [[<tf.Tensor 'input_2_1:0' shape=(?, 256, 128, 3) dtype=float32>]]\n",
      "batch_normalization_140 [[<tf.Tensor 'conv2d_88_1/convolution:0' shape=(?, 128, 64, 64) dtype=float32>]]\n",
      "called 0\n",
      "[64]\n",
      "[64]\n",
      "activation_90 [[<tf.Tensor 'batch_normalization_140_1/cond/Merge:0' shape=(?, 128, 64, 64) dtype=float32>]]\n",
      "max_pooling2d_2 [[<tf.Tensor 'activation_90_1/Relu:0' shape=(?, 128, 64, 64) dtype=float32>]]\n",
      "batch_normalization_141 [[<tf.Tensor 'max_pooling2d_2_1/MaxPool:0' shape=(?, 64, 32, 64) dtype=float32>]]\n",
      "called 0\n",
      "[64]\n",
      "[64]\n",
      "activation_91 [[<tf.Tensor 'batch_normalization_141_1/cond/Merge:0' shape=(?, 64, 32, 64) dtype=float32>]]\n",
      "conv2d_89 [[<tf.Tensor 'activation_91_1/Relu:0' shape=(?, 64, 32, 64) dtype=float32>]]\n",
      "batch_normalization_142 [[<tf.Tensor 'conv2d_89_1/convolution:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_92 [[<tf.Tensor 'batch_normalization_142_1/cond/Merge:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "conv2d_90 [[<tf.Tensor 'activation_92_1/Relu:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "concatenate_43 [[<tf.Tensor 'max_pooling2d_2_1/MaxPool:0' shape=(?, 64, 32, 64) dtype=float32>, <tf.Tensor 'conv2d_90_1/convolution:0' shape=(?, 64, 32, 32) dtype=float32>]]\n",
      "[None, 64, 32, 96]\n",
      "batch_normalization_143 [[<tf.Tensor 'concatenate_43_2/concat:0' shape=(?, 64, 32, 96) dtype=float32>]]\n",
      "called 0\n",
      "[96]\n",
      "[96]\n",
      "activation_93 [[<tf.Tensor 'batch_normalization_143_1/cond/Merge:0' shape=(?, 64, 32, 96) dtype=float32>]]\n",
      "conv2d_91 [[<tf.Tensor 'activation_93_1/Relu:0' shape=(?, 64, 32, 96) dtype=float32>]]\n",
      "batch_normalization_144 [[<tf.Tensor 'conv2d_91_1/convolution:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_94 [[<tf.Tensor 'batch_normalization_144_1/cond/Merge:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "conv2d_92 [[<tf.Tensor 'activation_94_1/Relu:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "concatenate_44 [[<tf.Tensor 'concatenate_43_2/concat:0' shape=(?, 64, 32, 96) dtype=float32>, <tf.Tensor 'conv2d_92_1/convolution:0' shape=(?, 64, 32, 32) dtype=float32>]]\n",
      "[None, 64, 32, 128]\n",
      "batch_normalization_145 [[<tf.Tensor 'concatenate_44_2/concat:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_95 [[<tf.Tensor 'batch_normalization_145_1/cond/Merge:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "conv2d_93 [[<tf.Tensor 'activation_95_1/Relu:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "batch_normalization_146 [[<tf.Tensor 'conv2d_93_1/convolution:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_96 [[<tf.Tensor 'batch_normalization_146_1/cond/Merge:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "conv2d_94 [[<tf.Tensor 'activation_96_1/Relu:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "concatenate_45 [[<tf.Tensor 'concatenate_44_2/concat:0' shape=(?, 64, 32, 128) dtype=float32>, <tf.Tensor 'conv2d_94_1/convolution:0' shape=(?, 64, 32, 32) dtype=float32>]]\n",
      "[None, 64, 32, 160]\n",
      "batch_normalization_147 [[<tf.Tensor 'concatenate_45_2/concat:0' shape=(?, 64, 32, 160) dtype=float32>]]\n",
      "called 0\n",
      "[160]\n",
      "[160]\n",
      "activation_97 [[<tf.Tensor 'batch_normalization_147_1/cond/Merge:0' shape=(?, 64, 32, 160) dtype=float32>]]\n",
      "conv2d_95 [[<tf.Tensor 'activation_97_1/Relu:0' shape=(?, 64, 32, 160) dtype=float32>]]\n",
      "batch_normalization_148 [[<tf.Tensor 'conv2d_95_1/convolution:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_98 [[<tf.Tensor 'batch_normalization_148_1/cond/Merge:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "conv2d_96 [[<tf.Tensor 'activation_98_1/Relu:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "concatenate_46 [[<tf.Tensor 'concatenate_45_2/concat:0' shape=(?, 64, 32, 160) dtype=float32>, <tf.Tensor 'conv2d_96_1/convolution:0' shape=(?, 64, 32, 32) dtype=float32>]]\n",
      "[None, 64, 32, 192]\n",
      "batch_normalization_149 [[<tf.Tensor 'concatenate_46_2/concat:0' shape=(?, 64, 32, 192) dtype=float32>]]\n",
      "called 0\n",
      "[192]\n",
      "[192]\n",
      "activation_99 [[<tf.Tensor 'batch_normalization_149_1/cond/Merge:0' shape=(?, 64, 32, 192) dtype=float32>]]\n",
      "conv2d_97 [[<tf.Tensor 'activation_99_1/Relu:0' shape=(?, 64, 32, 192) dtype=float32>]]\n",
      "batch_normalization_150 [[<tf.Tensor 'conv2d_97_1/convolution:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_100 [[<tf.Tensor 'batch_normalization_150_1/cond/Merge:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "conv2d_98 [[<tf.Tensor 'activation_100_1/Relu:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "concatenate_47 [[<tf.Tensor 'concatenate_46_2/concat:0' shape=(?, 64, 32, 192) dtype=float32>, <tf.Tensor 'conv2d_98_1/convolution:0' shape=(?, 64, 32, 32) dtype=float32>]]\n",
      "[None, 64, 32, 224]\n",
      "batch_normalization_151 [[<tf.Tensor 'concatenate_47_2/concat:0' shape=(?, 64, 32, 224) dtype=float32>]]\n",
      "called 0\n",
      "[224]\n",
      "[224]\n",
      "activation_101 [[<tf.Tensor 'batch_normalization_151_1/cond/Merge:0' shape=(?, 64, 32, 224) dtype=float32>]]\n",
      "conv2d_99 [[<tf.Tensor 'activation_101_1/Relu:0' shape=(?, 64, 32, 224) dtype=float32>]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_normalization_152 [[<tf.Tensor 'conv2d_99_1/convolution:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_102 [[<tf.Tensor 'batch_normalization_152_1/cond/Merge:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "conv2d_100 [[<tf.Tensor 'activation_102_1/Relu:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "concatenate_48 [[<tf.Tensor 'concatenate_47_2/concat:0' shape=(?, 64, 32, 224) dtype=float32>, <tf.Tensor 'conv2d_100_1/convolution:0' shape=(?, 64, 32, 32) dtype=float32>]]\n",
      "[None, 64, 32, 256]\n",
      "batch_normalization_153 [[<tf.Tensor 'concatenate_48_2/concat:0' shape=(?, 64, 32, 256) dtype=float32>]]\n",
      "called 0\n",
      "[256]\n",
      "[256]\n",
      "activation_103 [[<tf.Tensor 'batch_normalization_153_1/cond/Merge:0' shape=(?, 64, 32, 256) dtype=float32>]]\n",
      "conv2d_101 [[<tf.Tensor 'activation_103_1/Relu:0' shape=(?, 64, 32, 256) dtype=float32>]]\n",
      "average_pooling2d_3 [[<tf.Tensor 'conv2d_101_1/convolution:0' shape=(?, 64, 32, 128) dtype=float32>]]\n",
      "batch_normalization_154 [[<tf.Tensor 'average_pooling2d_3_1/AvgPool:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_104 [[<tf.Tensor 'batch_normalization_154_1/cond/Merge:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "conv2d_102 [[<tf.Tensor 'activation_104_1/Relu:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "batch_normalization_155 [[<tf.Tensor 'conv2d_102_1/convolution:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_105 [[<tf.Tensor 'batch_normalization_155_1/cond/Merge:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "conv2d_103 [[<tf.Tensor 'activation_105_1/Relu:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "concatenate_49 [[<tf.Tensor 'average_pooling2d_3_1/AvgPool:0' shape=(?, 32, 16, 128) dtype=float32>, <tf.Tensor 'conv2d_103_1/convolution:0' shape=(?, 32, 16, 32) dtype=float32>]]\n",
      "[None, 32, 16, 160]\n",
      "batch_normalization_156 [[<tf.Tensor 'concatenate_49_2/concat:0' shape=(?, 32, 16, 160) dtype=float32>]]\n",
      "called 0\n",
      "[160]\n",
      "[160]\n",
      "activation_106 [[<tf.Tensor 'batch_normalization_156_1/cond/Merge:0' shape=(?, 32, 16, 160) dtype=float32>]]\n",
      "conv2d_104 [[<tf.Tensor 'activation_106_1/Relu:0' shape=(?, 32, 16, 160) dtype=float32>]]\n",
      "batch_normalization_157 [[<tf.Tensor 'conv2d_104_1/convolution:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_107 [[<tf.Tensor 'batch_normalization_157_1/cond/Merge:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "conv2d_105 [[<tf.Tensor 'activation_107_1/Relu:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "concatenate_50 [[<tf.Tensor 'concatenate_49_2/concat:0' shape=(?, 32, 16, 160) dtype=float32>, <tf.Tensor 'conv2d_105_1/convolution:0' shape=(?, 32, 16, 32) dtype=float32>]]\n",
      "[None, 32, 16, 192]\n",
      "batch_normalization_158 [[<tf.Tensor 'concatenate_50_2/concat:0' shape=(?, 32, 16, 192) dtype=float32>]]\n",
      "called 0\n",
      "[192]\n",
      "[192]\n",
      "activation_108 [[<tf.Tensor 'batch_normalization_158_1/cond/Merge:0' shape=(?, 32, 16, 192) dtype=float32>]]\n",
      "conv2d_106 [[<tf.Tensor 'activation_108_1/Relu:0' shape=(?, 32, 16, 192) dtype=float32>]]\n",
      "batch_normalization_159 [[<tf.Tensor 'conv2d_106_1/convolution:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_109 [[<tf.Tensor 'batch_normalization_159_1/cond/Merge:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "conv2d_107 [[<tf.Tensor 'activation_109_1/Relu:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "concatenate_51 [[<tf.Tensor 'concatenate_50_2/concat:0' shape=(?, 32, 16, 192) dtype=float32>, <tf.Tensor 'conv2d_107_1/convolution:0' shape=(?, 32, 16, 32) dtype=float32>]]\n",
      "[None, 32, 16, 224]\n",
      "batch_normalization_160 [[<tf.Tensor 'concatenate_51_2/concat:0' shape=(?, 32, 16, 224) dtype=float32>]]\n",
      "called 0\n",
      "[224]\n",
      "[224]\n",
      "activation_110 [[<tf.Tensor 'batch_normalization_160_1/cond/Merge:0' shape=(?, 32, 16, 224) dtype=float32>]]\n",
      "conv2d_108 [[<tf.Tensor 'activation_110_1/Relu:0' shape=(?, 32, 16, 224) dtype=float32>]]\n",
      "batch_normalization_161 [[<tf.Tensor 'conv2d_108_1/convolution:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_111 [[<tf.Tensor 'batch_normalization_161_1/cond/Merge:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "conv2d_109 [[<tf.Tensor 'activation_111_1/Relu:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "concatenate_52 [[<tf.Tensor 'concatenate_51_2/concat:0' shape=(?, 32, 16, 224) dtype=float32>, <tf.Tensor 'conv2d_109_1/convolution:0' shape=(?, 32, 16, 32) dtype=float32>]]\n",
      "[None, 32, 16, 256]\n",
      "batch_normalization_162 [[<tf.Tensor 'concatenate_52_2/concat:0' shape=(?, 32, 16, 256) dtype=float32>]]\n",
      "called 0\n",
      "[256]\n",
      "[256]\n",
      "activation_112 [[<tf.Tensor 'batch_normalization_162_1/cond/Merge:0' shape=(?, 32, 16, 256) dtype=float32>]]\n",
      "conv2d_110 [[<tf.Tensor 'activation_112_1/Relu:0' shape=(?, 32, 16, 256) dtype=float32>]]\n",
      "batch_normalization_163 [[<tf.Tensor 'conv2d_110_1/convolution:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_113 [[<tf.Tensor 'batch_normalization_163_1/cond/Merge:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "conv2d_111 [[<tf.Tensor 'activation_113_1/Relu:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "concatenate_53 [[<tf.Tensor 'concatenate_52_2/concat:0' shape=(?, 32, 16, 256) dtype=float32>, <tf.Tensor 'conv2d_111_1/convolution:0' shape=(?, 32, 16, 32) dtype=float32>]]\n",
      "[None, 32, 16, 288]\n",
      "batch_normalization_164 [[<tf.Tensor 'concatenate_53_2/concat:0' shape=(?, 32, 16, 288) dtype=float32>]]\n",
      "called 0\n",
      "[288]\n",
      "[288]\n",
      "activation_114 [[<tf.Tensor 'batch_normalization_164_1/cond/Merge:0' shape=(?, 32, 16, 288) dtype=float32>]]\n",
      "conv2d_112 [[<tf.Tensor 'activation_114_1/Relu:0' shape=(?, 32, 16, 288) dtype=float32>]]\n",
      "batch_normalization_165 [[<tf.Tensor 'conv2d_112_1/convolution:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_115 [[<tf.Tensor 'batch_normalization_165_1/cond/Merge:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "conv2d_113 [[<tf.Tensor 'activation_115_1/Relu:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "concatenate_54 [[<tf.Tensor 'concatenate_53_2/concat:0' shape=(?, 32, 16, 288) dtype=float32>, <tf.Tensor 'conv2d_113_1/convolution:0' shape=(?, 32, 16, 32) dtype=float32>]]\n",
      "[None, 32, 16, 320]\n",
      "batch_normalization_166 [[<tf.Tensor 'concatenate_54_2/concat:0' shape=(?, 32, 16, 320) dtype=float32>]]\n",
      "called 0\n",
      "[320]\n",
      "[320]\n",
      "activation_116 [[<tf.Tensor 'batch_normalization_166_1/cond/Merge:0' shape=(?, 32, 16, 320) dtype=float32>]]\n",
      "conv2d_114 [[<tf.Tensor 'activation_116_1/Relu:0' shape=(?, 32, 16, 320) dtype=float32>]]\n",
      "batch_normalization_167 [[<tf.Tensor 'conv2d_114_1/convolution:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_117 [[<tf.Tensor 'batch_normalization_167_1/cond/Merge:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "conv2d_115 [[<tf.Tensor 'activation_117_1/Relu:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "concatenate_55 [[<tf.Tensor 'concatenate_54_2/concat:0' shape=(?, 32, 16, 320) dtype=float32>, <tf.Tensor 'conv2d_115_1/convolution:0' shape=(?, 32, 16, 32) dtype=float32>]]\n",
      "[None, 32, 16, 352]\n",
      "batch_normalization_168 [[<tf.Tensor 'concatenate_55_2/concat:0' shape=(?, 32, 16, 352) dtype=float32>]]\n",
      "called 0\n",
      "[352]\n",
      "[352]\n",
      "activation_118 [[<tf.Tensor 'batch_normalization_168_1/cond/Merge:0' shape=(?, 32, 16, 352) dtype=float32>]]\n",
      "conv2d_116 [[<tf.Tensor 'activation_118_1/Relu:0' shape=(?, 32, 16, 352) dtype=float32>]]\n",
      "batch_normalization_169 [[<tf.Tensor 'conv2d_116_1/convolution:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_119 [[<tf.Tensor 'batch_normalization_169_1/cond/Merge:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "conv2d_117 [[<tf.Tensor 'activation_119_1/Relu:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "concatenate_56 [[<tf.Tensor 'concatenate_55_2/concat:0' shape=(?, 32, 16, 352) dtype=float32>, <tf.Tensor 'conv2d_117_1/convolution:0' shape=(?, 32, 16, 32) dtype=float32>]]\n",
      "[None, 32, 16, 384]\n",
      "batch_normalization_170 [[<tf.Tensor 'concatenate_56_2/concat:0' shape=(?, 32, 16, 384) dtype=float32>]]\n",
      "called 0\n",
      "[384]\n",
      "[384]\n",
      "activation_120 [[<tf.Tensor 'batch_normalization_170_1/cond/Merge:0' shape=(?, 32, 16, 384) dtype=float32>]]\n",
      "conv2d_118 [[<tf.Tensor 'activation_120_1/Relu:0' shape=(?, 32, 16, 384) dtype=float32>]]\n",
      "batch_normalization_171 [[<tf.Tensor 'conv2d_118_1/convolution:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_121 [[<tf.Tensor 'batch_normalization_171_1/cond/Merge:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "conv2d_119 [[<tf.Tensor 'activation_121_1/Relu:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "concatenate_57 [[<tf.Tensor 'concatenate_56_2/concat:0' shape=(?, 32, 16, 384) dtype=float32>, <tf.Tensor 'conv2d_119_1/convolution:0' shape=(?, 32, 16, 32) dtype=float32>]]\n",
      "[None, 32, 16, 416]\n",
      "batch_normalization_172 [[<tf.Tensor 'concatenate_57_2/concat:0' shape=(?, 32, 16, 416) dtype=float32>]]\n",
      "called 0\n",
      "[416]\n",
      "[416]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation_122 [[<tf.Tensor 'batch_normalization_172_1/cond/Merge:0' shape=(?, 32, 16, 416) dtype=float32>]]\n",
      "conv2d_120 [[<tf.Tensor 'activation_122_1/Relu:0' shape=(?, 32, 16, 416) dtype=float32>]]\n",
      "batch_normalization_173 [[<tf.Tensor 'conv2d_120_1/convolution:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_123 [[<tf.Tensor 'batch_normalization_173_1/cond/Merge:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "conv2d_121 [[<tf.Tensor 'activation_123_1/Relu:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "concatenate_58 [[<tf.Tensor 'concatenate_57_2/concat:0' shape=(?, 32, 16, 416) dtype=float32>, <tf.Tensor 'conv2d_121_1/convolution:0' shape=(?, 32, 16, 32) dtype=float32>]]\n",
      "[None, 32, 16, 448]\n",
      "batch_normalization_174 [[<tf.Tensor 'concatenate_58_2/concat:0' shape=(?, 32, 16, 448) dtype=float32>]]\n",
      "called 0\n",
      "[448]\n",
      "[448]\n",
      "activation_124 [[<tf.Tensor 'batch_normalization_174_1/cond/Merge:0' shape=(?, 32, 16, 448) dtype=float32>]]\n",
      "conv2d_122 [[<tf.Tensor 'activation_124_1/Relu:0' shape=(?, 32, 16, 448) dtype=float32>]]\n",
      "batch_normalization_175 [[<tf.Tensor 'conv2d_122_1/convolution:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_125 [[<tf.Tensor 'batch_normalization_175_1/cond/Merge:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "conv2d_123 [[<tf.Tensor 'activation_125_1/Relu:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "concatenate_59 [[<tf.Tensor 'concatenate_58_2/concat:0' shape=(?, 32, 16, 448) dtype=float32>, <tf.Tensor 'conv2d_123_1/convolution:0' shape=(?, 32, 16, 32) dtype=float32>]]\n",
      "[None, 32, 16, 480]\n",
      "batch_normalization_176 [[<tf.Tensor 'concatenate_59_2/concat:0' shape=(?, 32, 16, 480) dtype=float32>]]\n",
      "called 0\n",
      "[480]\n",
      "[480]\n",
      "activation_126 [[<tf.Tensor 'batch_normalization_176_1/cond/Merge:0' shape=(?, 32, 16, 480) dtype=float32>]]\n",
      "conv2d_124 [[<tf.Tensor 'activation_126_1/Relu:0' shape=(?, 32, 16, 480) dtype=float32>]]\n",
      "batch_normalization_177 [[<tf.Tensor 'conv2d_124_1/convolution:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "called 0\n",
      "[128]\n",
      "[128]\n",
      "activation_127 [[<tf.Tensor 'batch_normalization_177_1/cond/Merge:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "conv2d_125 [[<tf.Tensor 'activation_127_1/Relu:0' shape=(?, 32, 16, 128) dtype=float32>]]\n",
      "concatenate_60 [[<tf.Tensor 'concatenate_59_2/concat:0' shape=(?, 32, 16, 480) dtype=float32>, <tf.Tensor 'conv2d_125_1/convolution:0' shape=(?, 32, 16, 32) dtype=float32>]]\n",
      "[None, 32, 16, 512]\n",
      "batch_normalization_178 [[<tf.Tensor 'concatenate_60_2/concat:0' shape=(?, 32, 16, 512) dtype=float32>]]\n",
      "called 0\n",
      "[512]\n",
      "[512]\n",
      "activation_128 [[<tf.Tensor 'batch_normalization_178_1/cond/Merge:0' shape=(?, 32, 16, 512) dtype=float32>]]\n",
      "conv2d_126 [[<tf.Tensor 'activation_128_1/Relu:0' shape=(?, 32, 16, 512) dtype=float32>]]\n",
      "average_pooling2d_4 [[<tf.Tensor 'conv2d_126_1/convolution:0' shape=(?, 32, 16, 256) dtype=float32>]]\n",
      "batch_normalization_90 [[<tf.Tensor 'average_pooling2d_4_1/AvgPool:0' shape=(?, 16, 8, 256) dtype=float32>]]\n",
      "activation_129 [[<tf.Tensor 'batch_normalization_90_1/cond/Merge:0' shape=(?, 16, 8, 256) dtype=float32>]]\n",
      "conv2d_127 [[<tf.Tensor 'activation_129_1/Relu:0' shape=(?, 16, 8, 256) dtype=float32>]]\n",
      "idx [10922, 4]\n",
      "gather [10922]\n",
      "batch_normalization_91 [[<tf.Tensor 'conv2d_127_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "activation_130 [[<tf.Tensor 'batch_normalization_91_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_128 [[<tf.Tensor 'activation_130_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_61 [[<tf.Tensor 'average_pooling2d_4_1/AvgPool:0' shape=(?, 16, 8, 256) dtype=float32>, <tf.Tensor 'conv2d_128_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 288]\n",
      "batch_normalization_92 [[<tf.Tensor 'concatenate_61_2/concat:0' shape=(?, 16, 8, 288) dtype=float32>]]\n",
      "activation_131 [[<tf.Tensor 'batch_normalization_92_1/cond/Merge:0' shape=(?, 16, 8, 288) dtype=float32>]]\n",
      "conv2d_129 [[<tf.Tensor 'activation_131_1/Relu:0' shape=(?, 16, 8, 288) dtype=float32>]]\n",
      "idx [12288, 4]\n",
      "gather [12288]\n",
      "batch_normalization_93 [[<tf.Tensor 'conv2d_129_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "activation_132 [[<tf.Tensor 'batch_normalization_93_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_130 [[<tf.Tensor 'activation_132_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_62 [[<tf.Tensor 'concatenate_61_2/concat:0' shape=(?, 16, 8, 288) dtype=float32>, <tf.Tensor 'conv2d_130_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 320]\n",
      "batch_normalization_94 [[<tf.Tensor 'concatenate_62_2/concat:0' shape=(?, 16, 8, 320) dtype=float32>]]\n",
      "activation_133 [[<tf.Tensor 'batch_normalization_94_1/cond/Merge:0' shape=(?, 16, 8, 320) dtype=float32>]]\n",
      "conv2d_131 [[<tf.Tensor 'activation_133_1/Relu:0' shape=(?, 16, 8, 320) dtype=float32>]]\n",
      "idx [13654, 4]\n",
      "gather [13654]\n",
      "batch_normalization_95 [[<tf.Tensor 'conv2d_131_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "activation_134 [[<tf.Tensor 'batch_normalization_95_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_132 [[<tf.Tensor 'activation_134_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_63 [[<tf.Tensor 'concatenate_62_2/concat:0' shape=(?, 16, 8, 320) dtype=float32>, <tf.Tensor 'conv2d_132_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 352]\n",
      "batch_normalization_96 [[<tf.Tensor 'concatenate_63_2/concat:0' shape=(?, 16, 8, 352) dtype=float32>]]\n",
      "activation_135 [[<tf.Tensor 'batch_normalization_96_1/cond/Merge:0' shape=(?, 16, 8, 352) dtype=float32>]]\n",
      "conv2d_133 [[<tf.Tensor 'activation_135_1/Relu:0' shape=(?, 16, 8, 352) dtype=float32>]]\n",
      "idx [15020, 4]\n",
      "gather [15020]\n",
      "batch_normalization_97 [[<tf.Tensor 'conv2d_133_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "activation_136 [[<tf.Tensor 'batch_normalization_97_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_134 [[<tf.Tensor 'activation_136_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_64 [[<tf.Tensor 'concatenate_63_2/concat:0' shape=(?, 16, 8, 352) dtype=float32>, <tf.Tensor 'conv2d_134_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 384]\n",
      "batch_normalization_98 [[<tf.Tensor 'concatenate_64_2/concat:0' shape=(?, 16, 8, 384) dtype=float32>]]\n",
      "activation_137 [[<tf.Tensor 'batch_normalization_98_1/cond/Merge:0' shape=(?, 16, 8, 384) dtype=float32>]]\n",
      "conv2d_135 [[<tf.Tensor 'activation_137_1/Relu:0' shape=(?, 16, 8, 384) dtype=float32>]]\n",
      "idx [16386, 4]\n",
      "gather [16386]\n",
      "batch_normalization_99 [[<tf.Tensor 'conv2d_135_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "activation_138 [[<tf.Tensor 'batch_normalization_99_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_136 [[<tf.Tensor 'activation_138_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_65 [[<tf.Tensor 'concatenate_64_2/concat:0' shape=(?, 16, 8, 384) dtype=float32>, <tf.Tensor 'conv2d_136_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 416]\n",
      "batch_normalization_100 [[<tf.Tensor 'concatenate_65_2/concat:0' shape=(?, 16, 8, 416) dtype=float32>]]\n",
      "activation_139 [[<tf.Tensor 'batch_normalization_100_1/cond/Merge:0' shape=(?, 16, 8, 416) dtype=float32>]]\n",
      "conv2d_137 [[<tf.Tensor 'activation_139_1/Relu:0' shape=(?, 16, 8, 416) dtype=float32>]]\n",
      "idx [17752, 4]\n",
      "gather [17752]\n",
      "batch_normalization_101 [[<tf.Tensor 'conv2d_137_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "activation_140 [[<tf.Tensor 'batch_normalization_101_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_138 [[<tf.Tensor 'activation_140_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_66 [[<tf.Tensor 'concatenate_65_2/concat:0' shape=(?, 16, 8, 416) dtype=float32>, <tf.Tensor 'conv2d_138_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 448]\n",
      "batch_normalization_102 [[<tf.Tensor 'concatenate_66_2/concat:0' shape=(?, 16, 8, 448) dtype=float32>]]\n",
      "activation_141 [[<tf.Tensor 'batch_normalization_102_1/cond/Merge:0' shape=(?, 16, 8, 448) dtype=float32>]]\n",
      "conv2d_139 [[<tf.Tensor 'activation_141_1/Relu:0' shape=(?, 16, 8, 448) dtype=float32>]]\n",
      "idx [19118, 4]\n",
      "gather [19118]\n",
      "batch_normalization_103 [[<tf.Tensor 'conv2d_139_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "activation_142 [[<tf.Tensor 'batch_normalization_103_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_140 [[<tf.Tensor 'activation_142_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_67 [[<tf.Tensor 'concatenate_66_2/concat:0' shape=(?, 16, 8, 448) dtype=float32>, <tf.Tensor 'conv2d_140_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 480]\n",
      "batch_normalization_104 [[<tf.Tensor 'concatenate_67_2/concat:0' shape=(?, 16, 8, 480) dtype=float32>]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation_143 [[<tf.Tensor 'batch_normalization_104_1/cond/Merge:0' shape=(?, 16, 8, 480) dtype=float32>]]\n",
      "conv2d_141 [[<tf.Tensor 'activation_143_1/Relu:0' shape=(?, 16, 8, 480) dtype=float32>]]\n",
      "idx [20484, 4]\n",
      "gather [20484]\n",
      "batch_normalization_105 [[<tf.Tensor 'conv2d_141_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "activation_144 [[<tf.Tensor 'batch_normalization_105_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_142 [[<tf.Tensor 'activation_144_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_68 [[<tf.Tensor 'concatenate_67_2/concat:0' shape=(?, 16, 8, 480) dtype=float32>, <tf.Tensor 'conv2d_142_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 512]\n",
      "batch_normalization_106 [[<tf.Tensor 'concatenate_68_2/concat:0' shape=(?, 16, 8, 512) dtype=float32>]]\n",
      "activation_145 [[<tf.Tensor 'batch_normalization_106_1/cond/Merge:0' shape=(?, 16, 8, 512) dtype=float32>]]\n",
      "conv2d_143 [[<tf.Tensor 'activation_145_1/Relu:0' shape=(?, 16, 8, 512) dtype=float32>]]\n",
      "idx [21850, 4]\n",
      "gather [21850]\n",
      "batch_normalization_107 [[<tf.Tensor 'conv2d_143_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "activation_146 [[<tf.Tensor 'batch_normalization_107_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_144 [[<tf.Tensor 'activation_146_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_69 [[<tf.Tensor 'concatenate_68_2/concat:0' shape=(?, 16, 8, 512) dtype=float32>, <tf.Tensor 'conv2d_144_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 544]\n",
      "batch_normalization_108 [[<tf.Tensor 'concatenate_69_2/concat:0' shape=(?, 16, 8, 544) dtype=float32>]]\n",
      "activation_147 [[<tf.Tensor 'batch_normalization_108_1/cond/Merge:0' shape=(?, 16, 8, 544) dtype=float32>]]\n",
      "conv2d_145 [[<tf.Tensor 'activation_147_1/Relu:0' shape=(?, 16, 8, 544) dtype=float32>]]\n",
      "idx [23216, 4]\n",
      "gather [23216]\n",
      "batch_normalization_109 [[<tf.Tensor 'conv2d_145_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "activation_148 [[<tf.Tensor 'batch_normalization_109_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_146 [[<tf.Tensor 'activation_148_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_70 [[<tf.Tensor 'concatenate_69_2/concat:0' shape=(?, 16, 8, 544) dtype=float32>, <tf.Tensor 'conv2d_146_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 576]\n",
      "batch_normalization_110 [[<tf.Tensor 'concatenate_70_2/concat:0' shape=(?, 16, 8, 576) dtype=float32>]]\n",
      "activation_149 [[<tf.Tensor 'batch_normalization_110_1/cond/Merge:0' shape=(?, 16, 8, 576) dtype=float32>]]\n",
      "conv2d_147 [[<tf.Tensor 'activation_149_1/Relu:0' shape=(?, 16, 8, 576) dtype=float32>]]\n",
      "idx [24582, 4]\n",
      "gather [24582]\n",
      "batch_normalization_111 [[<tf.Tensor 'conv2d_147_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "activation_150 [[<tf.Tensor 'batch_normalization_111_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_148 [[<tf.Tensor 'activation_150_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_71 [[<tf.Tensor 'concatenate_70_2/concat:0' shape=(?, 16, 8, 576) dtype=float32>, <tf.Tensor 'conv2d_148_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 608]\n",
      "batch_normalization_112 [[<tf.Tensor 'concatenate_71_2/concat:0' shape=(?, 16, 8, 608) dtype=float32>]]\n",
      "activation_151 [[<tf.Tensor 'batch_normalization_112_1/cond/Merge:0' shape=(?, 16, 8, 608) dtype=float32>]]\n",
      "conv2d_149 [[<tf.Tensor 'activation_151_1/Relu:0' shape=(?, 16, 8, 608) dtype=float32>]]\n",
      "idx [25948, 4]\n",
      "gather [25948]\n",
      "batch_normalization_113 [[<tf.Tensor 'conv2d_149_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "activation_152 [[<tf.Tensor 'batch_normalization_113_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_150 [[<tf.Tensor 'activation_152_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_72 [[<tf.Tensor 'concatenate_71_2/concat:0' shape=(?, 16, 8, 608) dtype=float32>, <tf.Tensor 'conv2d_150_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 640]\n",
      "batch_normalization_114 [[<tf.Tensor 'concatenate_72_2/concat:0' shape=(?, 16, 8, 640) dtype=float32>]]\n",
      "activation_153 [[<tf.Tensor 'batch_normalization_114_1/cond/Merge:0' shape=(?, 16, 8, 640) dtype=float32>]]\n",
      "conv2d_151 [[<tf.Tensor 'activation_153_1/Relu:0' shape=(?, 16, 8, 640) dtype=float32>]]\n",
      "idx [27314, 4]\n",
      "gather [27314]\n",
      "batch_normalization_115 [[<tf.Tensor 'conv2d_151_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "activation_154 [[<tf.Tensor 'batch_normalization_115_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_152 [[<tf.Tensor 'activation_154_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_73 [[<tf.Tensor 'concatenate_72_2/concat:0' shape=(?, 16, 8, 640) dtype=float32>, <tf.Tensor 'conv2d_152_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 672]\n",
      "batch_normalization_116 [[<tf.Tensor 'concatenate_73_2/concat:0' shape=(?, 16, 8, 672) dtype=float32>]]\n",
      "activation_155 [[<tf.Tensor 'batch_normalization_116_1/cond/Merge:0' shape=(?, 16, 8, 672) dtype=float32>]]\n",
      "conv2d_153 [[<tf.Tensor 'activation_155_1/Relu:0' shape=(?, 16, 8, 672) dtype=float32>]]\n",
      "idx [28680, 4]\n",
      "gather [28680]\n",
      "batch_normalization_117 [[<tf.Tensor 'conv2d_153_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "activation_156 [[<tf.Tensor 'batch_normalization_117_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_154 [[<tf.Tensor 'activation_156_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_74 [[<tf.Tensor 'concatenate_73_2/concat:0' shape=(?, 16, 8, 672) dtype=float32>, <tf.Tensor 'conv2d_154_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 704]\n",
      "batch_normalization_118 [[<tf.Tensor 'concatenate_74_2/concat:0' shape=(?, 16, 8, 704) dtype=float32>]]\n",
      "activation_157 [[<tf.Tensor 'batch_normalization_118_1/cond/Merge:0' shape=(?, 16, 8, 704) dtype=float32>]]\n",
      "conv2d_155 [[<tf.Tensor 'activation_157_1/Relu:0' shape=(?, 16, 8, 704) dtype=float32>]]\n",
      "idx [30046, 4]\n",
      "gather [30046]\n",
      "batch_normalization_119 [[<tf.Tensor 'conv2d_155_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "activation_158 [[<tf.Tensor 'batch_normalization_119_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_156 [[<tf.Tensor 'activation_158_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_75 [[<tf.Tensor 'concatenate_74_2/concat:0' shape=(?, 16, 8, 704) dtype=float32>, <tf.Tensor 'conv2d_156_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 736]\n",
      "batch_normalization_120 [[<tf.Tensor 'concatenate_75_2/concat:0' shape=(?, 16, 8, 736) dtype=float32>]]\n",
      "activation_159 [[<tf.Tensor 'batch_normalization_120_1/cond/Merge:0' shape=(?, 16, 8, 736) dtype=float32>]]\n",
      "conv2d_157 [[<tf.Tensor 'activation_159_1/Relu:0' shape=(?, 16, 8, 736) dtype=float32>]]\n",
      "idx [31412, 4]\n",
      "gather [31412]\n",
      "batch_normalization_121 [[<tf.Tensor 'conv2d_157_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "activation_160 [[<tf.Tensor 'batch_normalization_121_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_158 [[<tf.Tensor 'activation_160_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_76 [[<tf.Tensor 'concatenate_75_2/concat:0' shape=(?, 16, 8, 736) dtype=float32>, <tf.Tensor 'conv2d_158_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 768]\n",
      "batch_normalization_122 [[<tf.Tensor 'concatenate_76_2/concat:0' shape=(?, 16, 8, 768) dtype=float32>]]\n",
      "activation_161 [[<tf.Tensor 'batch_normalization_122_1/cond/Merge:0' shape=(?, 16, 8, 768) dtype=float32>]]\n",
      "conv2d_159 [[<tf.Tensor 'activation_161_1/Relu:0' shape=(?, 16, 8, 768) dtype=float32>]]\n",
      "idx [32778, 4]\n",
      "gather [32778]\n",
      "batch_normalization_123 [[<tf.Tensor 'conv2d_159_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "activation_162 [[<tf.Tensor 'batch_normalization_123_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_160 [[<tf.Tensor 'activation_162_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_77 [[<tf.Tensor 'concatenate_76_2/concat:0' shape=(?, 16, 8, 768) dtype=float32>, <tf.Tensor 'conv2d_160_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 800]\n",
      "batch_normalization_124 [[<tf.Tensor 'concatenate_77_2/concat:0' shape=(?, 16, 8, 800) dtype=float32>]]\n",
      "activation_163 [[<tf.Tensor 'batch_normalization_124_1/cond/Merge:0' shape=(?, 16, 8, 800) dtype=float32>]]\n",
      "conv2d_161 [[<tf.Tensor 'activation_163_1/Relu:0' shape=(?, 16, 8, 800) dtype=float32>]]\n",
      "idx [34144, 4]\n",
      "gather [34144]\n",
      "batch_normalization_125 [[<tf.Tensor 'conv2d_161_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "activation_164 [[<tf.Tensor 'batch_normalization_125_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_162 [[<tf.Tensor 'activation_164_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_78 [[<tf.Tensor 'concatenate_77_2/concat:0' shape=(?, 16, 8, 800) dtype=float32>, <tf.Tensor 'conv2d_162_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 832]\n",
      "batch_normalization_126 [[<tf.Tensor 'concatenate_78_2/concat:0' shape=(?, 16, 8, 832) dtype=float32>]]\n",
      "activation_165 [[<tf.Tensor 'batch_normalization_126_1/cond/Merge:0' shape=(?, 16, 8, 832) dtype=float32>]]\n",
      "conv2d_163 [[<tf.Tensor 'activation_165_1/Relu:0' shape=(?, 16, 8, 832) dtype=float32>]]\n",
      "idx [35510, 4]\n",
      "gather [35510]\n",
      "batch_normalization_127 [[<tf.Tensor 'conv2d_163_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "activation_166 [[<tf.Tensor 'batch_normalization_127_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_164 [[<tf.Tensor 'activation_166_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_79 [[<tf.Tensor 'concatenate_78_2/concat:0' shape=(?, 16, 8, 832) dtype=float32>, <tf.Tensor 'conv2d_164_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 864]\n",
      "batch_normalization_128 [[<tf.Tensor 'concatenate_79_2/concat:0' shape=(?, 16, 8, 864) dtype=float32>]]\n",
      "activation_167 [[<tf.Tensor 'batch_normalization_128_1/cond/Merge:0' shape=(?, 16, 8, 864) dtype=float32>]]\n",
      "conv2d_165 [[<tf.Tensor 'activation_167_1/Relu:0' shape=(?, 16, 8, 864) dtype=float32>]]\n",
      "idx [36876, 4]\n",
      "gather [36876]\n",
      "batch_normalization_129 [[<tf.Tensor 'conv2d_165_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "activation_168 [[<tf.Tensor 'batch_normalization_129_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_166 [[<tf.Tensor 'activation_168_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_80 [[<tf.Tensor 'concatenate_79_2/concat:0' shape=(?, 16, 8, 864) dtype=float32>, <tf.Tensor 'conv2d_166_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 896]\n",
      "batch_normalization_130 [[<tf.Tensor 'concatenate_80_2/concat:0' shape=(?, 16, 8, 896) dtype=float32>]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation_169 [[<tf.Tensor 'batch_normalization_130_1/cond/Merge:0' shape=(?, 16, 8, 896) dtype=float32>]]\n",
      "conv2d_167 [[<tf.Tensor 'activation_169_1/Relu:0' shape=(?, 16, 8, 896) dtype=float32>]]\n",
      "idx [38242, 4]\n",
      "gather [38242]\n",
      "batch_normalization_131 [[<tf.Tensor 'conv2d_167_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "activation_170 [[<tf.Tensor 'batch_normalization_131_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_168 [[<tf.Tensor 'activation_170_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_81 [[<tf.Tensor 'concatenate_80_2/concat:0' shape=(?, 16, 8, 896) dtype=float32>, <tf.Tensor 'conv2d_168_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 928]\n",
      "batch_normalization_132 [[<tf.Tensor 'concatenate_81_2/concat:0' shape=(?, 16, 8, 928) dtype=float32>]]\n",
      "activation_171 [[<tf.Tensor 'batch_normalization_132_1/cond/Merge:0' shape=(?, 16, 8, 928) dtype=float32>]]\n",
      "conv2d_169 [[<tf.Tensor 'activation_171_1/Relu:0' shape=(?, 16, 8, 928) dtype=float32>]]\n",
      "idx [39608, 4]\n",
      "gather [39608]\n",
      "batch_normalization_133 [[<tf.Tensor 'conv2d_169_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "activation_172 [[<tf.Tensor 'batch_normalization_133_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_170 [[<tf.Tensor 'activation_172_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_82 [[<tf.Tensor 'concatenate_81_2/concat:0' shape=(?, 16, 8, 928) dtype=float32>, <tf.Tensor 'conv2d_170_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 960]\n",
      "batch_normalization_134 [[<tf.Tensor 'concatenate_82_2/concat:0' shape=(?, 16, 8, 960) dtype=float32>]]\n",
      "activation_173 [[<tf.Tensor 'batch_normalization_134_1/cond/Merge:0' shape=(?, 16, 8, 960) dtype=float32>]]\n",
      "conv2d_171 [[<tf.Tensor 'activation_173_1/Relu:0' shape=(?, 16, 8, 960) dtype=float32>]]\n",
      "idx [40974, 4]\n",
      "gather [40974]\n",
      "batch_normalization_135 [[<tf.Tensor 'conv2d_171_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "activation_174 [[<tf.Tensor 'batch_normalization_135_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_172 [[<tf.Tensor 'activation_174_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_83 [[<tf.Tensor 'concatenate_82_2/concat:0' shape=(?, 16, 8, 960) dtype=float32>, <tf.Tensor 'conv2d_172_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 992]\n",
      "batch_normalization_136 [[<tf.Tensor 'concatenate_83_2/concat:0' shape=(?, 16, 8, 992) dtype=float32>]]\n",
      "activation_175 [[<tf.Tensor 'batch_normalization_136_1/cond/Merge:0' shape=(?, 16, 8, 992) dtype=float32>]]\n",
      "conv2d_173 [[<tf.Tensor 'activation_175_1/Relu:0' shape=(?, 16, 8, 992) dtype=float32>]]\n",
      "idx [42340, 4]\n",
      "gather [42340]\n",
      "batch_normalization_137 [[<tf.Tensor 'conv2d_173_1/convolution:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "activation_176 [[<tf.Tensor 'batch_normalization_137_1/cond/Merge:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "conv2d_174 [[<tf.Tensor 'activation_176_1/Relu:0' shape=(?, 16, 8, 128) dtype=float32>]]\n",
      "concatenate_84 [[<tf.Tensor 'concatenate_83_2/concat:0' shape=(?, 16, 8, 992) dtype=float32>, <tf.Tensor 'conv2d_174_1/convolution:0' shape=(?, 16, 8, 32) dtype=float32>]]\n",
      "[None, 16, 8, 1024]\n",
      "batch_normalization_138 [[<tf.Tensor 'concatenate_84_2/concat:0' shape=(?, 16, 8, 1024) dtype=float32>]]\n",
      "activation_177 [[<tf.Tensor 'batch_normalization_138_1/cond/Merge:0' shape=(?, 16, 8, 1024) dtype=float32>]]\n",
      "global_average_pooling2d_2 [[<tf.Tensor 'activation_177_1/Relu:0' shape=(?, 16, 8, 1024) dtype=float32>]]\n",
      "dense_3 [[<tf.Tensor 'global_average_pooling2d_2_1/Mean:0' shape=(?, 1024) dtype=float32>]]\n",
      "batch_normalization_139 [[<tf.Tensor 'dense_3_1/BiasAdd:0' shape=(?, 1024) dtype=float32>]]\n",
      "activation_178 [[<tf.Tensor 'batch_normalization_139_1/cond/Merge:0' shape=(?, 1024) dtype=float32>]]\n",
      "dense_4 [[<tf.Tensor 'activation_178_1/Relu:0' shape=(?, 1024) dtype=float32>]]\n"
     ]
    }
   ],
   "source": [
    "model, _, _ = models.DenseNetDrop(P_param=P_param, K_param=K_param,\n",
    "                                    weights=None, diagnostic=True, \n",
    "                                  blocks=3, tile=True)\n",
    "\n",
    "# model, _, _ = models_bk2.DenseNet121Drop(P_param=P_param, K_param=K_param,\n",
    "#                                     weights='imagenet', diagnostic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_2 []\n",
      "1 conv2d_88 [[['input_2' '0']]]\n",
      "2 batch_normalization_140 [[['conv2d_88' '0']]]\n",
      "3 activation_90 [[['batch_normalization_140' '0']]]\n",
      "4 max_pooling2d_2 [[['activation_90' '0']]]\n",
      "5 batch_normalization_141 [[['max_pooling2d_2' '0']]]\n",
      "6 activation_91 [[['batch_normalization_141' '0']]]\n",
      "7 conv2d_89 [[['activation_91' '0']]]\n",
      "8 batch_normalization_142 [[['conv2d_89' '0']]]\n",
      "9 activation_92 [[['batch_normalization_142' '0']]]\n",
      "10 conv2d_90 [[['activation_92' '0']]]\n",
      "11 concatenate_43 [[['max_pooling2d_2' '0']\n",
      "  ['conv2d_90' '0']]]\n",
      "12 batch_normalization_143 [[['concatenate_43' '0']]]\n",
      "13 activation_93 [[['batch_normalization_143' '0']]]\n",
      "14 conv2d_91 [[['activation_93' '0']]]\n",
      "15 batch_normalization_144 [[['conv2d_91' '0']]]\n",
      "16 activation_94 [[['batch_normalization_144' '0']]]\n",
      "17 conv2d_92 [[['activation_94' '0']]]\n",
      "18 concatenate_44 [[['concatenate_43' '0']\n",
      "  ['conv2d_92' '0']]]\n",
      "19 batch_normalization_145 [[['concatenate_44' '0']]]\n",
      "20 activation_95 [[['batch_normalization_145' '0']]]\n",
      "21 conv2d_93 [[['activation_95' '0']]]\n",
      "22 batch_normalization_146 [[['conv2d_93' '0']]]\n",
      "23 activation_96 [[['batch_normalization_146' '0']]]\n",
      "24 conv2d_94 [[['activation_96' '0']]]\n",
      "25 concatenate_45 [[['concatenate_44' '0']\n",
      "  ['conv2d_94' '0']]]\n",
      "26 batch_normalization_147 [[['concatenate_45' '0']]]\n",
      "27 activation_97 [[['batch_normalization_147' '0']]]\n",
      "28 conv2d_95 [[['activation_97' '0']]]\n",
      "29 batch_normalization_148 [[['conv2d_95' '0']]]\n",
      "30 activation_98 [[['batch_normalization_148' '0']]]\n",
      "31 conv2d_96 [[['activation_98' '0']]]\n",
      "32 concatenate_46 [[['concatenate_45' '0']\n",
      "  ['conv2d_96' '0']]]\n",
      "33 batch_normalization_149 [[['concatenate_46' '0']]]\n",
      "34 activation_99 [[['batch_normalization_149' '0']]]\n",
      "35 conv2d_97 [[['activation_99' '0']]]\n",
      "36 batch_normalization_150 [[['conv2d_97' '0']]]\n",
      "37 activation_100 [[['batch_normalization_150' '0']]]\n",
      "38 conv2d_98 [[['activation_100' '0']]]\n",
      "39 concatenate_47 [[['concatenate_46' '0']\n",
      "  ['conv2d_98' '0']]]\n",
      "40 batch_normalization_151 [[['concatenate_47' '0']]]\n",
      "41 activation_101 [[['batch_normalization_151' '0']]]\n",
      "42 conv2d_99 [[['activation_101' '0']]]\n",
      "43 batch_normalization_152 [[['conv2d_99' '0']]]\n",
      "44 activation_102 [[['batch_normalization_152' '0']]]\n",
      "45 conv2d_100 [[['activation_102' '0']]]\n",
      "46 concatenate_48 [[['concatenate_47' '0']\n",
      "  ['conv2d_100' '0']]]\n",
      "47 batch_normalization_153 [[['concatenate_48' '0']]]\n",
      "48 activation_103 [[['batch_normalization_153' '0']]]\n",
      "49 conv2d_101 [[['activation_103' '0']]]\n",
      "50 average_pooling2d_3 [[['conv2d_101' '0']]]\n",
      "51 batch_normalization_154 [[['average_pooling2d_3' '0']]]\n",
      "52 activation_104 [[['batch_normalization_154' '0']]]\n",
      "53 conv2d_102 [[['activation_104' '0']]]\n",
      "54 batch_normalization_155 [[['conv2d_102' '0']]]\n",
      "55 activation_105 [[['batch_normalization_155' '0']]]\n",
      "56 conv2d_103 [[['activation_105' '0']]]\n",
      "57 concatenate_49 [[['average_pooling2d_3' '0']\n",
      "  ['conv2d_103' '0']]]\n",
      "58 batch_normalization_156 [[['concatenate_49' '0']]]\n",
      "59 activation_106 [[['batch_normalization_156' '0']]]\n",
      "60 conv2d_104 [[['activation_106' '0']]]\n",
      "61 batch_normalization_157 [[['conv2d_104' '0']]]\n",
      "62 activation_107 [[['batch_normalization_157' '0']]]\n",
      "63 conv2d_105 [[['activation_107' '0']]]\n",
      "64 concatenate_50 [[['concatenate_49' '0']\n",
      "  ['conv2d_105' '0']]]\n",
      "65 batch_normalization_158 [[['concatenate_50' '0']]]\n",
      "66 activation_108 [[['batch_normalization_158' '0']]]\n",
      "67 conv2d_106 [[['activation_108' '0']]]\n",
      "68 batch_normalization_159 [[['conv2d_106' '0']]]\n",
      "69 activation_109 [[['batch_normalization_159' '0']]]\n",
      "70 conv2d_107 [[['activation_109' '0']]]\n",
      "71 concatenate_51 [[['concatenate_50' '0']\n",
      "  ['conv2d_107' '0']]]\n",
      "72 batch_normalization_160 [[['concatenate_51' '0']]]\n",
      "73 activation_110 [[['batch_normalization_160' '0']]]\n",
      "74 conv2d_108 [[['activation_110' '0']]]\n",
      "75 batch_normalization_161 [[['conv2d_108' '0']]]\n",
      "76 activation_111 [[['batch_normalization_161' '0']]]\n",
      "77 conv2d_109 [[['activation_111' '0']]]\n",
      "78 concatenate_52 [[['concatenate_51' '0']\n",
      "  ['conv2d_109' '0']]]\n",
      "79 batch_normalization_162 [[['concatenate_52' '0']]]\n",
      "80 activation_112 [[['batch_normalization_162' '0']]]\n",
      "81 conv2d_110 [[['activation_112' '0']]]\n",
      "82 batch_normalization_163 [[['conv2d_110' '0']]]\n",
      "83 activation_113 [[['batch_normalization_163' '0']]]\n",
      "84 conv2d_111 [[['activation_113' '0']]]\n",
      "85 concatenate_53 [[['concatenate_52' '0']\n",
      "  ['conv2d_111' '0']]]\n",
      "86 batch_normalization_164 [[['concatenate_53' '0']]]\n",
      "87 activation_114 [[['batch_normalization_164' '0']]]\n",
      "88 conv2d_112 [[['activation_114' '0']]]\n",
      "89 batch_normalization_165 [[['conv2d_112' '0']]]\n",
      "90 activation_115 [[['batch_normalization_165' '0']]]\n",
      "91 conv2d_113 [[['activation_115' '0']]]\n",
      "92 concatenate_54 [[['concatenate_53' '0']\n",
      "  ['conv2d_113' '0']]]\n",
      "93 batch_normalization_166 [[['concatenate_54' '0']]]\n",
      "94 activation_116 [[['batch_normalization_166' '0']]]\n",
      "95 conv2d_114 [[['activation_116' '0']]]\n",
      "96 batch_normalization_167 [[['conv2d_114' '0']]]\n",
      "97 activation_117 [[['batch_normalization_167' '0']]]\n",
      "98 conv2d_115 [[['activation_117' '0']]]\n",
      "99 concatenate_55 [[['concatenate_54' '0']\n",
      "  ['conv2d_115' '0']]]\n",
      "100 batch_normalization_168 [[['concatenate_55' '0']]]\n",
      "101 activation_118 [[['batch_normalization_168' '0']]]\n",
      "102 conv2d_116 [[['activation_118' '0']]]\n",
      "103 batch_normalization_169 [[['conv2d_116' '0']]]\n",
      "104 activation_119 [[['batch_normalization_169' '0']]]\n",
      "105 conv2d_117 [[['activation_119' '0']]]\n",
      "106 concatenate_56 [[['concatenate_55' '0']\n",
      "  ['conv2d_117' '0']]]\n",
      "107 batch_normalization_170 [[['concatenate_56' '0']]]\n",
      "108 activation_120 [[['batch_normalization_170' '0']]]\n",
      "109 conv2d_118 [[['activation_120' '0']]]\n",
      "110 batch_normalization_171 [[['conv2d_118' '0']]]\n",
      "111 activation_121 [[['batch_normalization_171' '0']]]\n",
      "112 conv2d_119 [[['activation_121' '0']]]\n",
      "113 concatenate_57 [[['concatenate_56' '0']\n",
      "  ['conv2d_119' '0']]]\n",
      "114 batch_normalization_172 [[['concatenate_57' '0']]]\n",
      "115 activation_122 [[['batch_normalization_172' '0']]]\n",
      "116 conv2d_120 [[['activation_122' '0']]]\n",
      "117 batch_normalization_173 [[['conv2d_120' '0']]]\n",
      "118 activation_123 [[['batch_normalization_173' '0']]]\n",
      "119 conv2d_121 [[['activation_123' '0']]]\n",
      "120 concatenate_58 [[['concatenate_57' '0']\n",
      "  ['conv2d_121' '0']]]\n",
      "121 batch_normalization_174 [[['concatenate_58' '0']]]\n",
      "122 activation_124 [[['batch_normalization_174' '0']]]\n",
      "123 conv2d_122 [[['activation_124' '0']]]\n",
      "124 batch_normalization_175 [[['conv2d_122' '0']]]\n",
      "125 activation_125 [[['batch_normalization_175' '0']]]\n",
      "126 conv2d_123 [[['activation_125' '0']]]\n",
      "127 concatenate_59 [[['concatenate_58' '0']\n",
      "  ['conv2d_123' '0']]]\n",
      "128 batch_normalization_176 [[['concatenate_59' '0']]]\n",
      "129 activation_126 [[['batch_normalization_176' '0']]]\n",
      "130 conv2d_124 [[['activation_126' '0']]]\n",
      "131 batch_normalization_177 [[['conv2d_124' '0']]]\n",
      "132 activation_127 [[['batch_normalization_177' '0']]]\n",
      "133 conv2d_125 [[['activation_127' '0']]]\n",
      "134 concatenate_60 [[['concatenate_59' '0']\n",
      "  ['conv2d_125' '0']]]\n",
      "135 batch_normalization_178 [[['concatenate_60' '0']]]\n",
      "136 activation_128 [[['batch_normalization_178' '0']]]\n",
      "137 conv2d_126 [[['activation_128' '0']]]\n",
      "138 average_pooling2d_4 [[['conv2d_126' '0']]]\n",
      "139 ip_139 [[[]]]\n",
      "140 l_140 [[['average_pooling2d_4' '0']\n",
      "  ['ip_139' '0']]]\n",
      "141 ip_141 [[[]]]\n",
      "142 l_142 [[['average_pooling2d_4' '0']\n",
      "  ['ip_141' '0']]]\n",
      "143 ip_143 [[[]]]\n",
      "144 l_144 [[['average_pooling2d_4' '0']\n",
      "  ['ip_143' '0']]]\n",
      "145 batch_normalization_90 [[['l_140' '0']]\n",
      "\n",
      " [['l_142' '0']]\n",
      "\n",
      " [['l_144' '0']]]\n",
      "146 ip_146 [[[]]]\n",
      "147 l_147 [[['batch_normalization_90' '0']\n",
      "  ['ip_146' '0']]]\n",
      "148 ip_148 [[[]]]\n",
      "149 l_149 [[['batch_normalization_90' '1']\n",
      "  ['ip_148' '0']]]\n",
      "150 ip_150 [[[]]]\n",
      "151 l_151 [[['batch_normalization_90' '2']\n",
      "  ['ip_150' '0']]]\n",
      "152 activation_129 [[['l_147' '0']]\n",
      "\n",
      " [['l_149' '0']]\n",
      "\n",
      " [['l_151' '0']]]\n",
      "153 ip_153 [[[]]]\n",
      "154 l_154 [[['activation_129' '0']\n",
      "  ['ip_153' '0']]]\n",
      "155 ip_155 [[[]]]\n",
      "156 l_156 [[['activation_129' '1']\n",
      "  ['ip_155' '0']]]\n",
      "157 ip_157 [[[]]]\n",
      "158 l_158 [[['activation_129' '2']\n",
      "  ['ip_157' '0']]]\n",
      "159 conv2d_127 [[['l_154' '0']]\n",
      "\n",
      " [['l_156' '0']]\n",
      "\n",
      " [['l_158' '0']]]\n",
      "160 ip_160 [[[]]]\n",
      "161 l_161 [[['conv2d_127' '0']\n",
      "  ['ip_160' '0']]]\n",
      "162 ip_162 [[[]]]\n",
      "163 l_163 [[['conv2d_127' '1']\n",
      "  ['ip_162' '0']]]\n",
      "164 ip_164 [[[]]]\n",
      "165 l_165 [[['conv2d_127' '2']\n",
      "  ['ip_164' '0']]]\n",
      "166 batch_normalization_91 [[['l_161' '0']]\n",
      "\n",
      " [['l_163' '0']]\n",
      "\n",
      " [['l_165' '0']]]\n",
      "167 ip_167 [[[]]]\n",
      "168 l_168 [[['batch_normalization_91' '0']\n",
      "  ['ip_167' '0']]]\n",
      "169 ip_169 [[[]]]\n",
      "170 l_170 [[['batch_normalization_91' '1']\n",
      "  ['ip_169' '0']]]\n",
      "171 ip_171 [[[]]]\n",
      "172 l_172 [[['batch_normalization_91' '2']\n",
      "  ['ip_171' '0']]]\n",
      "173 activation_130 [[['l_168' '0']]\n",
      "\n",
      " [['l_170' '0']]\n",
      "\n",
      " [['l_172' '0']]]\n",
      "174 ip_174 [[[]]]\n",
      "175 l_175 [[['activation_130' '0']\n",
      "  ['ip_174' '0']]]\n",
      "176 ip_176 [[[]]]\n",
      "177 l_177 [[['activation_130' '1']\n",
      "  ['ip_176' '0']]]\n",
      "178 ip_178 [[[]]]\n",
      "179 l_179 [[['activation_130' '2']\n",
      "  ['ip_178' '0']]]\n",
      "180 conv2d_128 [[['l_175' '0']]\n",
      "\n",
      " [['l_177' '0']]\n",
      "\n",
      " [['l_179' '0']]]\n",
      "181 ip_181 [[[]]]\n",
      "182 l_182 [[['conv2d_128' '0']\n",
      "  ['ip_181' '0']]]\n",
      "183 ip_183 [[[]]]\n",
      "184 l_184 [[['conv2d_128' '1']\n",
      "  ['ip_183' '0']]]\n",
      "185 ip_185 [[[]]]\n",
      "186 l_186 [[['conv2d_128' '2']\n",
      "  ['ip_185' '0']]]\n",
      "187 concatenate_61 [[['average_pooling2d_4' '0']\n",
      "  ['l_182' '0']]\n",
      "\n",
      " [['average_pooling2d_4' '0']\n",
      "  ['l_184' '0']]\n",
      "\n",
      " [['average_pooling2d_4' '0']\n",
      "  ['l_186' '0']]]\n",
      "188 batch_normalization_92 [[['concatenate_61' '0']]\n",
      "\n",
      " [['concatenate_61' '1']]\n",
      "\n",
      " [['concatenate_61' '2']]]\n",
      "189 ip_189 [[[]]]\n",
      "190 l_190 [[['batch_normalization_92' '0']\n",
      "  ['ip_189' '0']]]\n",
      "191 ip_191 [[[]]]\n",
      "192 l_192 [[['batch_normalization_92' '1']\n",
      "  ['ip_191' '0']]]\n",
      "193 ip_193 [[[]]]\n",
      "194 l_194 [[['batch_normalization_92' '2']\n",
      "  ['ip_193' '0']]]\n",
      "195 activation_131 [[['l_190' '0']]\n",
      "\n",
      " [['l_192' '0']]\n",
      "\n",
      " [['l_194' '0']]]\n",
      "196 ip_196 [[[]]]\n",
      "197 l_197 [[['activation_131' '0']\n",
      "  ['ip_196' '0']]]\n",
      "198 ip_198 [[[]]]\n",
      "199 l_199 [[['activation_131' '1']\n",
      "  ['ip_198' '0']]]\n",
      "200 ip_200 [[[]]]\n",
      "201 l_201 [[['activation_131' '2']\n",
      "  ['ip_200' '0']]]\n",
      "202 conv2d_129 [[['l_197' '0']]\n",
      "\n",
      " [['l_199' '0']]\n",
      "\n",
      " [['l_201' '0']]]\n",
      "203 ip_203 [[[]]]\n",
      "204 l_204 [[['conv2d_129' '0']\n",
      "  ['ip_203' '0']]]\n",
      "205 ip_205 [[[]]]\n",
      "206 l_206 [[['conv2d_129' '1']\n",
      "  ['ip_205' '0']]]\n",
      "207 ip_207 [[[]]]\n",
      "208 l_208 [[['conv2d_129' '2']\n",
      "  ['ip_207' '0']]]\n",
      "209 batch_normalization_93 [[['l_204' '0']]\n",
      "\n",
      " [['l_206' '0']]\n",
      "\n",
      " [['l_208' '0']]]\n",
      "210 ip_210 [[[]]]\n",
      "211 l_211 [[['batch_normalization_93' '0']\n",
      "  ['ip_210' '0']]]\n",
      "212 ip_212 [[[]]]\n",
      "213 l_213 [[['batch_normalization_93' '1']\n",
      "  ['ip_212' '0']]]\n",
      "214 ip_214 [[[]]]\n",
      "215 l_215 [[['batch_normalization_93' '2']\n",
      "  ['ip_214' '0']]]\n",
      "216 activation_132 [[['l_211' '0']]\n",
      "\n",
      " [['l_213' '0']]\n",
      "\n",
      " [['l_215' '0']]]\n",
      "217 ip_217 [[[]]]\n",
      "218 l_218 [[['activation_132' '0']\n",
      "  ['ip_217' '0']]]\n",
      "219 ip_219 [[[]]]\n",
      "220 l_220 [[['activation_132' '1']\n",
      "  ['ip_219' '0']]]\n",
      "221 ip_221 [[[]]]\n",
      "222 l_222 [[['activation_132' '2']\n",
      "  ['ip_221' '0']]]\n",
      "223 conv2d_130 [[['l_218' '0']]\n",
      "\n",
      " [['l_220' '0']]\n",
      "\n",
      " [['l_222' '0']]]\n",
      "224 ip_224 [[[]]]\n",
      "225 l_225 [[['conv2d_130' '0']\n",
      "  ['ip_224' '0']]]\n",
      "226 ip_226 [[[]]]\n",
      "227 l_227 [[['conv2d_130' '1']\n",
      "  ['ip_226' '0']]]\n",
      "228 ip_228 [[[]]]\n",
      "229 l_229 [[['conv2d_130' '2']\n",
      "  ['ip_228' '0']]]\n",
      "230 concatenate_62 [[['concatenate_61' '0']\n",
      "  ['l_225' '0']]\n",
      "\n",
      " [['concatenate_61' '1']\n",
      "  ['l_227' '0']]\n",
      "\n",
      " [['concatenate_61' '2']\n",
      "  ['l_229' '0']]]\n",
      "231 batch_normalization_94 [[['concatenate_62' '0']]\n",
      "\n",
      " [['concatenate_62' '1']]\n",
      "\n",
      " [['concatenate_62' '2']]]\n",
      "232 ip_232 [[[]]]\n",
      "233 l_233 [[['batch_normalization_94' '0']\n",
      "  ['ip_232' '0']]]\n",
      "234 ip_234 [[[]]]\n",
      "235 l_235 [[['batch_normalization_94' '1']\n",
      "  ['ip_234' '0']]]\n",
      "236 ip_236 [[[]]]\n",
      "237 l_237 [[['batch_normalization_94' '2']\n",
      "  ['ip_236' '0']]]\n",
      "238 activation_133 [[['l_233' '0']]\n",
      "\n",
      " [['l_235' '0']]\n",
      "\n",
      " [['l_237' '0']]]\n",
      "239 ip_239 [[[]]]\n",
      "240 l_240 [[['activation_133' '0']\n",
      "  ['ip_239' '0']]]\n",
      "241 ip_241 [[[]]]\n",
      "242 l_242 [[['activation_133' '1']\n",
      "  ['ip_241' '0']]]\n",
      "243 ip_243 [[[]]]\n",
      "244 l_244 [[['activation_133' '2']\n",
      "  ['ip_243' '0']]]\n",
      "245 conv2d_131 [[['l_240' '0']]\n",
      "\n",
      " [['l_242' '0']]\n",
      "\n",
      " [['l_244' '0']]]\n",
      "246 ip_246 [[[]]]\n",
      "247 l_247 [[['conv2d_131' '0']\n",
      "  ['ip_246' '0']]]\n",
      "248 ip_248 [[[]]]\n",
      "249 l_249 [[['conv2d_131' '1']\n",
      "  ['ip_248' '0']]]\n",
      "250 ip_250 [[[]]]\n",
      "251 l_251 [[['conv2d_131' '2']\n",
      "  ['ip_250' '0']]]\n",
      "252 batch_normalization_95 [[['l_247' '0']]\n",
      "\n",
      " [['l_249' '0']]\n",
      "\n",
      " [['l_251' '0']]]\n",
      "253 ip_253 [[[]]]\n",
      "254 l_254 [[['batch_normalization_95' '0']\n",
      "  ['ip_253' '0']]]\n",
      "255 ip_255 [[[]]]\n",
      "256 l_256 [[['batch_normalization_95' '1']\n",
      "  ['ip_255' '0']]]\n",
      "257 ip_257 [[[]]]\n",
      "258 l_258 [[['batch_normalization_95' '2']\n",
      "  ['ip_257' '0']]]\n",
      "259 activation_134 [[['l_254' '0']]\n",
      "\n",
      " [['l_256' '0']]\n",
      "\n",
      " [['l_258' '0']]]\n",
      "260 ip_260 [[[]]]\n",
      "261 l_261 [[['activation_134' '0']\n",
      "  ['ip_260' '0']]]\n",
      "262 ip_262 [[[]]]\n",
      "263 l_263 [[['activation_134' '1']\n",
      "  ['ip_262' '0']]]\n",
      "264 ip_264 [[[]]]\n",
      "265 l_265 [[['activation_134' '2']\n",
      "  ['ip_264' '0']]]\n",
      "266 conv2d_132 [[['l_261' '0']]\n",
      "\n",
      " [['l_263' '0']]\n",
      "\n",
      " [['l_265' '0']]]\n",
      "267 ip_267 [[[]]]\n",
      "268 l_268 [[['conv2d_132' '0']\n",
      "  ['ip_267' '0']]]\n",
      "269 ip_269 [[[]]]\n",
      "270 l_270 [[['conv2d_132' '1']\n",
      "  ['ip_269' '0']]]\n",
      "271 ip_271 [[[]]]\n",
      "272 l_272 [[['conv2d_132' '2']\n",
      "  ['ip_271' '0']]]\n",
      "273 concatenate_63 [[['concatenate_62' '0']\n",
      "  ['l_268' '0']]\n",
      "\n",
      " [['concatenate_62' '1']\n",
      "  ['l_270' '0']]\n",
      "\n",
      " [['concatenate_62' '2']\n",
      "  ['l_272' '0']]]\n",
      "274 batch_normalization_96 [[['concatenate_63' '0']]\n",
      "\n",
      " [['concatenate_63' '1']]\n",
      "\n",
      " [['concatenate_63' '2']]]\n",
      "275 ip_275 [[[]]]\n",
      "276 l_276 [[['batch_normalization_96' '0']\n",
      "  ['ip_275' '0']]]\n",
      "277 ip_277 [[[]]]\n",
      "278 l_278 [[['batch_normalization_96' '1']\n",
      "  ['ip_277' '0']]]\n",
      "279 ip_279 [[[]]]\n",
      "280 l_280 [[['batch_normalization_96' '2']\n",
      "  ['ip_279' '0']]]\n",
      "281 activation_135 [[['l_276' '0']]\n",
      "\n",
      " [['l_278' '0']]\n",
      "\n",
      " [['l_280' '0']]]\n",
      "282 ip_282 [[[]]]\n",
      "283 l_283 [[['activation_135' '0']\n",
      "  ['ip_282' '0']]]\n",
      "284 ip_284 [[[]]]\n",
      "285 l_285 [[['activation_135' '1']\n",
      "  ['ip_284' '0']]]\n",
      "286 ip_286 [[[]]]\n",
      "287 l_287 [[['activation_135' '2']\n",
      "  ['ip_286' '0']]]\n",
      "288 conv2d_133 [[['l_283' '0']]\n",
      "\n",
      " [['l_285' '0']]\n",
      "\n",
      " [['l_287' '0']]]\n",
      "289 ip_289 [[[]]]\n",
      "290 l_290 [[['conv2d_133' '0']\n",
      "  ['ip_289' '0']]]\n",
      "291 ip_291 [[[]]]\n",
      "292 l_292 [[['conv2d_133' '1']\n",
      "  ['ip_291' '0']]]\n",
      "293 ip_293 [[[]]]\n",
      "294 l_294 [[['conv2d_133' '2']\n",
      "  ['ip_293' '0']]]\n",
      "295 batch_normalization_97 [[['l_290' '0']]\n",
      "\n",
      " [['l_292' '0']]\n",
      "\n",
      " [['l_294' '0']]]\n",
      "296 ip_296 [[[]]]\n",
      "297 l_297 [[['batch_normalization_97' '0']\n",
      "  ['ip_296' '0']]]\n",
      "298 ip_298 [[[]]]\n",
      "299 l_299 [[['batch_normalization_97' '1']\n",
      "  ['ip_298' '0']]]\n",
      "300 ip_300 [[[]]]\n",
      "301 l_301 [[['batch_normalization_97' '2']\n",
      "  ['ip_300' '0']]]\n",
      "302 activation_136 [[['l_297' '0']]\n",
      "\n",
      " [['l_299' '0']]\n",
      "\n",
      " [['l_301' '0']]]\n",
      "303 ip_303 [[[]]]\n",
      "304 l_304 [[['activation_136' '0']\n",
      "  ['ip_303' '0']]]\n",
      "305 ip_305 [[[]]]\n",
      "306 l_306 [[['activation_136' '1']\n",
      "  ['ip_305' '0']]]\n",
      "307 ip_307 [[[]]]\n",
      "308 l_308 [[['activation_136' '2']\n",
      "  ['ip_307' '0']]]\n",
      "309 conv2d_134 [[['l_304' '0']]\n",
      "\n",
      " [['l_306' '0']]\n",
      "\n",
      " [['l_308' '0']]]\n",
      "310 ip_310 [[[]]]\n",
      "311 l_311 [[['conv2d_134' '0']\n",
      "  ['ip_310' '0']]]\n",
      "312 ip_312 [[[]]]\n",
      "313 l_313 [[['conv2d_134' '1']\n",
      "  ['ip_312' '0']]]\n",
      "314 ip_314 [[[]]]\n",
      "315 l_315 [[['conv2d_134' '2']\n",
      "  ['ip_314' '0']]]\n",
      "316 concatenate_64 [[['concatenate_63' '0']\n",
      "  ['l_311' '0']]\n",
      "\n",
      " [['concatenate_63' '1']\n",
      "  ['l_313' '0']]\n",
      "\n",
      " [['concatenate_63' '2']\n",
      "  ['l_315' '0']]]\n",
      "317 batch_normalization_98 [[['concatenate_64' '0']]\n",
      "\n",
      " [['concatenate_64' '1']]\n",
      "\n",
      " [['concatenate_64' '2']]]\n",
      "318 ip_318 [[[]]]\n",
      "319 l_319 [[['batch_normalization_98' '0']\n",
      "  ['ip_318' '0']]]\n",
      "320 ip_320 [[[]]]\n",
      "321 l_321 [[['batch_normalization_98' '1']\n",
      "  ['ip_320' '0']]]\n",
      "322 ip_322 [[[]]]\n",
      "323 l_323 [[['batch_normalization_98' '2']\n",
      "  ['ip_322' '0']]]\n",
      "324 activation_137 [[['l_319' '0']]\n",
      "\n",
      " [['l_321' '0']]\n",
      "\n",
      " [['l_323' '0']]]\n",
      "325 ip_325 [[[]]]\n",
      "326 l_326 [[['activation_137' '0']\n",
      "  ['ip_325' '0']]]\n",
      "327 ip_327 [[[]]]\n",
      "328 l_328 [[['activation_137' '1']\n",
      "  ['ip_327' '0']]]\n",
      "329 ip_329 [[[]]]\n",
      "330 l_330 [[['activation_137' '2']\n",
      "  ['ip_329' '0']]]\n",
      "331 conv2d_135 [[['l_326' '0']]\n",
      "\n",
      " [['l_328' '0']]\n",
      "\n",
      " [['l_330' '0']]]\n",
      "332 ip_332 [[[]]]\n",
      "333 l_333 [[['conv2d_135' '0']\n",
      "  ['ip_332' '0']]]\n",
      "334 ip_334 [[[]]]\n",
      "335 l_335 [[['conv2d_135' '1']\n",
      "  ['ip_334' '0']]]\n",
      "336 ip_336 [[[]]]\n",
      "337 l_337 [[['conv2d_135' '2']\n",
      "  ['ip_336' '0']]]\n",
      "338 batch_normalization_99 [[['l_333' '0']]\n",
      "\n",
      " [['l_335' '0']]\n",
      "\n",
      " [['l_337' '0']]]\n",
      "339 ip_339 [[[]]]\n",
      "340 l_340 [[['batch_normalization_99' '0']\n",
      "  ['ip_339' '0']]]\n",
      "341 ip_341 [[[]]]\n",
      "342 l_342 [[['batch_normalization_99' '1']\n",
      "  ['ip_341' '0']]]\n",
      "343 ip_343 [[[]]]\n",
      "344 l_344 [[['batch_normalization_99' '2']\n",
      "  ['ip_343' '0']]]\n",
      "345 activation_138 [[['l_340' '0']]\n",
      "\n",
      " [['l_342' '0']]\n",
      "\n",
      " [['l_344' '0']]]\n",
      "346 ip_346 [[[]]]\n",
      "347 l_347 [[['activation_138' '0']\n",
      "  ['ip_346' '0']]]\n",
      "348 ip_348 [[[]]]\n",
      "349 l_349 [[['activation_138' '1']\n",
      "  ['ip_348' '0']]]\n",
      "350 ip_350 [[[]]]\n",
      "351 l_351 [[['activation_138' '2']\n",
      "  ['ip_350' '0']]]\n",
      "352 conv2d_136 [[['l_347' '0']]\n",
      "\n",
      " [['l_349' '0']]\n",
      "\n",
      " [['l_351' '0']]]\n",
      "353 ip_353 [[[]]]\n",
      "354 l_354 [[['conv2d_136' '0']\n",
      "  ['ip_353' '0']]]\n",
      "355 ip_355 [[[]]]\n",
      "356 l_356 [[['conv2d_136' '1']\n",
      "  ['ip_355' '0']]]\n",
      "357 ip_357 [[[]]]\n",
      "358 l_358 [[['conv2d_136' '2']\n",
      "  ['ip_357' '0']]]\n",
      "359 concatenate_65 [[['l_312' '0']\n",
      "  ['l_354' '0']]\n",
      "\n",
      " [['l_314' '1']\n",
      "  ['l_356' '0']]\n",
      "\n",
      " [['l_316' '2']\n",
      "  ['l_358' '0']]]\n",
      "360 batch_normalization_100 [[['concatenate_65' '0']]\n",
      "\n",
      " [['concatenate_65' '1']]\n",
      "\n",
      " [['concatenate_65' '2']]]\n",
      "361 ip_361 [[[]]]\n",
      "362 l_362 [[['batch_normalization_100' '0']\n",
      "  ['ip_361' '0']]]\n",
      "363 ip_363 [[[]]]\n",
      "364 l_364 [[['batch_normalization_100' '1']\n",
      "  ['ip_363' '0']]]\n",
      "365 ip_365 [[[]]]\n",
      "366 l_366 [[['batch_normalization_100' '2']\n",
      "  ['ip_365' '0']]]\n",
      "367 activation_139 [[['l_362' '0']]\n",
      "\n",
      " [['l_364' '0']]\n",
      "\n",
      " [['l_366' '0']]]\n",
      "368 ip_368 [[[]]]\n",
      "369 l_369 [[['activation_139' '0']\n",
      "  ['ip_368' '0']]]\n",
      "370 ip_370 [[[]]]\n",
      "371 l_371 [[['activation_139' '1']\n",
      "  ['ip_370' '0']]]\n",
      "372 ip_372 [[[]]]\n",
      "373 l_373 [[['activation_139' '2']\n",
      "  ['ip_372' '0']]]\n",
      "374 conv2d_137 [[['l_369' '0']]\n",
      "\n",
      " [['l_371' '0']]\n",
      "\n",
      " [['l_373' '0']]]\n",
      "375 ip_375 [[[]]]\n",
      "376 l_376 [[['conv2d_137' '0']\n",
      "  ['ip_375' '0']]]\n",
      "377 ip_377 [[[]]]\n",
      "378 l_378 [[['conv2d_137' '1']\n",
      "  ['ip_377' '0']]]\n",
      "379 ip_379 [[[]]]\n",
      "380 l_380 [[['conv2d_137' '2']\n",
      "  ['ip_379' '0']]]\n",
      "381 batch_normalization_101 [[['l_376' '0']]\n",
      "\n",
      " [['l_378' '0']]\n",
      "\n",
      " [['l_380' '0']]]\n",
      "382 ip_382 [[[]]]\n",
      "383 l_383 [[['batch_normalization_101' '0']\n",
      "  ['ip_382' '0']]]\n",
      "384 ip_384 [[[]]]\n",
      "385 l_385 [[['batch_normalization_101' '1']\n",
      "  ['ip_384' '0']]]\n",
      "386 ip_386 [[[]]]\n",
      "387 l_387 [[['batch_normalization_101' '2']\n",
      "  ['ip_386' '0']]]\n",
      "388 activation_140 [[['l_383' '0']]\n",
      "\n",
      " [['l_385' '0']]\n",
      "\n",
      " [['l_387' '0']]]\n",
      "389 ip_389 [[[]]]\n",
      "390 l_390 [[['activation_140' '0']\n",
      "  ['ip_389' '0']]]\n",
      "391 ip_391 [[[]]]\n",
      "392 l_392 [[['activation_140' '1']\n",
      "  ['ip_391' '0']]]\n",
      "393 ip_393 [[[]]]\n",
      "394 l_394 [[['activation_140' '2']\n",
      "  ['ip_393' '0']]]\n",
      "395 conv2d_138 [[['l_390' '0']]\n",
      "\n",
      " [['l_392' '0']]\n",
      "\n",
      " [['l_394' '0']]]\n",
      "396 ip_396 [[[]]]\n",
      "397 l_397 [[['conv2d_138' '0']\n",
      "  ['ip_396' '0']]]\n",
      "398 ip_398 [[[]]]\n",
      "399 l_399 [[['conv2d_138' '1']\n",
      "  ['ip_398' '0']]]\n",
      "400 ip_400 [[[]]]\n",
      "401 l_401 [[['conv2d_138' '2']\n",
      "  ['ip_400' '0']]]\n",
      "402 concatenate_66 [[['concatenate_65' '0']\n",
      "  ['l_397' '0']]\n",
      "\n",
      " [['concatenate_65' '1']\n",
      "  ['l_399' '0']]\n",
      "\n",
      " [['concatenate_65' '2']\n",
      "  ['l_401' '0']]]\n",
      "403 batch_normalization_102 [[['concatenate_66' '0']]\n",
      "\n",
      " [['concatenate_66' '1']]\n",
      "\n",
      " [['concatenate_66' '2']]]\n",
      "404 ip_404 [[[]]]\n",
      "405 l_405 [[['batch_normalization_102' '0']\n",
      "  ['ip_404' '0']]]\n",
      "406 ip_406 [[[]]]\n",
      "407 l_407 [[['batch_normalization_102' '1']\n",
      "  ['ip_406' '0']]]\n",
      "408 ip_408 [[[]]]\n",
      "409 l_409 [[['batch_normalization_102' '2']\n",
      "  ['ip_408' '0']]]\n",
      "410 activation_141 [[['l_405' '0']]\n",
      "\n",
      " [['l_407' '0']]\n",
      "\n",
      " [['l_409' '0']]]\n",
      "411 ip_411 [[[]]]\n",
      "412 l_412 [[['activation_141' '0']\n",
      "  ['ip_411' '0']]]\n",
      "413 ip_413 [[[]]]\n",
      "414 l_414 [[['activation_141' '1']\n",
      "  ['ip_413' '0']]]\n",
      "415 ip_415 [[[]]]\n",
      "416 l_416 [[['activation_141' '2']\n",
      "  ['ip_415' '0']]]\n",
      "417 conv2d_139 [[['l_412' '0']]\n",
      "\n",
      " [['l_414' '0']]\n",
      "\n",
      " [['l_416' '0']]]\n",
      "418 ip_418 [[[]]]\n",
      "419 l_419 [[['conv2d_139' '0']\n",
      "  ['ip_418' '0']]]\n",
      "420 ip_420 [[[]]]\n",
      "421 l_421 [[['conv2d_139' '1']\n",
      "  ['ip_420' '0']]]\n",
      "422 ip_422 [[[]]]\n",
      "423 l_423 [[['conv2d_139' '2']\n",
      "  ['ip_422' '0']]]\n",
      "424 batch_normalization_103 [[['l_419' '0']]\n",
      "\n",
      " [['l_421' '0']]\n",
      "\n",
      " [['l_423' '0']]]\n",
      "425 ip_425 [[[]]]\n",
      "426 l_426 [[['batch_normalization_103' '0']\n",
      "  ['ip_425' '0']]]\n",
      "427 ip_427 [[[]]]\n",
      "428 l_428 [[['batch_normalization_103' '1']\n",
      "  ['ip_427' '0']]]\n",
      "429 ip_429 [[[]]]\n",
      "430 l_430 [[['batch_normalization_103' '2']\n",
      "  ['ip_429' '0']]]\n",
      "431 activation_142 [[['l_426' '0']]\n",
      "\n",
      " [['l_428' '0']]\n",
      "\n",
      " [['l_430' '0']]]\n",
      "432 ip_432 [[[]]]\n",
      "433 l_433 [[['activation_142' '0']\n",
      "  ['ip_432' '0']]]\n",
      "434 ip_434 [[[]]]\n",
      "435 l_435 [[['activation_142' '1']\n",
      "  ['ip_434' '0']]]\n",
      "436 ip_436 [[[]]]\n",
      "437 l_437 [[['activation_142' '2']\n",
      "  ['ip_436' '0']]]\n",
      "438 conv2d_140 [[['l_433' '0']]\n",
      "\n",
      " [['l_435' '0']]\n",
      "\n",
      " [['l_437' '0']]]\n",
      "439 ip_439 [[[]]]\n",
      "440 l_440 [[['conv2d_140' '0']\n",
      "  ['ip_439' '0']]]\n",
      "441 ip_441 [[[]]]\n",
      "442 l_442 [[['conv2d_140' '1']\n",
      "  ['ip_441' '0']]]\n",
      "443 ip_443 [[[]]]\n",
      "444 l_444 [[['conv2d_140' '2']\n",
      "  ['ip_443' '0']]]\n",
      "445 concatenate_67 [[['concatenate_66' '0']\n",
      "  ['l_440' '0']]\n",
      "\n",
      " [['concatenate_66' '1']\n",
      "  ['l_442' '0']]\n",
      "\n",
      " [['concatenate_66' '2']\n",
      "  ['l_444' '0']]]\n",
      "446 batch_normalization_104 [[['concatenate_67' '0']]\n",
      "\n",
      " [['concatenate_67' '1']]\n",
      "\n",
      " [['concatenate_67' '2']]]\n",
      "447 ip_447 [[[]]]\n",
      "448 l_448 [[['batch_normalization_104' '0']\n",
      "  ['ip_447' '0']]]\n",
      "449 ip_449 [[[]]]\n",
      "450 l_450 [[['batch_normalization_104' '1']\n",
      "  ['ip_449' '0']]]\n",
      "451 ip_451 [[[]]]\n",
      "452 l_452 [[['batch_normalization_104' '2']\n",
      "  ['ip_451' '0']]]\n",
      "453 activation_143 [[['l_448' '0']]\n",
      "\n",
      " [['l_450' '0']]\n",
      "\n",
      " [['l_452' '0']]]\n",
      "454 ip_454 [[[]]]\n",
      "455 l_455 [[['activation_143' '0']\n",
      "  ['ip_454' '0']]]\n",
      "456 ip_456 [[[]]]\n",
      "457 l_457 [[['activation_143' '1']\n",
      "  ['ip_456' '0']]]\n",
      "458 ip_458 [[[]]]\n",
      "459 l_459 [[['activation_143' '2']\n",
      "  ['ip_458' '0']]]\n",
      "460 conv2d_141 [[['l_455' '0']]\n",
      "\n",
      " [['l_457' '0']]\n",
      "\n",
      " [['l_459' '0']]]\n",
      "461 ip_461 [[[]]]\n",
      "462 l_462 [[['conv2d_141' '0']\n",
      "  ['ip_461' '0']]]\n",
      "463 ip_463 [[[]]]\n",
      "464 l_464 [[['conv2d_141' '1']\n",
      "  ['ip_463' '0']]]\n",
      "465 ip_465 [[[]]]\n",
      "466 l_466 [[['conv2d_141' '2']\n",
      "  ['ip_465' '0']]]\n",
      "467 batch_normalization_105 [[['l_462' '0']]\n",
      "\n",
      " [['l_464' '0']]\n",
      "\n",
      " [['l_466' '0']]]\n",
      "468 ip_468 [[[]]]\n",
      "469 l_469 [[['batch_normalization_105' '0']\n",
      "  ['ip_468' '0']]]\n",
      "470 ip_470 [[[]]]\n",
      "471 l_471 [[['batch_normalization_105' '1']\n",
      "  ['ip_470' '0']]]\n",
      "472 ip_472 [[[]]]\n",
      "473 l_473 [[['batch_normalization_105' '2']\n",
      "  ['ip_472' '0']]]\n",
      "474 activation_144 [[['l_469' '0']]\n",
      "\n",
      " [['l_471' '0']]\n",
      "\n",
      " [['l_473' '0']]]\n",
      "475 ip_475 [[[]]]\n",
      "476 l_476 [[['activation_144' '0']\n",
      "  ['ip_475' '0']]]\n",
      "477 ip_477 [[[]]]\n",
      "478 l_478 [[['activation_144' '1']\n",
      "  ['ip_477' '0']]]\n",
      "479 ip_479 [[[]]]\n",
      "480 l_480 [[['activation_144' '2']\n",
      "  ['ip_479' '0']]]\n",
      "481 conv2d_142 [[['l_476' '0']]\n",
      "\n",
      " [['l_478' '0']]\n",
      "\n",
      " [['l_480' '0']]]\n",
      "482 ip_482 [[[]]]\n",
      "483 l_483 [[['conv2d_142' '0']\n",
      "  ['ip_482' '0']]]\n",
      "484 ip_484 [[[]]]\n",
      "485 l_485 [[['conv2d_142' '1']\n",
      "  ['ip_484' '0']]]\n",
      "486 ip_486 [[[]]]\n",
      "487 l_487 [[['conv2d_142' '2']\n",
      "  ['ip_486' '0']]]\n",
      "488 concatenate_68 [[['concatenate_67' '0']\n",
      "  ['l_483' '0']]\n",
      "\n",
      " [['concatenate_67' '1']\n",
      "  ['l_485' '0']]\n",
      "\n",
      " [['concatenate_67' '2']\n",
      "  ['l_487' '0']]]\n",
      "489 batch_normalization_106 [[['concatenate_68' '0']]\n",
      "\n",
      " [['concatenate_68' '1']]\n",
      "\n",
      " [['concatenate_68' '2']]]\n",
      "490 ip_490 [[[]]]\n",
      "491 l_491 [[['batch_normalization_106' '0']\n",
      "  ['ip_490' '0']]]\n",
      "492 ip_492 [[[]]]\n",
      "493 l_493 [[['batch_normalization_106' '1']\n",
      "  ['ip_492' '0']]]\n",
      "494 ip_494 [[[]]]\n",
      "495 l_495 [[['batch_normalization_106' '2']\n",
      "  ['ip_494' '0']]]\n",
      "496 activation_145 [[['l_491' '0']]\n",
      "\n",
      " [['l_493' '0']]\n",
      "\n",
      " [['l_495' '0']]]\n",
      "497 ip_497 [[[]]]\n",
      "498 l_498 [[['activation_145' '0']\n",
      "  ['ip_497' '0']]]\n",
      "499 ip_499 [[[]]]\n",
      "500 l_500 [[['activation_145' '1']\n",
      "  ['ip_499' '0']]]\n",
      "501 ip_501 [[[]]]\n",
      "502 l_502 [[['activation_145' '2']\n",
      "  ['ip_501' '0']]]\n",
      "503 conv2d_143 [[['l_498' '0']]\n",
      "\n",
      " [['l_500' '0']]\n",
      "\n",
      " [['l_502' '0']]]\n",
      "504 ip_504 [[[]]]\n",
      "505 l_505 [[['conv2d_143' '0']\n",
      "  ['ip_504' '0']]]\n",
      "506 ip_506 [[[]]]\n",
      "507 l_507 [[['conv2d_143' '1']\n",
      "  ['ip_506' '0']]]\n",
      "508 ip_508 [[[]]]\n",
      "509 l_509 [[['conv2d_143' '2']\n",
      "  ['ip_508' '0']]]\n",
      "510 batch_normalization_107 [[['l_505' '0']]\n",
      "\n",
      " [['l_507' '0']]\n",
      "\n",
      " [['l_509' '0']]]\n",
      "511 ip_511 [[[]]]\n",
      "512 l_512 [[['batch_normalization_107' '0']\n",
      "  ['ip_511' '0']]]\n",
      "513 ip_513 [[[]]]\n",
      "514 l_514 [[['batch_normalization_107' '1']\n",
      "  ['ip_513' '0']]]\n",
      "515 ip_515 [[[]]]\n",
      "516 l_516 [[['batch_normalization_107' '2']\n",
      "  ['ip_515' '0']]]\n",
      "517 activation_146 [[['l_512' '0']]\n",
      "\n",
      " [['l_514' '0']]\n",
      "\n",
      " [['l_516' '0']]]\n",
      "518 ip_518 [[[]]]\n",
      "519 l_519 [[['activation_146' '0']\n",
      "  ['ip_518' '0']]]\n",
      "520 ip_520 [[[]]]\n",
      "521 l_521 [[['activation_146' '1']\n",
      "  ['ip_520' '0']]]\n",
      "522 ip_522 [[[]]]\n",
      "523 l_523 [[['activation_146' '2']\n",
      "  ['ip_522' '0']]]\n",
      "524 conv2d_144 [[['l_519' '0']]\n",
      "\n",
      " [['l_521' '0']]\n",
      "\n",
      " [['l_523' '0']]]\n",
      "525 ip_525 [[[]]]\n",
      "526 l_526 [[['conv2d_144' '0']\n",
      "  ['ip_525' '0']]]\n",
      "527 ip_527 [[[]]]\n",
      "528 l_528 [[['conv2d_144' '1']\n",
      "  ['ip_527' '0']]]\n",
      "529 ip_529 [[[]]]\n",
      "530 l_530 [[['conv2d_144' '2']\n",
      "  ['ip_529' '0']]]\n",
      "531 concatenate_69 [[['concatenate_68' '0']\n",
      "  ['l_526' '0']]\n",
      "\n",
      " [['concatenate_68' '1']\n",
      "  ['l_528' '0']]\n",
      "\n",
      " [['concatenate_68' '2']\n",
      "  ['l_530' '0']]]\n",
      "532 batch_normalization_108 [[['concatenate_69' '0']]\n",
      "\n",
      " [['concatenate_69' '1']]\n",
      "\n",
      " [['concatenate_69' '2']]]\n",
      "533 ip_533 [[[]]]\n",
      "534 l_534 [[['batch_normalization_108' '0']\n",
      "  ['ip_533' '0']]]\n",
      "535 ip_535 [[[]]]\n",
      "536 l_536 [[['batch_normalization_108' '1']\n",
      "  ['ip_535' '0']]]\n",
      "537 ip_537 [[[]]]\n",
      "538 l_538 [[['batch_normalization_108' '2']\n",
      "  ['ip_537' '0']]]\n",
      "539 activation_147 [[['l_534' '0']]\n",
      "\n",
      " [['l_536' '0']]\n",
      "\n",
      " [['l_538' '0']]]\n",
      "540 ip_540 [[[]]]\n",
      "541 l_541 [[['activation_147' '0']\n",
      "  ['ip_540' '0']]]\n",
      "542 ip_542 [[[]]]\n",
      "543 l_543 [[['activation_147' '1']\n",
      "  ['ip_542' '0']]]\n",
      "544 ip_544 [[[]]]\n",
      "545 l_545 [[['activation_147' '2']\n",
      "  ['ip_544' '0']]]\n",
      "546 conv2d_145 [[['l_541' '0']]\n",
      "\n",
      " [['l_543' '0']]\n",
      "\n",
      " [['l_545' '0']]]\n",
      "547 ip_547 [[[]]]\n",
      "548 l_548 [[['conv2d_145' '0']\n",
      "  ['ip_547' '0']]]\n",
      "549 ip_549 [[[]]]\n",
      "550 l_550 [[['conv2d_145' '1']\n",
      "  ['ip_549' '0']]]\n",
      "551 ip_551 [[[]]]\n",
      "552 l_552 [[['conv2d_145' '2']\n",
      "  ['ip_551' '0']]]\n",
      "553 batch_normalization_109 [[['l_548' '0']]\n",
      "\n",
      " [['l_550' '0']]\n",
      "\n",
      " [['l_552' '0']]]\n",
      "554 ip_554 [[[]]]\n",
      "555 l_555 [[['batch_normalization_109' '0']\n",
      "  ['ip_554' '0']]]\n",
      "556 ip_556 [[[]]]\n",
      "557 l_557 [[['batch_normalization_109' '1']\n",
      "  ['ip_556' '0']]]\n",
      "558 ip_558 [[[]]]\n",
      "559 l_559 [[['batch_normalization_109' '2']\n",
      "  ['ip_558' '0']]]\n",
      "560 activation_148 [[['l_555' '0']]\n",
      "\n",
      " [['l_557' '0']]\n",
      "\n",
      " [['l_559' '0']]]\n",
      "561 ip_561 [[[]]]\n",
      "562 l_562 [[['activation_148' '0']\n",
      "  ['ip_561' '0']]]\n",
      "563 ip_563 [[[]]]\n",
      "564 l_564 [[['activation_148' '1']\n",
      "  ['ip_563' '0']]]\n",
      "565 ip_565 [[[]]]\n",
      "566 l_566 [[['activation_148' '2']\n",
      "  ['ip_565' '0']]]\n",
      "567 conv2d_146 [[['l_562' '0']]\n",
      "\n",
      " [['l_564' '0']]\n",
      "\n",
      " [['l_566' '0']]]\n",
      "568 ip_568 [[[]]]\n",
      "569 l_569 [[['conv2d_146' '0']\n",
      "  ['ip_568' '0']]]\n",
      "570 ip_570 [[[]]]\n",
      "571 l_571 [[['conv2d_146' '1']\n",
      "  ['ip_570' '0']]]\n",
      "572 ip_572 [[[]]]\n",
      "573 l_573 [[['conv2d_146' '2']\n",
      "  ['ip_572' '0']]]\n",
      "574 concatenate_70 [[['concatenate_69' '0']\n",
      "  ['l_569' '0']]\n",
      "\n",
      " [['concatenate_69' '1']\n",
      "  ['l_571' '0']]\n",
      "\n",
      " [['concatenate_69' '2']\n",
      "  ['l_573' '0']]]\n",
      "575 batch_normalization_110 [[['concatenate_70' '0']]\n",
      "\n",
      " [['concatenate_70' '1']]\n",
      "\n",
      " [['concatenate_70' '2']]]\n",
      "576 ip_576 [[[]]]\n",
      "577 l_577 [[['batch_normalization_110' '0']\n",
      "  ['ip_576' '0']]]\n",
      "578 ip_578 [[[]]]\n",
      "579 l_579 [[['batch_normalization_110' '1']\n",
      "  ['ip_578' '0']]]\n",
      "580 ip_580 [[[]]]\n",
      "581 l_581 [[['batch_normalization_110' '2']\n",
      "  ['ip_580' '0']]]\n",
      "582 activation_149 [[['l_577' '0']]\n",
      "\n",
      " [['l_579' '0']]\n",
      "\n",
      " [['l_581' '0']]]\n",
      "583 ip_583 [[[]]]\n",
      "584 l_584 [[['activation_149' '0']\n",
      "  ['ip_583' '0']]]\n",
      "585 ip_585 [[[]]]\n",
      "586 l_586 [[['activation_149' '1']\n",
      "  ['ip_585' '0']]]\n",
      "587 ip_587 [[[]]]\n",
      "588 l_588 [[['activation_149' '2']\n",
      "  ['ip_587' '0']]]\n",
      "589 conv2d_147 [[['l_584' '0']]\n",
      "\n",
      " [['l_586' '0']]\n",
      "\n",
      " [['l_588' '0']]]\n",
      "590 ip_590 [[[]]]\n",
      "591 l_591 [[['conv2d_147' '0']\n",
      "  ['ip_590' '0']]]\n",
      "592 ip_592 [[[]]]\n",
      "593 l_593 [[['conv2d_147' '1']\n",
      "  ['ip_592' '0']]]\n",
      "594 ip_594 [[[]]]\n",
      "595 l_595 [[['conv2d_147' '2']\n",
      "  ['ip_594' '0']]]\n",
      "596 batch_normalization_111 [[['l_591' '0']]\n",
      "\n",
      " [['l_593' '0']]\n",
      "\n",
      " [['l_595' '0']]]\n",
      "597 ip_597 [[[]]]\n",
      "598 l_598 [[['batch_normalization_111' '0']\n",
      "  ['ip_597' '0']]]\n",
      "599 ip_599 [[[]]]\n",
      "600 l_600 [[['batch_normalization_111' '1']\n",
      "  ['ip_599' '0']]]\n",
      "601 ip_601 [[[]]]\n",
      "602 l_602 [[['batch_normalization_111' '2']\n",
      "  ['ip_601' '0']]]\n",
      "603 activation_150 [[['l_598' '0']]\n",
      "\n",
      " [['l_600' '0']]\n",
      "\n",
      " [['l_602' '0']]]\n",
      "604 ip_604 [[[]]]\n",
      "605 l_605 [[['activation_150' '0']\n",
      "  ['ip_604' '0']]]\n",
      "606 ip_606 [[[]]]\n",
      "607 l_607 [[['activation_150' '1']\n",
      "  ['ip_606' '0']]]\n",
      "608 ip_608 [[[]]]\n",
      "609 l_609 [[['activation_150' '2']\n",
      "  ['ip_608' '0']]]\n",
      "610 conv2d_148 [[['l_605' '0']]\n",
      "\n",
      " [['l_607' '0']]\n",
      "\n",
      " [['l_609' '0']]]\n",
      "611 ip_611 [[[]]]\n",
      "612 l_612 [[['conv2d_148' '0']\n",
      "  ['ip_611' '0']]]\n",
      "613 ip_613 [[[]]]\n",
      "614 l_614 [[['conv2d_148' '1']\n",
      "  ['ip_613' '0']]]\n",
      "615 ip_615 [[[]]]\n",
      "616 l_616 [[['conv2d_148' '2']\n",
      "  ['ip_615' '0']]]\n",
      "617 concatenate_71 [[['concatenate_70' '0']\n",
      "  ['l_612' '0']]\n",
      "\n",
      " [['concatenate_70' '1']\n",
      "  ['l_614' '0']]\n",
      "\n",
      " [['concatenate_70' '2']\n",
      "  ['l_616' '0']]]\n",
      "618 batch_normalization_112 [[['concatenate_71' '0']]\n",
      "\n",
      " [['concatenate_71' '1']]\n",
      "\n",
      " [['concatenate_71' '2']]]\n",
      "619 ip_619 [[[]]]\n",
      "620 l_620 [[['batch_normalization_112' '0']\n",
      "  ['ip_619' '0']]]\n",
      "621 ip_621 [[[]]]\n",
      "622 l_622 [[['batch_normalization_112' '1']\n",
      "  ['ip_621' '0']]]\n",
      "623 ip_623 [[[]]]\n",
      "624 l_624 [[['batch_normalization_112' '2']\n",
      "  ['ip_623' '0']]]\n",
      "625 activation_151 [[['l_620' '0']]\n",
      "\n",
      " [['l_622' '0']]\n",
      "\n",
      " [['l_624' '0']]]\n",
      "626 ip_626 [[[]]]\n",
      "627 l_627 [[['activation_151' '0']\n",
      "  ['ip_626' '0']]]\n",
      "628 ip_628 [[[]]]\n",
      "629 l_629 [[['activation_151' '1']\n",
      "  ['ip_628' '0']]]\n",
      "630 ip_630 [[[]]]\n",
      "631 l_631 [[['activation_151' '2']\n",
      "  ['ip_630' '0']]]\n",
      "632 conv2d_149 [[['l_627' '0']]\n",
      "\n",
      " [['l_629' '0']]\n",
      "\n",
      " [['l_631' '0']]]\n",
      "633 ip_633 [[[]]]\n",
      "634 l_634 [[['conv2d_149' '0']\n",
      "  ['ip_633' '0']]]\n",
      "635 ip_635 [[[]]]\n",
      "636 l_636 [[['conv2d_149' '1']\n",
      "  ['ip_635' '0']]]\n",
      "637 ip_637 [[[]]]\n",
      "638 l_638 [[['conv2d_149' '2']\n",
      "  ['ip_637' '0']]]\n",
      "639 batch_normalization_113 [[['l_634' '0']]\n",
      "\n",
      " [['l_636' '0']]\n",
      "\n",
      " [['l_638' '0']]]\n",
      "640 ip_640 [[[]]]\n",
      "641 l_641 [[['batch_normalization_113' '0']\n",
      "  ['ip_640' '0']]]\n",
      "642 ip_642 [[[]]]\n",
      "643 l_643 [[['batch_normalization_113' '1']\n",
      "  ['ip_642' '0']]]\n",
      "644 ip_644 [[[]]]\n",
      "645 l_645 [[['batch_normalization_113' '2']\n",
      "  ['ip_644' '0']]]\n",
      "646 activation_152 [[['l_641' '0']]\n",
      "\n",
      " [['l_643' '0']]\n",
      "\n",
      " [['l_645' '0']]]\n",
      "647 ip_647 [[[]]]\n",
      "648 l_648 [[['activation_152' '0']\n",
      "  ['ip_647' '0']]]\n",
      "649 ip_649 [[[]]]\n",
      "650 l_650 [[['activation_152' '1']\n",
      "  ['ip_649' '0']]]\n",
      "651 ip_651 [[[]]]\n",
      "652 l_652 [[['activation_152' '2']\n",
      "  ['ip_651' '0']]]\n",
      "653 conv2d_150 [[['l_648' '0']]\n",
      "\n",
      " [['l_650' '0']]\n",
      "\n",
      " [['l_652' '0']]]\n",
      "654 ip_654 [[[]]]\n",
      "655 l_655 [[['conv2d_150' '0']\n",
      "  ['ip_654' '0']]]\n",
      "656 ip_656 [[[]]]\n",
      "657 l_657 [[['conv2d_150' '1']\n",
      "  ['ip_656' '0']]]\n",
      "658 ip_658 [[[]]]\n",
      "659 l_659 [[['conv2d_150' '2']\n",
      "  ['ip_658' '0']]]\n",
      "660 concatenate_72 [[['concatenate_71' '0']\n",
      "  ['l_655' '0']]\n",
      "\n",
      " [['concatenate_71' '1']\n",
      "  ['l_657' '0']]\n",
      "\n",
      " [['concatenate_71' '2']\n",
      "  ['l_659' '0']]]\n",
      "661 batch_normalization_114 [[['concatenate_72' '0']]\n",
      "\n",
      " [['concatenate_72' '1']]\n",
      "\n",
      " [['concatenate_72' '2']]]\n",
      "662 ip_662 [[[]]]\n",
      "663 l_663 [[['batch_normalization_114' '0']\n",
      "  ['ip_662' '0']]]\n",
      "664 ip_664 [[[]]]\n",
      "665 l_665 [[['batch_normalization_114' '1']\n",
      "  ['ip_664' '0']]]\n",
      "666 ip_666 [[[]]]\n",
      "667 l_667 [[['batch_normalization_114' '2']\n",
      "  ['ip_666' '0']]]\n",
      "668 activation_153 [[['l_663' '0']]\n",
      "\n",
      " [['l_665' '0']]\n",
      "\n",
      " [['l_667' '0']]]\n",
      "669 ip_669 [[[]]]\n",
      "670 l_670 [[['activation_153' '0']\n",
      "  ['ip_669' '0']]]\n",
      "671 ip_671 [[[]]]\n",
      "672 l_672 [[['activation_153' '1']\n",
      "  ['ip_671' '0']]]\n",
      "673 ip_673 [[[]]]\n",
      "674 l_674 [[['activation_153' '2']\n",
      "  ['ip_673' '0']]]\n",
      "675 conv2d_151 [[['l_670' '0']]\n",
      "\n",
      " [['l_672' '0']]\n",
      "\n",
      " [['l_674' '0']]]\n",
      "676 ip_676 [[[]]]\n",
      "677 l_677 [[['conv2d_151' '0']\n",
      "  ['ip_676' '0']]]\n",
      "678 ip_678 [[[]]]\n",
      "679 l_679 [[['conv2d_151' '1']\n",
      "  ['ip_678' '0']]]\n",
      "680 ip_680 [[[]]]\n",
      "681 l_681 [[['conv2d_151' '2']\n",
      "  ['ip_680' '0']]]\n",
      "682 batch_normalization_115 [[['l_677' '0']]\n",
      "\n",
      " [['l_679' '0']]\n",
      "\n",
      " [['l_681' '0']]]\n",
      "683 ip_683 [[[]]]\n",
      "684 l_684 [[['batch_normalization_115' '0']\n",
      "  ['ip_683' '0']]]\n",
      "685 ip_685 [[[]]]\n",
      "686 l_686 [[['batch_normalization_115' '1']\n",
      "  ['ip_685' '0']]]\n",
      "687 ip_687 [[[]]]\n",
      "688 l_688 [[['batch_normalization_115' '2']\n",
      "  ['ip_687' '0']]]\n",
      "689 activation_154 [[['l_684' '0']]\n",
      "\n",
      " [['l_686' '0']]\n",
      "\n",
      " [['l_688' '0']]]\n",
      "690 ip_690 [[[]]]\n",
      "691 l_691 [[['activation_154' '0']\n",
      "  ['ip_690' '0']]]\n",
      "692 ip_692 [[[]]]\n",
      "693 l_693 [[['activation_154' '1']\n",
      "  ['ip_692' '0']]]\n",
      "694 ip_694 [[[]]]\n",
      "695 l_695 [[['activation_154' '2']\n",
      "  ['ip_694' '0']]]\n",
      "696 conv2d_152 [[['l_691' '0']]\n",
      "\n",
      " [['l_693' '0']]\n",
      "\n",
      " [['l_695' '0']]]\n",
      "697 ip_697 [[[]]]\n",
      "698 l_698 [[['conv2d_152' '0']\n",
      "  ['ip_697' '0']]]\n",
      "699 ip_699 [[[]]]\n",
      "700 l_700 [[['conv2d_152' '1']\n",
      "  ['ip_699' '0']]]\n",
      "701 ip_701 [[[]]]\n",
      "702 l_702 [[['conv2d_152' '2']\n",
      "  ['ip_701' '0']]]\n",
      "703 concatenate_73 [[['concatenate_72' '0']\n",
      "  ['l_698' '0']]\n",
      "\n",
      " [['concatenate_72' '1']\n",
      "  ['l_700' '0']]\n",
      "\n",
      " [['concatenate_72' '2']\n",
      "  ['l_702' '0']]]\n",
      "704 batch_normalization_116 [[['concatenate_73' '0']]\n",
      "\n",
      " [['concatenate_73' '1']]\n",
      "\n",
      " [['concatenate_73' '2']]]\n",
      "705 ip_705 [[[]]]\n",
      "706 l_706 [[['batch_normalization_116' '0']\n",
      "  ['ip_705' '0']]]\n",
      "707 ip_707 [[[]]]\n",
      "708 l_708 [[['batch_normalization_116' '1']\n",
      "  ['ip_707' '0']]]\n",
      "709 ip_709 [[[]]]\n",
      "710 l_710 [[['batch_normalization_116' '2']\n",
      "  ['ip_709' '0']]]\n",
      "711 activation_155 [[['l_706' '0']]\n",
      "\n",
      " [['l_708' '0']]\n",
      "\n",
      " [['l_710' '0']]]\n",
      "712 ip_712 [[[]]]\n",
      "713 l_713 [[['activation_155' '0']\n",
      "  ['ip_712' '0']]]\n",
      "714 ip_714 [[[]]]\n",
      "715 l_715 [[['activation_155' '1']\n",
      "  ['ip_714' '0']]]\n",
      "716 ip_716 [[[]]]\n",
      "717 l_717 [[['activation_155' '2']\n",
      "  ['ip_716' '0']]]\n",
      "718 conv2d_153 [[['l_713' '0']]\n",
      "\n",
      " [['l_715' '0']]\n",
      "\n",
      " [['l_717' '0']]]\n",
      "719 ip_719 [[[]]]\n",
      "720 l_720 [[['conv2d_153' '0']\n",
      "  ['ip_719' '0']]]\n",
      "721 ip_721 [[[]]]\n",
      "722 l_722 [[['conv2d_153' '1']\n",
      "  ['ip_721' '0']]]\n",
      "723 ip_723 [[[]]]\n",
      "724 l_724 [[['conv2d_153' '2']\n",
      "  ['ip_723' '0']]]\n",
      "725 batch_normalization_117 [[['l_720' '0']]\n",
      "\n",
      " [['l_722' '0']]\n",
      "\n",
      " [['l_724' '0']]]\n",
      "726 ip_726 [[[]]]\n",
      "727 l_727 [[['batch_normalization_117' '0']\n",
      "  ['ip_726' '0']]]\n",
      "728 ip_728 [[[]]]\n",
      "729 l_729 [[['batch_normalization_117' '1']\n",
      "  ['ip_728' '0']]]\n",
      "730 ip_730 [[[]]]\n",
      "731 l_731 [[['batch_normalization_117' '2']\n",
      "  ['ip_730' '0']]]\n",
      "732 activation_156 [[['l_727' '0']]\n",
      "\n",
      " [['l_729' '0']]\n",
      "\n",
      " [['l_731' '0']]]\n",
      "733 ip_733 [[[]]]\n",
      "734 l_734 [[['activation_156' '0']\n",
      "  ['ip_733' '0']]]\n",
      "735 ip_735 [[[]]]\n",
      "736 l_736 [[['activation_156' '1']\n",
      "  ['ip_735' '0']]]\n",
      "737 ip_737 [[[]]]\n",
      "738 l_738 [[['activation_156' '2']\n",
      "  ['ip_737' '0']]]\n",
      "739 conv2d_154 [[['l_734' '0']]\n",
      "\n",
      " [['l_736' '0']]\n",
      "\n",
      " [['l_738' '0']]]\n",
      "740 ip_740 [[[]]]\n",
      "741 l_741 [[['conv2d_154' '0']\n",
      "  ['ip_740' '0']]]\n",
      "742 ip_742 [[[]]]\n",
      "743 l_743 [[['conv2d_154' '1']\n",
      "  ['ip_742' '0']]]\n",
      "744 ip_744 [[[]]]\n",
      "745 l_745 [[['conv2d_154' '2']\n",
      "  ['ip_744' '0']]]\n",
      "746 concatenate_74 [[['concatenate_73' '0']\n",
      "  ['l_741' '0']]\n",
      "\n",
      " [['concatenate_73' '1']\n",
      "  ['l_743' '0']]\n",
      "\n",
      " [['concatenate_73' '2']\n",
      "  ['l_745' '0']]]\n",
      "747 batch_normalization_118 [[['concatenate_74' '0']]\n",
      "\n",
      " [['concatenate_74' '1']]\n",
      "\n",
      " [['concatenate_74' '2']]]\n",
      "748 ip_748 [[[]]]\n",
      "749 l_749 [[['batch_normalization_118' '0']\n",
      "  ['ip_748' '0']]]\n",
      "750 ip_750 [[[]]]\n",
      "751 l_751 [[['batch_normalization_118' '1']\n",
      "  ['ip_750' '0']]]\n",
      "752 ip_752 [[[]]]\n",
      "753 l_753 [[['batch_normalization_118' '2']\n",
      "  ['ip_752' '0']]]\n",
      "754 activation_157 [[['l_749' '0']]\n",
      "\n",
      " [['l_751' '0']]\n",
      "\n",
      " [['l_753' '0']]]\n",
      "755 ip_755 [[[]]]\n",
      "756 l_756 [[['activation_157' '0']\n",
      "  ['ip_755' '0']]]\n",
      "757 ip_757 [[[]]]\n",
      "758 l_758 [[['activation_157' '1']\n",
      "  ['ip_757' '0']]]\n",
      "759 ip_759 [[[]]]\n",
      "760 l_760 [[['activation_157' '2']\n",
      "  ['ip_759' '0']]]\n",
      "761 conv2d_155 [[['l_756' '0']]\n",
      "\n",
      " [['l_758' '0']]\n",
      "\n",
      " [['l_760' '0']]]\n",
      "762 ip_762 [[[]]]\n",
      "763 l_763 [[['conv2d_155' '0']\n",
      "  ['ip_762' '0']]]\n",
      "764 ip_764 [[[]]]\n",
      "765 l_765 [[['conv2d_155' '1']\n",
      "  ['ip_764' '0']]]\n",
      "766 ip_766 [[[]]]\n",
      "767 l_767 [[['conv2d_155' '2']\n",
      "  ['ip_766' '0']]]\n",
      "768 batch_normalization_119 [[['l_763' '0']]\n",
      "\n",
      " [['l_765' '0']]\n",
      "\n",
      " [['l_767' '0']]]\n",
      "769 ip_769 [[[]]]\n",
      "770 l_770 [[['batch_normalization_119' '0']\n",
      "  ['ip_769' '0']]]\n",
      "771 ip_771 [[[]]]\n",
      "772 l_772 [[['batch_normalization_119' '1']\n",
      "  ['ip_771' '0']]]\n",
      "773 ip_773 [[[]]]\n",
      "774 l_774 [[['batch_normalization_119' '2']\n",
      "  ['ip_773' '0']]]\n",
      "775 activation_158 [[['l_770' '0']]\n",
      "\n",
      " [['l_772' '0']]\n",
      "\n",
      " [['l_774' '0']]]\n",
      "776 ip_776 [[[]]]\n",
      "777 l_777 [[['activation_158' '0']\n",
      "  ['ip_776' '0']]]\n",
      "778 ip_778 [[[]]]\n",
      "779 l_779 [[['activation_158' '1']\n",
      "  ['ip_778' '0']]]\n",
      "780 ip_780 [[[]]]\n",
      "781 l_781 [[['activation_158' '2']\n",
      "  ['ip_780' '0']]]\n",
      "782 conv2d_156 [[['l_777' '0']]\n",
      "\n",
      " [['l_779' '0']]\n",
      "\n",
      " [['l_781' '0']]]\n",
      "783 ip_783 [[[]]]\n",
      "784 l_784 [[['conv2d_156' '0']\n",
      "  ['ip_783' '0']]]\n",
      "785 ip_785 [[[]]]\n",
      "786 l_786 [[['conv2d_156' '1']\n",
      "  ['ip_785' '0']]]\n",
      "787 ip_787 [[[]]]\n",
      "788 l_788 [[['conv2d_156' '2']\n",
      "  ['ip_787' '0']]]\n",
      "789 concatenate_75 [[['concatenate_74' '0']\n",
      "  ['l_784' '0']]\n",
      "\n",
      " [['concatenate_74' '1']\n",
      "  ['l_786' '0']]\n",
      "\n",
      " [['concatenate_74' '2']\n",
      "  ['l_788' '0']]]\n",
      "790 batch_normalization_120 [[['concatenate_75' '0']]\n",
      "\n",
      " [['concatenate_75' '1']]\n",
      "\n",
      " [['concatenate_75' '2']]]\n",
      "791 ip_791 [[[]]]\n",
      "792 l_792 [[['batch_normalization_120' '0']\n",
      "  ['ip_791' '0']]]\n",
      "793 ip_793 [[[]]]\n",
      "794 l_794 [[['batch_normalization_120' '1']\n",
      "  ['ip_793' '0']]]\n",
      "795 ip_795 [[[]]]\n",
      "796 l_796 [[['batch_normalization_120' '2']\n",
      "  ['ip_795' '0']]]\n",
      "797 activation_159 [[['l_792' '0']]\n",
      "\n",
      " [['l_794' '0']]\n",
      "\n",
      " [['l_796' '0']]]\n",
      "798 ip_798 [[[]]]\n",
      "799 l_799 [[['activation_159' '0']\n",
      "  ['ip_798' '0']]]\n",
      "800 ip_800 [[[]]]\n",
      "801 l_801 [[['activation_159' '1']\n",
      "  ['ip_800' '0']]]\n",
      "802 ip_802 [[[]]]\n",
      "803 l_803 [[['activation_159' '2']\n",
      "  ['ip_802' '0']]]\n",
      "804 conv2d_157 [[['l_799' '0']]\n",
      "\n",
      " [['l_801' '0']]\n",
      "\n",
      " [['l_803' '0']]]\n",
      "805 ip_805 [[[]]]\n",
      "806 l_806 [[['conv2d_157' '0']\n",
      "  ['ip_805' '0']]]\n",
      "807 ip_807 [[[]]]\n",
      "808 l_808 [[['conv2d_157' '1']\n",
      "  ['ip_807' '0']]]\n",
      "809 ip_809 [[[]]]\n",
      "810 l_810 [[['conv2d_157' '2']\n",
      "  ['ip_809' '0']]]\n",
      "811 batch_normalization_121 [[['l_806' '0']]\n",
      "\n",
      " [['l_808' '0']]\n",
      "\n",
      " [['l_810' '0']]]\n",
      "812 ip_812 [[[]]]\n",
      "813 l_813 [[['batch_normalization_121' '0']\n",
      "  ['ip_812' '0']]]\n",
      "814 ip_814 [[[]]]\n",
      "815 l_815 [[['batch_normalization_121' '1']\n",
      "  ['ip_814' '0']]]\n",
      "816 ip_816 [[[]]]\n",
      "817 l_817 [[['batch_normalization_121' '2']\n",
      "  ['ip_816' '0']]]\n",
      "818 activation_160 [[['l_813' '0']]\n",
      "\n",
      " [['l_815' '0']]\n",
      "\n",
      " [['l_817' '0']]]\n",
      "819 ip_819 [[[]]]\n",
      "820 l_820 [[['activation_160' '0']\n",
      "  ['ip_819' '0']]]\n",
      "821 ip_821 [[[]]]\n",
      "822 l_822 [[['activation_160' '1']\n",
      "  ['ip_821' '0']]]\n",
      "823 ip_823 [[[]]]\n",
      "824 l_824 [[['activation_160' '2']\n",
      "  ['ip_823' '0']]]\n",
      "825 conv2d_158 [[['l_820' '0']]\n",
      "\n",
      " [['l_822' '0']]\n",
      "\n",
      " [['l_824' '0']]]\n",
      "826 ip_826 [[[]]]\n",
      "827 l_827 [[['conv2d_158' '0']\n",
      "  ['ip_826' '0']]]\n",
      "828 ip_828 [[[]]]\n",
      "829 l_829 [[['conv2d_158' '1']\n",
      "  ['ip_828' '0']]]\n",
      "830 ip_830 [[[]]]\n",
      "831 l_831 [[['conv2d_158' '2']\n",
      "  ['ip_830' '0']]]\n",
      "832 concatenate_76 [[['concatenate_75' '0']\n",
      "  ['l_827' '0']]\n",
      "\n",
      " [['concatenate_75' '1']\n",
      "  ['l_829' '0']]\n",
      "\n",
      " [['concatenate_75' '2']\n",
      "  ['l_831' '0']]]\n",
      "833 batch_normalization_122 [[['concatenate_76' '0']]\n",
      "\n",
      " [['concatenate_76' '1']]\n",
      "\n",
      " [['concatenate_76' '2']]]\n",
      "834 ip_834 [[[]]]\n",
      "835 l_835 [[['batch_normalization_122' '0']\n",
      "  ['ip_834' '0']]]\n",
      "836 ip_836 [[[]]]\n",
      "837 l_837 [[['batch_normalization_122' '1']\n",
      "  ['ip_836' '0']]]\n",
      "838 ip_838 [[[]]]\n",
      "839 l_839 [[['batch_normalization_122' '2']\n",
      "  ['ip_838' '0']]]\n",
      "840 activation_161 [[['l_835' '0']]\n",
      "\n",
      " [['l_837' '0']]\n",
      "\n",
      " [['l_839' '0']]]\n",
      "841 ip_841 [[[]]]\n",
      "842 l_842 [[['activation_161' '0']\n",
      "  ['ip_841' '0']]]\n",
      "843 ip_843 [[[]]]\n",
      "844 l_844 [[['activation_161' '1']\n",
      "  ['ip_843' '0']]]\n",
      "845 ip_845 [[[]]]\n",
      "846 l_846 [[['activation_161' '2']\n",
      "  ['ip_845' '0']]]\n",
      "847 conv2d_159 [[['l_842' '0']]\n",
      "\n",
      " [['l_844' '0']]\n",
      "\n",
      " [['l_846' '0']]]\n",
      "848 ip_848 [[[]]]\n",
      "849 l_849 [[['conv2d_159' '0']\n",
      "  ['ip_848' '0']]]\n",
      "850 ip_850 [[[]]]\n",
      "851 l_851 [[['conv2d_159' '1']\n",
      "  ['ip_850' '0']]]\n",
      "852 ip_852 [[[]]]\n",
      "853 l_853 [[['conv2d_159' '2']\n",
      "  ['ip_852' '0']]]\n",
      "854 batch_normalization_123 [[['l_849' '0']]\n",
      "\n",
      " [['l_851' '0']]\n",
      "\n",
      " [['l_853' '0']]]\n",
      "855 ip_855 [[[]]]\n",
      "856 l_856 [[['batch_normalization_123' '0']\n",
      "  ['ip_855' '0']]]\n",
      "857 ip_857 [[[]]]\n",
      "858 l_858 [[['batch_normalization_123' '1']\n",
      "  ['ip_857' '0']]]\n",
      "859 ip_859 [[[]]]\n",
      "860 l_860 [[['batch_normalization_123' '2']\n",
      "  ['ip_859' '0']]]\n",
      "861 activation_162 [[['l_856' '0']]\n",
      "\n",
      " [['l_858' '0']]\n",
      "\n",
      " [['l_860' '0']]]\n",
      "862 ip_862 [[[]]]\n",
      "863 l_863 [[['activation_162' '0']\n",
      "  ['ip_862' '0']]]\n",
      "864 ip_864 [[[]]]\n",
      "865 l_865 [[['activation_162' '1']\n",
      "  ['ip_864' '0']]]\n",
      "866 ip_866 [[[]]]\n",
      "867 l_867 [[['activation_162' '2']\n",
      "  ['ip_866' '0']]]\n",
      "868 conv2d_160 [[['l_863' '0']]\n",
      "\n",
      " [['l_865' '0']]\n",
      "\n",
      " [['l_867' '0']]]\n",
      "869 ip_869 [[[]]]\n",
      "870 l_870 [[['conv2d_160' '0']\n",
      "  ['ip_869' '0']]]\n",
      "871 ip_871 [[[]]]\n",
      "872 l_872 [[['conv2d_160' '1']\n",
      "  ['ip_871' '0']]]\n",
      "873 ip_873 [[[]]]\n",
      "874 l_874 [[['conv2d_160' '2']\n",
      "  ['ip_873' '0']]]\n",
      "875 concatenate_77 [[['concatenate_76' '0']\n",
      "  ['l_870' '0']]\n",
      "\n",
      " [['concatenate_76' '1']\n",
      "  ['l_872' '0']]\n",
      "\n",
      " [['concatenate_76' '2']\n",
      "  ['l_874' '0']]]\n",
      "876 batch_normalization_124 [[['concatenate_77' '0']]\n",
      "\n",
      " [['concatenate_77' '1']]\n",
      "\n",
      " [['concatenate_77' '2']]]\n",
      "877 ip_877 [[[]]]\n",
      "878 l_878 [[['batch_normalization_124' '0']\n",
      "  ['ip_877' '0']]]\n",
      "879 ip_879 [[[]]]\n",
      "880 l_880 [[['batch_normalization_124' '1']\n",
      "  ['ip_879' '0']]]\n",
      "881 ip_881 [[[]]]\n",
      "882 l_882 [[['batch_normalization_124' '2']\n",
      "  ['ip_881' '0']]]\n",
      "883 activation_163 [[['l_878' '0']]\n",
      "\n",
      " [['l_880' '0']]\n",
      "\n",
      " [['l_882' '0']]]\n",
      "884 ip_884 [[[]]]\n",
      "885 l_885 [[['activation_163' '0']\n",
      "  ['ip_884' '0']]]\n",
      "886 ip_886 [[[]]]\n",
      "887 l_887 [[['activation_163' '1']\n",
      "  ['ip_886' '0']]]\n",
      "888 ip_888 [[[]]]\n",
      "889 l_889 [[['activation_163' '2']\n",
      "  ['ip_888' '0']]]\n",
      "890 conv2d_161 [[['l_885' '0']]\n",
      "\n",
      " [['l_887' '0']]\n",
      "\n",
      " [['l_889' '0']]]\n",
      "891 ip_891 [[[]]]\n",
      "892 l_892 [[['conv2d_161' '0']\n",
      "  ['ip_891' '0']]]\n",
      "893 ip_893 [[[]]]\n",
      "894 l_894 [[['conv2d_161' '1']\n",
      "  ['ip_893' '0']]]\n",
      "895 ip_895 [[[]]]\n",
      "896 l_896 [[['conv2d_161' '2']\n",
      "  ['ip_895' '0']]]\n",
      "897 batch_normalization_125 [[['l_892' '0']]\n",
      "\n",
      " [['l_894' '0']]\n",
      "\n",
      " [['l_896' '0']]]\n",
      "898 ip_898 [[[]]]\n",
      "899 l_899 [[['batch_normalization_125' '0']\n",
      "  ['ip_898' '0']]]\n",
      "900 ip_900 [[[]]]\n",
      "901 l_901 [[['batch_normalization_125' '1']\n",
      "  ['ip_900' '0']]]\n",
      "902 ip_902 [[[]]]\n",
      "903 l_903 [[['batch_normalization_125' '2']\n",
      "  ['ip_902' '0']]]\n",
      "904 activation_164 [[['l_899' '0']]\n",
      "\n",
      " [['l_901' '0']]\n",
      "\n",
      " [['l_903' '0']]]\n",
      "905 ip_905 [[[]]]\n",
      "906 l_906 [[['activation_164' '0']\n",
      "  ['ip_905' '0']]]\n",
      "907 ip_907 [[[]]]\n",
      "908 l_908 [[['activation_164' '1']\n",
      "  ['ip_907' '0']]]\n",
      "909 ip_909 [[[]]]\n",
      "910 l_910 [[['activation_164' '2']\n",
      "  ['ip_909' '0']]]\n",
      "911 conv2d_162 [[['l_906' '0']]\n",
      "\n",
      " [['l_908' '0']]\n",
      "\n",
      " [['l_910' '0']]]\n",
      "912 ip_912 [[[]]]\n",
      "913 l_913 [[['conv2d_162' '0']\n",
      "  ['ip_912' '0']]]\n",
      "914 ip_914 [[[]]]\n",
      "915 l_915 [[['conv2d_162' '1']\n",
      "  ['ip_914' '0']]]\n",
      "916 ip_916 [[[]]]\n",
      "917 l_917 [[['conv2d_162' '2']\n",
      "  ['ip_916' '0']]]\n",
      "918 concatenate_78 [[['concatenate_77' '0']\n",
      "  ['l_913' '0']]\n",
      "\n",
      " [['concatenate_77' '1']\n",
      "  ['l_915' '0']]\n",
      "\n",
      " [['concatenate_77' '2']\n",
      "  ['l_917' '0']]]\n",
      "919 batch_normalization_126 [[['concatenate_78' '0']]\n",
      "\n",
      " [['concatenate_78' '1']]\n",
      "\n",
      " [['concatenate_78' '2']]]\n",
      "920 ip_920 [[[]]]\n",
      "921 l_921 [[['batch_normalization_126' '0']\n",
      "  ['ip_920' '0']]]\n",
      "922 ip_922 [[[]]]\n",
      "923 l_923 [[['batch_normalization_126' '1']\n",
      "  ['ip_922' '0']]]\n",
      "924 ip_924 [[[]]]\n",
      "925 l_925 [[['batch_normalization_126' '2']\n",
      "  ['ip_924' '0']]]\n",
      "926 activation_165 [[['l_921' '0']]\n",
      "\n",
      " [['l_923' '0']]\n",
      "\n",
      " [['l_925' '0']]]\n",
      "927 ip_927 [[[]]]\n",
      "928 l_928 [[['activation_165' '0']\n",
      "  ['ip_927' '0']]]\n",
      "929 ip_929 [[[]]]\n",
      "930 l_930 [[['activation_165' '1']\n",
      "  ['ip_929' '0']]]\n",
      "931 ip_931 [[[]]]\n",
      "932 l_932 [[['activation_165' '2']\n",
      "  ['ip_931' '0']]]\n",
      "933 conv2d_163 [[['l_928' '0']]\n",
      "\n",
      " [['l_930' '0']]\n",
      "\n",
      " [['l_932' '0']]]\n",
      "934 ip_934 [[[]]]\n",
      "935 l_935 [[['conv2d_163' '0']\n",
      "  ['ip_934' '0']]]\n",
      "936 ip_936 [[[]]]\n",
      "937 l_937 [[['conv2d_163' '1']\n",
      "  ['ip_936' '0']]]\n",
      "938 ip_938 [[[]]]\n",
      "939 l_939 [[['conv2d_163' '2']\n",
      "  ['ip_938' '0']]]\n",
      "940 batch_normalization_127 [[['l_935' '0']]\n",
      "\n",
      " [['l_937' '0']]\n",
      "\n",
      " [['l_939' '0']]]\n",
      "941 ip_941 [[[]]]\n",
      "942 l_942 [[['batch_normalization_127' '0']\n",
      "  ['ip_941' '0']]]\n",
      "943 ip_943 [[[]]]\n",
      "944 l_944 [[['batch_normalization_127' '1']\n",
      "  ['ip_943' '0']]]\n",
      "945 ip_945 [[[]]]\n",
      "946 l_946 [[['batch_normalization_127' '2']\n",
      "  ['ip_945' '0']]]\n",
      "947 activation_166 [[['l_942' '0']]\n",
      "\n",
      " [['l_944' '0']]\n",
      "\n",
      " [['l_946' '0']]]\n",
      "948 ip_948 [[[]]]\n",
      "949 l_949 [[['activation_166' '0']\n",
      "  ['ip_948' '0']]]\n",
      "950 ip_950 [[[]]]\n",
      "951 l_951 [[['activation_166' '1']\n",
      "  ['ip_950' '0']]]\n",
      "952 ip_952 [[[]]]\n",
      "953 l_953 [[['activation_166' '2']\n",
      "  ['ip_952' '0']]]\n",
      "954 conv2d_164 [[['l_949' '0']]\n",
      "\n",
      " [['l_951' '0']]\n",
      "\n",
      " [['l_953' '0']]]\n",
      "955 ip_955 [[[]]]\n",
      "956 l_956 [[['conv2d_164' '0']\n",
      "  ['ip_955' '0']]]\n",
      "957 ip_957 [[[]]]\n",
      "958 l_958 [[['conv2d_164' '1']\n",
      "  ['ip_957' '0']]]\n",
      "959 ip_959 [[[]]]\n",
      "960 l_960 [[['conv2d_164' '2']\n",
      "  ['ip_959' '0']]]\n",
      "961 concatenate_79 [[['concatenate_78' '0']\n",
      "  ['l_956' '0']]\n",
      "\n",
      " [['concatenate_78' '1']\n",
      "  ['l_958' '0']]\n",
      "\n",
      " [['concatenate_78' '2']\n",
      "  ['l_960' '0']]]\n",
      "962 batch_normalization_128 [[['concatenate_79' '0']]\n",
      "\n",
      " [['concatenate_79' '1']]\n",
      "\n",
      " [['concatenate_79' '2']]]\n",
      "963 ip_963 [[[]]]\n",
      "964 l_964 [[['batch_normalization_128' '0']\n",
      "  ['ip_963' '0']]]\n",
      "965 ip_965 [[[]]]\n",
      "966 l_966 [[['batch_normalization_128' '1']\n",
      "  ['ip_965' '0']]]\n",
      "967 ip_967 [[[]]]\n",
      "968 l_968 [[['batch_normalization_128' '2']\n",
      "  ['ip_967' '0']]]\n",
      "969 activation_167 [[['l_964' '0']]\n",
      "\n",
      " [['l_966' '0']]\n",
      "\n",
      " [['l_968' '0']]]\n",
      "970 ip_970 [[[]]]\n",
      "971 l_971 [[['activation_167' '0']\n",
      "  ['ip_970' '0']]]\n",
      "972 ip_972 [[[]]]\n",
      "973 l_973 [[['activation_167' '1']\n",
      "  ['ip_972' '0']]]\n",
      "974 ip_974 [[[]]]\n",
      "975 l_975 [[['activation_167' '2']\n",
      "  ['ip_974' '0']]]\n",
      "976 conv2d_165 [[['l_971' '0']]\n",
      "\n",
      " [['l_973' '0']]\n",
      "\n",
      " [['l_975' '0']]]\n",
      "977 ip_977 [[[]]]\n",
      "978 l_978 [[['conv2d_165' '0']\n",
      "  ['ip_977' '0']]]\n",
      "979 ip_979 [[[]]]\n",
      "980 l_980 [[['conv2d_165' '1']\n",
      "  ['ip_979' '0']]]\n",
      "981 ip_981 [[[]]]\n",
      "982 l_982 [[['conv2d_165' '2']\n",
      "  ['ip_981' '0']]]\n",
      "983 batch_normalization_129 [[['l_978' '0']]\n",
      "\n",
      " [['l_980' '0']]\n",
      "\n",
      " [['l_982' '0']]]\n",
      "984 ip_984 [[[]]]\n",
      "985 l_985 [[['batch_normalization_129' '0']\n",
      "  ['ip_984' '0']]]\n",
      "986 ip_986 [[[]]]\n",
      "987 l_987 [[['batch_normalization_129' '1']\n",
      "  ['ip_986' '0']]]\n",
      "988 ip_988 [[[]]]\n",
      "989 l_989 [[['batch_normalization_129' '2']\n",
      "  ['ip_988' '0']]]\n",
      "990 activation_168 [[['l_985' '0']]\n",
      "\n",
      " [['l_987' '0']]\n",
      "\n",
      " [['l_989' '0']]]\n",
      "991 ip_991 [[[]]]\n",
      "992 l_992 [[['activation_168' '0']\n",
      "  ['ip_991' '0']]]\n",
      "993 ip_993 [[[]]]\n",
      "994 l_994 [[['activation_168' '1']\n",
      "  ['ip_993' '0']]]\n",
      "995 ip_995 [[[]]]\n",
      "996 l_996 [[['activation_168' '2']\n",
      "  ['ip_995' '0']]]\n",
      "997 conv2d_166 [[['l_992' '0']]\n",
      "\n",
      " [['l_994' '0']]\n",
      "\n",
      " [['l_996' '0']]]\n",
      "998 ip_998 [[[]]]\n",
      "999 l_999 [[['conv2d_166' '0']\n",
      "  ['ip_998' '0']]]\n",
      "1000 ip_1000 [[[]]]\n",
      "1001 l_1001 [[['conv2d_166' '1']\n",
      "  ['ip_1000' '0']]]\n",
      "1002 ip_1002 [[[]]]\n",
      "1003 l_1003 [[['conv2d_166' '2']\n",
      "  ['ip_1002' '0']]]\n",
      "1004 concatenate_80 [[['concatenate_79' '0']\n",
      "  ['l_999' '0']]\n",
      "\n",
      " [['concatenate_79' '1']\n",
      "  ['l_1001' '0']]\n",
      "\n",
      " [['concatenate_79' '2']\n",
      "  ['l_1003' '0']]]\n",
      "1005 batch_normalization_130 [[['concatenate_80' '0']]\n",
      "\n",
      " [['concatenate_80' '1']]\n",
      "\n",
      " [['concatenate_80' '2']]]\n",
      "1006 ip_1006 [[[]]]\n",
      "1007 l_1007 [[['batch_normalization_130' '0']\n",
      "  ['ip_1006' '0']]]\n",
      "1008 ip_1008 [[[]]]\n",
      "1009 l_1009 [[['batch_normalization_130' '1']\n",
      "  ['ip_1008' '0']]]\n",
      "1010 ip_1010 [[[]]]\n",
      "1011 l_1011 [[['batch_normalization_130' '2']\n",
      "  ['ip_1010' '0']]]\n",
      "1012 activation_169 [[['l_1007' '0']]\n",
      "\n",
      " [['l_1009' '0']]\n",
      "\n",
      " [['l_1011' '0']]]\n",
      "1013 ip_1013 [[[]]]\n",
      "1014 l_1014 [[['activation_169' '0']\n",
      "  ['ip_1013' '0']]]\n",
      "1015 ip_1015 [[[]]]\n",
      "1016 l_1016 [[['activation_169' '1']\n",
      "  ['ip_1015' '0']]]\n",
      "1017 ip_1017 [[[]]]\n",
      "1018 l_1018 [[['activation_169' '2']\n",
      "  ['ip_1017' '0']]]\n",
      "1019 conv2d_167 [[['l_1014' '0']]\n",
      "\n",
      " [['l_1016' '0']]\n",
      "\n",
      " [['l_1018' '0']]]\n",
      "1020 ip_1020 [[[]]]\n",
      "1021 l_1021 [[['conv2d_167' '0']\n",
      "  ['ip_1020' '0']]]\n",
      "1022 ip_1022 [[[]]]\n",
      "1023 l_1023 [[['conv2d_167' '1']\n",
      "  ['ip_1022' '0']]]\n",
      "1024 ip_1024 [[[]]]\n",
      "1025 l_1025 [[['conv2d_167' '2']\n",
      "  ['ip_1024' '0']]]\n",
      "1026 batch_normalization_131 [[['l_1021' '0']]\n",
      "\n",
      " [['l_1023' '0']]\n",
      "\n",
      " [['l_1025' '0']]]\n",
      "1027 ip_1027 [[[]]]\n",
      "1028 l_1028 [[['batch_normalization_131' '0']\n",
      "  ['ip_1027' '0']]]\n",
      "1029 ip_1029 [[[]]]\n",
      "1030 l_1030 [[['batch_normalization_131' '1']\n",
      "  ['ip_1029' '0']]]\n",
      "1031 ip_1031 [[[]]]\n",
      "1032 l_1032 [[['batch_normalization_131' '2']\n",
      "  ['ip_1031' '0']]]\n",
      "1033 activation_170 [[['l_1028' '0']]\n",
      "\n",
      " [['l_1030' '0']]\n",
      "\n",
      " [['l_1032' '0']]]\n",
      "1034 ip_1034 [[[]]]\n",
      "1035 l_1035 [[['activation_170' '0']\n",
      "  ['ip_1034' '0']]]\n",
      "1036 ip_1036 [[[]]]\n",
      "1037 l_1037 [[['activation_170' '1']\n",
      "  ['ip_1036' '0']]]\n",
      "1038 ip_1038 [[[]]]\n",
      "1039 l_1039 [[['activation_170' '2']\n",
      "  ['ip_1038' '0']]]\n",
      "1040 conv2d_168 [[['l_1035' '0']]\n",
      "\n",
      " [['l_1037' '0']]\n",
      "\n",
      " [['l_1039' '0']]]\n",
      "1041 ip_1041 [[[]]]\n",
      "1042 l_1042 [[['conv2d_168' '0']\n",
      "  ['ip_1041' '0']]]\n",
      "1043 ip_1043 [[[]]]\n",
      "1044 l_1044 [[['conv2d_168' '1']\n",
      "  ['ip_1043' '0']]]\n",
      "1045 ip_1045 [[[]]]\n",
      "1046 l_1046 [[['conv2d_168' '2']\n",
      "  ['ip_1045' '0']]]\n",
      "1047 concatenate_81 [[['concatenate_80' '0']\n",
      "  ['l_1042' '0']]\n",
      "\n",
      " [['concatenate_80' '1']\n",
      "  ['l_1044' '0']]\n",
      "\n",
      " [['concatenate_80' '2']\n",
      "  ['l_1046' '0']]]\n",
      "1048 batch_normalization_132 [[['concatenate_81' '0']]\n",
      "\n",
      " [['concatenate_81' '1']]\n",
      "\n",
      " [['concatenate_81' '2']]]\n",
      "1049 ip_1049 [[[]]]\n",
      "1050 l_1050 [[['batch_normalization_132' '0']\n",
      "  ['ip_1049' '0']]]\n",
      "1051 ip_1051 [[[]]]\n",
      "1052 l_1052 [[['batch_normalization_132' '1']\n",
      "  ['ip_1051' '0']]]\n",
      "1053 ip_1053 [[[]]]\n",
      "1054 l_1054 [[['batch_normalization_132' '2']\n",
      "  ['ip_1053' '0']]]\n",
      "1055 activation_171 [[['l_1050' '0']]\n",
      "\n",
      " [['l_1052' '0']]\n",
      "\n",
      " [['l_1054' '0']]]\n",
      "1056 ip_1056 [[[]]]\n",
      "1057 l_1057 [[['activation_171' '0']\n",
      "  ['ip_1056' '0']]]\n",
      "1058 ip_1058 [[[]]]\n",
      "1059 l_1059 [[['activation_171' '1']\n",
      "  ['ip_1058' '0']]]\n",
      "1060 ip_1060 [[[]]]\n",
      "1061 l_1061 [[['activation_171' '2']\n",
      "  ['ip_1060' '0']]]\n",
      "1062 conv2d_169 [[['l_1057' '0']]\n",
      "\n",
      " [['l_1059' '0']]\n",
      "\n",
      " [['l_1061' '0']]]\n",
      "1063 ip_1063 [[[]]]\n",
      "1064 l_1064 [[['conv2d_169' '0']\n",
      "  ['ip_1063' '0']]]\n",
      "1065 ip_1065 [[[]]]\n",
      "1066 l_1066 [[['conv2d_169' '1']\n",
      "  ['ip_1065' '0']]]\n",
      "1067 ip_1067 [[[]]]\n",
      "1068 l_1068 [[['conv2d_169' '2']\n",
      "  ['ip_1067' '0']]]\n",
      "1069 batch_normalization_133 [[['l_1064' '0']]\n",
      "\n",
      " [['l_1066' '0']]\n",
      "\n",
      " [['l_1068' '0']]]\n",
      "1070 ip_1070 [[[]]]\n",
      "1071 l_1071 [[['batch_normalization_133' '0']\n",
      "  ['ip_1070' '0']]]\n",
      "1072 ip_1072 [[[]]]\n",
      "1073 l_1073 [[['batch_normalization_133' '1']\n",
      "  ['ip_1072' '0']]]\n",
      "1074 ip_1074 [[[]]]\n",
      "1075 l_1075 [[['batch_normalization_133' '2']\n",
      "  ['ip_1074' '0']]]\n",
      "1076 activation_172 [[['l_1071' '0']]\n",
      "\n",
      " [['l_1073' '0']]\n",
      "\n",
      " [['l_1075' '0']]]\n",
      "1077 ip_1077 [[[]]]\n",
      "1078 l_1078 [[['activation_172' '0']\n",
      "  ['ip_1077' '0']]]\n",
      "1079 ip_1079 [[[]]]\n",
      "1080 l_1080 [[['activation_172' '1']\n",
      "  ['ip_1079' '0']]]\n",
      "1081 ip_1081 [[[]]]\n",
      "1082 l_1082 [[['activation_172' '2']\n",
      "  ['ip_1081' '0']]]\n",
      "1083 conv2d_170 [[['l_1078' '0']]\n",
      "\n",
      " [['l_1080' '0']]\n",
      "\n",
      " [['l_1082' '0']]]\n",
      "1084 ip_1084 [[[]]]\n",
      "1085 l_1085 [[['conv2d_170' '0']\n",
      "  ['ip_1084' '0']]]\n",
      "1086 ip_1086 [[[]]]\n",
      "1087 l_1087 [[['conv2d_170' '1']\n",
      "  ['ip_1086' '0']]]\n",
      "1088 ip_1088 [[[]]]\n",
      "1089 l_1089 [[['conv2d_170' '2']\n",
      "  ['ip_1088' '0']]]\n",
      "1090 concatenate_82 [[['concatenate_81' '0']\n",
      "  ['l_1085' '0']]\n",
      "\n",
      " [['concatenate_81' '1']\n",
      "  ['l_1087' '0']]\n",
      "\n",
      " [['concatenate_81' '2']\n",
      "  ['l_1089' '0']]]\n",
      "1091 batch_normalization_134 [[['concatenate_82' '0']]\n",
      "\n",
      " [['concatenate_82' '1']]\n",
      "\n",
      " [['concatenate_82' '2']]]\n",
      "1092 ip_1092 [[[]]]\n",
      "1093 l_1093 [[['batch_normalization_134' '0']\n",
      "  ['ip_1092' '0']]]\n",
      "1094 ip_1094 [[[]]]\n",
      "1095 l_1095 [[['batch_normalization_134' '1']\n",
      "  ['ip_1094' '0']]]\n",
      "1096 ip_1096 [[[]]]\n",
      "1097 l_1097 [[['batch_normalization_134' '2']\n",
      "  ['ip_1096' '0']]]\n",
      "1098 activation_173 [[['l_1093' '0']]\n",
      "\n",
      " [['l_1095' '0']]\n",
      "\n",
      " [['l_1097' '0']]]\n",
      "1099 ip_1099 [[[]]]\n",
      "1100 l_1100 [[['activation_173' '0']\n",
      "  ['ip_1099' '0']]]\n",
      "1101 ip_1101 [[[]]]\n",
      "1102 l_1102 [[['activation_173' '1']\n",
      "  ['ip_1101' '0']]]\n",
      "1103 ip_1103 [[[]]]\n",
      "1104 l_1104 [[['activation_173' '2']\n",
      "  ['ip_1103' '0']]]\n",
      "1105 conv2d_171 [[['l_1100' '0']]\n",
      "\n",
      " [['l_1102' '0']]\n",
      "\n",
      " [['l_1104' '0']]]\n",
      "1106 ip_1106 [[[]]]\n",
      "1107 l_1107 [[['conv2d_171' '0']\n",
      "  ['ip_1106' '0']]]\n",
      "1108 ip_1108 [[[]]]\n",
      "1109 l_1109 [[['conv2d_171' '1']\n",
      "  ['ip_1108' '0']]]\n",
      "1110 ip_1110 [[[]]]\n",
      "1111 l_1111 [[['conv2d_171' '2']\n",
      "  ['ip_1110' '0']]]\n",
      "1112 batch_normalization_135 [[['l_1107' '0']]\n",
      "\n",
      " [['l_1109' '0']]\n",
      "\n",
      " [['l_1111' '0']]]\n",
      "1113 ip_1113 [[[]]]\n",
      "1114 l_1114 [[['batch_normalization_135' '0']\n",
      "  ['ip_1113' '0']]]\n",
      "1115 ip_1115 [[[]]]\n",
      "1116 l_1116 [[['batch_normalization_135' '1']\n",
      "  ['ip_1115' '0']]]\n",
      "1117 ip_1117 [[[]]]\n",
      "1118 l_1118 [[['batch_normalization_135' '2']\n",
      "  ['ip_1117' '0']]]\n",
      "1119 activation_174 [[['l_1114' '0']]\n",
      "\n",
      " [['l_1116' '0']]\n",
      "\n",
      " [['l_1118' '0']]]\n",
      "1120 ip_1120 [[[]]]\n",
      "1121 l_1121 [[['activation_174' '0']\n",
      "  ['ip_1120' '0']]]\n",
      "1122 ip_1122 [[[]]]\n",
      "1123 l_1123 [[['activation_174' '1']\n",
      "  ['ip_1122' '0']]]\n",
      "1124 ip_1124 [[[]]]\n",
      "1125 l_1125 [[['activation_174' '2']\n",
      "  ['ip_1124' '0']]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126 conv2d_172 [[['l_1121' '0']]\n",
      "\n",
      " [['l_1123' '0']]\n",
      "\n",
      " [['l_1125' '0']]]\n",
      "1127 ip_1127 [[[]]]\n",
      "1128 l_1128 [[['conv2d_172' '0']\n",
      "  ['ip_1127' '0']]]\n",
      "1129 ip_1129 [[[]]]\n",
      "1130 l_1130 [[['conv2d_172' '1']\n",
      "  ['ip_1129' '0']]]\n",
      "1131 ip_1131 [[[]]]\n",
      "1132 l_1132 [[['conv2d_172' '2']\n",
      "  ['ip_1131' '0']]]\n",
      "1133 concatenate_83 [[['concatenate_82' '0']\n",
      "  ['l_1128' '0']]\n",
      "\n",
      " [['concatenate_82' '1']\n",
      "  ['l_1130' '0']]\n",
      "\n",
      " [['concatenate_82' '2']\n",
      "  ['l_1132' '0']]]\n",
      "1134 batch_normalization_136 [[['concatenate_83' '0']]\n",
      "\n",
      " [['concatenate_83' '1']]\n",
      "\n",
      " [['concatenate_83' '2']]]\n",
      "1135 ip_1135 [[[]]]\n",
      "1136 l_1136 [[['batch_normalization_136' '0']\n",
      "  ['ip_1135' '0']]]\n",
      "1137 ip_1137 [[[]]]\n",
      "1138 l_1138 [[['batch_normalization_136' '1']\n",
      "  ['ip_1137' '0']]]\n",
      "1139 ip_1139 [[[]]]\n",
      "1140 l_1140 [[['batch_normalization_136' '2']\n",
      "  ['ip_1139' '0']]]\n",
      "1141 activation_175 [[['l_1136' '0']]\n",
      "\n",
      " [['l_1138' '0']]\n",
      "\n",
      " [['l_1140' '0']]]\n",
      "1142 ip_1142 [[[]]]\n",
      "1143 l_1143 [[['activation_175' '0']\n",
      "  ['ip_1142' '0']]]\n",
      "1144 ip_1144 [[[]]]\n",
      "1145 l_1145 [[['activation_175' '1']\n",
      "  ['ip_1144' '0']]]\n",
      "1146 ip_1146 [[[]]]\n",
      "1147 l_1147 [[['activation_175' '2']\n",
      "  ['ip_1146' '0']]]\n",
      "1148 conv2d_173 [[['l_1143' '0']]\n",
      "\n",
      " [['l_1145' '0']]\n",
      "\n",
      " [['l_1147' '0']]]\n",
      "1149 ip_1149 [[[]]]\n",
      "1150 l_1150 [[['conv2d_173' '0']\n",
      "  ['ip_1149' '0']]]\n",
      "1151 ip_1151 [[[]]]\n",
      "1152 l_1152 [[['conv2d_173' '1']\n",
      "  ['ip_1151' '0']]]\n",
      "1153 ip_1153 [[[]]]\n",
      "1154 l_1154 [[['conv2d_173' '2']\n",
      "  ['ip_1153' '0']]]\n",
      "1155 batch_normalization_137 [[['l_1150' '0']]\n",
      "\n",
      " [['l_1152' '0']]\n",
      "\n",
      " [['l_1154' '0']]]\n",
      "1156 ip_1156 [[[]]]\n",
      "1157 l_1157 [[['batch_normalization_137' '0']\n",
      "  ['ip_1156' '0']]]\n",
      "1158 ip_1158 [[[]]]\n",
      "1159 l_1159 [[['batch_normalization_137' '1']\n",
      "  ['ip_1158' '0']]]\n",
      "1160 ip_1160 [[[]]]\n",
      "1161 l_1161 [[['batch_normalization_137' '2']\n",
      "  ['ip_1160' '0']]]\n",
      "1162 activation_176 [[['l_1157' '0']]\n",
      "\n",
      " [['l_1159' '0']]\n",
      "\n",
      " [['l_1161' '0']]]\n",
      "1163 ip_1163 [[[]]]\n",
      "1164 l_1164 [[['activation_176' '0']\n",
      "  ['ip_1163' '0']]]\n",
      "1165 ip_1165 [[[]]]\n",
      "1166 l_1166 [[['activation_176' '1']\n",
      "  ['ip_1165' '0']]]\n",
      "1167 ip_1167 [[[]]]\n",
      "1168 l_1168 [[['activation_176' '2']\n",
      "  ['ip_1167' '0']]]\n",
      "1169 conv2d_174 [[['l_1164' '0']]\n",
      "\n",
      " [['l_1166' '0']]\n",
      "\n",
      " [['l_1168' '0']]]\n",
      "1170 ip_1170 [[[]]]\n",
      "1171 l_1171 [[['conv2d_174' '0']\n",
      "  ['ip_1170' '0']]]\n",
      "1172 ip_1172 [[[]]]\n",
      "1173 l_1173 [[['conv2d_174' '1']\n",
      "  ['ip_1172' '0']]]\n",
      "1174 ip_1174 [[[]]]\n",
      "1175 l_1175 [[['conv2d_174' '2']\n",
      "  ['ip_1174' '0']]]\n",
      "1176 concatenate_84 [[['concatenate_83' '0']\n",
      "  ['l_1171' '0']]\n",
      "\n",
      " [['concatenate_83' '1']\n",
      "  ['l_1173' '0']]\n",
      "\n",
      " [['concatenate_83' '2']\n",
      "  ['l_1175' '0']]]\n",
      "1177 batch_normalization_138 [[['concatenate_84' '0']]\n",
      "\n",
      " [['concatenate_84' '1']]\n",
      "\n",
      " [['concatenate_84' '2']]]\n",
      "1178 ip_1178 [[[]]]\n",
      "1179 l_1179 [[['batch_normalization_138' '0']\n",
      "  ['ip_1178' '0']]]\n",
      "1180 ip_1180 [[[]]]\n",
      "1181 l_1181 [[['batch_normalization_138' '1']\n",
      "  ['ip_1180' '0']]]\n",
      "1182 ip_1182 [[[]]]\n",
      "1183 l_1183 [[['batch_normalization_138' '2']\n",
      "  ['ip_1182' '0']]]\n",
      "1184 activation_177 [[['l_1179' '0']]\n",
      "\n",
      " [['l_1181' '0']]\n",
      "\n",
      " [['l_1183' '0']]]\n",
      "1185 ip_1185 [[[]]]\n",
      "1186 l_1186 [[['activation_177' '0']\n",
      "  ['ip_1185' '0']]]\n",
      "1187 ip_1187 [[[]]]\n",
      "1188 l_1188 [[['activation_177' '1']\n",
      "  ['ip_1187' '0']]]\n",
      "1189 ip_1189 [[[]]]\n",
      "1190 l_1190 [[['activation_177' '2']\n",
      "  ['ip_1189' '0']]]\n",
      "1191 global_average_pooling2d_2 [[['l_1186' '0']]\n",
      "\n",
      " [['l_1188' '0']]\n",
      "\n",
      " [['l_1190' '0']]]\n",
      "1192 ip_1192 [[[]]]\n",
      "1193 l_1193 [[['global_average_pooling2d_2' '0']\n",
      "  ['ip_1192' '0']]]\n",
      "1194 ip_1194 [[[]]]\n",
      "1195 l_1195 [[['global_average_pooling2d_2' '1']\n",
      "  ['ip_1194' '0']]]\n",
      "1196 ip_1196 [[[]]]\n",
      "1197 l_1197 [[['global_average_pooling2d_2' '2']\n",
      "  ['ip_1196' '0']]]\n",
      "1198 dense_3 [[['l_1193' '0']]\n",
      "\n",
      " [['l_1195' '0']]\n",
      "\n",
      " [['l_1197' '0']]]\n",
      "1199 ip_1199 [[[]]]\n",
      "1200 l_1200 [[['dense_3' '0']\n",
      "  ['ip_1199' '0']]]\n",
      "1201 ip_1201 [[[]]]\n",
      "1202 l_1202 [[['dense_3' '1']\n",
      "  ['ip_1201' '0']]]\n",
      "1203 ip_1203 [[[]]]\n",
      "1204 l_1204 [[['dense_3' '2']\n",
      "  ['ip_1203' '0']]]\n",
      "1205 batch_normalization_139 [[['l_1200' '0']]\n",
      "\n",
      " [['l_1202' '0']]\n",
      "\n",
      " [['l_1204' '0']]]\n",
      "1206 ip_1206 [[[]]]\n",
      "1207 l_1207 [[['batch_normalization_139' '0']\n",
      "  ['ip_1206' '0']]]\n",
      "1208 ip_1208 [[[]]]\n",
      "1209 l_1209 [[['batch_normalization_139' '1']\n",
      "  ['ip_1208' '0']]]\n",
      "1210 ip_1210 [[[]]]\n",
      "1211 l_1211 [[['batch_normalization_139' '2']\n",
      "  ['ip_1210' '0']]]\n",
      "1212 activation_178 [[['l_1207' '0']]\n",
      "\n",
      " [['l_1209' '0']]\n",
      "\n",
      " [['l_1211' '0']]]\n",
      "1213 ip_1213 [[[]]]\n",
      "1214 l_1214 [[['activation_178' '0']\n",
      "  ['ip_1213' '0']]]\n",
      "1215 ip_1215 [[[]]]\n",
      "1216 l_1216 [[['activation_178' '1']\n",
      "  ['ip_1215' '0']]]\n",
      "1217 ip_1217 [[[]]]\n",
      "1218 l_1218 [[['activation_178' '2']\n",
      "  ['ip_1217' '0']]]\n",
      "1219 dense_4 [[['l_1214' '0']]\n",
      "\n",
      " [['l_1216' '0']]\n",
      "\n",
      " [['l_1218' '0']]]\n",
      "1220 ip_1220 [[[]]]\n",
      "1221 ip_1221 [[[]]]\n",
      "1222 l_1222 [[['dense_4' '0']\n",
      "  ['ip_1220' '0']\n",
      "  ['ip_1221' '0']]]\n",
      "1223 ip_1223 [[[]]]\n",
      "1224 ip_1224 [[[]]]\n",
      "1225 l_1225 [[['dense_4' '1']\n",
      "  ['ip_1223' '0']\n",
      "  ['ip_1224' '0']]]\n",
      "1226 ip_1226 [[[]]]\n",
      "1227 ip_1227 [[[]]]\n",
      "1228 l_1228 [[['dense_4' '2']\n",
      "  ['ip_1226' '0']\n",
      "  ['ip_1227' '0']]]\n"
     ]
    }
   ],
   "source": [
    "for l in range(len(model.layers)):\n",
    "    print l, model.layers[l].name, model.layers[l].inbound_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "test = Model(model.inputs, model.layers[543].output)\n",
    "a = tf.constant(test.predict(batch[0]))\n",
    "mask = K.eval(model.layers[540].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.00000000e+00,   1.12186298e-01,   5.56558892e-02,\n",
       "         9.41705517e-03,   0.00000000e+00,   2.98125873e-04,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         2.00105280e-01,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   2.18646955e-02,   0.00000000e+00,\n",
       "         0.00000000e+00,   3.06696922e-01,   0.00000000e+00,\n",
       "         8.23424682e-02,   2.86889166e-01,   4.14733559e-01,\n",
       "         0.00000000e+00,   0.00000000e+00,   3.43840830e-02,\n",
       "         1.08856201e-01,   0.00000000e+00,   0.00000000e+00,\n",
       "         9.30332765e-02,   2.04043090e-01,   3.43850136e-01,\n",
       "         5.92045523e-02,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   4.75657672e-01,   2.84294952e-02,\n",
       "         4.62558493e-02,   4.50276792e-01,   0.00000000e+00,\n",
       "         0.00000000e+00,   9.90876406e-02,   3.68063211e-01,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   3.28397453e-01,\n",
       "         0.00000000e+00,   3.34104270e-01,   0.00000000e+00,\n",
       "         0.00000000e+00,   2.52121508e-01,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   8.33539963e-02,\n",
       "         0.00000000e+00,   0.00000000e+00,   9.00952592e-02,\n",
       "         0.00000000e+00,   0.00000000e+00,   4.49642658e-01,\n",
       "         0.00000000e+00,   5.48911802e-02,   0.00000000e+00,\n",
       "         2.71055162e-01,   0.00000000e+00,   0.00000000e+00,\n",
       "         5.20108819e-01,   0.00000000e+00,   2.38872487e-02,\n",
       "         0.00000000e+00,   0.00000000e+00,   1.70077935e-01,\n",
       "         3.14667910e-01,   2.44766921e-02,   0.00000000e+00,\n",
       "         1.68241441e-01,   2.14100510e-01,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   1.54806495e-01,\n",
       "         1.79730639e-01,   1.56842604e-01,   2.65640974e-01,\n",
       "         3.05321217e-01,   4.02716905e-01,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   9.02527124e-02,\n",
       "         4.83477086e-01,   5.89077473e-02,   9.35298279e-02,\n",
       "         0.00000000e+00,   4.45802987e-01,   3.73120964e-01,\n",
       "         0.00000000e+00,   3.05401057e-01,   7.39960745e-02,\n",
       "         0.00000000e+00,   0.00000000e+00,   1.06360190e-01,\n",
       "         5.88935390e-02,   4.11105156e-01,   0.00000000e+00,\n",
       "         1.06902629e-01,   0.00000000e+00,   1.09637365e-01,\n",
       "         0.00000000e+00,   0.00000000e+00,   9.01231244e-02,\n",
       "         0.00000000e+00,   1.45327896e-01,   0.00000000e+00,\n",
       "         1.61305428e-01,   2.44300351e-01,   3.09304953e-01,\n",
       "         0.00000000e+00,   0.00000000e+00,   1.36598721e-01,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         8.25505052e-03,   2.00958669e-01,   2.33483478e-01,\n",
       "         0.00000000e+00,   0.00000000e+00,   2.40093291e-01,\n",
       "         4.28540967e-02,   0.00000000e+00,   1.10608481e-01,\n",
       "         0.00000000e+00,   4.26409468e-02,   0.00000000e+00,\n",
       "         0.00000000e+00,   1.93847284e-01,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   2.66749740e-01,\n",
       "         2.61919061e-03,   0.00000000e+00,   0.00000000e+00,\n",
       "         2.30475944e-02,   8.70849192e-02,   3.26228201e-01,\n",
       "         0.00000000e+00,   0.00000000e+00,   2.16364488e-01,\n",
       "         0.00000000e+00,   2.96228919e-02,   2.07589611e-01,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         2.77237356e-01,   1.50781870e-01,   1.38968661e-01,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   5.19007407e-02,\n",
       "         0.00000000e+00,   9.36671793e-02,   3.04202810e-02,\n",
       "         1.28243156e-02,   2.00946610e-02,   0.00000000e+00,\n",
       "         7.52666667e-02,   0.00000000e+00,   0.00000000e+00,\n",
       "         2.41741650e-02,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   9.05322060e-02,   0.00000000e+00,\n",
       "         3.20933871e-02,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         9.08808038e-02,   4.93598208e-02,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   3.66896838e-02,   1.17709562e-02,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         5.01931123e-02,   4.07652147e-02,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         2.39933170e-02,   0.00000000e+00,   8.49565417e-02,\n",
       "         9.26319603e-03,   0.00000000e+00,   1.24319028e-02,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         1.58247538e-02,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   3.43566872e-02,\n",
       "         5.72581217e-02,   0.00000000e+00,   5.83775751e-02,\n",
       "         6.31472170e-02,   0.00000000e+00,   1.14178061e-02,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.eval(a)[0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_indices(shape, mask):\n",
    "    w = np.ones(shape)\n",
    "    if mask is None:\n",
    "        return np.stack(np.where(w == 0)).transpose()\n",
    "    else:\n",
    "        for i in np.nditer(np.where(mask == 1)[0]):\n",
    "            exec('w[' + ':,' * (len(shape) - 1) + 'i] = 0') in locals()\n",
    "    return np.stack(np.where(w == 0)).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask[:512] = 0\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 8, 4, 672]\n"
     ]
    }
   ],
   "source": [
    "shape = [20] + a.get_shape().as_list()[1:]\n",
    "print shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.05190074  0.          0.09366718 ...,  0.          0.00388719\n",
      "  0.13098586]\n"
     ]
    }
   ],
   "source": [
    "b = tf.gather_nd(a, get_indices(shape, mask))\n",
    "print K.eval(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 8, 4, 5, 11)\n"
     ]
    }
   ],
   "source": [
    "c = tf.reshape(b, shape[:-1] + [-1, 11])\n",
    "print K.eval(c).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 8, 4, 5, 32)\n"
     ]
    }
   ],
   "source": [
    "d = tf.tile(c, [1]*len(shape) + [3])[:,:,:,:,:32]\n",
    "print K.eval(d).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 8, 4, 160)\n"
     ]
    }
   ],
   "source": [
    "e = tf.reshape(d, shape[:-1] + [-1])\n",
    "print K.eval(e).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1, 0, 1, 2, 3]\n",
      "l_start 310\n",
      "[-1, 0, 1, 2, 3]\n",
      "idx [21846, 4]\n",
      "gather [21846]\n",
      "idx [23212, 4]\n",
      "gather [23212]\n",
      "idx [24578, 4]\n",
      "gather [24578]\n",
      "idx [25944, 4]\n",
      "gather [25944]\n",
      "idx [27310, 4]\n",
      "gather [27310]\n",
      "idx [28676, 4]\n",
      "gather [28676]\n",
      "idx [30042, 4]\n",
      "gather [30042]\n",
      "idx [31408, 4]\n",
      "gather [31408]\n",
      "idx [32774, 4]\n",
      "gather [32774]\n",
      "idx [34140, 4]\n",
      "gather [34140]\n",
      "idx [35506, 4]\n",
      "gather [35506]\n",
      "idx [36872, 4]\n",
      "gather [36872]\n",
      "idx [38238, 4]\n",
      "gather [38238]\n",
      "idx [39604, 4]\n",
      "gather [39604]\n",
      "idx [40970, 4]\n",
      "gather [40970]\n",
      "idx [42336, 4]\n",
      "gather [42336]\n",
      "idx [21846, 4]\n",
      "gather [21846]\n",
      "idx [23212, 4]\n",
      "gather [23212]\n",
      "idx [24578, 4]\n",
      "gather [24578]\n",
      "idx [25944, 4]\n",
      "gather [25944]\n",
      "idx [27310, 4]\n",
      "gather [27310]\n",
      "idx [28676, 4]\n",
      "gather [28676]\n",
      "idx [30042, 4]\n",
      "gather [30042]\n",
      "idx [31408, 4]\n",
      "gather [31408]\n",
      "idx [32774, 4]\n",
      "gather [32774]\n",
      "idx [34140, 4]\n",
      "gather [34140]\n",
      "idx [35506, 4]\n",
      "gather [35506]\n",
      "idx [36872, 4]\n",
      "gather [36872]\n",
      "idx [38238, 4]\n",
      "gather [38238]\n",
      "idx [39604, 4]\n",
      "gather [39604]\n",
      "idx [40970, 4]\n",
      "gather [40970]\n",
      "idx [42336, 4]\n",
      "gather [42336]\n",
      "idx [21846, 4]\n",
      "gather [21846]\n",
      "idx [23212, 4]\n",
      "gather [23212]\n",
      "idx [24578, 4]\n",
      "gather [24578]\n",
      "idx [25944, 4]\n",
      "gather [25944]\n",
      "idx [27310, 4]\n",
      "gather [27310]\n",
      "idx [28676, 4]\n",
      "gather [28676]\n",
      "idx [30042, 4]\n",
      "gather [30042]\n",
      "idx [31408, 4]\n",
      "gather [31408]\n",
      "idx [32774, 4]\n",
      "gather [32774]\n",
      "idx [34140, 4]\n",
      "gather [34140]\n",
      "idx [35506, 4]\n",
      "gather [35506]\n",
      "idx [36872, 4]\n",
      "gather [36872]\n",
      "idx [38238, 4]\n",
      "gather [38238]\n",
      "idx [39604, 4]\n",
      "gather [39604]\n",
      "idx [40970, 4]\n",
      "gather [40970]\n",
      "idx [42336, 4]\n",
      "gather [42336]\n",
      "[<tf.Tensor 'lambda_622/Reshape:0' shape=(?, ?) dtype=float32>, <tf.Tensor 'lambda_623/Reshape:0' shape=(?, ?) dtype=float32>, <tf.Tensor 'lambda_624/Reshape:0' shape=(?, ?) dtype=float32>]\n",
      "0.2\n",
      "[0, 128, 256, 384]\n",
      "(1, 128)\n",
      "(1, 128)\n",
      "(1, 128)\n"
     ]
    }
   ],
   "source": [
    "model_eval = models.DenseNetDrop(blocks=4, tile=True)\n",
    "\n",
    "# model_eval = models_bk2.DenseNet121Drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_2 (InputLayer)             (None, 256, 128, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)              (None, 128, 64, 64)   9408        input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchNo (None, 128, 64, 64)   256         conv2d_121[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_123 (Activation)      (None, 128, 64, 64)   0           batch_normalization_157[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)   (None, 64, 32, 64)    0           activation_123[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchNo (None, 64, 32, 64)    256         max_pooling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_124 (Activation)      (None, 64, 32, 64)    0           batch_normalization_158[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)              (None, 64, 32, 128)   8192        activation_124[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchNo (None, 64, 32, 128)   512         conv2d_122[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_125 (Activation)      (None, 64, 32, 128)   0           batch_normalization_159[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)              (None, 64, 32, 32)    36864       activation_125[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_59 (Concatenate)     (None, 64, 32, 96)    0           max_pooling2d_2[0][0]            \n",
      "                                                                   conv2d_123[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchNo (None, 64, 32, 96)    384         concatenate_59[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_126 (Activation)      (None, 64, 32, 96)    0           batch_normalization_160[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)              (None, 64, 32, 128)   12288       activation_126[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchNo (None, 64, 32, 128)   512         conv2d_124[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_127 (Activation)      (None, 64, 32, 128)   0           batch_normalization_161[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)              (None, 64, 32, 32)    36864       activation_127[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_60 (Concatenate)     (None, 64, 32, 128)   0           concatenate_59[0][0]             \n",
      "                                                                   conv2d_125[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchNo (None, 64, 32, 128)   512         concatenate_60[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_128 (Activation)      (None, 64, 32, 128)   0           batch_normalization_162[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)              (None, 64, 32, 128)   16384       activation_128[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchNo (None, 64, 32, 128)   512         conv2d_126[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_129 (Activation)      (None, 64, 32, 128)   0           batch_normalization_163[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)              (None, 64, 32, 32)    36864       activation_129[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_61 (Concatenate)     (None, 64, 32, 160)   0           concatenate_60[0][0]             \n",
      "                                                                   conv2d_127[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchNo (None, 64, 32, 160)   640         concatenate_61[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_130 (Activation)      (None, 64, 32, 160)   0           batch_normalization_164[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)              (None, 64, 32, 128)   20480       activation_130[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchNo (None, 64, 32, 128)   512         conv2d_128[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_131 (Activation)      (None, 64, 32, 128)   0           batch_normalization_165[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)              (None, 64, 32, 32)    36864       activation_131[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_62 (Concatenate)     (None, 64, 32, 192)   0           concatenate_61[0][0]             \n",
      "                                                                   conv2d_129[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchNo (None, 64, 32, 192)   768         concatenate_62[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_132 (Activation)      (None, 64, 32, 192)   0           batch_normalization_166[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)              (None, 64, 32, 128)   24576       activation_132[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchNo (None, 64, 32, 128)   512         conv2d_130[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_133 (Activation)      (None, 64, 32, 128)   0           batch_normalization_167[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)              (None, 64, 32, 32)    36864       activation_133[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_63 (Concatenate)     (None, 64, 32, 224)   0           concatenate_62[0][0]             \n",
      "                                                                   conv2d_131[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchNo (None, 64, 32, 224)   896         concatenate_63[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_134 (Activation)      (None, 64, 32, 224)   0           batch_normalization_168[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)              (None, 64, 32, 128)   28672       activation_134[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchNo (None, 64, 32, 128)   512         conv2d_132[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_135 (Activation)      (None, 64, 32, 128)   0           batch_normalization_169[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)              (None, 64, 32, 32)    36864       activation_135[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_64 (Concatenate)     (None, 64, 32, 256)   0           concatenate_63[0][0]             \n",
      "                                                                   conv2d_133[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchNo (None, 64, 32, 256)   1024        concatenate_64[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_136 (Activation)      (None, 64, 32, 256)   0           batch_normalization_170[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)              (None, 64, 32, 128)   32768       activation_136[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePool (None, 32, 16, 128)   0           conv2d_134[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchNo (None, 32, 16, 128)   512         average_pooling2d_4[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "activation_137 (Activation)      (None, 32, 16, 128)   0           batch_normalization_171[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)              (None, 32, 16, 128)   16384       activation_137[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchNo (None, 32, 16, 128)   512         conv2d_135[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_138 (Activation)      (None, 32, 16, 128)   0           batch_normalization_172[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)              (None, 32, 16, 32)    36864       activation_138[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_65 (Concatenate)     (None, 32, 16, 160)   0           average_pooling2d_4[0][0]        \n",
      "                                                                   conv2d_136[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchNo (None, 32, 16, 160)   640         concatenate_65[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_139 (Activation)      (None, 32, 16, 160)   0           batch_normalization_173[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)              (None, 32, 16, 128)   20480       activation_139[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchNo (None, 32, 16, 128)   512         conv2d_137[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_140 (Activation)      (None, 32, 16, 128)   0           batch_normalization_174[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)              (None, 32, 16, 32)    36864       activation_140[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_66 (Concatenate)     (None, 32, 16, 192)   0           concatenate_65[0][0]             \n",
      "                                                                   conv2d_138[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchNo (None, 32, 16, 192)   768         concatenate_66[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_141 (Activation)      (None, 32, 16, 192)   0           batch_normalization_175[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)              (None, 32, 16, 128)   24576       activation_141[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchNo (None, 32, 16, 128)   512         conv2d_139[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_142 (Activation)      (None, 32, 16, 128)   0           batch_normalization_176[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)              (None, 32, 16, 32)    36864       activation_142[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_67 (Concatenate)     (None, 32, 16, 224)   0           concatenate_66[0][0]             \n",
      "                                                                   conv2d_140[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchNo (None, 32, 16, 224)   896         concatenate_67[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_143 (Activation)      (None, 32, 16, 224)   0           batch_normalization_177[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)              (None, 32, 16, 128)   28672       activation_143[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchNo (None, 32, 16, 128)   512         conv2d_141[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_144 (Activation)      (None, 32, 16, 128)   0           batch_normalization_178[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)              (None, 32, 16, 32)    36864       activation_144[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_68 (Concatenate)     (None, 32, 16, 256)   0           concatenate_67[0][0]             \n",
      "                                                                   conv2d_142[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchNo (None, 32, 16, 256)   1024        concatenate_68[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_145 (Activation)      (None, 32, 16, 256)   0           batch_normalization_179[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)              (None, 32, 16, 128)   32768       activation_145[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchNo (None, 32, 16, 128)   512         conv2d_143[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_146 (Activation)      (None, 32, 16, 128)   0           batch_normalization_180[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)              (None, 32, 16, 32)    36864       activation_146[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_69 (Concatenate)     (None, 32, 16, 288)   0           concatenate_68[0][0]             \n",
      "                                                                   conv2d_144[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchNo (None, 32, 16, 288)   1152        concatenate_69[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_147 (Activation)      (None, 32, 16, 288)   0           batch_normalization_181[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)              (None, 32, 16, 128)   36864       activation_147[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchNo (None, 32, 16, 128)   512         conv2d_145[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_148 (Activation)      (None, 32, 16, 128)   0           batch_normalization_182[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)              (None, 32, 16, 32)    36864       activation_148[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_70 (Concatenate)     (None, 32, 16, 320)   0           concatenate_69[0][0]             \n",
      "                                                                   conv2d_146[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchNo (None, 32, 16, 320)   1280        concatenate_70[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_149 (Activation)      (None, 32, 16, 320)   0           batch_normalization_183[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)              (None, 32, 16, 128)   40960       activation_149[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchNo (None, 32, 16, 128)   512         conv2d_147[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_150 (Activation)      (None, 32, 16, 128)   0           batch_normalization_184[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)              (None, 32, 16, 32)    36864       activation_150[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_71 (Concatenate)     (None, 32, 16, 352)   0           concatenate_70[0][0]             \n",
      "                                                                   conv2d_148[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchNo (None, 32, 16, 352)   1408        concatenate_71[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_151 (Activation)      (None, 32, 16, 352)   0           batch_normalization_185[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)              (None, 32, 16, 128)   45056       activation_151[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchNo (None, 32, 16, 128)   512         conv2d_149[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_152 (Activation)      (None, 32, 16, 128)   0           batch_normalization_186[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)              (None, 32, 16, 32)    36864       activation_152[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_72 (Concatenate)     (None, 32, 16, 384)   0           concatenate_71[0][0]             \n",
      "                                                                   conv2d_150[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchNo (None, 32, 16, 384)   1536        concatenate_72[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_153 (Activation)      (None, 32, 16, 384)   0           batch_normalization_187[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)              (None, 32, 16, 128)   49152       activation_153[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchNo (None, 32, 16, 128)   512         conv2d_151[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_154 (Activation)      (None, 32, 16, 128)   0           batch_normalization_188[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)              (None, 32, 16, 32)    36864       activation_154[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_73 (Concatenate)     (None, 32, 16, 416)   0           concatenate_72[0][0]             \n",
      "                                                                   conv2d_152[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchNo (None, 32, 16, 416)   1664        concatenate_73[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_155 (Activation)      (None, 32, 16, 416)   0           batch_normalization_189[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)              (None, 32, 16, 128)   53248       activation_155[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchNo (None, 32, 16, 128)   512         conv2d_153[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_156 (Activation)      (None, 32, 16, 128)   0           batch_normalization_190[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)              (None, 32, 16, 32)    36864       activation_156[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_74 (Concatenate)     (None, 32, 16, 448)   0           concatenate_73[0][0]             \n",
      "                                                                   conv2d_154[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchNo (None, 32, 16, 448)   1792        concatenate_74[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_157 (Activation)      (None, 32, 16, 448)   0           batch_normalization_191[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)              (None, 32, 16, 128)   57344       activation_157[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchNo (None, 32, 16, 128)   512         conv2d_155[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_158 (Activation)      (None, 32, 16, 128)   0           batch_normalization_192[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)              (None, 32, 16, 32)    36864       activation_158[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_75 (Concatenate)     (None, 32, 16, 480)   0           concatenate_74[0][0]             \n",
      "                                                                   conv2d_156[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchNo (None, 32, 16, 480)   1920        concatenate_75[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_159 (Activation)      (None, 32, 16, 480)   0           batch_normalization_193[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)              (None, 32, 16, 128)   61440       activation_159[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchNo (None, 32, 16, 128)   512         conv2d_157[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_160 (Activation)      (None, 32, 16, 128)   0           batch_normalization_194[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)              (None, 32, 16, 32)    36864       activation_160[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_76 (Concatenate)     (None, 32, 16, 512)   0           concatenate_75[0][0]             \n",
      "                                                                   conv2d_158[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchNo (None, 32, 16, 512)   2048        concatenate_76[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_161 (Activation)      (None, 32, 16, 512)   0           batch_normalization_195[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)              (None, 32, 16, 256)   131072      activation_161[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePool (None, 16, 8, 256)    0           conv2d_159[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchNo (None, 16, 8, 256)    1024        average_pooling2d_5[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "activation_162 (Activation)      (None, 16, 8, 256)    0           batch_normalization_196[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)              (None, 16, 8, 128)    32768       activation_162[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchNo (None, 16, 8, 128)    512         conv2d_160[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_163 (Activation)      (None, 16, 8, 128)    0           batch_normalization_197[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)              (None, 16, 8, 32)     36864       activation_163[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_77 (Concatenate)     (None, 16, 8, 288)    0           average_pooling2d_5[0][0]        \n",
      "                                                                   conv2d_161[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchNo (None, 16, 8, 288)    1152        concatenate_77[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_164 (Activation)      (None, 16, 8, 288)    0           batch_normalization_198[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)              (None, 16, 8, 128)    36864       activation_164[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchNo (None, 16, 8, 128)    512         conv2d_162[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_165 (Activation)      (None, 16, 8, 128)    0           batch_normalization_199[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)              (None, 16, 8, 32)     36864       activation_165[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_78 (Concatenate)     (None, 16, 8, 320)    0           concatenate_77[0][0]             \n",
      "                                                                   conv2d_163[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchNo (None, 16, 8, 320)    1280        concatenate_78[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_166 (Activation)      (None, 16, 8, 320)    0           batch_normalization_200[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)              (None, 16, 8, 128)    40960       activation_166[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchNo (None, 16, 8, 128)    512         conv2d_164[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_167 (Activation)      (None, 16, 8, 128)    0           batch_normalization_201[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)              (None, 16, 8, 32)     36864       activation_167[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_79 (Concatenate)     (None, 16, 8, 352)    0           concatenate_78[0][0]             \n",
      "                                                                   conv2d_165[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchNo (None, 16, 8, 352)    1408        concatenate_79[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_168 (Activation)      (None, 16, 8, 352)    0           batch_normalization_202[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)              (None, 16, 8, 128)    45056       activation_168[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchNo (None, 16, 8, 128)    512         conv2d_166[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_169 (Activation)      (None, 16, 8, 128)    0           batch_normalization_203[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)              (None, 16, 8, 32)     36864       activation_169[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_80 (Concatenate)     (None, 16, 8, 384)    0           concatenate_79[0][0]             \n",
      "                                                                   conv2d_167[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchNo (None, 16, 8, 384)    1536        concatenate_80[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_170 (Activation)      (None, 16, 8, 384)    0           batch_normalization_204[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)              (None, 16, 8, 128)    49152       activation_170[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchNo (None, 16, 8, 128)    512         conv2d_168[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_171 (Activation)      (None, 16, 8, 128)    0           batch_normalization_205[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)              (None, 16, 8, 32)     36864       activation_171[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_81 (Concatenate)     (None, 16, 8, 416)    0           concatenate_80[0][0]             \n",
      "                                                                   conv2d_169[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchNo (None, 16, 8, 416)    1664        concatenate_81[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_172 (Activation)      (None, 16, 8, 416)    0           batch_normalization_206[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)              (None, 16, 8, 128)    53248       activation_172[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchNo (None, 16, 8, 128)    512         conv2d_170[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_173 (Activation)      (None, 16, 8, 128)    0           batch_normalization_207[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)              (None, 16, 8, 32)     36864       activation_173[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_82 (Concatenate)     (None, 16, 8, 448)    0           concatenate_81[0][0]             \n",
      "                                                                   conv2d_171[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_208 (BatchNo (None, 16, 8, 448)    1792        concatenate_82[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_174 (Activation)      (None, 16, 8, 448)    0           batch_normalization_208[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)              (None, 16, 8, 128)    57344       activation_174[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_209 (BatchNo (None, 16, 8, 128)    512         conv2d_172[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_175 (Activation)      (None, 16, 8, 128)    0           batch_normalization_209[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)              (None, 16, 8, 32)     36864       activation_175[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_83 (Concatenate)     (None, 16, 8, 480)    0           concatenate_82[0][0]             \n",
      "                                                                   conv2d_173[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchNo (None, 16, 8, 480)    1920        concatenate_83[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_176 (Activation)      (None, 16, 8, 480)    0           batch_normalization_210[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)              (None, 16, 8, 128)    61440       activation_176[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchNo (None, 16, 8, 128)    512         conv2d_174[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_177 (Activation)      (None, 16, 8, 128)    0           batch_normalization_211[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)              (None, 16, 8, 32)     36864       activation_177[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_84 (Concatenate)     (None, 16, 8, 512)    0           concatenate_83[0][0]             \n",
      "                                                                   conv2d_175[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_212 (BatchNo (None, 16, 8, 512)    2048        concatenate_84[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_178 (Activation)      (None, 16, 8, 512)    0           batch_normalization_212[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)              (None, 16, 8, 128)    65536       activation_178[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_213 (BatchNo (None, 16, 8, 128)    512         conv2d_176[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_179 (Activation)      (None, 16, 8, 128)    0           batch_normalization_213[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)              (None, 16, 8, 32)     36864       activation_179[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_85 (Concatenate)     (None, 16, 8, 544)    0           concatenate_84[0][0]             \n",
      "                                                                   conv2d_177[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_214 (BatchNo (None, 16, 8, 544)    2176        concatenate_85[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_180 (Activation)      (None, 16, 8, 544)    0           batch_normalization_214[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)              (None, 16, 8, 128)    69632       activation_180[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_215 (BatchNo (None, 16, 8, 128)    512         conv2d_178[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_181 (Activation)      (None, 16, 8, 128)    0           batch_normalization_215[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)              (None, 16, 8, 32)     36864       activation_181[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_86 (Concatenate)     (None, 16, 8, 576)    0           concatenate_85[0][0]             \n",
      "                                                                   conv2d_179[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_216 (BatchNo (None, 16, 8, 576)    2304        concatenate_86[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_182 (Activation)      (None, 16, 8, 576)    0           batch_normalization_216[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)              (None, 16, 8, 128)    73728       activation_182[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_217 (BatchNo (None, 16, 8, 128)    512         conv2d_180[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_183 (Activation)      (None, 16, 8, 128)    0           batch_normalization_217[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)              (None, 16, 8, 32)     36864       activation_183[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_87 (Concatenate)     (None, 16, 8, 608)    0           concatenate_86[0][0]             \n",
      "                                                                   conv2d_181[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_218 (BatchNo (None, 16, 8, 608)    2432        concatenate_87[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_184 (Activation)      (None, 16, 8, 608)    0           batch_normalization_218[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)              (None, 16, 8, 128)    77824       activation_184[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_219 (BatchNo (None, 16, 8, 128)    512         conv2d_182[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_185 (Activation)      (None, 16, 8, 128)    0           batch_normalization_219[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)              (None, 16, 8, 32)     36864       activation_185[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_88 (Concatenate)     (None, 16, 8, 640)    0           concatenate_87[0][0]             \n",
      "                                                                   conv2d_183[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_220 (BatchNo (None, 16, 8, 640)    2560        concatenate_88[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_186 (Activation)      (None, 16, 8, 640)    0           batch_normalization_220[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)              (None, 16, 8, 128)    81920       activation_186[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_221 (BatchNo (None, 16, 8, 128)    512         conv2d_184[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_187 (Activation)      (None, 16, 8, 128)    0           batch_normalization_221[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)              (None, 16, 8, 32)     36864       activation_187[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_89 (Concatenate)     (None, 16, 8, 672)    0           concatenate_88[0][0]             \n",
      "                                                                   conv2d_185[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_222 (BatchNo (None, 16, 8, 672)    2688        concatenate_89[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_188 (Activation)      (None, 16, 8, 672)    0           batch_normalization_222[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)              (None, 16, 8, 128)    86016       activation_188[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_223 (BatchNo (None, 16, 8, 128)    512         conv2d_186[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_189 (Activation)      (None, 16, 8, 128)    0           batch_normalization_223[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)              (None, 16, 8, 32)     36864       activation_189[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_90 (Concatenate)     (None, 16, 8, 704)    0           concatenate_89[0][0]             \n",
      "                                                                   conv2d_187[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_224 (BatchNo (None, 16, 8, 704)    2816        concatenate_90[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_190 (Activation)      (None, 16, 8, 704)    0           batch_normalization_224[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)              (None, 16, 8, 128)    90112       activation_190[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_225 (BatchNo (None, 16, 8, 128)    512         conv2d_188[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_191 (Activation)      (None, 16, 8, 128)    0           batch_normalization_225[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)              (None, 16, 8, 32)     36864       activation_191[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_91 (Concatenate)     (None, 16, 8, 736)    0           concatenate_90[0][0]             \n",
      "                                                                   conv2d_189[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_226 (BatchNo (None, 16, 8, 736)    2944        concatenate_91[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_192 (Activation)      (None, 16, 8, 736)    0           batch_normalization_226[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)              (None, 16, 8, 128)    94208       activation_192[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_227 (BatchNo (None, 16, 8, 128)    512         conv2d_190[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_193 (Activation)      (None, 16, 8, 128)    0           batch_normalization_227[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)              (None, 16, 8, 32)     36864       activation_193[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_92 (Concatenate)     (None, 16, 8, 768)    0           concatenate_91[0][0]             \n",
      "                                                                   conv2d_191[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_228 (BatchNo (None, 16, 8, 768)    3072        concatenate_92[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_194 (Activation)      (None, 16, 8, 768)    0           batch_normalization_228[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)              (None, 16, 8, 128)    98304       activation_194[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_229 (BatchNo (None, 16, 8, 128)    512         conv2d_192[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_195 (Activation)      (None, 16, 8, 128)    0           batch_normalization_229[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)              (None, 16, 8, 32)     36864       activation_195[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_93 (Concatenate)     (None, 16, 8, 800)    0           concatenate_92[0][0]             \n",
      "                                                                   conv2d_193[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_230 (BatchNo (None, 16, 8, 800)    3200        concatenate_93[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_196 (Activation)      (None, 16, 8, 800)    0           batch_normalization_230[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)              (None, 16, 8, 128)    102400      activation_196[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_231 (BatchNo (None, 16, 8, 128)    512         conv2d_194[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_197 (Activation)      (None, 16, 8, 128)    0           batch_normalization_231[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)              (None, 16, 8, 32)     36864       activation_197[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_94 (Concatenate)     (None, 16, 8, 832)    0           concatenate_93[0][0]             \n",
      "                                                                   conv2d_195[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_232 (BatchNo (None, 16, 8, 832)    3328        concatenate_94[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_198 (Activation)      (None, 16, 8, 832)    0           batch_normalization_232[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)              (None, 16, 8, 128)    106496      activation_198[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_233 (BatchNo (None, 16, 8, 128)    512         conv2d_196[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_199 (Activation)      (None, 16, 8, 128)    0           batch_normalization_233[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)              (None, 16, 8, 32)     36864       activation_199[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_95 (Concatenate)     (None, 16, 8, 864)    0           concatenate_94[0][0]             \n",
      "                                                                   conv2d_197[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_234 (BatchNo (None, 16, 8, 864)    3456        concatenate_95[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_200 (Activation)      (None, 16, 8, 864)    0           batch_normalization_234[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)              (None, 16, 8, 128)    110592      activation_200[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_235 (BatchNo (None, 16, 8, 128)    512         conv2d_198[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_201 (Activation)      (None, 16, 8, 128)    0           batch_normalization_235[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)              (None, 16, 8, 32)     36864       activation_201[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_96 (Concatenate)     (None, 16, 8, 896)    0           concatenate_95[0][0]             \n",
      "                                                                   conv2d_199[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_236 (BatchNo (None, 16, 8, 896)    3584        concatenate_96[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_202 (Activation)      (None, 16, 8, 896)    0           batch_normalization_236[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)              (None, 16, 8, 128)    114688      activation_202[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_237 (BatchNo (None, 16, 8, 128)    512         conv2d_200[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_203 (Activation)      (None, 16, 8, 128)    0           batch_normalization_237[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)              (None, 16, 8, 32)     36864       activation_203[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_97 (Concatenate)     (None, 16, 8, 928)    0           concatenate_96[0][0]             \n",
      "                                                                   conv2d_201[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_238 (BatchNo (None, 16, 8, 928)    3712        concatenate_97[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_204 (Activation)      (None, 16, 8, 928)    0           batch_normalization_238[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)              (None, 16, 8, 128)    118784      activation_204[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_239 (BatchNo (None, 16, 8, 128)    512         conv2d_202[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_205 (Activation)      (None, 16, 8, 128)    0           batch_normalization_239[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)              (None, 16, 8, 32)     36864       activation_205[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_98 (Concatenate)     (None, 16, 8, 960)    0           concatenate_97[0][0]             \n",
      "                                                                   conv2d_203[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_240 (BatchNo (None, 16, 8, 960)    3840        concatenate_98[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_206 (Activation)      (None, 16, 8, 960)    0           batch_normalization_240[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)              (None, 16, 8, 128)    122880      activation_206[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_241 (BatchNo (None, 16, 8, 128)    512         conv2d_204[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_207 (Activation)      (None, 16, 8, 128)    0           batch_normalization_241[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)              (None, 16, 8, 32)     36864       activation_207[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_99 (Concatenate)     (None, 16, 8, 992)    0           concatenate_98[0][0]             \n",
      "                                                                   conv2d_205[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_242 (BatchNo (None, 16, 8, 992)    3968        concatenate_99[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_208 (Activation)      (None, 16, 8, 992)    0           batch_normalization_242[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)              (None, 16, 8, 128)    126976      activation_208[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_243 (BatchNo (None, 16, 8, 128)    512         conv2d_206[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_209 (Activation)      (None, 16, 8, 128)    0           batch_normalization_243[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)              (None, 16, 8, 32)     36864       activation_209[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_100 (Concatenate)    (None, 16, 8, 1024)   0           concatenate_99[0][0]             \n",
      "                                                                   conv2d_207[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_244 (BatchNo (None, 16, 8, 1024)   4096        concatenate_100[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_210 (Activation)      (None, 16, 8, 1024)   0           batch_normalization_244[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)              (None, 16, 8, 512)    524288      activation_210[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePool (None, 8, 4, 512)     0           conv2d_208[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_4 (InputLayer)             (512,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_5 (InputLayer)             (512,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_6 (InputLayer)             (512,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)                (None, 8, 4, 512)     0           average_pooling2d_6[0][0]        \n",
      "                                                                   input_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)                (None, 8, 4, 512)     0           average_pooling2d_6[0][0]        \n",
      "                                                                   input_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)                (None, 8, 4, 512)     0           average_pooling2d_6[0][0]        \n",
      "                                                                   input_6[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchNo (None, 8, 4, 512)     2048        lambda_1[0][0]                   \n",
      "                                                                   lambda_2[0][0]                   \n",
      "                                                                   lambda_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "input_7 (InputLayer)             (512,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_8 (InputLayer)             (512,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_9 (InputLayer)             (512,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)                (None, 8, 4, 512)     0           batch_normalization_123[0][0]    \n",
      "                                                                   input_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)                (None, 8, 4, 512)     0           batch_normalization_123[1][0]    \n",
      "                                                                   input_8[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)                (None, 8, 4, 512)     0           batch_normalization_123[2][0]    \n",
      "                                                                   input_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_211 (Activation)      (None, 8, 4, 512)     0           lambda_4[0][0]                   \n",
      "                                                                   lambda_5[0][0]                   \n",
      "                                                                   lambda_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "input_10 (InputLayer)            (512,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_11 (InputLayer)            (512,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_12 (InputLayer)            (512,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)                (None, 8, 4, 512)     0           activation_211[0][0]             \n",
      "                                                                   input_10[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)                (None, 8, 4, 512)     0           activation_211[1][0]             \n",
      "                                                                   input_11[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)                (None, 8, 4, 512)     0           activation_211[2][0]             \n",
      "                                                                   input_12[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)              (None, 8, 4, 128)     65536       lambda_7[0][0]                   \n",
      "                                                                   lambda_8[0][0]                   \n",
      "                                                                   lambda_9[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "input_13 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_14 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_15 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)               (None, 8, 4, 128)     0           conv2d_209[0][0]                 \n",
      "                                                                   input_13[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)               (None, 8, 4, 128)     0           conv2d_209[1][0]                 \n",
      "                                                                   input_14[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)               (None, 8, 4, 128)     0           conv2d_209[2][0]                 \n",
      "                                                                   input_15[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchNo (None, 8, 4, 128)     512         lambda_10[0][0]                  \n",
      "                                                                   lambda_11[0][0]                  \n",
      "                                                                   lambda_12[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_16 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_17 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_18 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)               (None, 8, 4, 128)     0           batch_normalization_124[0][0]    \n",
      "                                                                   input_16[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)               (None, 8, 4, 128)     0           batch_normalization_124[1][0]    \n",
      "                                                                   input_17[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)               (None, 8, 4, 128)     0           batch_normalization_124[2][0]    \n",
      "                                                                   input_18[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_212 (Activation)      (None, 8, 4, 128)     0           lambda_13[0][0]                  \n",
      "                                                                   lambda_14[0][0]                  \n",
      "                                                                   lambda_15[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_19 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_20 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_21 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)               (None, 8, 4, 128)     0           activation_212[0][0]             \n",
      "                                                                   input_19[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)               (None, 8, 4, 128)     0           activation_212[1][0]             \n",
      "                                                                   input_20[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)               (None, 8, 4, 128)     0           activation_212[2][0]             \n",
      "                                                                   input_21[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)              (None, 8, 4, 32)      36864       lambda_16[0][0]                  \n",
      "                                                                   lambda_17[0][0]                  \n",
      "                                                                   lambda_18[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_22 (InputLayer)            (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_23 (InputLayer)            (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_24 (InputLayer)            (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)               (None, 8, 4, 32)      0           conv2d_210[0][0]                 \n",
      "                                                                   input_22[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_20 (Lambda)               (None, 8, 4, 32)      0           conv2d_210[1][0]                 \n",
      "                                                                   input_23[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)               (None, 8, 4, 32)      0           conv2d_210[2][0]                 \n",
      "                                                                   input_24[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_101 (Concatenate)    (None, 8, 4, 544)     0           lambda_1[0][0]                   \n",
      "                                                                   lambda_19[0][0]                  \n",
      "                                                                   lambda_2[0][0]                   \n",
      "                                                                   lambda_20[0][0]                  \n",
      "                                                                   lambda_3[0][0]                   \n",
      "                                                                   lambda_21[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchNo (None, 8, 4, 544)     2176        concatenate_101[0][0]            \n",
      "                                                                   concatenate_101[1][0]            \n",
      "                                                                   concatenate_101[2][0]            \n",
      "____________________________________________________________________________________________________\n",
      "input_25 (InputLayer)            (544,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_26 (InputLayer)            (544,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_27 (InputLayer)            (544,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)               (None, 8, 4, 544)     0           batch_normalization_125[0][0]    \n",
      "                                                                   input_25[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)               (None, 8, 4, 544)     0           batch_normalization_125[1][0]    \n",
      "                                                                   input_26[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_24 (Lambda)               (None, 8, 4, 544)     0           batch_normalization_125[2][0]    \n",
      "                                                                   input_27[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_213 (Activation)      (None, 8, 4, 544)     0           lambda_22[0][0]                  \n",
      "                                                                   lambda_23[0][0]                  \n",
      "                                                                   lambda_24[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_28 (InputLayer)            (544,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_29 (InputLayer)            (544,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_30 (InputLayer)            (544,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_25 (Lambda)               (None, 8, 4, 544)     0           activation_213[0][0]             \n",
      "                                                                   input_28[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_26 (Lambda)               (None, 8, 4, 544)     0           activation_213[1][0]             \n",
      "                                                                   input_29[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_27 (Lambda)               (None, 8, 4, 544)     0           activation_213[2][0]             \n",
      "                                                                   input_30[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)              (None, 8, 4, 128)     69632       lambda_25[0][0]                  \n",
      "                                                                   lambda_26[0][0]                  \n",
      "                                                                   lambda_27[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_31 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_32 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_33 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_28 (Lambda)               (None, 8, 4, 128)     0           conv2d_211[0][0]                 \n",
      "                                                                   input_31[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_29 (Lambda)               (None, 8, 4, 128)     0           conv2d_211[1][0]                 \n",
      "                                                                   input_32[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_30 (Lambda)               (None, 8, 4, 128)     0           conv2d_211[2][0]                 \n",
      "                                                                   input_33[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchNo (None, 8, 4, 128)     512         lambda_28[0][0]                  \n",
      "                                                                   lambda_29[0][0]                  \n",
      "                                                                   lambda_30[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_34 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_35 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_36 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_31 (Lambda)               (None, 8, 4, 128)     0           batch_normalization_126[0][0]    \n",
      "                                                                   input_34[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_32 (Lambda)               (None, 8, 4, 128)     0           batch_normalization_126[1][0]    \n",
      "                                                                   input_35[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_33 (Lambda)               (None, 8, 4, 128)     0           batch_normalization_126[2][0]    \n",
      "                                                                   input_36[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_214 (Activation)      (None, 8, 4, 128)     0           lambda_31[0][0]                  \n",
      "                                                                   lambda_32[0][0]                  \n",
      "                                                                   lambda_33[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_37 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_38 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_39 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_34 (Lambda)               (None, 8, 4, 128)     0           activation_214[0][0]             \n",
      "                                                                   input_37[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_35 (Lambda)               (None, 8, 4, 128)     0           activation_214[1][0]             \n",
      "                                                                   input_38[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_36 (Lambda)               (None, 8, 4, 128)     0           activation_214[2][0]             \n",
      "                                                                   input_39[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)              (None, 8, 4, 32)      36864       lambda_34[0][0]                  \n",
      "                                                                   lambda_35[0][0]                  \n",
      "                                                                   lambda_36[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_40 (InputLayer)            (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_41 (InputLayer)            (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_42 (InputLayer)            (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_37 (Lambda)               (None, 8, 4, 32)      0           conv2d_212[0][0]                 \n",
      "                                                                   input_40[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_38 (Lambda)               (None, 8, 4, 32)      0           conv2d_212[1][0]                 \n",
      "                                                                   input_41[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_39 (Lambda)               (None, 8, 4, 32)      0           conv2d_212[2][0]                 \n",
      "                                                                   input_42[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_102 (Concatenate)    (None, 8, 4, 576)     0           concatenate_101[0][0]            \n",
      "                                                                   lambda_37[0][0]                  \n",
      "                                                                   concatenate_101[1][0]            \n",
      "                                                                   lambda_38[0][0]                  \n",
      "                                                                   concatenate_101[2][0]            \n",
      "                                                                   lambda_39[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchNo (None, 8, 4, 576)     2304        concatenate_102[0][0]            \n",
      "                                                                   concatenate_102[1][0]            \n",
      "                                                                   concatenate_102[2][0]            \n",
      "____________________________________________________________________________________________________\n",
      "input_43 (InputLayer)            (576,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_44 (InputLayer)            (576,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_45 (InputLayer)            (576,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_40 (Lambda)               (None, 8, 4, 576)     0           batch_normalization_127[0][0]    \n",
      "                                                                   input_43[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_41 (Lambda)               (None, 8, 4, 576)     0           batch_normalization_127[1][0]    \n",
      "                                                                   input_44[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_42 (Lambda)               (None, 8, 4, 576)     0           batch_normalization_127[2][0]    \n",
      "                                                                   input_45[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_215 (Activation)      (None, 8, 4, 576)     0           lambda_40[0][0]                  \n",
      "                                                                   lambda_41[0][0]                  \n",
      "                                                                   lambda_42[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_46 (InputLayer)            (576,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_47 (InputLayer)            (576,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_48 (InputLayer)            (576,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_43 (Lambda)               (None, 8, 4, 576)     0           activation_215[0][0]             \n",
      "                                                                   input_46[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_44 (Lambda)               (None, 8, 4, 576)     0           activation_215[1][0]             \n",
      "                                                                   input_47[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_45 (Lambda)               (None, 8, 4, 576)     0           activation_215[2][0]             \n",
      "                                                                   input_48[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)              (None, 8, 4, 128)     73728       lambda_43[0][0]                  \n",
      "                                                                   lambda_44[0][0]                  \n",
      "                                                                   lambda_45[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_49 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_50 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_51 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_46 (Lambda)               (None, 8, 4, 128)     0           conv2d_213[0][0]                 \n",
      "                                                                   input_49[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_47 (Lambda)               (None, 8, 4, 128)     0           conv2d_213[1][0]                 \n",
      "                                                                   input_50[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_48 (Lambda)               (None, 8, 4, 128)     0           conv2d_213[2][0]                 \n",
      "                                                                   input_51[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchNo (None, 8, 4, 128)     512         lambda_46[0][0]                  \n",
      "                                                                   lambda_47[0][0]                  \n",
      "                                                                   lambda_48[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_52 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_53 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_54 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_49 (Lambda)               (None, 8, 4, 128)     0           batch_normalization_128[0][0]    \n",
      "                                                                   input_52[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_50 (Lambda)               (None, 8, 4, 128)     0           batch_normalization_128[1][0]    \n",
      "                                                                   input_53[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_51 (Lambda)               (None, 8, 4, 128)     0           batch_normalization_128[2][0]    \n",
      "                                                                   input_54[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_216 (Activation)      (None, 8, 4, 128)     0           lambda_49[0][0]                  \n",
      "                                                                   lambda_50[0][0]                  \n",
      "                                                                   lambda_51[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_55 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_56 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_57 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_52 (Lambda)               (None, 8, 4, 128)     0           activation_216[0][0]             \n",
      "                                                                   input_55[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_53 (Lambda)               (None, 8, 4, 128)     0           activation_216[1][0]             \n",
      "                                                                   input_56[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_54 (Lambda)               (None, 8, 4, 128)     0           activation_216[2][0]             \n",
      "                                                                   input_57[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)              (None, 8, 4, 32)      36864       lambda_52[0][0]                  \n",
      "                                                                   lambda_53[0][0]                  \n",
      "                                                                   lambda_54[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_58 (InputLayer)            (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_59 (InputLayer)            (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_60 (InputLayer)            (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_55 (Lambda)               (None, 8, 4, 32)      0           conv2d_214[0][0]                 \n",
      "                                                                   input_58[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_56 (Lambda)               (None, 8, 4, 32)      0           conv2d_214[1][0]                 \n",
      "                                                                   input_59[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_57 (Lambda)               (None, 8, 4, 32)      0           conv2d_214[2][0]                 \n",
      "                                                                   input_60[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_103 (Concatenate)    (None, 8, 4, 608)     0           concatenate_102[0][0]            \n",
      "                                                                   lambda_55[0][0]                  \n",
      "                                                                   concatenate_102[1][0]            \n",
      "                                                                   lambda_56[0][0]                  \n",
      "                                                                   concatenate_102[2][0]            \n",
      "                                                                   lambda_57[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchNo (None, 8, 4, 608)     2432        concatenate_103[0][0]            \n",
      "                                                                   concatenate_103[1][0]            \n",
      "                                                                   concatenate_103[2][0]            \n",
      "____________________________________________________________________________________________________\n",
      "input_61 (InputLayer)            (608,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_62 (InputLayer)            (608,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_63 (InputLayer)            (608,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_58 (Lambda)               (None, 8, 4, 608)     0           batch_normalization_129[0][0]    \n",
      "                                                                   input_61[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_59 (Lambda)               (None, 8, 4, 608)     0           batch_normalization_129[1][0]    \n",
      "                                                                   input_62[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_60 (Lambda)               (None, 8, 4, 608)     0           batch_normalization_129[2][0]    \n",
      "                                                                   input_63[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_217 (Activation)      (None, 8, 4, 608)     0           lambda_58[0][0]                  \n",
      "                                                                   lambda_59[0][0]                  \n",
      "                                                                   lambda_60[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_64 (InputLayer)            (608,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_65 (InputLayer)            (608,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_66 (InputLayer)            (608,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_61 (Lambda)               (None, 8, 4, 608)     0           activation_217[0][0]             \n",
      "                                                                   input_64[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_62 (Lambda)               (None, 8, 4, 608)     0           activation_217[1][0]             \n",
      "                                                                   input_65[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_63 (Lambda)               (None, 8, 4, 608)     0           activation_217[2][0]             \n",
      "                                                                   input_66[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)              (None, 8, 4, 128)     77824       lambda_61[0][0]                  \n",
      "                                                                   lambda_62[0][0]                  \n",
      "                                                                   lambda_63[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_67 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_68 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_69 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_64 (Lambda)               (None, 8, 4, 128)     0           conv2d_215[0][0]                 \n",
      "                                                                   input_67[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_65 (Lambda)               (None, 8, 4, 128)     0           conv2d_215[1][0]                 \n",
      "                                                                   input_68[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_66 (Lambda)               (None, 8, 4, 128)     0           conv2d_215[2][0]                 \n",
      "                                                                   input_69[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchNo (None, 8, 4, 128)     512         lambda_64[0][0]                  \n",
      "                                                                   lambda_65[0][0]                  \n",
      "                                                                   lambda_66[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_70 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_71 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_72 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_67 (Lambda)               (None, 8, 4, 128)     0           batch_normalization_130[0][0]    \n",
      "                                                                   input_70[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_68 (Lambda)               (None, 8, 4, 128)     0           batch_normalization_130[1][0]    \n",
      "                                                                   input_71[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_69 (Lambda)               (None, 8, 4, 128)     0           batch_normalization_130[2][0]    \n",
      "                                                                   input_72[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_218 (Activation)      (None, 8, 4, 128)     0           lambda_67[0][0]                  \n",
      "                                                                   lambda_68[0][0]                  \n",
      "                                                                   lambda_69[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_73 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_74 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_75 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_70 (Lambda)               (None, 8, 4, 128)     0           activation_218[0][0]             \n",
      "                                                                   input_73[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_71 (Lambda)               (None, 8, 4, 128)     0           activation_218[1][0]             \n",
      "                                                                   input_74[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_72 (Lambda)               (None, 8, 4, 128)     0           activation_218[2][0]             \n",
      "                                                                   input_75[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)              (None, 8, 4, 32)      36864       lambda_70[0][0]                  \n",
      "                                                                   lambda_71[0][0]                  \n",
      "                                                                   lambda_72[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_76 (InputLayer)            (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_77 (InputLayer)            (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_78 (InputLayer)            (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_73 (Lambda)               (None, 8, 4, 32)      0           conv2d_216[0][0]                 \n",
      "                                                                   input_76[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_74 (Lambda)               (None, 8, 4, 32)      0           conv2d_216[1][0]                 \n",
      "                                                                   input_77[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_75 (Lambda)               (None, 8, 4, 32)      0           conv2d_216[2][0]                 \n",
      "                                                                   input_78[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_104 (Concatenate)    (None, 8, 4, 640)     0           concatenate_103[0][0]            \n",
      "                                                                   lambda_73[0][0]                  \n",
      "                                                                   concatenate_103[1][0]            \n",
      "                                                                   lambda_74[0][0]                  \n",
      "                                                                   concatenate_103[2][0]            \n",
      "                                                                   lambda_75[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchNo (None, 8, 4, 640)     2560        concatenate_104[0][0]            \n",
      "                                                                   concatenate_104[1][0]            \n",
      "                                                                   concatenate_104[2][0]            \n",
      "____________________________________________________________________________________________________\n",
      "input_79 (InputLayer)            (640,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_80 (InputLayer)            (640,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_81 (InputLayer)            (640,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_76 (Lambda)               (None, 8, 4, 640)     0           batch_normalization_131[0][0]    \n",
      "                                                                   input_79[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_77 (Lambda)               (None, 8, 4, 640)     0           batch_normalization_131[1][0]    \n",
      "                                                                   input_80[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_78 (Lambda)               (None, 8, 4, 640)     0           batch_normalization_131[2][0]    \n",
      "                                                                   input_81[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_219 (Activation)      (None, 8, 4, 640)     0           lambda_76[0][0]                  \n",
      "                                                                   lambda_77[0][0]                  \n",
      "                                                                   lambda_78[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_82 (InputLayer)            (640,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_83 (InputLayer)            (640,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_84 (InputLayer)            (640,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_79 (Lambda)               (None, 8, 4, 640)     0           activation_219[0][0]             \n",
      "                                                                   input_82[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_80 (Lambda)               (None, 8, 4, 640)     0           activation_219[1][0]             \n",
      "                                                                   input_83[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_81 (Lambda)               (None, 8, 4, 640)     0           activation_219[2][0]             \n",
      "                                                                   input_84[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_217 (Conv2D)              (None, 8, 4, 128)     81920       lambda_79[0][0]                  \n",
      "                                                                   lambda_80[0][0]                  \n",
      "                                                                   lambda_81[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_85 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_86 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_87 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_82 (Lambda)               (None, 8, 4, 128)     0           conv2d_217[0][0]                 \n",
      "                                                                   input_85[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_83 (Lambda)               (None, 8, 4, 128)     0           conv2d_217[1][0]                 \n",
      "                                                                   input_86[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_84 (Lambda)               (None, 8, 4, 128)     0           conv2d_217[2][0]                 \n",
      "                                                                   input_87[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchNo (None, 8, 4, 128)     512         lambda_82[0][0]                  \n",
      "                                                                   lambda_83[0][0]                  \n",
      "                                                                   lambda_84[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_88 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_89 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_90 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_85 (Lambda)               (None, 8, 4, 128)     0           batch_normalization_132[0][0]    \n",
      "                                                                   input_88[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_86 (Lambda)               (None, 8, 4, 128)     0           batch_normalization_132[1][0]    \n",
      "                                                                   input_89[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_87 (Lambda)               (None, 8, 4, 128)     0           batch_normalization_132[2][0]    \n",
      "                                                                   input_90[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_220 (Activation)      (None, 8, 4, 128)     0           lambda_85[0][0]                  \n",
      "                                                                   lambda_86[0][0]                  \n",
      "                                                                   lambda_87[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_91 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_92 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_93 (InputLayer)            (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_88 (Lambda)               (None, 8, 4, 128)     0           activation_220[0][0]             \n",
      "                                                                   input_91[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_89 (Lambda)               (None, 8, 4, 128)     0           activation_220[1][0]             \n",
      "                                                                   input_92[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_90 (Lambda)               (None, 8, 4, 128)     0           activation_220[2][0]             \n",
      "                                                                   input_93[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_218 (Conv2D)              (None, 8, 4, 32)      36864       lambda_88[0][0]                  \n",
      "                                                                   lambda_89[0][0]                  \n",
      "                                                                   lambda_90[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_94 (InputLayer)            (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_95 (InputLayer)            (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_96 (InputLayer)            (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_91 (Lambda)               (None, 8, 4, 32)      0           conv2d_218[0][0]                 \n",
      "                                                                   input_94[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_92 (Lambda)               (None, 8, 4, 32)      0           conv2d_218[1][0]                 \n",
      "                                                                   input_95[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_93 (Lambda)               (None, 8, 4, 32)      0           conv2d_218[2][0]                 \n",
      "                                                                   input_96[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_105 (Concatenate)    (None, 8, 4, 672)     0           concatenate_104[0][0]            \n",
      "                                                                   lambda_91[0][0]                  \n",
      "                                                                   concatenate_104[1][0]            \n",
      "                                                                   lambda_92[0][0]                  \n",
      "                                                                   concatenate_104[2][0]            \n",
      "                                                                   lambda_93[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchNo (None, 8, 4, 672)     2688        concatenate_105[0][0]            \n",
      "                                                                   concatenate_105[1][0]            \n",
      "                                                                   concatenate_105[2][0]            \n",
      "____________________________________________________________________________________________________\n",
      "input_97 (InputLayer)            (672,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_98 (InputLayer)            (672,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_99 (InputLayer)            (672,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_94 (Lambda)               (None, 8, 4, 672)     0           batch_normalization_133[0][0]    \n",
      "                                                                   input_97[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_95 (Lambda)               (None, 8, 4, 672)     0           batch_normalization_133[1][0]    \n",
      "                                                                   input_98[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_96 (Lambda)               (None, 8, 4, 672)     0           batch_normalization_133[2][0]    \n",
      "                                                                   input_99[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_221 (Activation)      (None, 8, 4, 672)     0           lambda_94[0][0]                  \n",
      "                                                                   lambda_95[0][0]                  \n",
      "                                                                   lambda_96[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_100 (InputLayer)           (672,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_101 (InputLayer)           (672,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_102 (InputLayer)           (672,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_97 (Lambda)               (None, 8, 4, 672)     0           activation_221[0][0]             \n",
      "                                                                   input_100[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_98 (Lambda)               (None, 8, 4, 672)     0           activation_221[1][0]             \n",
      "                                                                   input_101[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_99 (Lambda)               (None, 8, 4, 672)     0           activation_221[2][0]             \n",
      "                                                                   input_102[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_219 (Conv2D)              (None, 8, 4, 128)     86016       lambda_97[0][0]                  \n",
      "                                                                   lambda_98[0][0]                  \n",
      "                                                                   lambda_99[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_103 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_104 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_105 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_100 (Lambda)              (None, 8, 4, 128)     0           conv2d_219[0][0]                 \n",
      "                                                                   input_103[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_101 (Lambda)              (None, 8, 4, 128)     0           conv2d_219[1][0]                 \n",
      "                                                                   input_104[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_102 (Lambda)              (None, 8, 4, 128)     0           conv2d_219[2][0]                 \n",
      "                                                                   input_105[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchNo (None, 8, 4, 128)     512         lambda_100[0][0]                 \n",
      "                                                                   lambda_101[0][0]                 \n",
      "                                                                   lambda_102[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_106 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_107 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_108 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_103 (Lambda)              (None, 8, 4, 128)     0           batch_normalization_134[0][0]    \n",
      "                                                                   input_106[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_104 (Lambda)              (None, 8, 4, 128)     0           batch_normalization_134[1][0]    \n",
      "                                                                   input_107[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_105 (Lambda)              (None, 8, 4, 128)     0           batch_normalization_134[2][0]    \n",
      "                                                                   input_108[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_222 (Activation)      (None, 8, 4, 128)     0           lambda_103[0][0]                 \n",
      "                                                                   lambda_104[0][0]                 \n",
      "                                                                   lambda_105[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_109 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_110 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_111 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_106 (Lambda)              (None, 8, 4, 128)     0           activation_222[0][0]             \n",
      "                                                                   input_109[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_107 (Lambda)              (None, 8, 4, 128)     0           activation_222[1][0]             \n",
      "                                                                   input_110[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_108 (Lambda)              (None, 8, 4, 128)     0           activation_222[2][0]             \n",
      "                                                                   input_111[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_220 (Conv2D)              (None, 8, 4, 32)      36864       lambda_106[0][0]                 \n",
      "                                                                   lambda_107[0][0]                 \n",
      "                                                                   lambda_108[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_112 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_113 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_114 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_109 (Lambda)              (None, 8, 4, 32)      0           conv2d_220[0][0]                 \n",
      "                                                                   input_112[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_110 (Lambda)              (None, 8, 4, 32)      0           conv2d_220[1][0]                 \n",
      "                                                                   input_113[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_111 (Lambda)              (None, 8, 4, 32)      0           conv2d_220[2][0]                 \n",
      "                                                                   input_114[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_106 (Concatenate)    (None, 8, 4, 704)     0           concatenate_105[0][0]            \n",
      "                                                                   lambda_109[0][0]                 \n",
      "                                                                   concatenate_105[1][0]            \n",
      "                                                                   lambda_110[0][0]                 \n",
      "                                                                   concatenate_105[2][0]            \n",
      "                                                                   lambda_111[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchNo (None, 8, 4, 704)     2816        concatenate_106[0][0]            \n",
      "                                                                   concatenate_106[1][0]            \n",
      "                                                                   concatenate_106[2][0]            \n",
      "____________________________________________________________________________________________________\n",
      "input_115 (InputLayer)           (704,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_116 (InputLayer)           (704,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_117 (InputLayer)           (704,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_112 (Lambda)              (None, 8, 4, 704)     0           batch_normalization_135[0][0]    \n",
      "                                                                   input_115[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_113 (Lambda)              (None, 8, 4, 704)     0           batch_normalization_135[1][0]    \n",
      "                                                                   input_116[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_114 (Lambda)              (None, 8, 4, 704)     0           batch_normalization_135[2][0]    \n",
      "                                                                   input_117[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_223 (Activation)      (None, 8, 4, 704)     0           lambda_112[0][0]                 \n",
      "                                                                   lambda_113[0][0]                 \n",
      "                                                                   lambda_114[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_118 (InputLayer)           (704,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_119 (InputLayer)           (704,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_120 (InputLayer)           (704,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_115 (Lambda)              (None, 8, 4, 704)     0           activation_223[0][0]             \n",
      "                                                                   input_118[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_116 (Lambda)              (None, 8, 4, 704)     0           activation_223[1][0]             \n",
      "                                                                   input_119[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_117 (Lambda)              (None, 8, 4, 704)     0           activation_223[2][0]             \n",
      "                                                                   input_120[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_221 (Conv2D)              (None, 8, 4, 128)     90112       lambda_115[0][0]                 \n",
      "                                                                   lambda_116[0][0]                 \n",
      "                                                                   lambda_117[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_121 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_122 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_123 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_118 (Lambda)              (None, 8, 4, 128)     0           conv2d_221[0][0]                 \n",
      "                                                                   input_121[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_119 (Lambda)              (None, 8, 4, 128)     0           conv2d_221[1][0]                 \n",
      "                                                                   input_122[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_120 (Lambda)              (None, 8, 4, 128)     0           conv2d_221[2][0]                 \n",
      "                                                                   input_123[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchNo (None, 8, 4, 128)     512         lambda_118[0][0]                 \n",
      "                                                                   lambda_119[0][0]                 \n",
      "                                                                   lambda_120[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_124 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_125 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_126 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_121 (Lambda)              (None, 8, 4, 128)     0           batch_normalization_136[0][0]    \n",
      "                                                                   input_124[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_122 (Lambda)              (None, 8, 4, 128)     0           batch_normalization_136[1][0]    \n",
      "                                                                   input_125[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_123 (Lambda)              (None, 8, 4, 128)     0           batch_normalization_136[2][0]    \n",
      "                                                                   input_126[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_224 (Activation)      (None, 8, 4, 128)     0           lambda_121[0][0]                 \n",
      "                                                                   lambda_122[0][0]                 \n",
      "                                                                   lambda_123[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_127 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_128 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_129 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_124 (Lambda)              (None, 8, 4, 128)     0           activation_224[0][0]             \n",
      "                                                                   input_127[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_125 (Lambda)              (None, 8, 4, 128)     0           activation_224[1][0]             \n",
      "                                                                   input_128[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_126 (Lambda)              (None, 8, 4, 128)     0           activation_224[2][0]             \n",
      "                                                                   input_129[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_222 (Conv2D)              (None, 8, 4, 32)      36864       lambda_124[0][0]                 \n",
      "                                                                   lambda_125[0][0]                 \n",
      "                                                                   lambda_126[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_130 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_131 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_132 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_127 (Lambda)              (None, 8, 4, 32)      0           conv2d_222[0][0]                 \n",
      "                                                                   input_130[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_128 (Lambda)              (None, 8, 4, 32)      0           conv2d_222[1][0]                 \n",
      "                                                                   input_131[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_129 (Lambda)              (None, 8, 4, 32)      0           conv2d_222[2][0]                 \n",
      "                                                                   input_132[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_107 (Concatenate)    (None, 8, 4, 736)     0           concatenate_106[0][0]            \n",
      "                                                                   lambda_127[0][0]                 \n",
      "                                                                   concatenate_106[1][0]            \n",
      "                                                                   lambda_128[0][0]                 \n",
      "                                                                   concatenate_106[2][0]            \n",
      "                                                                   lambda_129[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchNo (None, 8, 4, 736)     2944        concatenate_107[0][0]            \n",
      "                                                                   concatenate_107[1][0]            \n",
      "                                                                   concatenate_107[2][0]            \n",
      "____________________________________________________________________________________________________\n",
      "input_133 (InputLayer)           (736,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_134 (InputLayer)           (736,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_135 (InputLayer)           (736,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_130 (Lambda)              (None, 8, 4, 736)     0           batch_normalization_137[0][0]    \n",
      "                                                                   input_133[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_131 (Lambda)              (None, 8, 4, 736)     0           batch_normalization_137[1][0]    \n",
      "                                                                   input_134[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_132 (Lambda)              (None, 8, 4, 736)     0           batch_normalization_137[2][0]    \n",
      "                                                                   input_135[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_225 (Activation)      (None, 8, 4, 736)     0           lambda_130[0][0]                 \n",
      "                                                                   lambda_131[0][0]                 \n",
      "                                                                   lambda_132[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_136 (InputLayer)           (736,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_137 (InputLayer)           (736,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_138 (InputLayer)           (736,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_133 (Lambda)              (None, 8, 4, 736)     0           activation_225[0][0]             \n",
      "                                                                   input_136[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_134 (Lambda)              (None, 8, 4, 736)     0           activation_225[1][0]             \n",
      "                                                                   input_137[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_135 (Lambda)              (None, 8, 4, 736)     0           activation_225[2][0]             \n",
      "                                                                   input_138[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_223 (Conv2D)              (None, 8, 4, 128)     94208       lambda_133[0][0]                 \n",
      "                                                                   lambda_134[0][0]                 \n",
      "                                                                   lambda_135[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_139 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_140 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_141 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_136 (Lambda)              (None, 8, 4, 128)     0           conv2d_223[0][0]                 \n",
      "                                                                   input_139[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_137 (Lambda)              (None, 8, 4, 128)     0           conv2d_223[1][0]                 \n",
      "                                                                   input_140[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_138 (Lambda)              (None, 8, 4, 128)     0           conv2d_223[2][0]                 \n",
      "                                                                   input_141[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchNo (None, 8, 4, 128)     512         lambda_136[0][0]                 \n",
      "                                                                   lambda_137[0][0]                 \n",
      "                                                                   lambda_138[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_142 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_143 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_144 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_139 (Lambda)              (None, 8, 4, 128)     0           batch_normalization_138[0][0]    \n",
      "                                                                   input_142[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_140 (Lambda)              (None, 8, 4, 128)     0           batch_normalization_138[1][0]    \n",
      "                                                                   input_143[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_141 (Lambda)              (None, 8, 4, 128)     0           batch_normalization_138[2][0]    \n",
      "                                                                   input_144[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_226 (Activation)      (None, 8, 4, 128)     0           lambda_139[0][0]                 \n",
      "                                                                   lambda_140[0][0]                 \n",
      "                                                                   lambda_141[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_145 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_146 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_147 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_142 (Lambda)              (None, 8, 4, 128)     0           activation_226[0][0]             \n",
      "                                                                   input_145[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_143 (Lambda)              (None, 8, 4, 128)     0           activation_226[1][0]             \n",
      "                                                                   input_146[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_144 (Lambda)              (None, 8, 4, 128)     0           activation_226[2][0]             \n",
      "                                                                   input_147[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_224 (Conv2D)              (None, 8, 4, 32)      36864       lambda_142[0][0]                 \n",
      "                                                                   lambda_143[0][0]                 \n",
      "                                                                   lambda_144[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_148 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_149 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_150 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_145 (Lambda)              (None, 8, 4, 32)      0           conv2d_224[0][0]                 \n",
      "                                                                   input_148[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_146 (Lambda)              (None, 8, 4, 32)      0           conv2d_224[1][0]                 \n",
      "                                                                   input_149[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_147 (Lambda)              (None, 8, 4, 32)      0           conv2d_224[2][0]                 \n",
      "                                                                   input_150[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_108 (Concatenate)    (None, 8, 4, 768)     0           concatenate_107[0][0]            \n",
      "                                                                   lambda_145[0][0]                 \n",
      "                                                                   concatenate_107[1][0]            \n",
      "                                                                   lambda_146[0][0]                 \n",
      "                                                                   concatenate_107[2][0]            \n",
      "                                                                   lambda_147[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchNo (None, 8, 4, 768)     3072        concatenate_108[0][0]            \n",
      "                                                                   concatenate_108[1][0]            \n",
      "                                                                   concatenate_108[2][0]            \n",
      "____________________________________________________________________________________________________\n",
      "input_151 (InputLayer)           (768,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_152 (InputLayer)           (768,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_153 (InputLayer)           (768,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_148 (Lambda)              (None, 8, 4, 768)     0           batch_normalization_139[0][0]    \n",
      "                                                                   input_151[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_149 (Lambda)              (None, 8, 4, 768)     0           batch_normalization_139[1][0]    \n",
      "                                                                   input_152[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_150 (Lambda)              (None, 8, 4, 768)     0           batch_normalization_139[2][0]    \n",
      "                                                                   input_153[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_227 (Activation)      (None, 8, 4, 768)     0           lambda_148[0][0]                 \n",
      "                                                                   lambda_149[0][0]                 \n",
      "                                                                   lambda_150[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_154 (InputLayer)           (768,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_155 (InputLayer)           (768,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_156 (InputLayer)           (768,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_151 (Lambda)              (None, 8, 4, 768)     0           activation_227[0][0]             \n",
      "                                                                   input_154[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_152 (Lambda)              (None, 8, 4, 768)     0           activation_227[1][0]             \n",
      "                                                                   input_155[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_153 (Lambda)              (None, 8, 4, 768)     0           activation_227[2][0]             \n",
      "                                                                   input_156[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_225 (Conv2D)              (None, 8, 4, 128)     98304       lambda_151[0][0]                 \n",
      "                                                                   lambda_152[0][0]                 \n",
      "                                                                   lambda_153[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_157 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_158 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_159 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_154 (Lambda)              (None, 8, 4, 128)     0           conv2d_225[0][0]                 \n",
      "                                                                   input_157[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_155 (Lambda)              (None, 8, 4, 128)     0           conv2d_225[1][0]                 \n",
      "                                                                   input_158[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_156 (Lambda)              (None, 8, 4, 128)     0           conv2d_225[2][0]                 \n",
      "                                                                   input_159[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchNo (None, 8, 4, 128)     512         lambda_154[0][0]                 \n",
      "                                                                   lambda_155[0][0]                 \n",
      "                                                                   lambda_156[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_160 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_161 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_162 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_157 (Lambda)              (None, 8, 4, 128)     0           batch_normalization_140[0][0]    \n",
      "                                                                   input_160[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_158 (Lambda)              (None, 8, 4, 128)     0           batch_normalization_140[1][0]    \n",
      "                                                                   input_161[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_159 (Lambda)              (None, 8, 4, 128)     0           batch_normalization_140[2][0]    \n",
      "                                                                   input_162[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_228 (Activation)      (None, 8, 4, 128)     0           lambda_157[0][0]                 \n",
      "                                                                   lambda_158[0][0]                 \n",
      "                                                                   lambda_159[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_163 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_164 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_165 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_160 (Lambda)              (None, 8, 4, 128)     0           activation_228[0][0]             \n",
      "                                                                   input_163[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_161 (Lambda)              (None, 8, 4, 128)     0           activation_228[1][0]             \n",
      "                                                                   input_164[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_162 (Lambda)              (None, 8, 4, 128)     0           activation_228[2][0]             \n",
      "                                                                   input_165[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_226 (Conv2D)              (None, 8, 4, 32)      36864       lambda_160[0][0]                 \n",
      "                                                                   lambda_161[0][0]                 \n",
      "                                                                   lambda_162[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_166 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_167 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_168 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_163 (Lambda)              (None, 8, 4, 32)      0           conv2d_226[0][0]                 \n",
      "                                                                   input_166[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_164 (Lambda)              (None, 8, 4, 32)      0           conv2d_226[1][0]                 \n",
      "                                                                   input_167[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_165 (Lambda)              (None, 8, 4, 32)      0           conv2d_226[2][0]                 \n",
      "                                                                   input_168[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_109 (Concatenate)    (None, 8, 4, 800)     0           concatenate_108[0][0]            \n",
      "                                                                   lambda_163[0][0]                 \n",
      "                                                                   concatenate_108[1][0]            \n",
      "                                                                   lambda_164[0][0]                 \n",
      "                                                                   concatenate_108[2][0]            \n",
      "                                                                   lambda_165[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchNo (None, 8, 4, 800)     3200        concatenate_109[0][0]            \n",
      "                                                                   concatenate_109[1][0]            \n",
      "                                                                   concatenate_109[2][0]            \n",
      "____________________________________________________________________________________________________\n",
      "input_169 (InputLayer)           (800,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_170 (InputLayer)           (800,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_171 (InputLayer)           (800,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_166 (Lambda)              (None, 8, 4, 800)     0           batch_normalization_141[0][0]    \n",
      "                                                                   input_169[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_167 (Lambda)              (None, 8, 4, 800)     0           batch_normalization_141[1][0]    \n",
      "                                                                   input_170[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_168 (Lambda)              (None, 8, 4, 800)     0           batch_normalization_141[2][0]    \n",
      "                                                                   input_171[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_229 (Activation)      (None, 8, 4, 800)     0           lambda_166[0][0]                 \n",
      "                                                                   lambda_167[0][0]                 \n",
      "                                                                   lambda_168[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_172 (InputLayer)           (800,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_173 (InputLayer)           (800,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_174 (InputLayer)           (800,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_169 (Lambda)              (None, 8, 4, 800)     0           activation_229[0][0]             \n",
      "                                                                   input_172[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_170 (Lambda)              (None, 8, 4, 800)     0           activation_229[1][0]             \n",
      "                                                                   input_173[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_171 (Lambda)              (None, 8, 4, 800)     0           activation_229[2][0]             \n",
      "                                                                   input_174[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_227 (Conv2D)              (None, 8, 4, 128)     102400      lambda_169[0][0]                 \n",
      "                                                                   lambda_170[0][0]                 \n",
      "                                                                   lambda_171[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_175 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_176 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_177 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_172 (Lambda)              (None, 8, 4, 128)     0           conv2d_227[0][0]                 \n",
      "                                                                   input_175[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_173 (Lambda)              (None, 8, 4, 128)     0           conv2d_227[1][0]                 \n",
      "                                                                   input_176[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_174 (Lambda)              (None, 8, 4, 128)     0           conv2d_227[2][0]                 \n",
      "                                                                   input_177[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchNo (None, 8, 4, 128)     512         lambda_172[0][0]                 \n",
      "                                                                   lambda_173[0][0]                 \n",
      "                                                                   lambda_174[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_178 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_179 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_180 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_175 (Lambda)              (None, 8, 4, 128)     0           batch_normalization_142[0][0]    \n",
      "                                                                   input_178[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_176 (Lambda)              (None, 8, 4, 128)     0           batch_normalization_142[1][0]    \n",
      "                                                                   input_179[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_177 (Lambda)              (None, 8, 4, 128)     0           batch_normalization_142[2][0]    \n",
      "                                                                   input_180[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_230 (Activation)      (None, 8, 4, 128)     0           lambda_175[0][0]                 \n",
      "                                                                   lambda_176[0][0]                 \n",
      "                                                                   lambda_177[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_181 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_182 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_183 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_178 (Lambda)              (None, 8, 4, 128)     0           activation_230[0][0]             \n",
      "                                                                   input_181[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_179 (Lambda)              (None, 8, 4, 128)     0           activation_230[1][0]             \n",
      "                                                                   input_182[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_180 (Lambda)              (None, 8, 4, 128)     0           activation_230[2][0]             \n",
      "                                                                   input_183[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_228 (Conv2D)              (None, 8, 4, 32)      36864       lambda_178[0][0]                 \n",
      "                                                                   lambda_179[0][0]                 \n",
      "                                                                   lambda_180[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_184 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_185 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_186 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_181 (Lambda)              (None, 8, 4, 32)      0           conv2d_228[0][0]                 \n",
      "                                                                   input_184[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_182 (Lambda)              (None, 8, 4, 32)      0           conv2d_228[1][0]                 \n",
      "                                                                   input_185[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_183 (Lambda)              (None, 8, 4, 32)      0           conv2d_228[2][0]                 \n",
      "                                                                   input_186[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_110 (Concatenate)    (None, 8, 4, 832)     0           concatenate_109[0][0]            \n",
      "                                                                   lambda_181[0][0]                 \n",
      "                                                                   concatenate_109[1][0]            \n",
      "                                                                   lambda_182[0][0]                 \n",
      "                                                                   concatenate_109[2][0]            \n",
      "                                                                   lambda_183[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchNo (None, 8, 4, 832)     3328        concatenate_110[0][0]            \n",
      "                                                                   concatenate_110[1][0]            \n",
      "                                                                   concatenate_110[2][0]            \n",
      "____________________________________________________________________________________________________\n",
      "input_187 (InputLayer)           (832,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_188 (InputLayer)           (832,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_189 (InputLayer)           (832,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_184 (Lambda)              (None, 8, 4, 832)     0           batch_normalization_143[0][0]    \n",
      "                                                                   input_187[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_185 (Lambda)              (None, 8, 4, 832)     0           batch_normalization_143[1][0]    \n",
      "                                                                   input_188[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_186 (Lambda)              (None, 8, 4, 832)     0           batch_normalization_143[2][0]    \n",
      "                                                                   input_189[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_231 (Activation)      (None, 8, 4, 832)     0           lambda_184[0][0]                 \n",
      "                                                                   lambda_185[0][0]                 \n",
      "                                                                   lambda_186[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_190 (InputLayer)           (832,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_191 (InputLayer)           (832,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_192 (InputLayer)           (832,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_187 (Lambda)              (None, 8, 4, 832)     0           activation_231[0][0]             \n",
      "                                                                   input_190[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_188 (Lambda)              (None, 8, 4, 832)     0           activation_231[1][0]             \n",
      "                                                                   input_191[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_189 (Lambda)              (None, 8, 4, 832)     0           activation_231[2][0]             \n",
      "                                                                   input_192[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_229 (Conv2D)              (None, 8, 4, 128)     106496      lambda_187[0][0]                 \n",
      "                                                                   lambda_188[0][0]                 \n",
      "                                                                   lambda_189[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_193 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_194 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_195 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_190 (Lambda)              (None, 8, 4, 128)     0           conv2d_229[0][0]                 \n",
      "                                                                   input_193[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_191 (Lambda)              (None, 8, 4, 128)     0           conv2d_229[1][0]                 \n",
      "                                                                   input_194[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_192 (Lambda)              (None, 8, 4, 128)     0           conv2d_229[2][0]                 \n",
      "                                                                   input_195[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchNo (None, 8, 4, 128)     512         lambda_190[0][0]                 \n",
      "                                                                   lambda_191[0][0]                 \n",
      "                                                                   lambda_192[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_196 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_197 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_198 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_193 (Lambda)              (None, 8, 4, 128)     0           batch_normalization_144[0][0]    \n",
      "                                                                   input_196[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_194 (Lambda)              (None, 8, 4, 128)     0           batch_normalization_144[1][0]    \n",
      "                                                                   input_197[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_195 (Lambda)              (None, 8, 4, 128)     0           batch_normalization_144[2][0]    \n",
      "                                                                   input_198[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_232 (Activation)      (None, 8, 4, 128)     0           lambda_193[0][0]                 \n",
      "                                                                   lambda_194[0][0]                 \n",
      "                                                                   lambda_195[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_199 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_200 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_201 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_196 (Lambda)              (None, 8, 4, 128)     0           activation_232[0][0]             \n",
      "                                                                   input_199[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_197 (Lambda)              (None, 8, 4, 128)     0           activation_232[1][0]             \n",
      "                                                                   input_200[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_198 (Lambda)              (None, 8, 4, 128)     0           activation_232[2][0]             \n",
      "                                                                   input_201[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_230 (Conv2D)              (None, 8, 4, 32)      36864       lambda_196[0][0]                 \n",
      "                                                                   lambda_197[0][0]                 \n",
      "                                                                   lambda_198[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_202 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_203 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_204 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_199 (Lambda)              (None, 8, 4, 32)      0           conv2d_230[0][0]                 \n",
      "                                                                   input_202[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_200 (Lambda)              (None, 8, 4, 32)      0           conv2d_230[1][0]                 \n",
      "                                                                   input_203[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_201 (Lambda)              (None, 8, 4, 32)      0           conv2d_230[2][0]                 \n",
      "                                                                   input_204[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_111 (Concatenate)    (None, 8, 4, 864)     0           concatenate_110[0][0]            \n",
      "                                                                   lambda_199[0][0]                 \n",
      "                                                                   concatenate_110[1][0]            \n",
      "                                                                   lambda_200[0][0]                 \n",
      "                                                                   concatenate_110[2][0]            \n",
      "                                                                   lambda_201[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchNo (None, 8, 4, 864)     3456        concatenate_111[0][0]            \n",
      "                                                                   concatenate_111[1][0]            \n",
      "                                                                   concatenate_111[2][0]            \n",
      "____________________________________________________________________________________________________\n",
      "input_205 (InputLayer)           (864,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_206 (InputLayer)           (864,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_207 (InputLayer)           (864,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_202 (Lambda)              (None, 8, 4, 864)     0           batch_normalization_145[0][0]    \n",
      "                                                                   input_205[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_203 (Lambda)              (None, 8, 4, 864)     0           batch_normalization_145[1][0]    \n",
      "                                                                   input_206[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_204 (Lambda)              (None, 8, 4, 864)     0           batch_normalization_145[2][0]    \n",
      "                                                                   input_207[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_233 (Activation)      (None, 8, 4, 864)     0           lambda_202[0][0]                 \n",
      "                                                                   lambda_203[0][0]                 \n",
      "                                                                   lambda_204[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_208 (InputLayer)           (864,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_209 (InputLayer)           (864,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_210 (InputLayer)           (864,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_205 (Lambda)              (None, 8, 4, 864)     0           activation_233[0][0]             \n",
      "                                                                   input_208[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_206 (Lambda)              (None, 8, 4, 864)     0           activation_233[1][0]             \n",
      "                                                                   input_209[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_207 (Lambda)              (None, 8, 4, 864)     0           activation_233[2][0]             \n",
      "                                                                   input_210[0][0]                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "conv2d_231 (Conv2D)              (None, 8, 4, 128)     110592      lambda_205[0][0]                 \n",
      "                                                                   lambda_206[0][0]                 \n",
      "                                                                   lambda_207[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_211 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_212 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_213 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_208 (Lambda)              (None, 8, 4, 128)     0           conv2d_231[0][0]                 \n",
      "                                                                   input_211[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_209 (Lambda)              (None, 8, 4, 128)     0           conv2d_231[1][0]                 \n",
      "                                                                   input_212[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_210 (Lambda)              (None, 8, 4, 128)     0           conv2d_231[2][0]                 \n",
      "                                                                   input_213[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchNo (None, 8, 4, 128)     512         lambda_208[0][0]                 \n",
      "                                                                   lambda_209[0][0]                 \n",
      "                                                                   lambda_210[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_214 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_215 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_216 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_211 (Lambda)              (None, 8, 4, 128)     0           batch_normalization_146[0][0]    \n",
      "                                                                   input_214[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_212 (Lambda)              (None, 8, 4, 128)     0           batch_normalization_146[1][0]    \n",
      "                                                                   input_215[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_213 (Lambda)              (None, 8, 4, 128)     0           batch_normalization_146[2][0]    \n",
      "                                                                   input_216[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_234 (Activation)      (None, 8, 4, 128)     0           lambda_211[0][0]                 \n",
      "                                                                   lambda_212[0][0]                 \n",
      "                                                                   lambda_213[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_217 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_218 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_219 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_214 (Lambda)              (None, 8, 4, 128)     0           activation_234[0][0]             \n",
      "                                                                   input_217[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_215 (Lambda)              (None, 8, 4, 128)     0           activation_234[1][0]             \n",
      "                                                                   input_218[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_216 (Lambda)              (None, 8, 4, 128)     0           activation_234[2][0]             \n",
      "                                                                   input_219[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_232 (Conv2D)              (None, 8, 4, 32)      36864       lambda_214[0][0]                 \n",
      "                                                                   lambda_215[0][0]                 \n",
      "                                                                   lambda_216[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_220 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_221 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_222 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_217 (Lambda)              (None, 8, 4, 32)      0           conv2d_232[0][0]                 \n",
      "                                                                   input_220[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_218 (Lambda)              (None, 8, 4, 32)      0           conv2d_232[1][0]                 \n",
      "                                                                   input_221[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_219 (Lambda)              (None, 8, 4, 32)      0           conv2d_232[2][0]                 \n",
      "                                                                   input_222[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_112 (Concatenate)    (None, 8, 4, 896)     0           concatenate_111[0][0]            \n",
      "                                                                   lambda_217[0][0]                 \n",
      "                                                                   concatenate_111[1][0]            \n",
      "                                                                   lambda_218[0][0]                 \n",
      "                                                                   concatenate_111[2][0]            \n",
      "                                                                   lambda_219[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchNo (None, 8, 4, 896)     3584        concatenate_112[0][0]            \n",
      "                                                                   concatenate_112[1][0]            \n",
      "                                                                   concatenate_112[2][0]            \n",
      "____________________________________________________________________________________________________\n",
      "input_223 (InputLayer)           (896,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_224 (InputLayer)           (896,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_225 (InputLayer)           (896,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_220 (Lambda)              (None, 8, 4, 896)     0           batch_normalization_147[0][0]    \n",
      "                                                                   input_223[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_221 (Lambda)              (None, 8, 4, 896)     0           batch_normalization_147[1][0]    \n",
      "                                                                   input_224[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_222 (Lambda)              (None, 8, 4, 896)     0           batch_normalization_147[2][0]    \n",
      "                                                                   input_225[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_235 (Activation)      (None, 8, 4, 896)     0           lambda_220[0][0]                 \n",
      "                                                                   lambda_221[0][0]                 \n",
      "                                                                   lambda_222[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_226 (InputLayer)           (896,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_227 (InputLayer)           (896,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_228 (InputLayer)           (896,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_223 (Lambda)              (None, 8, 4, 896)     0           activation_235[0][0]             \n",
      "                                                                   input_226[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_224 (Lambda)              (None, 8, 4, 896)     0           activation_235[1][0]             \n",
      "                                                                   input_227[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_225 (Lambda)              (None, 8, 4, 896)     0           activation_235[2][0]             \n",
      "                                                                   input_228[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_233 (Conv2D)              (None, 8, 4, 128)     114688      lambda_223[0][0]                 \n",
      "                                                                   lambda_224[0][0]                 \n",
      "                                                                   lambda_225[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_229 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_230 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_231 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_226 (Lambda)              (None, 8, 4, 128)     0           conv2d_233[0][0]                 \n",
      "                                                                   input_229[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_227 (Lambda)              (None, 8, 4, 128)     0           conv2d_233[1][0]                 \n",
      "                                                                   input_230[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_228 (Lambda)              (None, 8, 4, 128)     0           conv2d_233[2][0]                 \n",
      "                                                                   input_231[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchNo (None, 8, 4, 128)     512         lambda_226[0][0]                 \n",
      "                                                                   lambda_227[0][0]                 \n",
      "                                                                   lambda_228[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_232 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_233 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_234 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_229 (Lambda)              (None, 8, 4, 128)     0           batch_normalization_148[0][0]    \n",
      "                                                                   input_232[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_230 (Lambda)              (None, 8, 4, 128)     0           batch_normalization_148[1][0]    \n",
      "                                                                   input_233[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_231 (Lambda)              (None, 8, 4, 128)     0           batch_normalization_148[2][0]    \n",
      "                                                                   input_234[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_236 (Activation)      (None, 8, 4, 128)     0           lambda_229[0][0]                 \n",
      "                                                                   lambda_230[0][0]                 \n",
      "                                                                   lambda_231[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_235 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_236 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_237 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_232 (Lambda)              (None, 8, 4, 128)     0           activation_236[0][0]             \n",
      "                                                                   input_235[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_233 (Lambda)              (None, 8, 4, 128)     0           activation_236[1][0]             \n",
      "                                                                   input_236[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_234 (Lambda)              (None, 8, 4, 128)     0           activation_236[2][0]             \n",
      "                                                                   input_237[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_234 (Conv2D)              (None, 8, 4, 32)      36864       lambda_232[0][0]                 \n",
      "                                                                   lambda_233[0][0]                 \n",
      "                                                                   lambda_234[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_238 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_239 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_240 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_235 (Lambda)              (None, 8, 4, 32)      0           conv2d_234[0][0]                 \n",
      "                                                                   input_238[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_236 (Lambda)              (None, 8, 4, 32)      0           conv2d_234[1][0]                 \n",
      "                                                                   input_239[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_237 (Lambda)              (None, 8, 4, 32)      0           conv2d_234[2][0]                 \n",
      "                                                                   input_240[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_113 (Concatenate)    (None, 8, 4, 928)     0           concatenate_112[0][0]            \n",
      "                                                                   lambda_235[0][0]                 \n",
      "                                                                   concatenate_112[1][0]            \n",
      "                                                                   lambda_236[0][0]                 \n",
      "                                                                   concatenate_112[2][0]            \n",
      "                                                                   lambda_237[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchNo (None, 8, 4, 928)     3712        concatenate_113[0][0]            \n",
      "                                                                   concatenate_113[1][0]            \n",
      "                                                                   concatenate_113[2][0]            \n",
      "____________________________________________________________________________________________________\n",
      "input_241 (InputLayer)           (928,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_242 (InputLayer)           (928,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_243 (InputLayer)           (928,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_238 (Lambda)              (None, 8, 4, 928)     0           batch_normalization_149[0][0]    \n",
      "                                                                   input_241[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_239 (Lambda)              (None, 8, 4, 928)     0           batch_normalization_149[1][0]    \n",
      "                                                                   input_242[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_240 (Lambda)              (None, 8, 4, 928)     0           batch_normalization_149[2][0]    \n",
      "                                                                   input_243[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_237 (Activation)      (None, 8, 4, 928)     0           lambda_238[0][0]                 \n",
      "                                                                   lambda_239[0][0]                 \n",
      "                                                                   lambda_240[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_244 (InputLayer)           (928,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_245 (InputLayer)           (928,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_246 (InputLayer)           (928,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_241 (Lambda)              (None, 8, 4, 928)     0           activation_237[0][0]             \n",
      "                                                                   input_244[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_242 (Lambda)              (None, 8, 4, 928)     0           activation_237[1][0]             \n",
      "                                                                   input_245[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_243 (Lambda)              (None, 8, 4, 928)     0           activation_237[2][0]             \n",
      "                                                                   input_246[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_235 (Conv2D)              (None, 8, 4, 128)     118784      lambda_241[0][0]                 \n",
      "                                                                   lambda_242[0][0]                 \n",
      "                                                                   lambda_243[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_247 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_248 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_249 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_244 (Lambda)              (None, 8, 4, 128)     0           conv2d_235[0][0]                 \n",
      "                                                                   input_247[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_245 (Lambda)              (None, 8, 4, 128)     0           conv2d_235[1][0]                 \n",
      "                                                                   input_248[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_246 (Lambda)              (None, 8, 4, 128)     0           conv2d_235[2][0]                 \n",
      "                                                                   input_249[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchNo (None, 8, 4, 128)     512         lambda_244[0][0]                 \n",
      "                                                                   lambda_245[0][0]                 \n",
      "                                                                   lambda_246[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_250 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_251 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_252 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_247 (Lambda)              (None, 8, 4, 128)     0           batch_normalization_150[0][0]    \n",
      "                                                                   input_250[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_248 (Lambda)              (None, 8, 4, 128)     0           batch_normalization_150[1][0]    \n",
      "                                                                   input_251[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_249 (Lambda)              (None, 8, 4, 128)     0           batch_normalization_150[2][0]    \n",
      "                                                                   input_252[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_238 (Activation)      (None, 8, 4, 128)     0           lambda_247[0][0]                 \n",
      "                                                                   lambda_248[0][0]                 \n",
      "                                                                   lambda_249[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_253 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_254 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_255 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_250 (Lambda)              (None, 8, 4, 128)     0           activation_238[0][0]             \n",
      "                                                                   input_253[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_251 (Lambda)              (None, 8, 4, 128)     0           activation_238[1][0]             \n",
      "                                                                   input_254[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_252 (Lambda)              (None, 8, 4, 128)     0           activation_238[2][0]             \n",
      "                                                                   input_255[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_236 (Conv2D)              (None, 8, 4, 32)      36864       lambda_250[0][0]                 \n",
      "                                                                   lambda_251[0][0]                 \n",
      "                                                                   lambda_252[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_256 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_257 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_258 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_253 (Lambda)              (None, 8, 4, 32)      0           conv2d_236[0][0]                 \n",
      "                                                                   input_256[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_254 (Lambda)              (None, 8, 4, 32)      0           conv2d_236[1][0]                 \n",
      "                                                                   input_257[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_255 (Lambda)              (None, 8, 4, 32)      0           conv2d_236[2][0]                 \n",
      "                                                                   input_258[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_114 (Concatenate)    (None, 8, 4, 960)     0           concatenate_113[0][0]            \n",
      "                                                                   lambda_253[0][0]                 \n",
      "                                                                   concatenate_113[1][0]            \n",
      "                                                                   lambda_254[0][0]                 \n",
      "                                                                   concatenate_113[2][0]            \n",
      "                                                                   lambda_255[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchNo (None, 8, 4, 960)     3840        concatenate_114[0][0]            \n",
      "                                                                   concatenate_114[1][0]            \n",
      "                                                                   concatenate_114[2][0]            \n",
      "____________________________________________________________________________________________________\n",
      "input_259 (InputLayer)           (960,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_260 (InputLayer)           (960,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_261 (InputLayer)           (960,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_256 (Lambda)              (None, 8, 4, 960)     0           batch_normalization_151[0][0]    \n",
      "                                                                   input_259[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_257 (Lambda)              (None, 8, 4, 960)     0           batch_normalization_151[1][0]    \n",
      "                                                                   input_260[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_258 (Lambda)              (None, 8, 4, 960)     0           batch_normalization_151[2][0]    \n",
      "                                                                   input_261[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_239 (Activation)      (None, 8, 4, 960)     0           lambda_256[0][0]                 \n",
      "                                                                   lambda_257[0][0]                 \n",
      "                                                                   lambda_258[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_262 (InputLayer)           (960,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_263 (InputLayer)           (960,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_264 (InputLayer)           (960,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_259 (Lambda)              (None, 8, 4, 960)     0           activation_239[0][0]             \n",
      "                                                                   input_262[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_260 (Lambda)              (None, 8, 4, 960)     0           activation_239[1][0]             \n",
      "                                                                   input_263[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_261 (Lambda)              (None, 8, 4, 960)     0           activation_239[2][0]             \n",
      "                                                                   input_264[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_237 (Conv2D)              (None, 8, 4, 128)     122880      lambda_259[0][0]                 \n",
      "                                                                   lambda_260[0][0]                 \n",
      "                                                                   lambda_261[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_265 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_266 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_267 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_262 (Lambda)              (None, 8, 4, 128)     0           conv2d_237[0][0]                 \n",
      "                                                                   input_265[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_263 (Lambda)              (None, 8, 4, 128)     0           conv2d_237[1][0]                 \n",
      "                                                                   input_266[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_264 (Lambda)              (None, 8, 4, 128)     0           conv2d_237[2][0]                 \n",
      "                                                                   input_267[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchNo (None, 8, 4, 128)     512         lambda_262[0][0]                 \n",
      "                                                                   lambda_263[0][0]                 \n",
      "                                                                   lambda_264[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_268 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_269 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_270 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_265 (Lambda)              (None, 8, 4, 128)     0           batch_normalization_152[0][0]    \n",
      "                                                                   input_268[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_266 (Lambda)              (None, 8, 4, 128)     0           batch_normalization_152[1][0]    \n",
      "                                                                   input_269[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_267 (Lambda)              (None, 8, 4, 128)     0           batch_normalization_152[2][0]    \n",
      "                                                                   input_270[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_240 (Activation)      (None, 8, 4, 128)     0           lambda_265[0][0]                 \n",
      "                                                                   lambda_266[0][0]                 \n",
      "                                                                   lambda_267[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_271 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_272 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_273 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_268 (Lambda)              (None, 8, 4, 128)     0           activation_240[0][0]             \n",
      "                                                                   input_271[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_269 (Lambda)              (None, 8, 4, 128)     0           activation_240[1][0]             \n",
      "                                                                   input_272[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_270 (Lambda)              (None, 8, 4, 128)     0           activation_240[2][0]             \n",
      "                                                                   input_273[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_238 (Conv2D)              (None, 8, 4, 32)      36864       lambda_268[0][0]                 \n",
      "                                                                   lambda_269[0][0]                 \n",
      "                                                                   lambda_270[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_274 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_275 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_276 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_271 (Lambda)              (None, 8, 4, 32)      0           conv2d_238[0][0]                 \n",
      "                                                                   input_274[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_272 (Lambda)              (None, 8, 4, 32)      0           conv2d_238[1][0]                 \n",
      "                                                                   input_275[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_273 (Lambda)              (None, 8, 4, 32)      0           conv2d_238[2][0]                 \n",
      "                                                                   input_276[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_115 (Concatenate)    (None, 8, 4, 992)     0           concatenate_114[0][0]            \n",
      "                                                                   lambda_271[0][0]                 \n",
      "                                                                   concatenate_114[1][0]            \n",
      "                                                                   lambda_272[0][0]                 \n",
      "                                                                   concatenate_114[2][0]            \n",
      "                                                                   lambda_273[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchNo (None, 8, 4, 992)     3968        concatenate_115[0][0]            \n",
      "                                                                   concatenate_115[1][0]            \n",
      "                                                                   concatenate_115[2][0]            \n",
      "____________________________________________________________________________________________________\n",
      "input_277 (InputLayer)           (992,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_278 (InputLayer)           (992,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_279 (InputLayer)           (992,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_274 (Lambda)              (None, 8, 4, 992)     0           batch_normalization_153[0][0]    \n",
      "                                                                   input_277[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_275 (Lambda)              (None, 8, 4, 992)     0           batch_normalization_153[1][0]    \n",
      "                                                                   input_278[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_276 (Lambda)              (None, 8, 4, 992)     0           batch_normalization_153[2][0]    \n",
      "                                                                   input_279[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_241 (Activation)      (None, 8, 4, 992)     0           lambda_274[0][0]                 \n",
      "                                                                   lambda_275[0][0]                 \n",
      "                                                                   lambda_276[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_280 (InputLayer)           (992,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_281 (InputLayer)           (992,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_282 (InputLayer)           (992,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_277 (Lambda)              (None, 8, 4, 992)     0           activation_241[0][0]             \n",
      "                                                                   input_280[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_278 (Lambda)              (None, 8, 4, 992)     0           activation_241[1][0]             \n",
      "                                                                   input_281[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_279 (Lambda)              (None, 8, 4, 992)     0           activation_241[2][0]             \n",
      "                                                                   input_282[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_239 (Conv2D)              (None, 8, 4, 128)     126976      lambda_277[0][0]                 \n",
      "                                                                   lambda_278[0][0]                 \n",
      "                                                                   lambda_279[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_283 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_284 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_285 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_280 (Lambda)              (None, 8, 4, 128)     0           conv2d_239[0][0]                 \n",
      "                                                                   input_283[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_281 (Lambda)              (None, 8, 4, 128)     0           conv2d_239[1][0]                 \n",
      "                                                                   input_284[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_282 (Lambda)              (None, 8, 4, 128)     0           conv2d_239[2][0]                 \n",
      "                                                                   input_285[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchNo (None, 8, 4, 128)     512         lambda_280[0][0]                 \n",
      "                                                                   lambda_281[0][0]                 \n",
      "                                                                   lambda_282[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_286 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_287 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_288 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_283 (Lambda)              (None, 8, 4, 128)     0           batch_normalization_154[0][0]    \n",
      "                                                                   input_286[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_284 (Lambda)              (None, 8, 4, 128)     0           batch_normalization_154[1][0]    \n",
      "                                                                   input_287[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_285 (Lambda)              (None, 8, 4, 128)     0           batch_normalization_154[2][0]    \n",
      "                                                                   input_288[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_242 (Activation)      (None, 8, 4, 128)     0           lambda_283[0][0]                 \n",
      "                                                                   lambda_284[0][0]                 \n",
      "                                                                   lambda_285[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_289 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_290 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_291 (InputLayer)           (128,)                0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_286 (Lambda)              (None, 8, 4, 128)     0           activation_242[0][0]             \n",
      "                                                                   input_289[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_287 (Lambda)              (None, 8, 4, 128)     0           activation_242[1][0]             \n",
      "                                                                   input_290[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_288 (Lambda)              (None, 8, 4, 128)     0           activation_242[2][0]             \n",
      "                                                                   input_291[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_240 (Conv2D)              (None, 8, 4, 32)      36864       lambda_286[0][0]                 \n",
      "                                                                   lambda_287[0][0]                 \n",
      "                                                                   lambda_288[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_292 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_293 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_294 (InputLayer)           (32,)                 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_289 (Lambda)              (None, 8, 4, 32)      0           conv2d_240[0][0]                 \n",
      "                                                                   input_292[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_290 (Lambda)              (None, 8, 4, 32)      0           conv2d_240[1][0]                 \n",
      "                                                                   input_293[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_291 (Lambda)              (None, 8, 4, 32)      0           conv2d_240[2][0]                 \n",
      "                                                                   input_294[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_116 (Concatenate)    (None, 8, 4, 1024)    0           concatenate_115[0][0]            \n",
      "                                                                   lambda_289[0][0]                 \n",
      "                                                                   concatenate_115[1][0]            \n",
      "                                                                   lambda_290[0][0]                 \n",
      "                                                                   concatenate_115[2][0]            \n",
      "                                                                   lambda_291[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchNo (None, 8, 4, 1024)    4096        concatenate_116[0][0]            \n",
      "                                                                   concatenate_116[1][0]            \n",
      "                                                                   concatenate_116[2][0]            \n",
      "____________________________________________________________________________________________________\n",
      "input_295 (InputLayer)           (1024,)               0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_296 (InputLayer)           (1024,)               0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_297 (InputLayer)           (1024,)               0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_292 (Lambda)              (None, 8, 4, 1024)    0           batch_normalization_155[0][0]    \n",
      "                                                                   input_295[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_293 (Lambda)              (None, 8, 4, 1024)    0           batch_normalization_155[1][0]    \n",
      "                                                                   input_296[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_294 (Lambda)              (None, 8, 4, 1024)    0           batch_normalization_155[2][0]    \n",
      "                                                                   input_297[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_243 (Activation)      (None, 8, 4, 1024)    0           lambda_292[0][0]                 \n",
      "                                                                   lambda_293[0][0]                 \n",
      "                                                                   lambda_294[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_298 (InputLayer)           (1024,)               0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_299 (InputLayer)           (1024,)               0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_300 (InputLayer)           (1024,)               0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_295 (Lambda)              (None, 8, 4, 1024)    0           activation_243[0][0]             \n",
      "                                                                   input_298[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_296 (Lambda)              (None, 8, 4, 1024)    0           activation_243[1][0]             \n",
      "                                                                   input_299[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_297 (Lambda)              (None, 8, 4, 1024)    0           activation_243[2][0]             \n",
      "                                                                   input_300[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glob (None, 1024)          0           lambda_295[0][0]                 \n",
      "                                                                   lambda_296[0][0]                 \n",
      "                                                                   lambda_297[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_301 (InputLayer)           (1024,)               0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_302 (InputLayer)           (1024,)               0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_303 (InputLayer)           (1024,)               0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_298 (Lambda)              (None, 1024)          0           global_average_pooling2d_2[0][0] \n",
      "                                                                   input_301[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_299 (Lambda)              (None, 1024)          0           global_average_pooling2d_2[1][0] \n",
      "                                                                   input_302[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_300 (Lambda)              (None, 1024)          0           global_average_pooling2d_2[2][0] \n",
      "                                                                   input_303[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 1024)          1049600     lambda_298[0][0]                 \n",
      "                                                                   lambda_299[0][0]                 \n",
      "                                                                   lambda_300[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_304 (InputLayer)           (1024,)               0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_305 (InputLayer)           (1024,)               0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_306 (InputLayer)           (1024,)               0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_301 (Lambda)              (None, 1024)          0           dense_3[0][0]                    \n",
      "                                                                   input_304[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_302 (Lambda)              (None, 1024)          0           dense_3[1][0]                    \n",
      "                                                                   input_305[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_303 (Lambda)              (None, 1024)          0           dense_3[2][0]                    \n",
      "                                                                   input_306[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchNo (None, 1024)          4096        lambda_301[0][0]                 \n",
      "                                                                   lambda_302[0][0]                 \n",
      "                                                                   lambda_303[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_307 (InputLayer)           (1024,)               0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_308 (InputLayer)           (1024,)               0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_309 (InputLayer)           (1024,)               0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_304 (Lambda)              (None, 1024)          0           batch_normalization_156[0][0]    \n",
      "                                                                   input_307[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_305 (Lambda)              (None, 1024)          0           batch_normalization_156[1][0]    \n",
      "                                                                   input_308[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_306 (Lambda)              (None, 1024)          0           batch_normalization_156[2][0]    \n",
      "                                                                   input_309[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_244 (Activation)      (None, 1024)          0           lambda_304[0][0]                 \n",
      "                                                                   lambda_305[0][0]                 \n",
      "                                                                   lambda_306[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_310 (InputLayer)           (1024,)               0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_311 (InputLayer)           (1024,)               0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_312 (InputLayer)           (1024,)               0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_307 (Lambda)              (None, 1024)          0           activation_244[0][0]             \n",
      "                                                                   input_310[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_308 (Lambda)              (None, 1024)          0           activation_244[1][0]             \n",
      "                                                                   input_311[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_309 (Lambda)              (None, 1024)          0           activation_244[2][0]             \n",
      "                                                                   input_312[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 384)           393600      lambda_307[0][0]                 \n",
      "                                                                   lambda_308[0][0]                 \n",
      "                                                                   lambda_309[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "input_313 (InputLayer)           (2560, 2)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_314 (InputLayer)           (1,)                  0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_315 (InputLayer)           (2560, 2)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_316 (InputLayer)           (1,)                  0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_317 (InputLayer)           (2560, 2)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_318 (InputLayer)           (1,)                  0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_310 (Lambda)              (None, None)          0           dense_4[0][0]                    \n",
      "                                                                   input_313[0][0]                  \n",
      "                                                                   input_314[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_311 (Lambda)              (None, None)          0           dense_4[1][0]                    \n",
      "                                                                   input_315[0][0]                  \n",
      "                                                                   input_316[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_312 (Lambda)              (None, None)          0           dense_4[2][0]                    \n",
      "                                                                   input_317[0][0]                  \n",
      "                                                                   input_318[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_175 (Concatenate)    (None, None)          0           lambda_310[0][0]                 \n",
      "                                                                   lambda_311[0][0]                 \n",
      "                                                                   lambda_312[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 8,484,800\n",
      "Trainable params: 8,399,104\n",
      "Non-trainable params: 85,696\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "era, 1\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 75s - loss: 641.1021    \n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 64s - loss: 359.6964    \n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 65s - loss: 250.1669    \n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 65s - loss: 199.6265    \n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 65s - loss: 159.4833    \n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 65s - loss: 126.6377    \n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 65s - loss: 128.3365    \n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 65s - loss: 109.0945    \n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 65s - loss: 94.9540    \n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 65s - loss: 95.7924    \n",
      "1000 40.9676239491\n",
      "2000 76.7858929634\n",
      "3000 113.142735004\n",
      "4000 149.208667994\n",
      "5000 185.744769096\n",
      "6000 221.831789017\n",
      "7000 258.44321394\n",
      "8000 295.516969919\n",
      "9000 331.925808907\n",
      "10000 367.878422976\n",
      "11000 404.501230001\n",
      "12000 441.084537983\n",
      "13000 478.049861908\n",
      "14000 514.95532608\n",
      "15000 550.964147091\n",
      "1000 30.2801730633\n",
      "2000 59.7983319759\n",
      "3000 89.4119620323\n",
      "metric time: 230.914691\n",
      "{'mAP': 0.3417, 'rank': {'r5': 0.7699, 'r1': 0.5517}, 'loss': [641.10208892822266, 359.69638465881349, 250.16691799163817, 199.6265230369568, 159.48327156335117, 126.63765413075686, 128.33648907810451, 109.09448417305947, 94.953955333530899, 95.792370168864721]}\n",
      "era, 2\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 65s - loss: 78.9660    \n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 65s - loss: 86.2731    \n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 65s - loss: 83.2809    \n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 65s - loss: 73.8826    \n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 65s - loss: 70.5067    \n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 65s - loss: 67.9727    \n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 65s - loss: 64.3811    \n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 65s - loss: 73.9651    \n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 65s - loss: 53.5134    \n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 65s - loss: 52.3020    \n",
      "1000 29.4071609974\n",
      "2000 58.684620142\n",
      "3000 87.9519600868\n",
      "4000 117.208810091\n",
      "5000 146.494394064\n",
      "6000 175.810031176\n",
      "7000 205.099951982\n",
      "8000 234.397950172\n",
      "9000 263.67744112\n",
      "10000 292.969499111\n",
      "11000 322.269172192\n",
      "12000 351.557948112\n",
      "13000 380.84809804\n",
      "14000 410.135161161\n",
      "15000 439.414739132\n",
      "1000 29.2966639996\n",
      "2000 58.5782139301\n",
      "3000 87.8838949203\n",
      "metric time: 239.293431\n",
      "{'mAP': 0.3911, 'rank': {'r5': 0.8144, 'r1': 0.6087}, 'loss': [78.965994117856027, 86.27314119040966, 83.280909095108512, 73.882576099336148, 70.506733903586863, 67.972729249000551, 64.381124969720844, 73.965090367496018, 53.513369024395942, 52.302015672922131]}\n",
      "era, 3\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 65s - loss: 49.6287    \n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 65s - loss: 53.1996    \n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 65s - loss: 57.5395    \n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 65s - loss: 57.3800    \n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 65s - loss: 48.7067    \n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 65s - loss: 64.3510    \n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 65s - loss: 55.0167    \n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 65s - loss: 64.7775    \n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 65s - loss: 61.7789    \n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 65s - loss: 49.7657    \n",
      "1000 29.3572700024\n",
      "2000 58.7189078331\n",
      "3000 87.9420449734\n",
      "4000 117.562911987\n",
      "5000 146.79142499\n",
      "6000 176.08127284\n",
      "7000 205.587709904\n",
      "8000 234.824321985\n",
      "9000 264.043534994\n",
      "10000 293.250076056\n",
      "11000 322.45675993\n",
      "12000 351.688632965\n",
      "13000 380.903995037\n",
      "14000 410.136487007\n",
      "15000 439.337632895\n",
      "1000 29.4815149307\n",
      "2000 58.8130221367\n",
      "3000 88.0338749886\n",
      "metric time: 238.432461\n",
      "{'mAP': 0.36299999999999999, 'rank': {'r5': 0.7877, 'r1': 0.5721}, 'loss': [49.628691932559015, 53.199625612795352, 57.539489519000057, 57.379970431625843, 48.706715028584, 64.350980936288835, 55.016681411564349, 64.777502983510487, 61.77885590493679, 49.76570681333542]}\n",
      "era, 4\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 65s - loss: 58.7905    \n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 65s - loss: 51.8708    \n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 65s - loss: 40.1606    \n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 65s - loss: 57.1962    \n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 65s - loss: 44.7926    \n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 65s - loss: 44.3194    \n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 65s - loss: 42.4581    \n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 65s - loss: 37.9697    \n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 65s - loss: 41.8055    \n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 65s - loss: 72.4858    \n",
      "1000 29.386909008\n",
      "2000 58.6753189564\n",
      "3000 87.957431078\n",
      "4000 117.253693104\n",
      "5000 146.549335957\n",
      "6000 175.849287033\n",
      "7000 205.13784194\n",
      "8000 234.417623997\n",
      "9000 263.619349003\n",
      "10000 292.814851046\n",
      "11000 321.994514942\n",
      "12000 351.191062927\n",
      "13000 380.393960953\n",
      "14000 409.594016075\n",
      "15000 438.777240992\n",
      "1000 29.1864988804\n",
      "2000 58.3734228611\n",
      "3000 87.5711369514\n",
      "metric time: 238.877165\n",
      "{'mAP': 0.34539999999999998, 'rank': {'r5': 0.7714, 'r1': 0.5546}, 'loss': [58.790503707528117, 51.870839563906195, 40.160582427382472, 57.196173961460588, 44.792550966739654, 44.319357795715334, 42.45811076045036, 37.96966521054506, 41.805485353469848, 72.485758971571926]}\n",
      "era, 5\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 65s - loss: 45.8258    \n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 65s - loss: 50.4932    \n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 65s - loss: 45.5339    \n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 65s - loss: 38.0969    \n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 65s - loss: 44.9626    \n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 65s - loss: 46.0539    \n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 65s - loss: 45.5523    \n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 65s - loss: 46.5739    \n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 65s - loss: 42.4687    \n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 65s - loss: 44.9380    \n",
      "1000 29.305077076\n",
      "2000 58.596421957\n",
      "3000 87.9022960663\n",
      "4000 117.116872072\n",
      "5000 146.32861495\n",
      "6000 175.561843157\n",
      "7000 204.791552067\n",
      "8000 234.009575129\n",
      "9000 263.221929073\n",
      "10000 292.436903954\n",
      "11000 321.684184074\n",
      "12000 350.89892602\n",
      "13000 380.16140604\n",
      "14000 409.379596949\n",
      "15000 438.594270945\n",
      "1000 29.2013809681\n",
      "2000 58.4063391685\n",
      "3000 87.6319460869\n",
      "metric time: 238.051398\n",
      "{'mAP': 0.3619, 'rank': {'r5': 0.7794, 'r1': 0.5638}, 'loss': [45.825806545615194, 50.493169501423836, 45.533878891468049, 38.096923445761206, 44.962648727893828, 46.053921195268629, 45.552318867444995, 46.573919283747671, 42.468698016703129, 44.93804496407509]}\n",
      "era, 6\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 65s - loss: 33.3287    \n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 65s - loss: 28.4098    \n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 65s - loss: 18.6485    \n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 65s - loss: 19.0537    \n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 65s - loss: 21.6719    \n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 65s - loss: 20.8979    \n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 65s - loss: 13.4051    \n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 65s - loss: 15.2043    \n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 65s - loss: 20.5085    \n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 65s - loss: 11.6528    \n",
      "1000 29.3723599911\n",
      "2000 58.7212309837\n",
      "3000 87.9694871902\n",
      "4000 117.190071106\n",
      "5000 146.426815987\n",
      "6000 175.660991192\n",
      "7000 205.260452986\n",
      "8000 234.479809046\n",
      "9000 263.696511984\n",
      "10000 292.913707018\n",
      "11000 322.170062065\n",
      "12000 351.67762208\n",
      "13000 380.914719105\n",
      "14000 410.288438082\n",
      "15000 439.531079054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 29.2467868328\n",
      "2000 58.4987578392\n",
      "3000 88.2747409344\n",
      "metric time: 240.310124\n",
      "{'mAP': 0.48010000000000003, 'rank': {'r5': 0.8539, 'r1': 0.6847}, 'loss': [33.328669249117375, 28.40977145344019, 18.648524189889432, 19.053696137070656, 21.671913271546362, 20.897945700585844, 13.405129644274712, 15.204256120622158, 20.508495917916299, 11.652796576023102]}\n",
      "era, 7\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 65s - loss: 13.4585    \n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 66s - loss: 10.7137    \n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 65s - loss: 10.3142    \n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 65s - loss: 12.1424    \n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 65s - loss: 6.8690    \n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 66s - loss: 10.4189    \n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 65s - loss: 5.4582    \n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 65s - loss: 7.9718    \n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 65s - loss: 9.9922     \n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 66s - loss: 7.8608    \n",
      "1000 29.5731868744\n",
      "2000 59.0735018253\n",
      "3000 88.5363578796\n",
      "4000 118.103592873\n",
      "5000 147.65444684\n",
      "6000 177.001535892\n",
      "7000 206.628184795\n",
      "8000 236.07581687\n",
      "9000 265.398736954\n",
      "10000 294.861317873\n",
      "11000 324.256790876\n",
      "12000 353.514853001\n",
      "13000 383.007537842\n",
      "14000 412.504966974\n",
      "15000 441.827569962\n",
      "1000 29.297645092\n",
      "2000 58.9355170727\n",
      "3000 88.6038219929\n",
      "metric time: 239.605512\n",
      "{'mAP': 0.52959999999999996, 'rank': {'r5': 0.8803, 'r1': 0.7289}, 'loss': [13.458509635627269, 10.713717161715032, 10.314185182154178, 12.142372812032699, 6.8689622101187702, 10.41890764772892, 5.458180174827576, 7.971832849085331, 9.9921577376127235, 7.8607699406147002]}\n",
      "era, 8\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 64s - loss: 10.3616    \n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 65s - loss: 8.0276    \n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 65s - loss: 9.0867    \n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 65s - loss: 5.6930    \n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 65s - loss: 7.5822    \n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 65s - loss: 8.7865    \n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 65s - loss: 5.8711    \n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 65s - loss: 7.7894    \n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 65s - loss: 7.5688    \n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 65s - loss: 5.6050    \n",
      "1000 29.2964310646\n",
      "2000 58.6302239895\n",
      "3000 88.0345971584\n",
      "4000 117.370859146\n",
      "5000 146.743695974\n",
      "6000 176.084379196\n",
      "7000 205.568710089\n",
      "8000 234.933405161\n",
      "9000 264.23468709\n",
      "10000 293.537192106\n",
      "11000 322.944815159\n",
      "12000 352.304877996\n",
      "13000 381.649546146\n",
      "14000 410.984202147\n",
      "15000 440.367530107\n",
      "1000 29.3044960499\n",
      "2000 58.5901470184\n",
      "3000 87.9771690369\n",
      "metric time: 239.519540\n",
      "{'mAP': 0.55279999999999996, 'rank': {'r5': 0.8928, 'r1': 0.7482}, 'loss': [10.361564396619796, 8.0276137632131572, 9.0866844487190246, 5.6930044370889661, 7.5822202441096307, 8.7865287345647811, 5.871097455024719, 7.7893736514449117, 7.5687929943203924, 5.6050196143984792]}\n",
      "era, 9\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 65s - loss: 9.6691    \n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 65s - loss: 6.7224    \n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 65s - loss: 6.7589    \n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 65s - loss: 7.2979    \n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 65s - loss: 7.8411    \n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 65s - loss: 6.6303    \n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 65s - loss: 9.9551    \n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 65s - loss: 7.2698    \n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 65s - loss: 6.7387    \n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 65s - loss: 4.5088    \n",
      "1000 29.3978071213\n",
      "2000 58.6956350803\n",
      "3000 87.9662699699\n",
      "4000 117.247447968\n",
      "5000 146.544826031\n",
      "6000 175.870001078\n",
      "7000 205.135348082\n",
      "8000 234.418504\n",
      "9000 263.712687969\n",
      "10000 292.998631001\n",
      "11000 322.275722027\n",
      "12000 351.564495087\n",
      "13000 380.863960028\n",
      "14000 410.152608156\n",
      "15000 439.434086084\n",
      "1000 29.2998728752\n",
      "2000 58.5848920345\n",
      "3000 87.8661780357\n",
      "metric time: 238.266166\n",
      "{'mAP': 0.55130000000000001, 'rank': {'r5': 0.891, 'r1': 0.7458}, 'loss': [9.6691415253281594, 6.7223581784963606, 6.7589157405495648, 7.2978569984436037, 7.8410900181531904, 6.6303468966484074, 9.9550624713301659, 7.2698208156228068, 6.7387490433454511, 4.5087969142198565]}\n",
      "era, 10\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 65s - loss: 7.8607    \n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 65s - loss: 5.6551    \n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 65s - loss: 7.1180    \n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 65s - loss: 5.9263    \n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 65s - loss: 7.0580    \n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 65s - loss: 2.2441    \n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 65s - loss: 3.3324    \n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 65s - loss: 7.8956    \n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 65s - loss: 6.4197    \n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 65s - loss: 3.1775    \n",
      "1000 29.2887041569\n",
      "2000 58.5714831352\n",
      "3000 87.8442780972\n",
      "4000 117.148363113\n",
      "5000 146.4432652\n",
      "6000 175.76051116\n",
      "7000 205.049468994\n",
      "8000 234.360854149\n",
      "9000 263.699657202\n",
      "10000 293.019878149\n",
      "11000 322.312844038\n",
      "12000 351.626824141\n",
      "13000 380.907278061\n",
      "14000 410.196976185\n",
      "15000 439.473031998\n",
      "1000 29.3115048409\n",
      "2000 58.6028769016\n",
      "3000 87.8877499104\n",
      "metric time: 239.306237\n",
      "{'mAP': 0.56710000000000005, 'rank': {'r5': 0.9002, 'r1': 0.7592}, 'loss': [7.8607000243663787, 5.6551444473862649, 7.1179608142375947, 5.9262623965740202, 7.0580152389407154, 2.244086466729641, 3.3324006026983262, 7.8956462299823764, 6.4197152975201606, 3.1774741420149804]}\n",
      "era, 11\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 65s - loss: 6.5672    \n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 65s - loss: 4.9156    \n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 65s - loss: 8.7845    \n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 65s - loss: 4.3468    \n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 65s - loss: 5.0219    \n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 65s - loss: 4.5552    \n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 65s - loss: 5.0833    \n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 65s - loss: 5.5709    \n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 65s - loss: 5.3219    \n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 65s - loss: 5.2694    \n",
      "1000 29.2775931358\n",
      "2000 58.5693659782\n",
      "3000 87.9540390968\n",
      "4000 117.54602313\n",
      "5000 146.760346174\n",
      "6000 175.998502016\n",
      "7000 205.221153975\n",
      "8000 234.454602003\n",
      "9000 263.678892136\n",
      "10000 292.890887976\n",
      "11000 322.12369895\n",
      "12000 351.340976\n",
      "13000 380.563160181\n",
      "14000 409.798983097\n",
      "15000 439.027796984\n",
      "1000 29.2363572121\n",
      "2000 58.4779222012\n",
      "3000 87.7166061401\n",
      "metric time: 238.912864\n",
      "{'mAP': 0.57099999999999995, 'rank': {'r5': 0.9035, 'r1': 0.7628}, 'loss': [6.5671667131781577, 4.9156368592381474, 8.7844696655869488, 4.3468350338935853, 5.0218687593936924, 4.555161603093147, 5.0833059680461883, 5.5708554160594943, 5.32194130718708, 5.2693519046902653]}\n",
      "era, 12\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 65s - loss: 5.4718    \n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 65s - loss: 7.0619    \n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 65s - loss: 4.7919    \n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 65s - loss: 4.9443    \n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 65s - loss: 3.8237    \n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 65s - loss: 5.4985    \n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 65s - loss: 2.5594    \n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 65s - loss: 6.9449    \n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 65s - loss: 4.4335    \n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 65s - loss: 7.7415    \n",
      "1000 29.4122860432\n",
      "2000 58.713518858\n",
      "3000 88.0234489441\n",
      "4000 117.316124916\n",
      "5000 146.604346991\n",
      "6000 175.938546896\n",
      "7000 205.254343987\n",
      "8000 234.555346012\n",
      "9000 263.831934929\n",
      "10000 293.142683029\n",
      "11000 322.451864004\n",
      "12000 351.745650053\n",
      "13000 381.037041903\n",
      "14000 410.344274998\n",
      "15000 439.654525042\n",
      "1000 29.2744688988\n",
      "2000 58.570994854\n",
      "3000 87.8666348457\n",
      "metric time: 239.671108\n",
      "{'mAP': 0.57199999999999995, 'rank': {'r5': 0.9008, 'r1': 0.7643}, 'loss': [5.4717588159441952, 7.0619179284572597, 4.7918783491849899, 4.9442544889450071, 3.8236795452237131, 5.4985447403788568, 2.5593959489464759, 6.9449424144625667, 4.4334677121043207, 7.7414544424414631]}\n",
      "era, 13\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 65s - loss: 4.6232    \n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 65s - loss: 4.2178    \n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 65s - loss: 7.7946    \n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 65s - loss: 3.5494    \n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 65s - loss: 5.2914    \n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 65s - loss: 5.8954    \n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 65s - loss: 5.9293    \n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 65s - loss: 3.3892    \n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 65s - loss: 4.2781    \n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 65s - loss: 7.6119    \n",
      "1000 29.2928929329\n",
      "2000 58.5986690521\n",
      "3000 87.8720359802\n",
      "4000 117.140330076\n",
      "5000 146.435258865\n",
      "6000 175.73583889\n",
      "7000 205.032558918\n",
      "8000 234.339001894\n",
      "9000 263.624824047\n",
      "10000 292.933179855\n",
      "11000 322.244726896\n",
      "12000 351.616721869\n",
      "13000 380.907620907\n",
      "14000 410.209655046\n",
      "15000 439.494430065\n",
      "1000 29.2928478718\n",
      "2000 58.6018459797\n",
      "3000 87.8738369942\n",
      "metric time: 238.597444\n",
      "{'mAP': 0.57310000000000005, 'rank': {'r5': 0.8999, 'r1': 0.7595}, 'loss': [4.6231911471486091, 4.2177868551015854, 7.7945516741275789, 3.5493589988350869, 5.2914378291368482, 5.8953892594575885, 5.929331039786339, 3.3892485535144807, 4.2780906876921652, 7.6119328105449675]}\n",
      "era, 14\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 65s - loss: 4.6195    \n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 65s - loss: 5.3794    \n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 65s - loss: 4.1831    \n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 65s - loss: 5.1276    \n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 65s - loss: 5.9514    \n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 65s - loss: 4.3887    \n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 65s - loss: 3.4266    \n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 65s - loss: 6.7671    \n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 65s - loss: 5.5595    \n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 65s - loss: 4.4739    \n",
      "1000 29.3595998287\n",
      "2000 58.7013468742\n",
      "3000 88.0524220467\n",
      "4000 117.375118971\n",
      "5000 146.717785835\n",
      "6000 176.060588837\n",
      "7000 205.371455908\n",
      "8000 234.667264938\n",
      "9000 263.882187843\n",
      "10000 293.081894875\n",
      "11000 322.273933887\n",
      "12000 351.477838039\n",
      "13000 380.686717033\n",
      "14000 409.907960892\n",
      "15000 439.122107029\n",
      "1000 29.2107300758\n",
      "2000 58.4381520748\n",
      "3000 87.6570320129\n",
      "metric time: 239.269846\n",
      "{'mAP': 0.57220000000000004, 'rank': {'r5': 0.9002, 'r1': 0.7598}, 'loss': [4.6195242464542385, 5.379397898316383, 4.1831325408816333, 5.1275875672698019, 5.9513986006379129, 4.3886506524682041, 3.4266094470024111, 6.7671008050441745, 5.5594588825106621, 4.4738846862316128]}\n",
      "era, 15\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 65s - loss: 2.1113    \n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 65s - loss: 4.9102    \n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 65s - loss: 6.1619    \n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 65s - loss: 3.5730    \n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 65s - loss: 6.4796    \n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 65s - loss: 5.0590    \n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 65s - loss: 6.4896    \n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 65s - loss: 5.8153    \n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 65s - loss: 4.7840    \n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 65s - loss: 5.3992    \n",
      "1000 29.3163897991\n",
      "2000 58.6165828705\n",
      "3000 87.8945119381\n",
      "4000 117.186372995\n",
      "5000 146.504550934\n",
      "6000 175.867064953\n",
      "7000 205.164429903\n",
      "8000 234.457630873\n",
      "9000 263.776633978\n",
      "10000 293.023960829\n",
      "11000 322.219113827\n",
      "12000 351.425951958\n",
      "13000 380.645534992\n",
      "14000 409.856880903\n",
      "15000 439.052902937\n",
      "1000 29.2142288685\n",
      "2000 58.4255590439\n",
      "3000 87.6338410378\n",
      "metric time: 238.858695\n",
      "{'mAP': 0.57299999999999995, 'rank': {'r5': 0.9008, 'r1': 0.7637}, 'loss': [2.1113393738865853, 4.9102432981133459, 6.1618846994638439, 3.573044637143612, 6.4796109795570374, 5.0590012055635452, 6.4895651966333388, 5.8152982878685, 4.7839612394571303, 5.3991713178157807]}\n"
     ]
    }
   ],
   "source": [
    "history = History()\n",
    "for era in range(1,16):\n",
    "    iterations = era * epochs * steps_per_epoch\n",
    "    lrate = LearningRateScheduler(training.step_decay_cont(epochs, era))\n",
    "\n",
    "    print 'era, ' + str(era)\n",
    "\n",
    "    model.fit_generator(data.batch_generator(train_dict, P=P_param, K=K_param,\n",
    "                            preprocess=True, shape=(256,128)),\n",
    "                         steps_per_epoch=steps_per_epoch,\n",
    "                         epochs=epochs,\n",
    "                         callbacks=[lrate,history])\n",
    "\n",
    "    path = training.save_weights(model, it=iterations, root='mergenet_P5K4_tile')\n",
    "    model_eval.set_weights(model.get_weights())\n",
    "\n",
    "    print evaluation.get_score(model_eval, hist=history, inputs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
