{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with Virtual Branching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from vbranch.callbacks import classification_acc\n",
    "from vbranch.applications.fcn import FCN\n",
    "from vbranch.applications.cnn import CNN\n",
    "from vbranch.losses import softmax_cross_entropy_with_logits\n",
    "\n",
    "from vbranch.utils import TFSessionGrow, restore_sess\n",
    "from vbranch.utils.training import get_data, bag_samples, get_data_iterator\n",
    "from vbranch.utils.generic import get_path, save_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = 1\n",
    "ARCHITECTURE = 'fcn3A'\n",
    "DATASET = 'mnist'\n",
    "NUM_CLASSES = 10\n",
    "NUM_FEATURES = None\n",
    "SAMPLES_PER_CLASS = None\n",
    "BAGGING_SAMPLES = 1.\n",
    "TRAIN_FRAC = 0.01\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "STEPS_PER_EPOCH = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = get_data(DATASET, ARCHITECTURE, NUM_CLASSES,\n",
    "                                                NUM_FEATURES, SAMPLES_PER_CLASS, \n",
    "                                                train_frac=TRAIN_FRAC)\n",
    "# Bagging\n",
    "if BAGGING_SAMPLES < 1:\n",
    "    x_train_list, y_train_list = bag_samples(X_train, y_train, NUM_BRANCHES, \n",
    "                                             max_samples=BAGGING_SAMPLES)\n",
    "    \n",
    "x_shape = (None,) + X_train.shape[1:]\n",
    "y_shape = (None, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path(n_branches, shared_frac):\n",
    "    return get_path(DATASET, ARCHITECTURE, 'sensitivity', vb=True, \n",
    "                    B=n_branches, S=shared_frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_branches, shared_frac, name='model'):\n",
    "    inputs, labels, train_init_op, test_init_op = get_data_iterator(x_shape, y_shape, \n",
    "                                                                    batch_size=BATCH_SIZE, \n",
    "                                                                    n=n_branches, \n",
    "                                                                    share_xy=BAGGING_SAMPLES == 1)\n",
    "    with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n",
    "        if ARCHITECTURE == 'fcn':\n",
    "            layer_spec = [(512, shared_frac), NUM_CLASSES]\n",
    "        elif ARCHITECTURE == 'fcn2':\n",
    "            layer_spec = [(512, shared_frac), 512, NUM_CLASSES]\n",
    "        elif ARCHITECTURE == 'fcn3':\n",
    "            layer_spec = [(512, shared_frac), 512, 512, NUM_CLASSES]\n",
    "        elif ARCHITECTURE == 'fcn2A':\n",
    "            layer_spec = [(512, shared_frac), (512, shared_frac), (NUM_CLASSES, shared_frac)]\n",
    "        elif ARCHITECTURE == 'fcn3A':\n",
    "            layer_spec = [(512, shared_frac), (512, shared_frac), \n",
    "                          (512, shared_frac), (NUM_CLASSES, shared_frac)]\n",
    "        else:\n",
    "            raise ValueError('invalid model')\n",
    "            \n",
    "        model = FCN(inputs, *layer_spec, name=name, shared_frac=1)\n",
    "#         elif ARCHITECTURE == 'cnn':\n",
    "#             model = SimpleCNNSmall(inputs, NUM_CLASSES, name=name, shared_frac=shared_frac)\n",
    "\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "        model.compile(optimizer, softmax_cross_entropy_with_logits(), \n",
    "                      train_init_op, test_init_op, labels=labels, \n",
    "                      callbacks={'acc':classification_acc(n_branches)})\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n_branches, shared_frac, model_id=1):\n",
    "    dirpath = path(n_branches, shared_frac)\n",
    "    print(dirpath)\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    model = build_model(n_branches, shared_frac)\n",
    "    model.summary()\n",
    "\n",
    "    if n_branches == 1 or BAGGING_SAMPLES == 1:\n",
    "        train_dict = {'x:0': X_train, 'y:0': y_train, 'batch_size:0': BATCH_SIZE}\n",
    "    else:\n",
    "        train_dict = {}\n",
    "        for i in range(n_branches):\n",
    "            train_dict['vb{}_x:0'.format(i+1)] = x_train_list[i]\n",
    "            train_dict['vb{}_y:0'.format(i+1)] = y_train_list[i]\n",
    "        train_dict['batch_size:0'] = BATCH_SIZE\n",
    "\n",
    "    val_dict = {'x:0': X_test, 'y:0': y_test, 'batch_size:0': len(X_test)}\n",
    "\n",
    "    model_path = os.path.join('models', dirpath, 'model_{}'.format(model_id))\n",
    "    os.system('mkdir -p ' + model_path)\n",
    "    history = model.fit(EPOCHS, STEPS_PER_EPOCH, train_dict=train_dict,\n",
    "                        val_dict=val_dict, log_path=model_path)\n",
    "    save_results(history, dirpath, 'train_{}.csv'.format(model_id))\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensitivity/vb-mnist-fcn3A/B2/S0.00\n",
      "WARNING:tensorflow:From /home/gong/anaconda3/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py:358: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/gong/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "i  Layer name                Output shape   Num param  Inbound  \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "0  fc1 (Dense)               [] [None,512]  803840     input    \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [] [None,512]  2048       fc1      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "2  relu1 (Activation)        [] [None,512]  0          bn1      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "3  fc2 (Dense)               [] [None,512]  525312     relu1    \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [] [None,512]  2048       fc2      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "5  relu2 (Activation)        [] [None,512]  0          bn2      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "6  fc3 (Dense)               [] [None,512]  525312     relu2    \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [] [None,512]  2048       fc3      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "8  relu3 (Activation)        [] [None,512]  0          bn3      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]      10260      relu3    \n",
      "                             [None,10]                          \n",
      "----------------------------------------------------------------\n",
      "Total parameters: 1870868\n",
      "Epoch 1/10\n",
      " - 1s - loss_1: 0.2357 - loss_2: 0.2266 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 0.9983 - val_loss_1: 0.3876 - val_loss_2: 0.3897 - val_acc_ensemble: 0.9016 - val_acc_1: 0.8866 - val_acc_2: 0.8873\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 0.0043 - loss_2: 0.0031 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3655 - val_loss_2: 0.3622 - val_acc_ensemble: 0.9070 - val_acc_1: 0.8995 - val_acc_2: 0.8971\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 9.4204e-04 - loss_2: 9.0993e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3689 - val_loss_2: 0.3616 - val_acc_ensemble: 0.9074 - val_acc_1: 0.8991 - val_acc_2: 0.9000\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 5.5336e-04 - loss_2: 5.7969e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3714 - val_loss_2: 0.3637 - val_acc_ensemble: 0.9078 - val_acc_1: 0.8999 - val_acc_2: 0.9007\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 3.9861e-04 - loss_2: 4.1795e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3740 - val_loss_2: 0.3644 - val_acc_ensemble: 0.9082 - val_acc_1: 0.9006 - val_acc_2: 0.9017\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 3.0944e-04 - loss_2: 3.2848e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3763 - val_loss_2: 0.3667 - val_acc_ensemble: 0.9090 - val_acc_1: 0.9008 - val_acc_2: 0.9020\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 2.4878e-04 - loss_2: 2.5316e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3783 - val_loss_2: 0.3683 - val_acc_ensemble: 0.9096 - val_acc_1: 0.9011 - val_acc_2: 0.9028\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 1.9760e-04 - loss_2: 2.0641e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3812 - val_loss_2: 0.3702 - val_acc_ensemble: 0.9090 - val_acc_1: 0.9012 - val_acc_2: 0.9032\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 1.6946e-04 - loss_2: 1.7806e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3827 - val_loss_2: 0.3718 - val_acc_ensemble: 0.9096 - val_acc_1: 0.9013 - val_acc_2: 0.9029\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 1.5124e-04 - loss_2: 1.4963e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3851 - val_loss_2: 0.3740 - val_acc_ensemble: 0.9097 - val_acc_1: 0.9013 - val_acc_2: 0.9025\n",
      "sensitivity/vb-mnist-fcn3A/B2/S0.00\n",
      "i  Layer name                Output shape   Num param  Inbound  \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "0  fc1 (Dense)               [] [None,512]  803840     input    \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [] [None,512]  2048       fc1      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "2  relu1 (Activation)        [] [None,512]  0          bn1      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "3  fc2 (Dense)               [] [None,512]  525312     relu1    \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [] [None,512]  2048       fc2      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "5  relu2 (Activation)        [] [None,512]  0          bn2      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "6  fc3 (Dense)               [] [None,512]  525312     relu2    \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [] [None,512]  2048       fc3      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "8  relu3 (Activation)        [] [None,512]  0          bn3      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]      10260      relu3    \n",
      "                             [None,10]                          \n",
      "----------------------------------------------------------------\n",
      "Total parameters: 1870868\n",
      "Epoch 1/10\n",
      " - 1s - loss_1: 0.2328 - loss_2: 0.2390 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3617 - val_loss_2: 0.3608 - val_acc_ensemble: 0.9055 - val_acc_1: 0.8931 - val_acc_2: 0.8969\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 0.0082 - loss_2: 0.0025 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3846 - val_loss_2: 0.3466 - val_acc_ensemble: 0.9060 - val_acc_1: 0.8922 - val_acc_2: 0.9019\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 0.0062 - loss_2: 8.6537e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.4028 - val_loss_2: 0.3480 - val_acc_ensemble: 0.9071 - val_acc_1: 0.8908 - val_acc_2: 0.9029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      " - 1s - loss_1: 9.5622e-04 - loss_2: 5.9037e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3783 - val_loss_2: 0.3503 - val_acc_ensemble: 0.9091 - val_acc_1: 0.8977 - val_acc_2: 0.9034\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 4.8448e-04 - loss_2: 4.1629e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3772 - val_loss_2: 0.3534 - val_acc_ensemble: 0.9087 - val_acc_1: 0.8980 - val_acc_2: 0.9030\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 3.2794e-04 - loss_2: 3.1385e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3779 - val_loss_2: 0.3565 - val_acc_ensemble: 0.9089 - val_acc_1: 0.8985 - val_acc_2: 0.9037\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 2.2993e-04 - loss_2: 2.6107e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3801 - val_loss_2: 0.3591 - val_acc_ensemble: 0.9085 - val_acc_1: 0.8989 - val_acc_2: 0.9037\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 2.1094e-04 - loss_2: 2.0812e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3811 - val_loss_2: 0.3609 - val_acc_ensemble: 0.9086 - val_acc_1: 0.8995 - val_acc_2: 0.9039\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 1.7303e-04 - loss_2: 1.7327e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3818 - val_loss_2: 0.3618 - val_acc_ensemble: 0.9088 - val_acc_1: 0.9002 - val_acc_2: 0.9042\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 1.4383e-04 - loss_2: 1.5412e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3834 - val_loss_2: 0.3642 - val_acc_ensemble: 0.9087 - val_acc_1: 0.9003 - val_acc_2: 0.9038\n",
      "sensitivity/vb-mnist-fcn3A/B2/S0.00\n",
      "i  Layer name                Output shape   Num param  Inbound  \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "0  fc1 (Dense)               [] [None,512]  803840     input    \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [] [None,512]  2048       fc1      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "2  relu1 (Activation)        [] [None,512]  0          bn1      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "3  fc2 (Dense)               [] [None,512]  525312     relu1    \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [] [None,512]  2048       fc2      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "5  relu2 (Activation)        [] [None,512]  0          bn2      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "6  fc3 (Dense)               [] [None,512]  525312     relu2    \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [] [None,512]  2048       fc3      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "8  relu3 (Activation)        [] [None,512]  0          bn3      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]      10260      relu3    \n",
      "                             [None,10]                          \n",
      "----------------------------------------------------------------\n",
      "Total parameters: 1870868\n",
      "Epoch 1/10\n",
      " - 1s - loss_1: 0.2241 - loss_2: 0.2325 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.4076 - val_loss_2: 0.3686 - val_acc_ensemble: 0.9022 - val_acc_1: 0.8854 - val_acc_2: 0.8930\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 0.0034 - loss_2: 0.0023 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3766 - val_loss_2: 0.3538 - val_acc_ensemble: 0.9082 - val_acc_1: 0.8966 - val_acc_2: 0.9001\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 8.9452e-04 - loss_2: 9.9663e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3777 - val_loss_2: 0.3547 - val_acc_ensemble: 0.9090 - val_acc_1: 0.8993 - val_acc_2: 0.9017\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 5.7215e-04 - loss_2: 5.8084e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3799 - val_loss_2: 0.3570 - val_acc_ensemble: 0.9093 - val_acc_1: 0.8991 - val_acc_2: 0.9017\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 4.2422e-04 - loss_2: 4.1751e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3813 - val_loss_2: 0.3587 - val_acc_ensemble: 0.9101 - val_acc_1: 0.9003 - val_acc_2: 0.9034\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 3.2117e-04 - loss_2: 3.2034e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3838 - val_loss_2: 0.3611 - val_acc_ensemble: 0.9101 - val_acc_1: 0.9015 - val_acc_2: 0.9031\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 2.5527e-04 - loss_2: 2.5611e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3855 - val_loss_2: 0.3637 - val_acc_ensemble: 0.9103 - val_acc_1: 0.9016 - val_acc_2: 0.9033\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 2.1434e-04 - loss_2: 2.0718e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3884 - val_loss_2: 0.3660 - val_acc_ensemble: 0.9103 - val_acc_1: 0.9019 - val_acc_2: 0.9033\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 1.8081e-04 - loss_2: 1.7057e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3913 - val_loss_2: 0.3681 - val_acc_ensemble: 0.9102 - val_acc_1: 0.9024 - val_acc_2: 0.9025\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 1.4982e-04 - loss_2: 1.5548e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3931 - val_loss_2: 0.3698 - val_acc_ensemble: 0.9105 - val_acc_1: 0.9028 - val_acc_2: 0.9039\n",
      "sensitivity/vb-mnist-fcn3A/B2/S0.00\n",
      "i  Layer name                Output shape   Num param  Inbound  \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "0  fc1 (Dense)               [] [None,512]  803840     input    \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [] [None,512]  2048       fc1      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "2  relu1 (Activation)        [] [None,512]  0          bn1      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "3  fc2 (Dense)               [] [None,512]  525312     relu1    \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [] [None,512]  2048       fc2      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "5  relu2 (Activation)        [] [None,512]  0          bn2      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "6  fc3 (Dense)               [] [None,512]  525312     relu2    \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [] [None,512]  2048       fc3      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "8  relu3 (Activation)        [] [None,512]  0          bn3      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]      10260      relu3    \n",
      "                             [None,10]                          \n",
      "----------------------------------------------------------------\n",
      "Total parameters: 1870868\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss_1: 0.2295 - loss_2: 0.2216 - acc_ensemble: 1.0000 - acc_1: 0.9967 - acc_2: 1.0000 - val_loss_1: 0.4755 - val_loss_2: 0.3891 - val_acc_ensemble: 0.8977 - val_acc_1: 0.8662 - val_acc_2: 0.8874\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 0.0044 - loss_2: 0.0029 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3738 - val_loss_2: 0.3668 - val_acc_ensemble: 0.9057 - val_acc_1: 0.8966 - val_acc_2: 0.8969\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 9.0261e-04 - loss_2: 8.4836e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3736 - val_loss_2: 0.3653 - val_acc_ensemble: 0.9060 - val_acc_1: 0.8976 - val_acc_2: 0.9001\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 5.3343e-04 - loss_2: 5.4641e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3745 - val_loss_2: 0.3668 - val_acc_ensemble: 0.9073 - val_acc_1: 0.8991 - val_acc_2: 0.8996\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 4.1399e-04 - loss_2: 4.0798e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3749 - val_loss_2: 0.3707 - val_acc_ensemble: 0.9078 - val_acc_1: 0.9001 - val_acc_2: 0.9001\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 3.0939e-04 - loss_2: 2.9619e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3779 - val_loss_2: 0.3730 - val_acc_ensemble: 0.9080 - val_acc_1: 0.9008 - val_acc_2: 0.8998\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 2.4150e-04 - loss_2: 2.3402e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3805 - val_loss_2: 0.3749 - val_acc_ensemble: 0.9084 - val_acc_1: 0.9002 - val_acc_2: 0.9005\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 2.0511e-04 - loss_2: 2.0166e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3821 - val_loss_2: 0.3771 - val_acc_ensemble: 0.9091 - val_acc_1: 0.9006 - val_acc_2: 0.9009\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 1.7317e-04 - loss_2: 1.6228e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3839 - val_loss_2: 0.3791 - val_acc_ensemble: 0.9089 - val_acc_1: 0.9008 - val_acc_2: 0.9011\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 1.4235e-04 - loss_2: 1.3215e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3849 - val_loss_2: 0.3811 - val_acc_ensemble: 0.9090 - val_acc_1: 0.9012 - val_acc_2: 0.9012\n",
      "sensitivity/vb-mnist-fcn3A/B2/S0.25\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,128] [None,384]  703360     input    \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,128] [None,384]  1792       fc1      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,128] [None,384]  0          bn1      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,128] [None,384]  509824     relu1    \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,128] [None,384]  1792       fc2      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,128] [None,384]  0          bn2      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,128] [None,384]  509824     relu2    \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,128] [None,384]  1792       fc3      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,128] [None,384]  0          bn3      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              10022      relu3    \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 1738406\n",
      "Epoch 1/10\n",
      " - 2s - loss_1: 0.2459 - loss_2: 0.2338 - acc_ensemble: 1.0000 - acc_1: 0.9933 - acc_2: 1.0000 - val_loss_1: 0.4184 - val_loss_2: 0.3726 - val_acc_ensemble: 0.9026 - val_acc_1: 0.8845 - val_acc_2: 0.8899\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 0.0080 - loss_2: 0.0036 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3759 - val_loss_2: 0.3631 - val_acc_ensemble: 0.9072 - val_acc_1: 0.8976 - val_acc_2: 0.8989\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 8.8706e-04 - loss_2: 7.6221e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3701 - val_loss_2: 0.3621 - val_acc_ensemble: 0.9085 - val_acc_1: 0.9016 - val_acc_2: 0.9018\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 5.2064e-04 - loss_2: 4.8061e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3704 - val_loss_2: 0.3646 - val_acc_ensemble: 0.9093 - val_acc_1: 0.9021 - val_acc_2: 0.9010\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 3.6814e-04 - loss_2: 3.5160e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3726 - val_loss_2: 0.3676 - val_acc_ensemble: 0.9092 - val_acc_1: 0.9030 - val_acc_2: 0.9015\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 2.8993e-04 - loss_2: 2.7832e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3748 - val_loss_2: 0.3705 - val_acc_ensemble: 0.9097 - val_acc_1: 0.9035 - val_acc_2: 0.9020\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 2.3488e-04 - loss_2: 2.1889e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3763 - val_loss_2: 0.3733 - val_acc_ensemble: 0.9101 - val_acc_1: 0.9034 - val_acc_2: 0.9021\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 1.8786e-04 - loss_2: 1.7296e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3783 - val_loss_2: 0.3749 - val_acc_ensemble: 0.9102 - val_acc_1: 0.9037 - val_acc_2: 0.9025\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 1.5960e-04 - loss_2: 1.5175e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3797 - val_loss_2: 0.3771 - val_acc_ensemble: 0.9106 - val_acc_1: 0.9039 - val_acc_2: 0.9028\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 1.3802e-04 - loss_2: 1.2542e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3812 - val_loss_2: 0.3789 - val_acc_ensemble: 0.9108 - val_acc_1: 0.9044 - val_acc_2: 0.9033\n",
      "sensitivity/vb-mnist-fcn3A/B2/S0.25\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,128] [None,384]  703360     input    \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,128] [None,384]  1792       fc1      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,128] [None,384]  0          bn1      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,128] [None,384]  509824     relu1    \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,128] [None,384]  1792       fc2      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,128] [None,384]  0          bn2      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,128] [None,384]  509824     relu2    \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,128] [None,384]  1792       fc3      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,128] [None,384]  0          bn3      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              10022      relu3    \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 1738406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 2s - loss_1: 0.2401 - loss_2: 0.2403 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3771 - val_loss_2: 0.3961 - val_acc_ensemble: 0.9017 - val_acc_1: 0.8966 - val_acc_2: 0.8898\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 0.0025 - loss_2: 0.0098 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3678 - val_loss_2: 0.3854 - val_acc_ensemble: 0.9061 - val_acc_1: 0.8995 - val_acc_2: 0.8979\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 7.5635e-04 - loss_2: 9.2750e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3696 - val_loss_2: 0.3812 - val_acc_ensemble: 0.9069 - val_acc_1: 0.9007 - val_acc_2: 0.9015\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 4.9854e-04 - loss_2: 4.8844e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3713 - val_loss_2: 0.3808 - val_acc_ensemble: 0.9080 - val_acc_1: 0.9025 - val_acc_2: 0.9024\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 3.5842e-04 - loss_2: 3.4768e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3740 - val_loss_2: 0.3826 - val_acc_ensemble: 0.9085 - val_acc_1: 0.9022 - val_acc_2: 0.9032\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 2.8329e-04 - loss_2: 2.6921e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3769 - val_loss_2: 0.3848 - val_acc_ensemble: 0.9088 - val_acc_1: 0.9026 - val_acc_2: 0.9037\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 2.2294e-04 - loss_2: 2.1521e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3791 - val_loss_2: 0.3872 - val_acc_ensemble: 0.9090 - val_acc_1: 0.9036 - val_acc_2: 0.9039\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 1.8389e-04 - loss_2: 1.8209e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3819 - val_loss_2: 0.3890 - val_acc_ensemble: 0.9089 - val_acc_1: 0.9032 - val_acc_2: 0.9037\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 1.5881e-04 - loss_2: 1.4750e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3838 - val_loss_2: 0.3910 - val_acc_ensemble: 0.9091 - val_acc_1: 0.9033 - val_acc_2: 0.9045\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 1.3952e-04 - loss_2: 1.2955e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3864 - val_loss_2: 0.3928 - val_acc_ensemble: 0.9092 - val_acc_1: 0.9026 - val_acc_2: 0.9044\n",
      "sensitivity/vb-mnist-fcn3A/B2/S0.25\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,128] [None,384]  703360     input    \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,128] [None,384]  1792       fc1      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,128] [None,384]  0          bn1      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,128] [None,384]  509824     relu1    \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,128] [None,384]  1792       fc2      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,128] [None,384]  0          bn2      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,128] [None,384]  509824     relu2    \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,128] [None,384]  1792       fc3      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,128] [None,384]  0          bn3      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              10022      relu3    \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 1738406\n",
      "Epoch 1/10\n",
      " - 2s - loss_1: 0.2327 - loss_2: 0.2307 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 0.9983 - val_loss_1: 0.4317 - val_loss_2: 0.4253 - val_acc_ensemble: 0.8933 - val_acc_1: 0.8789 - val_acc_2: 0.8838\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 0.0034 - loss_2: 0.0039 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3818 - val_loss_2: 0.4061 - val_acc_ensemble: 0.9038 - val_acc_1: 0.8966 - val_acc_2: 0.8931\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 7.4134e-04 - loss_2: 7.5773e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3872 - val_loss_2: 0.4052 - val_acc_ensemble: 0.9045 - val_acc_1: 0.8975 - val_acc_2: 0.8955\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 4.8912e-04 - loss_2: 4.6272e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3930 - val_loss_2: 0.4067 - val_acc_ensemble: 0.9053 - val_acc_1: 0.8969 - val_acc_2: 0.8972\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 3.3266e-04 - loss_2: 3.3068e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3950 - val_loss_2: 0.4083 - val_acc_ensemble: 0.9054 - val_acc_1: 0.8971 - val_acc_2: 0.8980\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 2.5386e-04 - loss_2: 2.6835e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3976 - val_loss_2: 0.4105 - val_acc_ensemble: 0.9051 - val_acc_1: 0.8974 - val_acc_2: 0.8980\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 2.1710e-04 - loss_2: 2.2172e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3996 - val_loss_2: 0.4124 - val_acc_ensemble: 0.9052 - val_acc_1: 0.8974 - val_acc_2: 0.8985\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 1.7949e-04 - loss_2: 1.8046e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.4014 - val_loss_2: 0.4146 - val_acc_ensemble: 0.9050 - val_acc_1: 0.8983 - val_acc_2: 0.8990\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 1.5112e-04 - loss_2: 1.4241e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.4041 - val_loss_2: 0.4164 - val_acc_ensemble: 0.9054 - val_acc_1: 0.8982 - val_acc_2: 0.8993\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 1.3023e-04 - loss_2: 1.2541e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.4067 - val_loss_2: 0.4188 - val_acc_ensemble: 0.9052 - val_acc_1: 0.8980 - val_acc_2: 0.8994\n",
      "sensitivity/vb-mnist-fcn3A/B2/S0.25\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,128] [None,384]  703360     input    \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,128] [None,384]  1792       fc1      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,128] [None,384]  0          bn1      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,128] [None,384]  509824     relu1    \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,128] [None,384]  1792       fc2      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,128] [None,384]  0          bn2      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,128] [None,384]  509824     relu2    \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,128] [None,384]  1792       fc3      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,128] [None,384]  0          bn3      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              10022      relu3    \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 1738406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 2s - loss_1: 0.2314 - loss_2: 0.2379 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.4085 - val_loss_2: 0.3941 - val_acc_ensemble: 0.9001 - val_acc_1: 0.8859 - val_acc_2: 0.8880\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 0.0028 - loss_2: 0.0028 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3845 - val_loss_2: 0.3650 - val_acc_ensemble: 0.9068 - val_acc_1: 0.8956 - val_acc_2: 0.8995\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 7.2102e-04 - loss_2: 7.2901e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3801 - val_loss_2: 0.3682 - val_acc_ensemble: 0.9063 - val_acc_1: 0.8993 - val_acc_2: 0.9004\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 4.7519e-04 - loss_2: 4.7012e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3813 - val_loss_2: 0.3719 - val_acc_ensemble: 0.9060 - val_acc_1: 0.9006 - val_acc_2: 0.9009\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 3.3813e-04 - loss_2: 3.4131e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3817 - val_loss_2: 0.3749 - val_acc_ensemble: 0.9059 - val_acc_1: 0.9016 - val_acc_2: 0.9018\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 2.6755e-04 - loss_2: 2.6867e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3833 - val_loss_2: 0.3782 - val_acc_ensemble: 0.9063 - val_acc_1: 0.9021 - val_acc_2: 0.9021\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 2.1480e-04 - loss_2: 2.2331e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3841 - val_loss_2: 0.3809 - val_acc_ensemble: 0.9069 - val_acc_1: 0.9027 - val_acc_2: 0.9027\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 1.7750e-04 - loss_2: 1.8008e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3861 - val_loss_2: 0.3838 - val_acc_ensemble: 0.9074 - val_acc_1: 0.9027 - val_acc_2: 0.9034\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 1.5763e-04 - loss_2: 1.5475e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3872 - val_loss_2: 0.3861 - val_acc_ensemble: 0.9078 - val_acc_1: 0.9029 - val_acc_2: 0.9035\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 1.3339e-04 - loss_2: 1.3094e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3889 - val_loss_2: 0.3882 - val_acc_ensemble: 0.9080 - val_acc_1: 0.9028 - val_acc_2: 0.9039\n",
      "sensitivity/vb-mnist-fcn3A/B2/S0.50\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,256] [None,256]  602880     input    \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,256] [None,256]  1536       fc1      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,256] [None,256]  0          bn1      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,256] [None,256]  460544     relu1    \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,256] [None,256]  1536       fc2      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,256] [None,256]  0          bn2      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,256] [None,256]  460544     relu2    \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,256] [None,256]  1536       fc3      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,256] [None,256]  0          bn3      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              8995       relu3    \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 1537571\n",
      "Epoch 1/10\n",
      " - 2s - loss_1: 0.2419 - loss_2: 0.2260 - acc_ensemble: 1.0000 - acc_1: 0.9983 - acc_2: 1.0000 - val_loss_1: 0.3985 - val_loss_2: 0.3952 - val_acc_ensemble: 0.8972 - val_acc_1: 0.8877 - val_acc_2: 0.8881\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 0.0033 - loss_2: 0.0017 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3789 - val_loss_2: 0.3888 - val_acc_ensemble: 0.9022 - val_acc_1: 0.8978 - val_acc_2: 0.8932\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 7.0770e-04 - loss_2: 6.8724e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3766 - val_loss_2: 0.3859 - val_acc_ensemble: 0.9038 - val_acc_1: 0.9007 - val_acc_2: 0.8951\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 4.6335e-04 - loss_2: 4.5127e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3779 - val_loss_2: 0.3884 - val_acc_ensemble: 0.9046 - val_acc_1: 0.9018 - val_acc_2: 0.8959\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 3.3829e-04 - loss_2: 3.4846e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3808 - val_loss_2: 0.3913 - val_acc_ensemble: 0.9044 - val_acc_1: 0.9015 - val_acc_2: 0.8975\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 2.5370e-04 - loss_2: 2.6154e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3820 - val_loss_2: 0.3934 - val_acc_ensemble: 0.9055 - val_acc_1: 0.9015 - val_acc_2: 0.8976\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 2.0766e-04 - loss_2: 2.0083e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3831 - val_loss_2: 0.3952 - val_acc_ensemble: 0.9058 - val_acc_1: 0.9017 - val_acc_2: 0.8984\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 1.7708e-04 - loss_2: 1.7782e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3847 - val_loss_2: 0.3974 - val_acc_ensemble: 0.9058 - val_acc_1: 0.9023 - val_acc_2: 0.8984\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 1.4440e-04 - loss_2: 1.4316e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3866 - val_loss_2: 0.3985 - val_acc_ensemble: 0.9066 - val_acc_1: 0.9028 - val_acc_2: 0.8983\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 1.2485e-04 - loss_2: 1.2650e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3884 - val_loss_2: 0.3999 - val_acc_ensemble: 0.9068 - val_acc_1: 0.9028 - val_acc_2: 0.8988\n",
      "sensitivity/vb-mnist-fcn3A/B2/S0.50\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,256] [None,256]  602880     input    \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,256] [None,256]  1536       fc1      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,256] [None,256]  0          bn1      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,256] [None,256]  460544     relu1    \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,256] [None,256]  1536       fc2      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,256] [None,256]  0          bn2      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,256] [None,256]  460544     relu2    \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,256] [None,256]  1536       fc3      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,256] [None,256]  0          bn3      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              8995       relu3    \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 1537571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 2s - loss_1: 0.2205 - loss_2: 0.2198 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 0.9967 - val_loss_1: 0.4219 - val_loss_2: 0.4837 - val_acc_ensemble: 0.8858 - val_acc_1: 0.8832 - val_acc_2: 0.8662\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 0.0029 - loss_2: 0.0066 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3886 - val_loss_2: 0.4217 - val_acc_ensemble: 0.9012 - val_acc_1: 0.8982 - val_acc_2: 0.8917\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 6.6874e-04 - loss_2: 7.3267e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3897 - val_loss_2: 0.4194 - val_acc_ensemble: 0.9033 - val_acc_1: 0.8994 - val_acc_2: 0.8936\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 4.5221e-04 - loss_2: 4.3233e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3932 - val_loss_2: 0.4237 - val_acc_ensemble: 0.9034 - val_acc_1: 0.8999 - val_acc_2: 0.8951\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 3.0890e-04 - loss_2: 2.9482e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3957 - val_loss_2: 0.4255 - val_acc_ensemble: 0.9044 - val_acc_1: 0.9006 - val_acc_2: 0.8956\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 2.4472e-04 - loss_2: 2.2439e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3979 - val_loss_2: 0.4270 - val_acc_ensemble: 0.9051 - val_acc_1: 0.9004 - val_acc_2: 0.8963\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 1.9940e-04 - loss_2: 1.8525e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.4003 - val_loss_2: 0.4293 - val_acc_ensemble: 0.9057 - val_acc_1: 0.9013 - val_acc_2: 0.8965\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 1.6411e-04 - loss_2: 1.6022e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.4022 - val_loss_2: 0.4311 - val_acc_ensemble: 0.9062 - val_acc_1: 0.9012 - val_acc_2: 0.8968\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 1.3847e-04 - loss_2: 1.3678e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.4046 - val_loss_2: 0.4327 - val_acc_ensemble: 0.9063 - val_acc_1: 0.9014 - val_acc_2: 0.8968\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 1.2337e-04 - loss_2: 1.1343e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.4062 - val_loss_2: 0.4346 - val_acc_ensemble: 0.9063 - val_acc_1: 0.9017 - val_acc_2: 0.8972\n",
      "sensitivity/vb-mnist-fcn3A/B2/S0.50\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,256] [None,256]  602880     input    \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,256] [None,256]  1536       fc1      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,256] [None,256]  0          bn1      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,256] [None,256]  460544     relu1    \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,256] [None,256]  1536       fc2      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,256] [None,256]  0          bn2      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,256] [None,256]  460544     relu2    \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,256] [None,256]  1536       fc3      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,256] [None,256]  0          bn3      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              8995       relu3    \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 1537571\n",
      "Epoch 1/10\n",
      " - 2s - loss_1: 0.2495 - loss_2: 0.2181 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3713 - val_loss_2: 0.4262 - val_acc_ensemble: 0.8943 - val_acc_1: 0.8940 - val_acc_2: 0.8797\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 0.0030 - loss_2: 0.0026 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3604 - val_loss_2: 0.3829 - val_acc_ensemble: 0.9019 - val_acc_1: 0.8984 - val_acc_2: 0.8954\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 8.0543e-04 - loss_2: 7.4588e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3634 - val_loss_2: 0.3852 - val_acc_ensemble: 0.9023 - val_acc_1: 0.8989 - val_acc_2: 0.8963\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 4.9660e-04 - loss_2: 5.0937e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3656 - val_loss_2: 0.3906 - val_acc_ensemble: 0.9022 - val_acc_1: 0.9003 - val_acc_2: 0.8967\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 3.8279e-04 - loss_2: 3.5918e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3694 - val_loss_2: 0.3941 - val_acc_ensemble: 0.9024 - val_acc_1: 0.9012 - val_acc_2: 0.8971\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 3.0319e-04 - loss_2: 2.7641e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3734 - val_loss_2: 0.3975 - val_acc_ensemble: 0.9027 - val_acc_1: 0.9013 - val_acc_2: 0.8971\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 2.3718e-04 - loss_2: 2.1137e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3759 - val_loss_2: 0.3996 - val_acc_ensemble: 0.9032 - val_acc_1: 0.9016 - val_acc_2: 0.8974\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 1.8995e-04 - loss_2: 1.7577e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3782 - val_loss_2: 0.4013 - val_acc_ensemble: 0.9036 - val_acc_1: 0.9020 - val_acc_2: 0.8975\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 1.5855e-04 - loss_2: 1.5185e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3800 - val_loss_2: 0.4037 - val_acc_ensemble: 0.9035 - val_acc_1: 0.9026 - val_acc_2: 0.8976\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 1.3759e-04 - loss_2: 1.3231e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3819 - val_loss_2: 0.4058 - val_acc_ensemble: 0.9035 - val_acc_1: 0.9025 - val_acc_2: 0.8974\n",
      "sensitivity/vb-mnist-fcn3A/B2/S0.50\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,256] [None,256]  602880     input    \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,256] [None,256]  1536       fc1      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,256] [None,256]  0          bn1      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,256] [None,256]  460544     relu1    \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,256] [None,256]  1536       fc2      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,256] [None,256]  0          bn2      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,256] [None,256]  460544     relu2    \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,256] [None,256]  1536       fc3      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,256] [None,256]  0          bn3      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              8995       relu3    \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 1537571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 3s - loss_1: 0.2296 - loss_2: 0.2160 - acc_ensemble: 1.0000 - acc_1: 0.9983 - acc_2: 1.0000 - val_loss_1: 0.4267 - val_loss_2: 0.4219 - val_acc_ensemble: 0.8914 - val_acc_1: 0.8831 - val_acc_2: 0.8806\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 0.0037 - loss_2: 0.0025 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3855 - val_loss_2: 0.3821 - val_acc_ensemble: 0.9036 - val_acc_1: 0.9002 - val_acc_2: 0.8937\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 6.4054e-04 - loss_2: 6.7489e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3860 - val_loss_2: 0.3826 - val_acc_ensemble: 0.9039 - val_acc_1: 0.9023 - val_acc_2: 0.8953\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 4.2713e-04 - loss_2: 4.1936e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3893 - val_loss_2: 0.3853 - val_acc_ensemble: 0.9044 - val_acc_1: 0.9023 - val_acc_2: 0.8960\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 3.0472e-04 - loss_2: 3.2194e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3916 - val_loss_2: 0.3883 - val_acc_ensemble: 0.9050 - val_acc_1: 0.9028 - val_acc_2: 0.8969\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 2.3150e-04 - loss_2: 2.5257e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3937 - val_loss_2: 0.3907 - val_acc_ensemble: 0.9051 - val_acc_1: 0.9039 - val_acc_2: 0.8974\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 1.9200e-04 - loss_2: 2.0314e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3967 - val_loss_2: 0.3936 - val_acc_ensemble: 0.9054 - val_acc_1: 0.9040 - val_acc_2: 0.8973\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 1.5970e-04 - loss_2: 1.5883e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3987 - val_loss_2: 0.3956 - val_acc_ensemble: 0.9056 - val_acc_1: 0.9037 - val_acc_2: 0.8981\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 1.3320e-04 - loss_2: 1.4063e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.4012 - val_loss_2: 0.3978 - val_acc_ensemble: 0.9054 - val_acc_1: 0.9038 - val_acc_2: 0.8983\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 1.1543e-04 - loss_2: 1.2193e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.4037 - val_loss_2: 0.4002 - val_acc_ensemble: 0.9055 - val_acc_1: 0.9032 - val_acc_2: 0.8984\n",
      "sensitivity/vb-mnist-fcn3A/B2/S0.75\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,384] [None,128]  502400     input    \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,384] [None,128]  1280       fc1      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,384] [None,128]  0          bn1      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,384] [None,128]  378496     relu1    \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,384] [None,128]  1280       fc2      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,384] [None,128]  0          bn2      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,384] [None,128]  378496     relu2    \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,384] [None,128]  1280       fc3      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,384] [None,128]  0          bn3      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              7585       relu3    \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 1270817\n",
      "Epoch 1/10\n",
      " - 2s - loss_1: 0.1989 - loss_2: 0.1984 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 0.9983 - val_loss_1: 0.3778 - val_loss_2: 0.3812 - val_acc_ensemble: 0.8983 - val_acc_1: 0.8925 - val_acc_2: 0.8904\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 0.0012 - loss_2: 0.0038 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3830 - val_loss_2: 0.3723 - val_acc_ensemble: 0.8989 - val_acc_1: 0.8949 - val_acc_2: 0.8968\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 5.6488e-04 - loss_2: 6.1803e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3861 - val_loss_2: 0.3745 - val_acc_ensemble: 0.9000 - val_acc_1: 0.8954 - val_acc_2: 0.8985\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 3.8095e-04 - loss_2: 4.1155e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3878 - val_loss_2: 0.3776 - val_acc_ensemble: 0.9005 - val_acc_1: 0.8966 - val_acc_2: 0.8988\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 2.8773e-04 - loss_2: 3.0838e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3890 - val_loss_2: 0.3796 - val_acc_ensemble: 0.9008 - val_acc_1: 0.8970 - val_acc_2: 0.9000\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 2.3580e-04 - loss_2: 2.3801e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3917 - val_loss_2: 0.3822 - val_acc_ensemble: 0.9011 - val_acc_1: 0.8967 - val_acc_2: 0.9009\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 1.7165e-04 - loss_2: 1.9014e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3938 - val_loss_2: 0.3839 - val_acc_ensemble: 0.9016 - val_acc_1: 0.8976 - val_acc_2: 0.9011\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 1.5185e-04 - loss_2: 1.5730e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3978 - val_loss_2: 0.3877 - val_acc_ensemble: 0.9012 - val_acc_1: 0.8976 - val_acc_2: 0.9011\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 1.2176e-04 - loss_2: 1.3155e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3997 - val_loss_2: 0.3901 - val_acc_ensemble: 0.9014 - val_acc_1: 0.8979 - val_acc_2: 0.9011\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 1.1419e-04 - loss_2: 1.1255e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.4018 - val_loss_2: 0.3922 - val_acc_ensemble: 0.9014 - val_acc_1: 0.8981 - val_acc_2: 0.9008\n",
      "sensitivity/vb-mnist-fcn3A/B2/S0.75\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,384] [None,128]  502400     input    \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,384] [None,128]  1280       fc1      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,384] [None,128]  0          bn1      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,384] [None,128]  378496     relu1    \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,384] [None,128]  1280       fc2      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,384] [None,128]  0          bn2      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,384] [None,128]  378496     relu2    \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,384] [None,128]  1280       fc3      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,384] [None,128]  0          bn3      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              7585       relu3    \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 1270817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 2s - loss_1: 0.1876 - loss_2: 0.1863 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 0.9983 - val_loss_1: 0.3869 - val_loss_2: 0.3927 - val_acc_ensemble: 0.8968 - val_acc_1: 0.8917 - val_acc_2: 0.8924\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 0.0016 - loss_2: 0.0015 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3679 - val_loss_2: 0.3725 - val_acc_ensemble: 0.9032 - val_acc_1: 0.8998 - val_acc_2: 0.9014\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 5.7595e-04 - loss_2: 5.3032e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3719 - val_loss_2: 0.3775 - val_acc_ensemble: 0.9037 - val_acc_1: 0.9006 - val_acc_2: 0.9010\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 3.9221e-04 - loss_2: 3.4917e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3751 - val_loss_2: 0.3817 - val_acc_ensemble: 0.9042 - val_acc_1: 0.9016 - val_acc_2: 0.9011\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 2.8794e-04 - loss_2: 2.5604e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3779 - val_loss_2: 0.3852 - val_acc_ensemble: 0.9041 - val_acc_1: 0.9022 - val_acc_2: 0.9014\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 2.1962e-04 - loss_2: 2.0617e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3808 - val_loss_2: 0.3886 - val_acc_ensemble: 0.9040 - val_acc_1: 0.9020 - val_acc_2: 0.9012\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 1.7806e-04 - loss_2: 1.5907e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3834 - val_loss_2: 0.3910 - val_acc_ensemble: 0.9040 - val_acc_1: 0.9026 - val_acc_2: 0.9015\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 1.4582e-04 - loss_2: 1.3346e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3856 - val_loss_2: 0.3935 - val_acc_ensemble: 0.9040 - val_acc_1: 0.9028 - val_acc_2: 0.9016\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 1.2953e-04 - loss_2: 1.1091e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3884 - val_loss_2: 0.3965 - val_acc_ensemble: 0.9043 - val_acc_1: 0.9031 - val_acc_2: 0.9016\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 1.0986e-04 - loss_2: 9.6209e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3908 - val_loss_2: 0.3989 - val_acc_ensemble: 0.9045 - val_acc_1: 0.9033 - val_acc_2: 0.9020\n",
      "sensitivity/vb-mnist-fcn3A/B2/S0.75\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,384] [None,128]  502400     input    \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,384] [None,128]  1280       fc1      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,384] [None,128]  0          bn1      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,384] [None,128]  378496     relu1    \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,384] [None,128]  1280       fc2      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,384] [None,128]  0          bn2      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,384] [None,128]  378496     relu2    \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,384] [None,128]  1280       fc3      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,384] [None,128]  0          bn3      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              7585       relu3    \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 1270817\n",
      "Epoch 1/10\n",
      " - 2s - loss_1: 0.2073 - loss_2: 0.2108 - acc_ensemble: 0.9983 - acc_1: 0.9983 - acc_2: 0.9967 - val_loss_1: 0.4038 - val_loss_2: 0.4047 - val_acc_ensemble: 0.8937 - val_acc_1: 0.8858 - val_acc_2: 0.8926\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 0.0019 - loss_2: 0.0025 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3764 - val_loss_2: 0.3815 - val_acc_ensemble: 0.9036 - val_acc_1: 0.8981 - val_acc_2: 0.9010\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 5.8932e-04 - loss_2: 6.3676e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3792 - val_loss_2: 0.3831 - val_acc_ensemble: 0.9037 - val_acc_1: 0.9005 - val_acc_2: 0.9016\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 3.7733e-04 - loss_2: 4.0810e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3821 - val_loss_2: 0.3850 - val_acc_ensemble: 0.9039 - val_acc_1: 0.9002 - val_acc_2: 0.9016\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 2.7811e-04 - loss_2: 2.9117e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3844 - val_loss_2: 0.3875 - val_acc_ensemble: 0.9034 - val_acc_1: 0.9005 - val_acc_2: 0.9027\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 2.1296e-04 - loss_2: 2.3575e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3863 - val_loss_2: 0.3898 - val_acc_ensemble: 0.9037 - val_acc_1: 0.9008 - val_acc_2: 0.9035\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 1.7970e-04 - loss_2: 1.8903e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3890 - val_loss_2: 0.3928 - val_acc_ensemble: 0.9041 - val_acc_1: 0.9008 - val_acc_2: 0.9034\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 1.4582e-04 - loss_2: 1.5655e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3906 - val_loss_2: 0.3948 - val_acc_ensemble: 0.9044 - val_acc_1: 0.9010 - val_acc_2: 0.9038\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 1.2675e-04 - loss_2: 1.3158e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3932 - val_loss_2: 0.3973 - val_acc_ensemble: 0.9046 - val_acc_1: 0.9012 - val_acc_2: 0.9035\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 1.0928e-04 - loss_2: 1.1259e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3954 - val_loss_2: 0.3995 - val_acc_ensemble: 0.9048 - val_acc_1: 0.9013 - val_acc_2: 0.9034\n",
      "sensitivity/vb-mnist-fcn3A/B2/S0.75\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,384] [None,128]  502400     input    \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,384] [None,128]  1280       fc1      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,384] [None,128]  0          bn1      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,384] [None,128]  378496     relu1    \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,384] [None,128]  1280       fc2      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,384] [None,128]  0          bn2      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,384] [None,128]  378496     relu2    \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,384] [None,128]  1280       fc3      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,384] [None,128]  0          bn3      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              7585       relu3    \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 1270817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 2s - loss_1: 0.2120 - loss_2: 0.1951 - acc_ensemble: 0.9983 - acc_1: 0.9950 - acc_2: 0.9983 - val_loss_1: 0.4562 - val_loss_2: 0.4162 - val_acc_ensemble: 0.8845 - val_acc_1: 0.8740 - val_acc_2: 0.8870\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 0.0019 - loss_2: 0.0018 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3971 - val_loss_2: 0.3967 - val_acc_ensemble: 0.8988 - val_acc_1: 0.8936 - val_acc_2: 0.8977\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 6.6911e-04 - loss_2: 6.3748e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3941 - val_loss_2: 0.3948 - val_acc_ensemble: 0.9013 - val_acc_1: 0.8945 - val_acc_2: 0.8999\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 4.0722e-04 - loss_2: 4.0373e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3944 - val_loss_2: 0.3958 - val_acc_ensemble: 0.9020 - val_acc_1: 0.8956 - val_acc_2: 0.9000\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 3.1012e-04 - loss_2: 2.8157e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3950 - val_loss_2: 0.3975 - val_acc_ensemble: 0.9026 - val_acc_1: 0.8970 - val_acc_2: 0.9029\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 2.3508e-04 - loss_2: 2.2775e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3980 - val_loss_2: 0.4001 - val_acc_ensemble: 0.9027 - val_acc_1: 0.8976 - val_acc_2: 0.9024\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 1.9224e-04 - loss_2: 1.8716e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.4001 - val_loss_2: 0.4027 - val_acc_ensemble: 0.9027 - val_acc_1: 0.8990 - val_acc_2: 0.9021\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 1.5465e-04 - loss_2: 1.5095e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.4007 - val_loss_2: 0.4039 - val_acc_ensemble: 0.9036 - val_acc_1: 0.8992 - val_acc_2: 0.9026\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 1.2995e-04 - loss_2: 1.2971e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.4028 - val_loss_2: 0.4057 - val_acc_ensemble: 0.9034 - val_acc_1: 0.8988 - val_acc_2: 0.9028\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 1.1465e-04 - loss_2: 1.1264e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.4043 - val_loss_2: 0.4079 - val_acc_ensemble: 0.9040 - val_acc_1: 0.8995 - val_acc_2: 0.9033\n",
      "sensitivity/vb-mnist-fcn3A/B2/S1.00\n",
      "i  Layer name                Output shape   Num param  Inbound  \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,512] []  401920     input    \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,512] []  1024       fc1      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,512] []  0          bn1      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,512] []  262656     relu1    \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,512] []  1024       fc2      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,512] []  0          bn2      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,512] []  262656     relu2    \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,512] []  1024       fc3      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,512] []  0          bn3      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]      5130       relu3    \n",
      "                             [None,10]                          \n",
      "----------------------------------------------------------------\n",
      "Total parameters: 935434\n",
      "Epoch 1/10\n",
      " - 1s - loss_1: 0.1354 - loss_2: 0.1431 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3568 - val_loss_2: 0.3568 - val_acc_ensemble: 0.8923 - val_acc_1: 0.8923 - val_acc_2: 0.8923\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 0.0016 - loss_2: 0.0015 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3513 - val_loss_2: 0.3513 - val_acc_ensemble: 0.8968 - val_acc_1: 0.8968 - val_acc_2: 0.8968\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 7.7172e-04 - loss_2: 7.5773e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3566 - val_loss_2: 0.3566 - val_acc_ensemble: 0.8973 - val_acc_1: 0.8973 - val_acc_2: 0.8973\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 4.6072e-04 - loss_2: 4.6455e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3609 - val_loss_2: 0.3609 - val_acc_ensemble: 0.8978 - val_acc_1: 0.8978 - val_acc_2: 0.8978\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 3.4459e-04 - loss_2: 3.2997e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3658 - val_loss_2: 0.3658 - val_acc_ensemble: 0.8970 - val_acc_1: 0.8970 - val_acc_2: 0.8970\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 2.6104e-04 - loss_2: 2.5872e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3696 - val_loss_2: 0.3696 - val_acc_ensemble: 0.8978 - val_acc_1: 0.8978 - val_acc_2: 0.8978\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 2.0061e-04 - loss_2: 1.9519e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3732 - val_loss_2: 0.3732 - val_acc_ensemble: 0.8975 - val_acc_1: 0.8975 - val_acc_2: 0.8975\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 1.6093e-04 - loss_2: 1.6015e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3761 - val_loss_2: 0.3761 - val_acc_ensemble: 0.8978 - val_acc_1: 0.8978 - val_acc_2: 0.8978\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 1.2891e-04 - loss_2: 1.3342e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3794 - val_loss_2: 0.3794 - val_acc_ensemble: 0.8979 - val_acc_1: 0.8979 - val_acc_2: 0.8979\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 1.1605e-04 - loss_2: 1.0849e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3821 - val_loss_2: 0.3821 - val_acc_ensemble: 0.8974 - val_acc_1: 0.8974 - val_acc_2: 0.8974\n",
      "sensitivity/vb-mnist-fcn3A/B2/S1.00\n",
      "i  Layer name                Output shape   Num param  Inbound  \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,512] []  401920     input    \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,512] []  1024       fc1      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,512] []  0          bn1      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,512] []  262656     relu1    \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,512] []  1024       fc2      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,512] []  0          bn2      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,512] []  262656     relu2    \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,512] []  1024       fc3      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,512] []  0          bn3      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]      5130       relu3    \n",
      "                             [None,10]                          \n",
      "----------------------------------------------------------------\n",
      "Total parameters: 935434\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss_1: 0.1292 - loss_2: 0.1537 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3719 - val_loss_2: 0.3719 - val_acc_ensemble: 0.8922 - val_acc_1: 0.8922 - val_acc_2: 0.8922\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 0.0014 - loss_2: 0.0014 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3688 - val_loss_2: 0.3688 - val_acc_ensemble: 0.8956 - val_acc_1: 0.8956 - val_acc_2: 0.8956\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 7.1356e-04 - loss_2: 7.0378e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3700 - val_loss_2: 0.3700 - val_acc_ensemble: 0.8973 - val_acc_1: 0.8973 - val_acc_2: 0.8973\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 4.6154e-04 - loss_2: 4.7641e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3726 - val_loss_2: 0.3726 - val_acc_ensemble: 0.8978 - val_acc_1: 0.8978 - val_acc_2: 0.8978\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 3.4478e-04 - loss_2: 3.3317e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3752 - val_loss_2: 0.3752 - val_acc_ensemble: 0.8986 - val_acc_1: 0.8986 - val_acc_2: 0.8986\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 2.5479e-04 - loss_2: 2.6355e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3788 - val_loss_2: 0.3788 - val_acc_ensemble: 0.8990 - val_acc_1: 0.8990 - val_acc_2: 0.8990\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 2.0339e-04 - loss_2: 2.0284e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3811 - val_loss_2: 0.3811 - val_acc_ensemble: 0.8995 - val_acc_1: 0.8995 - val_acc_2: 0.8995\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 1.6626e-04 - loss_2: 1.5923e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3836 - val_loss_2: 0.3836 - val_acc_ensemble: 0.8998 - val_acc_1: 0.8998 - val_acc_2: 0.8998\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 1.3890e-04 - loss_2: 1.3219e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3860 - val_loss_2: 0.3860 - val_acc_ensemble: 0.8997 - val_acc_1: 0.8997 - val_acc_2: 0.8997\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 1.1359e-04 - loss_2: 1.1231e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3881 - val_loss_2: 0.3881 - val_acc_ensemble: 0.8998 - val_acc_1: 0.8998 - val_acc_2: 0.8998\n",
      "sensitivity/vb-mnist-fcn3A/B2/S1.00\n",
      "i  Layer name                Output shape   Num param  Inbound  \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,512] []  401920     input    \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,512] []  1024       fc1      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,512] []  0          bn1      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,512] []  262656     relu1    \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,512] []  1024       fc2      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,512] []  0          bn2      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,512] []  262656     relu2    \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,512] []  1024       fc3      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,512] []  0          bn3      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]      5130       relu3    \n",
      "                             [None,10]                          \n",
      "----------------------------------------------------------------\n",
      "Total parameters: 935434\n",
      "Epoch 1/10\n",
      " - 1s - loss_1: 0.1492 - loss_2: 0.1312 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3735 - val_loss_2: 0.3735 - val_acc_ensemble: 0.8881 - val_acc_1: 0.8881 - val_acc_2: 0.8881\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 0.0015 - loss_2: 0.0015 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3707 - val_loss_2: 0.3707 - val_acc_ensemble: 0.8926 - val_acc_1: 0.8926 - val_acc_2: 0.8926\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 7.7137e-04 - loss_2: 7.3774e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3725 - val_loss_2: 0.3725 - val_acc_ensemble: 0.8945 - val_acc_1: 0.8945 - val_acc_2: 0.8945\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 4.9170e-04 - loss_2: 4.9308e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3768 - val_loss_2: 0.3768 - val_acc_ensemble: 0.8946 - val_acc_1: 0.8946 - val_acc_2: 0.8946\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 3.3746e-04 - loss_2: 3.4604e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3793 - val_loss_2: 0.3793 - val_acc_ensemble: 0.8951 - val_acc_1: 0.8951 - val_acc_2: 0.8951\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 2.5658e-04 - loss_2: 2.5944e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3832 - val_loss_2: 0.3832 - val_acc_ensemble: 0.8950 - val_acc_1: 0.8950 - val_acc_2: 0.8950\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 2.0666e-04 - loss_2: 2.0037e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3865 - val_loss_2: 0.3865 - val_acc_ensemble: 0.8953 - val_acc_1: 0.8953 - val_acc_2: 0.8953\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 1.6615e-04 - loss_2: 1.6871e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3885 - val_loss_2: 0.3885 - val_acc_ensemble: 0.8956 - val_acc_1: 0.8956 - val_acc_2: 0.8956\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 1.3858e-04 - loss_2: 1.3579e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3913 - val_loss_2: 0.3913 - val_acc_ensemble: 0.8957 - val_acc_1: 0.8957 - val_acc_2: 0.8957\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 1.1879e-04 - loss_2: 1.1282e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3938 - val_loss_2: 0.3938 - val_acc_ensemble: 0.8957 - val_acc_1: 0.8957 - val_acc_2: 0.8957\n",
      "sensitivity/vb-mnist-fcn3A/B2/S1.00\n",
      "i  Layer name                Output shape   Num param  Inbound  \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,512] []  401920     input    \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,512] []  1024       fc1      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,512] []  0          bn1      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,512] []  262656     relu1    \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,512] []  1024       fc2      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,512] []  0          bn2      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,512] []  262656     relu2    \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,512] []  1024       fc3      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,512] []  0          bn3      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]      5130       relu3    \n",
      "                             [None,10]                          \n",
      "----------------------------------------------------------------\n",
      "Total parameters: 935434\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss_1: 0.1306 - loss_2: 0.1394 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3572 - val_loss_2: 0.3572 - val_acc_ensemble: 0.8931 - val_acc_1: 0.8931 - val_acc_2: 0.8931\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 0.0014 - loss_2: 0.0014 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3572 - val_loss_2: 0.3572 - val_acc_ensemble: 0.8950 - val_acc_1: 0.8950 - val_acc_2: 0.8950\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 7.0336e-04 - loss_2: 6.8807e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3574 - val_loss_2: 0.3574 - val_acc_ensemble: 0.8971 - val_acc_1: 0.8971 - val_acc_2: 0.8971\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 4.2767e-04 - loss_2: 4.1880e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3601 - val_loss_2: 0.3601 - val_acc_ensemble: 0.8981 - val_acc_1: 0.8981 - val_acc_2: 0.8981\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 3.0484e-04 - loss_2: 3.2210e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3628 - val_loss_2: 0.3628 - val_acc_ensemble: 0.8982 - val_acc_1: 0.8982 - val_acc_2: 0.8982\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 2.3301e-04 - loss_2: 2.2816e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3658 - val_loss_2: 0.3658 - val_acc_ensemble: 0.8991 - val_acc_1: 0.8991 - val_acc_2: 0.8991\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 1.8645e-04 - loss_2: 1.9215e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3683 - val_loss_2: 0.3683 - val_acc_ensemble: 0.8990 - val_acc_1: 0.8990 - val_acc_2: 0.8990\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 1.4758e-04 - loss_2: 1.4869e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3705 - val_loss_2: 0.3705 - val_acc_ensemble: 0.9001 - val_acc_1: 0.9001 - val_acc_2: 0.9001\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 1.1840e-04 - loss_2: 1.2376e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3736 - val_loss_2: 0.3736 - val_acc_ensemble: 0.8995 - val_acc_1: 0.8995 - val_acc_2: 0.8995\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 9.9121e-05 - loss_2: 9.9934e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - val_loss_1: 0.3753 - val_loss_2: 0.3753 - val_acc_ensemble: 0.9001 - val_acc_1: 0.9001 - val_acc_2: 0.9001\n",
      "sensitivity/vb-mnist-fcn3A/B3/S0.00\n",
      "i  Layer name                Output shape   Num param  Inbound  \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "0  fc1 (Dense)               [] [None,512]  1205760    input    \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [] [None,512]  3072       fc1      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "2  relu1 (Activation)        [] [None,512]  0          bn1      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "3  fc2 (Dense)               [] [None,512]  787968     relu1    \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [] [None,512]  3072       fc2      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "5  relu2 (Activation)        [] [None,512]  0          bn2      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "6  fc3 (Dense)               [] [None,512]  787968     relu2    \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [] [None,512]  3072       fc3      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "8  relu3 (Activation)        [] [None,512]  0          bn3      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]      15390      relu3    \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "----------------------------------------------------------------\n",
      "Total parameters: 2806302\n",
      "Epoch 1/10\n",
      " - 1s - loss_1: 0.2442 - loss_2: 0.2409 - loss_3: 0.2233 - acc_ensemble: 1.0000 - acc_1: 0.9950 - acc_2: 0.9950 - acc_3: 0.9967 - val_loss_1: 0.4730 - val_loss_2: 0.4896 - val_loss_3: 0.4074 - val_acc_ensemble: 0.8937 - val_acc_1: 0.8722 - val_acc_2: 0.8647 - val_acc_3: 0.8850\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 0.0051 - loss_2: 0.0062 - loss_3: 0.0068 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3742 - val_loss_2: 0.3996 - val_loss_3: 0.4163 - val_acc_ensemble: 0.9072 - val_acc_1: 0.8967 - val_acc_2: 0.8927 - val_acc_3: 0.8905\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 8.1472e-04 - loss_2: 8.7468e-04 - loss_3: 8.1803e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3766 - val_loss_2: 0.3976 - val_loss_3: 0.4053 - val_acc_ensemble: 0.9089 - val_acc_1: 0.8983 - val_acc_2: 0.8968 - val_acc_3: 0.8956\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 5.1086e-04 - loss_2: 4.7777e-04 - loss_3: 4.8507e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3779 - val_loss_2: 0.3988 - val_loss_3: 0.4066 - val_acc_ensemble: 0.9097 - val_acc_1: 0.9000 - val_acc_2: 0.8976 - val_acc_3: 0.8965\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 3.6100e-04 - loss_2: 3.5764e-04 - loss_3: 3.2006e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3787 - val_loss_2: 0.4002 - val_loss_3: 0.4056 - val_acc_ensemble: 0.9107 - val_acc_1: 0.9005 - val_acc_2: 0.8990 - val_acc_3: 0.8985\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 2.6774e-04 - loss_2: 2.7789e-04 - loss_3: 2.3832e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3808 - val_loss_2: 0.4024 - val_loss_3: 0.4083 - val_acc_ensemble: 0.9110 - val_acc_1: 0.9009 - val_acc_2: 0.8989 - val_acc_3: 0.8986\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 2.2420e-04 - loss_2: 2.2318e-04 - loss_3: 1.9816e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3827 - val_loss_2: 0.4039 - val_loss_3: 0.4089 - val_acc_ensemble: 0.9111 - val_acc_1: 0.9012 - val_acc_2: 0.8995 - val_acc_3: 0.8992\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 1.9144e-04 - loss_2: 1.7172e-04 - loss_3: 1.6582e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3849 - val_loss_2: 0.4057 - val_loss_3: 0.4098 - val_acc_ensemble: 0.9112 - val_acc_1: 0.9020 - val_acc_2: 0.9002 - val_acc_3: 0.8991\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 1.6237e-04 - loss_2: 1.5404e-04 - loss_3: 1.3473e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3865 - val_loss_2: 0.4076 - val_loss_3: 0.4113 - val_acc_ensemble: 0.9113 - val_acc_1: 0.9022 - val_acc_2: 0.9013 - val_acc_3: 0.8992\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 1.3900e-04 - loss_2: 1.3292e-04 - loss_3: 1.1570e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3890 - val_loss_2: 0.4094 - val_loss_3: 0.4129 - val_acc_ensemble: 0.9112 - val_acc_1: 0.9021 - val_acc_2: 0.9017 - val_acc_3: 0.8995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensitivity/vb-mnist-fcn3A/B3/S0.00\n",
      "i  Layer name                Output shape   Num param  Inbound  \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "0  fc1 (Dense)               [] [None,512]  1205760    input    \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [] [None,512]  3072       fc1      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "2  relu1 (Activation)        [] [None,512]  0          bn1      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "3  fc2 (Dense)               [] [None,512]  787968     relu1    \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [] [None,512]  3072       fc2      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "5  relu2 (Activation)        [] [None,512]  0          bn2      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "6  fc3 (Dense)               [] [None,512]  787968     relu2    \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [] [None,512]  3072       fc3      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "8  relu3 (Activation)        [] [None,512]  0          bn3      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]      15390      relu3    \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "----------------------------------------------------------------\n",
      "Total parameters: 2806302\n",
      "Epoch 1/10\n",
      " - 2s - loss_1: 0.2613 - loss_2: 0.2517 - loss_3: 0.2497 - acc_ensemble: 1.0000 - acc_1: 0.9967 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3759 - val_loss_2: 0.3657 - val_loss_3: 0.4486 - val_acc_ensemble: 0.9074 - val_acc_1: 0.8895 - val_acc_2: 0.8939 - val_acc_3: 0.8772\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 0.0079 - loss_2: 0.0023 - loss_3: 0.0055 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3578 - val_loss_2: 0.3520 - val_loss_3: 0.4174 - val_acc_ensemble: 0.9098 - val_acc_1: 0.8988 - val_acc_2: 0.8996 - val_acc_3: 0.8898\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 9.6346e-04 - loss_2: 7.8315e-04 - loss_3: 8.0312e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3581 - val_loss_2: 0.3553 - val_loss_3: 0.4083 - val_acc_ensemble: 0.9090 - val_acc_1: 0.9020 - val_acc_2: 0.9005 - val_acc_3: 0.8943\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 5.5684e-04 - loss_2: 5.1657e-04 - loss_3: 4.8383e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3609 - val_loss_2: 0.3588 - val_loss_3: 0.4079 - val_acc_ensemble: 0.9088 - val_acc_1: 0.9015 - val_acc_2: 0.9000 - val_acc_3: 0.8966\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 3.9045e-04 - loss_2: 3.8599e-04 - loss_3: 3.4648e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3632 - val_loss_2: 0.3615 - val_loss_3: 0.4081 - val_acc_ensemble: 0.9089 - val_acc_1: 0.9011 - val_acc_2: 0.9002 - val_acc_3: 0.8977\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 3.1988e-04 - loss_2: 2.6848e-04 - loss_3: 2.7685e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3658 - val_loss_2: 0.3641 - val_loss_3: 0.4082 - val_acc_ensemble: 0.9093 - val_acc_1: 0.9020 - val_acc_2: 0.9010 - val_acc_3: 0.8982\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 2.5938e-04 - loss_2: 2.3652e-04 - loss_3: 2.2210e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3690 - val_loss_2: 0.3660 - val_loss_3: 0.4095 - val_acc_ensemble: 0.9092 - val_acc_1: 0.9016 - val_acc_2: 0.9017 - val_acc_3: 0.8988\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 2.0921e-04 - loss_2: 1.9813e-04 - loss_3: 1.8817e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3713 - val_loss_2: 0.3691 - val_loss_3: 0.4102 - val_acc_ensemble: 0.9090 - val_acc_1: 0.9020 - val_acc_2: 0.9018 - val_acc_3: 0.8985\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 1.6588e-04 - loss_2: 1.6601e-04 - loss_3: 1.5827e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3737 - val_loss_2: 0.3712 - val_loss_3: 0.4117 - val_acc_ensemble: 0.9087 - val_acc_1: 0.9023 - val_acc_2: 0.9015 - val_acc_3: 0.8987\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 1.4598e-04 - loss_2: 1.3719e-04 - loss_3: 1.3597e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3757 - val_loss_2: 0.3733 - val_loss_3: 0.4125 - val_acc_ensemble: 0.9088 - val_acc_1: 0.9032 - val_acc_2: 0.9013 - val_acc_3: 0.8993\n",
      "sensitivity/vb-mnist-fcn3A/B3/S0.00\n",
      "i  Layer name                Output shape   Num param  Inbound  \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "0  fc1 (Dense)               [] [None,512]  1205760    input    \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [] [None,512]  3072       fc1      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "2  relu1 (Activation)        [] [None,512]  0          bn1      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "3  fc2 (Dense)               [] [None,512]  787968     relu1    \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [] [None,512]  3072       fc2      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "5  relu2 (Activation)        [] [None,512]  0          bn2      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "6  fc3 (Dense)               [] [None,512]  787968     relu2    \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [] [None,512]  3072       fc3      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "8  relu3 (Activation)        [] [None,512]  0          bn3      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]      15390      relu3    \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "----------------------------------------------------------------\n",
      "Total parameters: 2806302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 1s - loss_1: 0.2188 - loss_2: 0.2353 - loss_3: 0.2543 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 0.9967 - acc_3: 0.9933 - val_loss_1: 0.4152 - val_loss_2: 0.4202 - val_loss_3: 0.4011 - val_acc_ensemble: 0.9040 - val_acc_1: 0.8845 - val_acc_2: 0.8829 - val_acc_3: 0.8858\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 0.0038 - loss_2: 0.0085 - loss_3: 0.0057 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 0.9983 - acc_3: 1.0000 - val_loss_1: 0.4089 - val_loss_2: 0.4184 - val_loss_3: 0.3722 - val_acc_ensemble: 0.9069 - val_acc_1: 0.8901 - val_acc_2: 0.8906 - val_acc_3: 0.8996\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 7.4531e-04 - loss_2: 0.0012 - loss_3: 9.0949e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.4044 - val_loss_2: 0.3967 - val_loss_3: 0.3700 - val_acc_ensemble: 0.9095 - val_acc_1: 0.8918 - val_acc_2: 0.8991 - val_acc_3: 0.9021\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 4.6028e-04 - loss_2: 5.1876e-04 - loss_3: 5.2962e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.4055 - val_loss_2: 0.3963 - val_loss_3: 0.3718 - val_acc_ensemble: 0.9091 - val_acc_1: 0.8931 - val_acc_2: 0.9010 - val_acc_3: 0.9030\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 3.1847e-04 - loss_2: 3.6476e-04 - loss_3: 3.8200e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.4068 - val_loss_2: 0.3976 - val_loss_3: 0.3734 - val_acc_ensemble: 0.9096 - val_acc_1: 0.8938 - val_acc_2: 0.9016 - val_acc_3: 0.9029\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 2.5530e-04 - loss_2: 2.8458e-04 - loss_3: 2.9993e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.4095 - val_loss_2: 0.3997 - val_loss_3: 0.3734 - val_acc_ensemble: 0.9093 - val_acc_1: 0.8937 - val_acc_2: 0.9023 - val_acc_3: 0.9040\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 2.0790e-04 - loss_2: 2.3157e-04 - loss_3: 2.3721e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.4111 - val_loss_2: 0.4002 - val_loss_3: 0.3749 - val_acc_ensemble: 0.9102 - val_acc_1: 0.8950 - val_acc_2: 0.9028 - val_acc_3: 0.9041\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 1.7733e-04 - loss_2: 1.7930e-04 - loss_3: 1.9600e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.4122 - val_loss_2: 0.4023 - val_loss_3: 0.3767 - val_acc_ensemble: 0.9109 - val_acc_1: 0.8957 - val_acc_2: 0.9031 - val_acc_3: 0.9043\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 1.4386e-04 - loss_2: 1.5192e-04 - loss_3: 1.6261e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.4139 - val_loss_2: 0.4036 - val_loss_3: 0.3786 - val_acc_ensemble: 0.9106 - val_acc_1: 0.8961 - val_acc_2: 0.9029 - val_acc_3: 0.9041\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 1.2658e-04 - loss_2: 1.2906e-04 - loss_3: 1.4161e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.4158 - val_loss_2: 0.4053 - val_loss_3: 0.3802 - val_acc_ensemble: 0.9105 - val_acc_1: 0.8961 - val_acc_2: 0.9033 - val_acc_3: 0.9039\n",
      "sensitivity/vb-mnist-fcn3A/B3/S0.00\n",
      "i  Layer name                Output shape   Num param  Inbound  \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "0  fc1 (Dense)               [] [None,512]  1205760    input    \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [] [None,512]  3072       fc1      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "2  relu1 (Activation)        [] [None,512]  0          bn1      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "3  fc2 (Dense)               [] [None,512]  787968     relu1    \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [] [None,512]  3072       fc2      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "5  relu2 (Activation)        [] [None,512]  0          bn2      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "6  fc3 (Dense)               [] [None,512]  787968     relu2    \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [] [None,512]  3072       fc3      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "8  relu3 (Activation)        [] [None,512]  0          bn3      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]      15390      relu3    \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "----------------------------------------------------------------\n",
      "Total parameters: 2806302\n",
      "Epoch 1/10\n",
      " - 1s - loss_1: 0.2550 - loss_2: 0.2451 - loss_3: 0.2298 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 0.9983 - acc_3: 1.0000 - val_loss_1: 0.3905 - val_loss_2: 0.4423 - val_loss_3: 0.3738 - val_acc_ensemble: 0.9046 - val_acc_1: 0.8831 - val_acc_2: 0.8758 - val_acc_3: 0.8925\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 0.0029 - loss_2: 0.0038 - loss_3: 0.0028 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3657 - val_loss_2: 0.3881 - val_loss_3: 0.3637 - val_acc_ensemble: 0.9091 - val_acc_1: 0.8956 - val_acc_2: 0.8965 - val_acc_3: 0.8989\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 8.9533e-04 - loss_2: 8.1478e-04 - loss_3: 8.2278e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3601 - val_loss_2: 0.3790 - val_loss_3: 0.3585 - val_acc_ensemble: 0.9112 - val_acc_1: 0.8999 - val_acc_2: 0.8986 - val_acc_3: 0.9020\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 5.1753e-04 - loss_2: 4.9781e-04 - loss_3: 4.6716e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3627 - val_loss_2: 0.3780 - val_loss_3: 0.3615 - val_acc_ensemble: 0.9118 - val_acc_1: 0.9002 - val_acc_2: 0.9000 - val_acc_3: 0.9019\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 3.6080e-04 - loss_2: 3.5804e-04 - loss_3: 3.3263e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3654 - val_loss_2: 0.3795 - val_loss_3: 0.3620 - val_acc_ensemble: 0.9123 - val_acc_1: 0.9009 - val_acc_2: 0.9007 - val_acc_3: 0.9026\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 2.7511e-04 - loss_2: 2.8742e-04 - loss_3: 2.6827e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3661 - val_loss_2: 0.3812 - val_loss_3: 0.3637 - val_acc_ensemble: 0.9121 - val_acc_1: 0.9016 - val_acc_2: 0.9019 - val_acc_3: 0.9028\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 2.3519e-04 - loss_2: 2.3061e-04 - loss_3: 2.1529e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3683 - val_loss_2: 0.3826 - val_loss_3: 0.3652 - val_acc_ensemble: 0.9121 - val_acc_1: 0.9022 - val_acc_2: 0.9020 - val_acc_3: 0.9037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      " - 1s - loss_1: 1.9025e-04 - loss_2: 1.8673e-04 - loss_3: 1.8235e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3706 - val_loss_2: 0.3837 - val_loss_3: 0.3670 - val_acc_ensemble: 0.9125 - val_acc_1: 0.9027 - val_acc_2: 0.9029 - val_acc_3: 0.9039\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 1.6330e-04 - loss_2: 1.6554e-04 - loss_3: 1.4334e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3720 - val_loss_2: 0.3850 - val_loss_3: 0.3689 - val_acc_ensemble: 0.9125 - val_acc_1: 0.9032 - val_acc_2: 0.9029 - val_acc_3: 0.9041\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 1.3414e-04 - loss_2: 1.3440e-04 - loss_3: 1.2755e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3739 - val_loss_2: 0.3867 - val_loss_3: 0.3707 - val_acc_ensemble: 0.9125 - val_acc_1: 0.9036 - val_acc_2: 0.9030 - val_acc_3: 0.9041\n",
      "sensitivity/vb-mnist-fcn3A/B3/S0.25\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,128] [None,384]  1004800    input    \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,128] [None,384]  2560       fc1      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,128] [None,384]  0          bn1      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,128] [None,384]  756480     relu1    \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,128] [None,384]  2560       fc2      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,128] [None,384]  0          bn2      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,128] [None,384]  756480     relu2    \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,128] [None,384]  2560       fc3      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,128] [None,384]  0          bn3      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              14904      relu3    \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 2540344\n",
      "Epoch 1/10\n",
      " - 4s - loss_1: 0.2516 - loss_2: 0.2395 - loss_3: 0.2466 - acc_ensemble: 1.0000 - acc_1: 0.9983 - acc_2: 0.9883 - acc_3: 0.9983 - val_loss_1: 0.4001 - val_loss_2: 0.4482 - val_loss_3: 0.3793 - val_acc_ensemble: 0.9045 - val_acc_1: 0.8856 - val_acc_2: 0.8789 - val_acc_3: 0.8946\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 0.0044 - loss_2: 0.0072 - loss_3: 0.0063 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3926 - val_loss_2: 0.4179 - val_loss_3: 0.3779 - val_acc_ensemble: 0.9046 - val_acc_1: 0.8929 - val_acc_2: 0.8902 - val_acc_3: 0.8978\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 7.7278e-04 - loss_2: 7.3237e-04 - loss_3: 8.1113e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3883 - val_loss_2: 0.4068 - val_loss_3: 0.3759 - val_acc_ensemble: 0.9063 - val_acc_1: 0.8977 - val_acc_2: 0.8956 - val_acc_3: 0.8994\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 4.8825e-04 - loss_2: 4.2632e-04 - loss_3: 4.6698e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3871 - val_loss_2: 0.4073 - val_loss_3: 0.3761 - val_acc_ensemble: 0.9074 - val_acc_1: 0.8984 - val_acc_2: 0.8970 - val_acc_3: 0.9020\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 3.4888e-04 - loss_2: 3.1301e-04 - loss_3: 3.5903e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3875 - val_loss_2: 0.4080 - val_loss_3: 0.3773 - val_acc_ensemble: 0.9077 - val_acc_1: 0.8993 - val_acc_2: 0.8973 - val_acc_3: 0.9035\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 2.5731e-04 - loss_2: 2.3837e-04 - loss_3: 2.6805e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3902 - val_loss_2: 0.4106 - val_loss_3: 0.3798 - val_acc_ensemble: 0.9077 - val_acc_1: 0.8996 - val_acc_2: 0.8981 - val_acc_3: 0.9043\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 2.1018e-04 - loss_2: 2.0605e-04 - loss_3: 2.0626e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3919 - val_loss_2: 0.4118 - val_loss_3: 0.3811 - val_acc_ensemble: 0.9083 - val_acc_1: 0.9000 - val_acc_2: 0.8983 - val_acc_3: 0.9044\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 1.8024e-04 - loss_2: 1.6479e-04 - loss_3: 1.7768e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3940 - val_loss_2: 0.4137 - val_loss_3: 0.3823 - val_acc_ensemble: 0.9086 - val_acc_1: 0.9003 - val_acc_2: 0.8989 - val_acc_3: 0.9050\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 1.5156e-04 - loss_2: 1.3882e-04 - loss_3: 1.4577e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3963 - val_loss_2: 0.4151 - val_loss_3: 0.3843 - val_acc_ensemble: 0.9084 - val_acc_1: 0.9007 - val_acc_2: 0.8995 - val_acc_3: 0.9051\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 1.3628e-04 - loss_2: 1.2887e-04 - loss_3: 1.3107e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3978 - val_loss_2: 0.4167 - val_loss_3: 0.3857 - val_acc_ensemble: 0.9086 - val_acc_1: 0.9006 - val_acc_2: 0.8994 - val_acc_3: 0.9048\n",
      "sensitivity/vb-mnist-fcn3A/B3/S0.25\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,128] [None,384]  1004800    input    \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,128] [None,384]  2560       fc1      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,128] [None,384]  0          bn1      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,128] [None,384]  756480     relu1    \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,128] [None,384]  2560       fc2      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,128] [None,384]  0          bn2      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,128] [None,384]  756480     relu2    \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,128] [None,384]  2560       fc3      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,128] [None,384]  0          bn3      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              14904      relu3    \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 2540344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 4s - loss_1: 0.2408 - loss_2: 0.2360 - loss_3: 0.2298 - acc_ensemble: 1.0000 - acc_1: 0.9983 - acc_2: 0.9983 - acc_3: 0.9983 - val_loss_1: 0.4116 - val_loss_2: 0.4763 - val_loss_3: 0.4360 - val_acc_ensemble: 0.8974 - val_acc_1: 0.8811 - val_acc_2: 0.8704 - val_acc_3: 0.8840\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 0.0022 - loss_2: 0.0027 - loss_3: 0.0025 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3852 - val_loss_2: 0.3973 - val_loss_3: 0.4033 - val_acc_ensemble: 0.9060 - val_acc_1: 0.8956 - val_acc_2: 0.9002 - val_acc_3: 0.8955\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 6.7695e-04 - loss_2: 6.4056e-04 - loss_3: 7.1047e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3851 - val_loss_2: 0.3966 - val_loss_3: 0.4015 - val_acc_ensemble: 0.9071 - val_acc_1: 0.8975 - val_acc_2: 0.9024 - val_acc_3: 0.8982\n",
      "Epoch 4/10\n",
      " - 2s - loss_1: 4.3985e-04 - loss_2: 4.0377e-04 - loss_3: 4.5637e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3864 - val_loss_2: 0.3955 - val_loss_3: 0.4028 - val_acc_ensemble: 0.9072 - val_acc_1: 0.8972 - val_acc_2: 0.9031 - val_acc_3: 0.8989\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 3.1828e-04 - loss_2: 2.9632e-04 - loss_3: 3.2442e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3883 - val_loss_2: 0.3973 - val_loss_3: 0.4053 - val_acc_ensemble: 0.9077 - val_acc_1: 0.8981 - val_acc_2: 0.9040 - val_acc_3: 0.8992\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 2.5011e-04 - loss_2: 2.4578e-04 - loss_3: 2.6032e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3916 - val_loss_2: 0.3995 - val_loss_3: 0.4073 - val_acc_ensemble: 0.9079 - val_acc_1: 0.8985 - val_acc_2: 0.9047 - val_acc_3: 0.8997\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 1.9095e-04 - loss_2: 1.9197e-04 - loss_3: 2.0733e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3927 - val_loss_2: 0.4016 - val_loss_3: 0.4088 - val_acc_ensemble: 0.9081 - val_acc_1: 0.8992 - val_acc_2: 0.9045 - val_acc_3: 0.8999\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 1.7271e-04 - loss_2: 1.6123e-04 - loss_3: 1.7097e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3951 - val_loss_2: 0.4036 - val_loss_3: 0.4108 - val_acc_ensemble: 0.9081 - val_acc_1: 0.8992 - val_acc_2: 0.9055 - val_acc_3: 0.9002\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 1.4483e-04 - loss_2: 1.3850e-04 - loss_3: 1.4955e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3966 - val_loss_2: 0.4044 - val_loss_3: 0.4134 - val_acc_ensemble: 0.9086 - val_acc_1: 0.8995 - val_acc_2: 0.9053 - val_acc_3: 0.9006\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 1.2610e-04 - loss_2: 1.1995e-04 - loss_3: 1.3195e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3987 - val_loss_2: 0.4058 - val_loss_3: 0.4145 - val_acc_ensemble: 0.9089 - val_acc_1: 0.8999 - val_acc_2: 0.9054 - val_acc_3: 0.9008\n",
      "sensitivity/vb-mnist-fcn3A/B3/S0.25\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,128] [None,384]  1004800    input    \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,128] [None,384]  2560       fc1      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,128] [None,384]  0          bn1      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,128] [None,384]  756480     relu1    \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,128] [None,384]  2560       fc2      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,128] [None,384]  0          bn2      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,128] [None,384]  756480     relu2    \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,128] [None,384]  2560       fc3      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,128] [None,384]  0          bn3      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              14904      relu3    \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 2540344\n",
      "Epoch 1/10\n",
      " - 4s - loss_1: 0.2284 - loss_2: 0.2338 - loss_3: 0.2350 - acc_ensemble: 1.0000 - acc_1: 0.9967 - acc_2: 0.9917 - acc_3: 1.0000 - val_loss_1: 0.4031 - val_loss_2: 0.4550 - val_loss_3: 0.4322 - val_acc_ensemble: 0.9013 - val_acc_1: 0.8882 - val_acc_2: 0.8792 - val_acc_3: 0.8849\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 0.0038 - loss_2: 0.0118 - loss_3: 0.0051 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3845 - val_loss_2: 0.4284 - val_loss_3: 0.4029 - val_acc_ensemble: 0.9059 - val_acc_1: 0.8961 - val_acc_2: 0.8896 - val_acc_3: 0.8982\n",
      "Epoch 3/10\n",
      " - 2s - loss_1: 6.1436e-04 - loss_2: 9.4291e-04 - loss_3: 6.8765e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3811 - val_loss_2: 0.4053 - val_loss_3: 0.3965 - val_acc_ensemble: 0.9088 - val_acc_1: 0.8988 - val_acc_2: 0.8971 - val_acc_3: 0.9016\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 4.0399e-04 - loss_2: 4.1304e-04 - loss_3: 4.2441e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3834 - val_loss_2: 0.4065 - val_loss_3: 0.3996 - val_acc_ensemble: 0.9088 - val_acc_1: 0.8993 - val_acc_2: 0.8971 - val_acc_3: 0.9018\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 2.8824e-04 - loss_2: 3.0782e-04 - loss_3: 3.0238e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3842 - val_loss_2: 0.4080 - val_loss_3: 0.4020 - val_acc_ensemble: 0.9083 - val_acc_1: 0.8999 - val_acc_2: 0.8984 - val_acc_3: 0.9026\n",
      "Epoch 6/10\n",
      " - 2s - loss_1: 2.4429e-04 - loss_2: 2.2637e-04 - loss_3: 2.3927e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3858 - val_loss_2: 0.4101 - val_loss_3: 0.4044 - val_acc_ensemble: 0.9089 - val_acc_1: 0.8999 - val_acc_2: 0.8986 - val_acc_3: 0.9022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      " - 1s - loss_1: 1.8831e-04 - loss_2: 1.8811e-04 - loss_3: 1.8657e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3867 - val_loss_2: 0.4122 - val_loss_3: 0.4063 - val_acc_ensemble: 0.9093 - val_acc_1: 0.9004 - val_acc_2: 0.8990 - val_acc_3: 0.9035\n",
      "Epoch 8/10\n",
      " - 2s - loss_1: 1.6988e-04 - loss_2: 1.6260e-04 - loss_3: 1.6190e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3893 - val_loss_2: 0.4139 - val_loss_3: 0.4085 - val_acc_ensemble: 0.9097 - val_acc_1: 0.9006 - val_acc_2: 0.8993 - val_acc_3: 0.9035\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 1.3765e-04 - loss_2: 1.3992e-04 - loss_3: 1.3530e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3904 - val_loss_2: 0.4154 - val_loss_3: 0.4101 - val_acc_ensemble: 0.9098 - val_acc_1: 0.9007 - val_acc_2: 0.8990 - val_acc_3: 0.9040\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 1.1626e-04 - loss_2: 1.2167e-04 - loss_3: 1.1320e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3923 - val_loss_2: 0.4172 - val_loss_3: 0.4121 - val_acc_ensemble: 0.9099 - val_acc_1: 0.9013 - val_acc_2: 0.8994 - val_acc_3: 0.9042\n",
      "sensitivity/vb-mnist-fcn3A/B3/S0.25\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,128] [None,384]  1004800    input    \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,128] [None,384]  2560       fc1      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,128] [None,384]  0          bn1      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,128] [None,384]  756480     relu1    \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,128] [None,384]  2560       fc2      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,128] [None,384]  0          bn2      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,128] [None,384]  756480     relu2    \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,128] [None,384]  2560       fc3      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,128] [None,384]  0          bn3      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              14904      relu3    \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 2540344\n",
      "Epoch 1/10\n",
      " - 4s - loss_1: 0.2339 - loss_2: 0.2602 - loss_3: 0.2342 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 0.9967 - acc_3: 1.0000 - val_loss_1: 0.4066 - val_loss_2: 0.4577 - val_loss_3: 0.4183 - val_acc_ensemble: 0.8993 - val_acc_1: 0.8837 - val_acc_2: 0.8756 - val_acc_3: 0.8851\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 0.0025 - loss_2: 0.0045 - loss_3: 0.0026 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3799 - val_loss_2: 0.3901 - val_loss_3: 0.3959 - val_acc_ensemble: 0.9056 - val_acc_1: 0.8959 - val_acc_2: 0.8972 - val_acc_3: 0.8916\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 7.8998e-04 - loss_2: 7.5358e-04 - loss_3: 6.4508e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3764 - val_loss_2: 0.3899 - val_loss_3: 0.3959 - val_acc_ensemble: 0.9063 - val_acc_1: 0.8996 - val_acc_2: 0.8990 - val_acc_3: 0.8939\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 4.5482e-04 - loss_2: 4.3811e-04 - loss_3: 3.8599e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3790 - val_loss_2: 0.3927 - val_loss_3: 0.3956 - val_acc_ensemble: 0.9068 - val_acc_1: 0.9000 - val_acc_2: 0.8998 - val_acc_3: 0.8957\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 3.2180e-04 - loss_2: 3.3717e-04 - loss_3: 3.0511e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3826 - val_loss_2: 0.3944 - val_loss_3: 0.3972 - val_acc_ensemble: 0.9076 - val_acc_1: 0.9002 - val_acc_2: 0.8996 - val_acc_3: 0.8966\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 2.3951e-04 - loss_2: 2.6531e-04 - loss_3: 2.3523e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3852 - val_loss_2: 0.3972 - val_loss_3: 0.4011 - val_acc_ensemble: 0.9075 - val_acc_1: 0.9000 - val_acc_2: 0.8993 - val_acc_3: 0.8973\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 1.9764e-04 - loss_2: 2.0521e-04 - loss_3: 1.8330e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3882 - val_loss_2: 0.3999 - val_loss_3: 0.4029 - val_acc_ensemble: 0.9080 - val_acc_1: 0.9003 - val_acc_2: 0.8996 - val_acc_3: 0.8980\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 1.6704e-04 - loss_2: 1.7263e-04 - loss_3: 1.6038e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3903 - val_loss_2: 0.4019 - val_loss_3: 0.4047 - val_acc_ensemble: 0.9084 - val_acc_1: 0.9010 - val_acc_2: 0.8999 - val_acc_3: 0.8981\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 1.3998e-04 - loss_2: 1.5320e-04 - loss_3: 1.3557e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3920 - val_loss_2: 0.4034 - val_loss_3: 0.4070 - val_acc_ensemble: 0.9086 - val_acc_1: 0.9013 - val_acc_2: 0.9004 - val_acc_3: 0.8978\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 1.2331e-04 - loss_2: 1.3021e-04 - loss_3: 1.1677e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3935 - val_loss_2: 0.4051 - val_loss_3: 0.4084 - val_acc_ensemble: 0.9083 - val_acc_1: 0.9014 - val_acc_2: 0.9005 - val_acc_3: 0.8977\n",
      "sensitivity/vb-mnist-fcn3A/B3/S0.50\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,256] [None,256]  803840     input    \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,256] [None,256]  2048       fc1      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,256] [None,256]  0          bn1      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,256] [None,256]  657920     relu1    \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,256] [None,256]  2048       fc2      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,256] [None,256]  0          bn2      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,256] [None,256]  657920     relu2    \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,256] [None,256]  2048       fc3      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,256] [None,256]  0          bn3      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              12850      relu3    \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 2138674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 4s - loss_1: 0.2211 - loss_2: 0.2291 - loss_3: 0.2245 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 0.9983 - acc_3: 0.9983 - val_loss_1: 0.3948 - val_loss_2: 0.4346 - val_loss_3: 0.4270 - val_acc_ensemble: 0.8983 - val_acc_1: 0.8930 - val_acc_2: 0.8858 - val_acc_3: 0.8865\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 0.0016 - loss_2: 0.0070 - loss_3: 0.0019 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3928 - val_loss_2: 0.4339 - val_loss_3: 0.4154 - val_acc_ensemble: 0.9019 - val_acc_1: 0.8975 - val_acc_2: 0.8910 - val_acc_3: 0.8925\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 5.9708e-04 - loss_2: 8.2481e-04 - loss_3: 5.9742e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3916 - val_loss_2: 0.4290 - val_loss_3: 0.4163 - val_acc_ensemble: 0.9038 - val_acc_1: 0.8994 - val_acc_2: 0.8947 - val_acc_3: 0.8939\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 3.7655e-04 - loss_2: 4.3091e-04 - loss_3: 4.0210e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3922 - val_loss_2: 0.4272 - val_loss_3: 0.4154 - val_acc_ensemble: 0.9046 - val_acc_1: 0.9001 - val_acc_2: 0.8959 - val_acc_3: 0.8961\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 2.8388e-04 - loss_2: 3.1267e-04 - loss_3: 2.8729e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3959 - val_loss_2: 0.4286 - val_loss_3: 0.4196 - val_acc_ensemble: 0.9043 - val_acc_1: 0.9008 - val_acc_2: 0.8982 - val_acc_3: 0.8966\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 2.1487e-04 - loss_2: 2.2433e-04 - loss_3: 2.1636e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3985 - val_loss_2: 0.4297 - val_loss_3: 0.4212 - val_acc_ensemble: 0.9050 - val_acc_1: 0.9011 - val_acc_2: 0.8991 - val_acc_3: 0.8976\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 1.7900e-04 - loss_2: 1.8310e-04 - loss_3: 1.8406e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.4004 - val_loss_2: 0.4313 - val_loss_3: 0.4231 - val_acc_ensemble: 0.9054 - val_acc_1: 0.9015 - val_acc_2: 0.8994 - val_acc_3: 0.8986\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 1.5025e-04 - loss_2: 1.5445e-04 - loss_3: 1.4369e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.4029 - val_loss_2: 0.4327 - val_loss_3: 0.4247 - val_acc_ensemble: 0.9062 - val_acc_1: 0.9014 - val_acc_2: 0.8995 - val_acc_3: 0.8988\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 1.2103e-04 - loss_2: 1.3693e-04 - loss_3: 1.2158e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.4048 - val_loss_2: 0.4337 - val_loss_3: 0.4265 - val_acc_ensemble: 0.9066 - val_acc_1: 0.9014 - val_acc_2: 0.9000 - val_acc_3: 0.8988\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 1.1111e-04 - loss_2: 1.1201e-04 - loss_3: 1.0857e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.4070 - val_loss_2: 0.4352 - val_loss_3: 0.4285 - val_acc_ensemble: 0.9068 - val_acc_1: 0.9016 - val_acc_2: 0.8998 - val_acc_3: 0.8988\n",
      "sensitivity/vb-mnist-fcn3A/B3/S0.50\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,256] [None,256]  803840     input    \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,256] [None,256]  2048       fc1      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,256] [None,256]  0          bn1      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,256] [None,256]  657920     relu1    \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,256] [None,256]  2048       fc2      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,256] [None,256]  0          bn2      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,256] [None,256]  657920     relu2    \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,256] [None,256]  2048       fc3      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,256] [None,256]  0          bn3      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              12850      relu3    \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 2138674\n",
      "Epoch 1/10\n",
      " - 4s - loss_1: 0.2169 - loss_2: 0.2076 - loss_3: 0.2120 - acc_ensemble: 1.0000 - acc_1: 0.9983 - acc_2: 0.9917 - acc_3: 1.0000 - val_loss_1: 0.4305 - val_loss_2: 0.4139 - val_loss_3: 0.4319 - val_acc_ensemble: 0.8995 - val_acc_1: 0.8853 - val_acc_2: 0.8905 - val_acc_3: 0.8856\n",
      "Epoch 2/10\n",
      " - 2s - loss_1: 0.0023 - loss_2: 0.0160 - loss_3: 0.0026 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.4127 - val_loss_2: 0.4036 - val_loss_3: 0.4223 - val_acc_ensemble: 0.9021 - val_acc_1: 0.8968 - val_acc_2: 0.8944 - val_acc_3: 0.8919\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 6.0628e-04 - loss_2: 7.5765e-04 - loss_3: 6.3026e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.4130 - val_loss_2: 0.3972 - val_loss_3: 0.4086 - val_acc_ensemble: 0.9045 - val_acc_1: 0.8987 - val_acc_2: 0.9001 - val_acc_3: 0.8970\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 3.6971e-04 - loss_2: 4.2911e-04 - loss_3: 3.6743e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.4167 - val_loss_2: 0.4012 - val_loss_3: 0.4105 - val_acc_ensemble: 0.9049 - val_acc_1: 0.8993 - val_acc_2: 0.9008 - val_acc_3: 0.8982\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 2.8319e-04 - loss_2: 2.9826e-04 - loss_3: 2.7581e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.4192 - val_loss_2: 0.4028 - val_loss_3: 0.4114 - val_acc_ensemble: 0.9051 - val_acc_1: 0.8996 - val_acc_2: 0.9023 - val_acc_3: 0.8984\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 2.0390e-04 - loss_2: 2.2370e-04 - loss_3: 2.1679e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.4211 - val_loss_2: 0.4055 - val_loss_3: 0.4121 - val_acc_ensemble: 0.9055 - val_acc_1: 0.8997 - val_acc_2: 0.9023 - val_acc_3: 0.8985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      " - 1s - loss_1: 1.7856e-04 - loss_2: 1.7076e-04 - loss_3: 1.6289e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.4237 - val_loss_2: 0.4085 - val_loss_3: 0.4142 - val_acc_ensemble: 0.9060 - val_acc_1: 0.9000 - val_acc_2: 0.9024 - val_acc_3: 0.8982\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 1.4403e-04 - loss_2: 1.5222e-04 - loss_3: 1.4201e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.4261 - val_loss_2: 0.4109 - val_loss_3: 0.4157 - val_acc_ensemble: 0.9062 - val_acc_1: 0.9010 - val_acc_2: 0.9027 - val_acc_3: 0.8986\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 1.2684e-04 - loss_2: 1.2671e-04 - loss_3: 1.2257e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.4284 - val_loss_2: 0.4135 - val_loss_3: 0.4177 - val_acc_ensemble: 0.9064 - val_acc_1: 0.9009 - val_acc_2: 0.9029 - val_acc_3: 0.8989\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 1.0729e-04 - loss_2: 1.1291e-04 - loss_3: 1.0125e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.4304 - val_loss_2: 0.4157 - val_loss_3: 0.4197 - val_acc_ensemble: 0.9067 - val_acc_1: 0.9014 - val_acc_2: 0.9028 - val_acc_3: 0.8993\n",
      "sensitivity/vb-mnist-fcn3A/B3/S0.50\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,256] [None,256]  803840     input    \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,256] [None,256]  2048       fc1      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,256] [None,256]  0          bn1      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,256] [None,256]  657920     relu1    \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,256] [None,256]  2048       fc2      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,256] [None,256]  0          bn2      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,256] [None,256]  657920     relu2    \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,256] [None,256]  2048       fc3      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,256] [None,256]  0          bn3      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              12850      relu3    \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 2138674\n",
      "Epoch 1/10\n",
      " - 4s - loss_1: 0.2193 - loss_2: 0.2342 - loss_3: 0.2257 - acc_ensemble: 1.0000 - acc_1: 0.9983 - acc_2: 1.0000 - acc_3: 0.9933 - val_loss_1: 0.4015 - val_loss_2: 0.4429 - val_loss_3: 0.4375 - val_acc_ensemble: 0.8998 - val_acc_1: 0.8933 - val_acc_2: 0.8831 - val_acc_3: 0.8855\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 0.0021 - loss_2: 0.0025 - loss_3: 0.0053 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3737 - val_loss_2: 0.4081 - val_loss_3: 0.3976 - val_acc_ensemble: 0.9059 - val_acc_1: 0.9002 - val_acc_2: 0.8963 - val_acc_3: 0.8969\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 5.5029e-04 - loss_2: 6.2413e-04 - loss_3: 6.6543e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3762 - val_loss_2: 0.4043 - val_loss_3: 0.3948 - val_acc_ensemble: 0.9071 - val_acc_1: 0.8999 - val_acc_2: 0.8990 - val_acc_3: 0.8987\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 3.5897e-04 - loss_2: 4.0052e-04 - loss_3: 4.3450e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3784 - val_loss_2: 0.4050 - val_loss_3: 0.3944 - val_acc_ensemble: 0.9071 - val_acc_1: 0.9009 - val_acc_2: 0.8994 - val_acc_3: 0.8998\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 2.7057e-04 - loss_2: 2.8275e-04 - loss_3: 3.0750e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3819 - val_loss_2: 0.4062 - val_loss_3: 0.3962 - val_acc_ensemble: 0.9069 - val_acc_1: 0.9020 - val_acc_2: 0.8999 - val_acc_3: 0.9006\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 2.1903e-04 - loss_2: 2.1185e-04 - loss_3: 2.4610e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3849 - val_loss_2: 0.4086 - val_loss_3: 0.3983 - val_acc_ensemble: 0.9073 - val_acc_1: 0.9021 - val_acc_2: 0.9008 - val_acc_3: 0.9006\n",
      "Epoch 7/10\n",
      " - 2s - loss_1: 1.7444e-04 - loss_2: 1.8518e-04 - loss_3: 1.9119e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3872 - val_loss_2: 0.4106 - val_loss_3: 0.3998 - val_acc_ensemble: 0.9075 - val_acc_1: 0.9023 - val_acc_2: 0.9008 - val_acc_3: 0.9014\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 1.4055e-04 - loss_2: 1.4775e-04 - loss_3: 1.5424e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3896 - val_loss_2: 0.4120 - val_loss_3: 0.4010 - val_acc_ensemble: 0.9078 - val_acc_1: 0.9029 - val_acc_2: 0.9015 - val_acc_3: 0.9022\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 1.2298e-04 - loss_2: 1.3036e-04 - loss_3: 1.2932e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3917 - val_loss_2: 0.4133 - val_loss_3: 0.4031 - val_acc_ensemble: 0.9078 - val_acc_1: 0.9024 - val_acc_2: 0.9013 - val_acc_3: 0.9022\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 1.0577e-04 - loss_2: 1.1330e-04 - loss_3: 1.1847e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3942 - val_loss_2: 0.4154 - val_loss_3: 0.4055 - val_acc_ensemble: 0.9078 - val_acc_1: 0.9028 - val_acc_2: 0.9006 - val_acc_3: 0.9024\n",
      "sensitivity/vb-mnist-fcn3A/B3/S0.50\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,256] [None,256]  803840     input    \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,256] [None,256]  2048       fc1      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,256] [None,256]  0          bn1      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,256] [None,256]  657920     relu1    \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,256] [None,256]  2048       fc2      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,256] [None,256]  0          bn2      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,256] [None,256]  657920     relu2    \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,256] [None,256]  2048       fc3      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,256] [None,256]  0          bn3      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              12850      relu3    \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 2138674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 4s - loss_1: 0.2182 - loss_2: 0.2413 - loss_3: 0.2188 - acc_ensemble: 1.0000 - acc_1: 0.9967 - acc_2: 0.9983 - acc_3: 1.0000 - val_loss_1: 0.3955 - val_loss_2: 0.4265 - val_loss_3: 0.4267 - val_acc_ensemble: 0.8981 - val_acc_1: 0.8869 - val_acc_2: 0.8792 - val_acc_3: 0.8830\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 0.0024 - loss_2: 0.0028 - loss_3: 0.0016 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3901 - val_loss_2: 0.3968 - val_loss_3: 0.3967 - val_acc_ensemble: 0.9059 - val_acc_1: 0.8954 - val_acc_2: 0.8934 - val_acc_3: 0.8972\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 6.0654e-04 - loss_2: 6.5652e-04 - loss_3: 5.7185e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3921 - val_loss_2: 0.3912 - val_loss_3: 0.3931 - val_acc_ensemble: 0.9064 - val_acc_1: 0.8970 - val_acc_2: 0.8970 - val_acc_3: 0.8998\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 3.8327e-04 - loss_2: 4.1520e-04 - loss_3: 3.7026e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3954 - val_loss_2: 0.3935 - val_loss_3: 0.3954 - val_acc_ensemble: 0.9062 - val_acc_1: 0.8975 - val_acc_2: 0.8980 - val_acc_3: 0.9017\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 2.7998e-04 - loss_2: 2.9976e-04 - loss_3: 2.7088e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3977 - val_loss_2: 0.3963 - val_loss_3: 0.3965 - val_acc_ensemble: 0.9067 - val_acc_1: 0.8988 - val_acc_2: 0.8984 - val_acc_3: 0.9017\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 2.1599e-04 - loss_2: 2.3575e-04 - loss_3: 2.0957e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.4007 - val_loss_2: 0.3979 - val_loss_3: 0.3983 - val_acc_ensemble: 0.9069 - val_acc_1: 0.8991 - val_acc_2: 0.8994 - val_acc_3: 0.9027\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 1.7536e-04 - loss_2: 1.9695e-04 - loss_3: 1.7205e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.4030 - val_loss_2: 0.3993 - val_loss_3: 0.3996 - val_acc_ensemble: 0.9070 - val_acc_1: 0.8990 - val_acc_2: 0.8997 - val_acc_3: 0.9028\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 1.4799e-04 - loss_2: 1.6473e-04 - loss_3: 1.4472e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.4052 - val_loss_2: 0.4013 - val_loss_3: 0.4021 - val_acc_ensemble: 0.9068 - val_acc_1: 0.8990 - val_acc_2: 0.9004 - val_acc_3: 0.9029\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 1.2515e-04 - loss_2: 1.3487e-04 - loss_3: 1.2532e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.4076 - val_loss_2: 0.4032 - val_loss_3: 0.4036 - val_acc_ensemble: 0.9071 - val_acc_1: 0.8994 - val_acc_2: 0.9003 - val_acc_3: 0.9029\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 1.1120e-04 - loss_2: 1.1809e-04 - loss_3: 1.0576e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.4097 - val_loss_2: 0.4053 - val_loss_3: 0.4052 - val_acc_ensemble: 0.9069 - val_acc_1: 0.8996 - val_acc_2: 0.9003 - val_acc_3: 0.9033\n",
      "sensitivity/vb-mnist-fcn3A/B3/S0.75\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,384] [None,128]  602880     input    \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,384] [None,128]  1536       fc1      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,384] [None,128]  0          bn1      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,384] [None,128]  493824     relu1    \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,384] [None,128]  1536       fc2      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,384] [None,128]  0          bn2      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,384] [None,128]  493824     relu2    \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,384] [None,128]  1536       fc3      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,384] [None,128]  0          bn3      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              10030      relu3    \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 1605166\n",
      "Epoch 1/10\n",
      " - 4s - loss_1: 0.1713 - loss_2: 0.1825 - loss_3: 0.1799 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.4135 - val_loss_2: 0.4090 - val_loss_3: 0.4484 - val_acc_ensemble: 0.8925 - val_acc_1: 0.8873 - val_acc_2: 0.8909 - val_acc_3: 0.8803\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 0.0012 - loss_2: 0.0010 - loss_3: 0.0010 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3931 - val_loss_2: 0.3908 - val_loss_3: 0.4198 - val_acc_ensemble: 0.9001 - val_acc_1: 0.8969 - val_acc_2: 0.9012 - val_acc_3: 0.8928\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 4.6444e-04 - loss_2: 4.7062e-04 - loss_3: 4.5926e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3925 - val_loss_2: 0.3895 - val_loss_3: 0.4189 - val_acc_ensemble: 0.9036 - val_acc_1: 0.8995 - val_acc_2: 0.9028 - val_acc_3: 0.8939\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 3.2772e-04 - loss_2: 3.2545e-04 - loss_3: 3.1940e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3945 - val_loss_2: 0.3904 - val_loss_3: 0.4202 - val_acc_ensemble: 0.9047 - val_acc_1: 0.9012 - val_acc_2: 0.9035 - val_acc_3: 0.8941\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 2.2551e-04 - loss_2: 2.3662e-04 - loss_3: 2.3414e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3978 - val_loss_2: 0.3936 - val_loss_3: 0.4218 - val_acc_ensemble: 0.9040 - val_acc_1: 0.9013 - val_acc_2: 0.9037 - val_acc_3: 0.8959\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 1.7442e-04 - loss_2: 1.7596e-04 - loss_3: 1.8211e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.4009 - val_loss_2: 0.3962 - val_loss_3: 0.4245 - val_acc_ensemble: 0.9043 - val_acc_1: 0.9013 - val_acc_2: 0.9038 - val_acc_3: 0.8968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      " - 1s - loss_1: 1.4277e-04 - loss_2: 1.3853e-04 - loss_3: 1.4637e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.4028 - val_loss_2: 0.3978 - val_loss_3: 0.4254 - val_acc_ensemble: 0.9047 - val_acc_1: 0.9017 - val_acc_2: 0.9039 - val_acc_3: 0.8976\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 1.2241e-04 - loss_2: 1.1850e-04 - loss_3: 1.2032e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.4048 - val_loss_2: 0.3993 - val_loss_3: 0.4268 - val_acc_ensemble: 0.9050 - val_acc_1: 0.9021 - val_acc_2: 0.9036 - val_acc_3: 0.8982\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 9.7971e-05 - loss_2: 1.0580e-04 - loss_3: 1.0381e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.4069 - val_loss_2: 0.4008 - val_loss_3: 0.4285 - val_acc_ensemble: 0.9052 - val_acc_1: 0.9025 - val_acc_2: 0.9043 - val_acc_3: 0.8986\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 9.0368e-05 - loss_2: 8.9269e-05 - loss_3: 8.7404e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.4088 - val_loss_2: 0.4022 - val_loss_3: 0.4299 - val_acc_ensemble: 0.9058 - val_acc_1: 0.9027 - val_acc_2: 0.9046 - val_acc_3: 0.8987\n",
      "sensitivity/vb-mnist-fcn3A/B3/S0.75\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,384] [None,128]  602880     input    \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,384] [None,128]  1536       fc1      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,384] [None,128]  0          bn1      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,384] [None,128]  493824     relu1    \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,384] [None,128]  1536       fc2      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,384] [None,128]  0          bn2      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,384] [None,128]  493824     relu2    \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,384] [None,128]  1536       fc3      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,384] [None,128]  0          bn3      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              10030      relu3    \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 1605166\n",
      "Epoch 1/10\n",
      " - 4s - loss_1: 0.1930 - loss_2: 0.1913 - loss_3: 0.1576 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.4038 - val_loss_2: 0.4093 - val_loss_3: 0.3894 - val_acc_ensemble: 0.9005 - val_acc_1: 0.8929 - val_acc_2: 0.8921 - val_acc_3: 0.8947\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 0.0011 - loss_2: 0.0012 - loss_3: 0.0011 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3889 - val_loss_2: 0.3953 - val_loss_3: 0.3853 - val_acc_ensemble: 0.9034 - val_acc_1: 0.9007 - val_acc_2: 0.8989 - val_acc_3: 0.9000\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 4.7241e-04 - loss_2: 5.0356e-04 - loss_3: 4.1957e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3879 - val_loss_2: 0.3952 - val_loss_3: 0.3863 - val_acc_ensemble: 0.9040 - val_acc_1: 0.9022 - val_acc_2: 0.9001 - val_acc_3: 0.9008\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 3.1055e-04 - loss_2: 3.4166e-04 - loss_3: 2.8118e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3898 - val_loss_2: 0.3972 - val_loss_3: 0.3875 - val_acc_ensemble: 0.9044 - val_acc_1: 0.9019 - val_acc_2: 0.9003 - val_acc_3: 0.9021\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 2.4302e-04 - loss_2: 2.4207e-04 - loss_3: 2.2383e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3914 - val_loss_2: 0.3994 - val_loss_3: 0.3911 - val_acc_ensemble: 0.9047 - val_acc_1: 0.9029 - val_acc_2: 0.9012 - val_acc_3: 0.9031\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 1.8386e-04 - loss_2: 2.0533e-04 - loss_3: 1.6752e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3933 - val_loss_2: 0.4016 - val_loss_3: 0.3940 - val_acc_ensemble: 0.9055 - val_acc_1: 0.9041 - val_acc_2: 0.9014 - val_acc_3: 0.9029\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 1.5317e-04 - loss_2: 1.6179e-04 - loss_3: 1.2820e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3949 - val_loss_2: 0.4037 - val_loss_3: 0.3957 - val_acc_ensemble: 0.9061 - val_acc_1: 0.9044 - val_acc_2: 0.9018 - val_acc_3: 0.9033\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 1.3099e-04 - loss_2: 1.3074e-04 - loss_3: 1.1060e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3972 - val_loss_2: 0.4056 - val_loss_3: 0.3985 - val_acc_ensemble: 0.9061 - val_acc_1: 0.9046 - val_acc_2: 0.9021 - val_acc_3: 0.9038\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 1.0841e-04 - loss_2: 1.0913e-04 - loss_3: 8.9598e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3989 - val_loss_2: 0.4071 - val_loss_3: 0.4005 - val_acc_ensemble: 0.9062 - val_acc_1: 0.9046 - val_acc_2: 0.9024 - val_acc_3: 0.9037\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 9.2511e-05 - loss_2: 9.8549e-05 - loss_3: 7.7458e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.4011 - val_loss_2: 0.4094 - val_loss_3: 0.4026 - val_acc_ensemble: 0.9065 - val_acc_1: 0.9047 - val_acc_2: 0.9023 - val_acc_3: 0.9036\n",
      "sensitivity/vb-mnist-fcn3A/B3/S0.75\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,384] [None,128]  602880     input    \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,384] [None,128]  1536       fc1      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,384] [None,128]  0          bn1      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,384] [None,128]  493824     relu1    \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,384] [None,128]  1536       fc2      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,384] [None,128]  0          bn2      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,384] [None,128]  493824     relu2    \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,384] [None,128]  1536       fc3      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,384] [None,128]  0          bn3      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              10030      relu3    \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 1605166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 4s - loss_1: 0.1923 - loss_2: 0.1843 - loss_3: 0.1732 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 0.9967 - acc_3: 1.0000 - val_loss_1: 0.3753 - val_loss_2: 0.3960 - val_loss_3: 0.3986 - val_acc_ensemble: 0.9037 - val_acc_1: 0.8990 - val_acc_2: 0.8964 - val_acc_3: 0.8925\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 0.0018 - loss_2: 0.0017 - loss_3: 0.0012 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3780 - val_loss_2: 0.3831 - val_loss_3: 0.3927 - val_acc_ensemble: 0.9061 - val_acc_1: 0.9022 - val_acc_2: 0.9031 - val_acc_3: 0.8985\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 4.3799e-04 - loss_2: 4.0550e-04 - loss_3: 4.0097e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3789 - val_loss_2: 0.3816 - val_loss_3: 0.3935 - val_acc_ensemble: 0.9061 - val_acc_1: 0.9038 - val_acc_2: 0.9046 - val_acc_3: 0.9001\n",
      "Epoch 4/10\n",
      " - 2s - loss_1: 3.1690e-04 - loss_2: 2.6574e-04 - loss_3: 2.6948e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3832 - val_loss_2: 0.3839 - val_loss_3: 0.3967 - val_acc_ensemble: 0.9062 - val_acc_1: 0.9045 - val_acc_2: 0.9053 - val_acc_3: 0.9003\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 2.2616e-04 - loss_2: 2.0685e-04 - loss_3: 2.0456e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3867 - val_loss_2: 0.3854 - val_loss_3: 0.3985 - val_acc_ensemble: 0.9063 - val_acc_1: 0.9049 - val_acc_2: 0.9061 - val_acc_3: 0.8999\n",
      "Epoch 6/10\n",
      " - 2s - loss_1: 1.7252e-04 - loss_2: 1.6347e-04 - loss_3: 1.5976e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3888 - val_loss_2: 0.3873 - val_loss_3: 0.4003 - val_acc_ensemble: 0.9062 - val_acc_1: 0.9046 - val_acc_2: 0.9061 - val_acc_3: 0.9006\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 1.4642e-04 - loss_2: 1.4254e-04 - loss_3: 1.2209e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3909 - val_loss_2: 0.3889 - val_loss_3: 0.4017 - val_acc_ensemble: 0.9070 - val_acc_1: 0.9052 - val_acc_2: 0.9058 - val_acc_3: 0.9005\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 1.2049e-04 - loss_2: 1.1032e-04 - loss_3: 1.0742e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3931 - val_loss_2: 0.3905 - val_loss_3: 0.4035 - val_acc_ensemble: 0.9073 - val_acc_1: 0.9052 - val_acc_2: 0.9064 - val_acc_3: 0.9010\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 1.0395e-04 - loss_2: 9.0951e-05 - loss_3: 9.6771e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3950 - val_loss_2: 0.3922 - val_loss_3: 0.4051 - val_acc_ensemble: 0.9077 - val_acc_1: 0.9060 - val_acc_2: 0.9068 - val_acc_3: 0.9010\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 9.2806e-05 - loss_2: 8.4021e-05 - loss_3: 8.2802e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3975 - val_loss_2: 0.3942 - val_loss_3: 0.4073 - val_acc_ensemble: 0.9075 - val_acc_1: 0.9057 - val_acc_2: 0.9066 - val_acc_3: 0.9013\n",
      "sensitivity/vb-mnist-fcn3A/B3/S0.75\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,384] [None,128]  602880     input    \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,384] [None,128]  1536       fc1      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,384] [None,128]  0          bn1      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,384] [None,128]  493824     relu1    \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,384] [None,128]  1536       fc2      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,384] [None,128]  0          bn2      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,384] [None,128]  493824     relu2    \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,384] [None,128]  1536       fc3      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,384] [None,128]  0          bn3      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              10030      relu3    \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 1605166\n",
      "Epoch 1/10\n",
      " - 4s - loss_1: 0.1646 - loss_2: 0.1767 - loss_3: 0.1718 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.4140 - val_loss_2: 0.4069 - val_loss_3: 0.3958 - val_acc_ensemble: 0.9003 - val_acc_1: 0.8901 - val_acc_2: 0.8911 - val_acc_3: 0.8951\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 9.8257e-04 - loss_2: 0.0012 - loss_3: 9.9236e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3996 - val_loss_2: 0.3943 - val_loss_3: 0.3840 - val_acc_ensemble: 0.9042 - val_acc_1: 0.8988 - val_acc_2: 0.8968 - val_acc_3: 0.9018\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 4.2797e-04 - loss_2: 4.2741e-04 - loss_3: 4.5027e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.4002 - val_loss_2: 0.3947 - val_loss_3: 0.3857 - val_acc_ensemble: 0.9049 - val_acc_1: 0.9005 - val_acc_2: 0.8992 - val_acc_3: 0.9034\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 2.7617e-04 - loss_2: 2.8834e-04 - loss_3: 3.0047e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.4040 - val_loss_2: 0.3979 - val_loss_3: 0.3887 - val_acc_ensemble: 0.9048 - val_acc_1: 0.9005 - val_acc_2: 0.8996 - val_acc_3: 0.9042\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 2.2269e-04 - loss_2: 2.0406e-04 - loss_3: 2.2044e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.4069 - val_loss_2: 0.3999 - val_loss_3: 0.3924 - val_acc_ensemble: 0.9055 - val_acc_1: 0.9009 - val_acc_2: 0.9004 - val_acc_3: 0.9040\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 1.6545e-04 - loss_2: 1.6597e-04 - loss_3: 1.8132e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.4096 - val_loss_2: 0.4024 - val_loss_3: 0.3953 - val_acc_ensemble: 0.9061 - val_acc_1: 0.9008 - val_acc_2: 0.9015 - val_acc_3: 0.9036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      " - 1s - loss_1: 1.3739e-04 - loss_2: 1.3046e-04 - loss_3: 1.4568e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.4116 - val_loss_2: 0.4049 - val_loss_3: 0.3982 - val_acc_ensemble: 0.9066 - val_acc_1: 0.9009 - val_acc_2: 0.9011 - val_acc_3: 0.9040\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 1.1171e-04 - loss_2: 1.1074e-04 - loss_3: 1.1796e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.4141 - val_loss_2: 0.4075 - val_loss_3: 0.4013 - val_acc_ensemble: 0.9066 - val_acc_1: 0.9013 - val_acc_2: 0.9010 - val_acc_3: 0.9039\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 9.6596e-05 - loss_2: 9.3396e-05 - loss_3: 1.0093e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.4163 - val_loss_2: 0.4095 - val_loss_3: 0.4031 - val_acc_ensemble: 0.9071 - val_acc_1: 0.9014 - val_acc_2: 0.9015 - val_acc_3: 0.9042\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 8.2318e-05 - loss_2: 8.4439e-05 - loss_3: 8.8358e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.4183 - val_loss_2: 0.4119 - val_loss_3: 0.4054 - val_acc_ensemble: 0.9070 - val_acc_1: 0.9016 - val_acc_2: 0.9013 - val_acc_3: 0.9046\n",
      "sensitivity/vb-mnist-fcn3A/B3/S1.00\n",
      "i  Layer name                Output shape   Num param  Inbound  \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,512] []  401920     input    \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,512] []  1024       fc1      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,512] []  0          bn1      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,512] []  262656     relu1    \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,512] []  1024       fc2      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,512] []  0          bn2      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,512] []  262656     relu2    \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,512] []  1024       fc3      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,512] []  0          bn3      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]      5130       relu3    \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "----------------------------------------------------------------\n",
      "Total parameters: 935434\n",
      "Epoch 1/10\n",
      " - 1s - loss_1: 0.1033 - loss_2: 0.0993 - loss_3: 0.1081 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3518 - val_loss_2: 0.3518 - val_loss_3: 0.3518 - val_acc_ensemble: 0.9002 - val_acc_1: 0.9002 - val_acc_2: 0.9002 - val_acc_3: 0.9002\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 0.0011 - loss_2: 0.0010 - loss_3: 0.0011 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3574 - val_loss_2: 0.3574 - val_loss_3: 0.3574 - val_acc_ensemble: 0.9028 - val_acc_1: 0.9028 - val_acc_2: 0.9028 - val_acc_3: 0.9028\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 5.3559e-04 - loss_2: 5.3803e-04 - loss_3: 5.4502e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3612 - val_loss_2: 0.3612 - val_loss_3: 0.3612 - val_acc_ensemble: 0.9033 - val_acc_1: 0.9033 - val_acc_2: 0.9033 - val_acc_3: 0.9033\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 3.3914e-04 - loss_2: 3.4799e-04 - loss_3: 3.5027e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3662 - val_loss_2: 0.3662 - val_loss_3: 0.3662 - val_acc_ensemble: 0.9041 - val_acc_1: 0.9041 - val_acc_2: 0.9041 - val_acc_3: 0.9041\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 2.4145e-04 - loss_2: 2.4192e-04 - loss_3: 2.3983e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3704 - val_loss_2: 0.3704 - val_loss_3: 0.3704 - val_acc_ensemble: 0.9042 - val_acc_1: 0.9042 - val_acc_2: 0.9042 - val_acc_3: 0.9042\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 1.7742e-04 - loss_2: 1.8299e-04 - loss_3: 1.8116e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3738 - val_loss_2: 0.3738 - val_loss_3: 0.3738 - val_acc_ensemble: 0.9042 - val_acc_1: 0.9042 - val_acc_2: 0.9042 - val_acc_3: 0.9042\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 1.4617e-04 - loss_2: 1.4191e-04 - loss_3: 1.4430e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3771 - val_loss_2: 0.3771 - val_loss_3: 0.3771 - val_acc_ensemble: 0.9044 - val_acc_1: 0.9044 - val_acc_2: 0.9044 - val_acc_3: 0.9044\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 1.1753e-04 - loss_2: 1.1548e-04 - loss_3: 1.1444e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3806 - val_loss_2: 0.3806 - val_loss_3: 0.3806 - val_acc_ensemble: 0.9044 - val_acc_1: 0.9044 - val_acc_2: 0.9044 - val_acc_3: 0.9044\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 9.4672e-05 - loss_2: 9.2852e-05 - loss_3: 9.5809e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3834 - val_loss_2: 0.3834 - val_loss_3: 0.3834 - val_acc_ensemble: 0.9044 - val_acc_1: 0.9044 - val_acc_2: 0.9044 - val_acc_3: 0.9044\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 7.7041e-05 - loss_2: 7.8081e-05 - loss_3: 8.0506e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3860 - val_loss_2: 0.3860 - val_loss_3: 0.3860 - val_acc_ensemble: 0.9041 - val_acc_1: 0.9041 - val_acc_2: 0.9041 - val_acc_3: 0.9041\n",
      "sensitivity/vb-mnist-fcn3A/B3/S1.00\n",
      "i  Layer name                Output shape   Num param  Inbound  \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,512] []  401920     input    \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,512] []  1024       fc1      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,512] []  0          bn1      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,512] []  262656     relu1    \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,512] []  1024       fc2      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,512] []  0          bn2      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,512] []  262656     relu2    \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,512] []  1024       fc3      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,512] []  0          bn3      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]      5130       relu3    \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "----------------------------------------------------------------\n",
      "Total parameters: 935434\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss_1: 0.1254 - loss_2: 0.1140 - loss_3: 0.1213 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3608 - val_loss_2: 0.3608 - val_loss_3: 0.3608 - val_acc_ensemble: 0.8950 - val_acc_1: 0.8950 - val_acc_2: 0.8950 - val_acc_3: 0.8950\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 0.0012 - loss_2: 0.0012 - loss_3: 0.0012 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3646 - val_loss_2: 0.3646 - val_loss_3: 0.3646 - val_acc_ensemble: 0.8974 - val_acc_1: 0.8974 - val_acc_2: 0.8974 - val_acc_3: 0.8974\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 6.3345e-04 - loss_2: 6.3936e-04 - loss_3: 6.2897e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3691 - val_loss_2: 0.3691 - val_loss_3: 0.3691 - val_acc_ensemble: 0.8983 - val_acc_1: 0.8983 - val_acc_2: 0.8983 - val_acc_3: 0.8983\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 4.0737e-04 - loss_2: 4.1206e-04 - loss_3: 4.0472e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3738 - val_loss_2: 0.3738 - val_loss_3: 0.3738 - val_acc_ensemble: 0.8991 - val_acc_1: 0.8991 - val_acc_2: 0.8991 - val_acc_3: 0.8991\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 2.8520e-04 - loss_2: 2.8134e-04 - loss_3: 2.8722e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3769 - val_loss_2: 0.3769 - val_loss_3: 0.3769 - val_acc_ensemble: 0.8991 - val_acc_1: 0.8991 - val_acc_2: 0.8991 - val_acc_3: 0.8991\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 2.0709e-04 - loss_2: 2.1252e-04 - loss_3: 2.0686e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3810 - val_loss_2: 0.3810 - val_loss_3: 0.3810 - val_acc_ensemble: 0.8998 - val_acc_1: 0.8998 - val_acc_2: 0.8998 - val_acc_3: 0.8998\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 1.6616e-04 - loss_2: 1.6557e-04 - loss_3: 1.6391e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3851 - val_loss_2: 0.3851 - val_loss_3: 0.3851 - val_acc_ensemble: 0.8995 - val_acc_1: 0.8995 - val_acc_2: 0.8995 - val_acc_3: 0.8995\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 1.3330e-04 - loss_2: 1.3091e-04 - loss_3: 1.2952e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3882 - val_loss_2: 0.3882 - val_loss_3: 0.3882 - val_acc_ensemble: 0.8995 - val_acc_1: 0.8995 - val_acc_2: 0.8995 - val_acc_3: 0.8995\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 1.0651e-04 - loss_2: 1.1361e-04 - loss_3: 1.0857e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3913 - val_loss_2: 0.3913 - val_loss_3: 0.3913 - val_acc_ensemble: 0.8995 - val_acc_1: 0.8995 - val_acc_2: 0.8995 - val_acc_3: 0.8995\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 9.0771e-05 - loss_2: 8.9395e-05 - loss_3: 9.0989e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3940 - val_loss_2: 0.3940 - val_loss_3: 0.3940 - val_acc_ensemble: 0.8994 - val_acc_1: 0.8994 - val_acc_2: 0.8994 - val_acc_3: 0.8994\n",
      "sensitivity/vb-mnist-fcn3A/B3/S1.00\n",
      "i  Layer name                Output shape   Num param  Inbound  \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,512] []  401920     input    \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,512] []  1024       fc1      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,512] []  0          bn1      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,512] []  262656     relu1    \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,512] []  1024       fc2      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,512] []  0          bn2      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,512] []  262656     relu2    \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,512] []  1024       fc3      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,512] []  0          bn3      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]      5130       relu3    \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "----------------------------------------------------------------\n",
      "Total parameters: 935434\n",
      "Epoch 1/10\n",
      " - 1s - loss_1: 0.0889 - loss_2: 0.1100 - loss_3: 0.1104 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3445 - val_loss_2: 0.3445 - val_loss_3: 0.3445 - val_acc_ensemble: 0.8994 - val_acc_1: 0.8994 - val_acc_2: 0.8994 - val_acc_3: 0.8994\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 0.0011 - loss_2: 0.0011 - loss_3: 0.0012 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3496 - val_loss_2: 0.3496 - val_loss_3: 0.3496 - val_acc_ensemble: 0.9000 - val_acc_1: 0.9000 - val_acc_2: 0.9000 - val_acc_3: 0.9000\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 5.9765e-04 - loss_2: 5.9016e-04 - loss_3: 5.8883e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3519 - val_loss_2: 0.3519 - val_loss_3: 0.3519 - val_acc_ensemble: 0.9011 - val_acc_1: 0.9011 - val_acc_2: 0.9011 - val_acc_3: 0.9011\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 3.6152e-04 - loss_2: 3.6883e-04 - loss_3: 3.7431e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3555 - val_loss_2: 0.3555 - val_loss_3: 0.3555 - val_acc_ensemble: 0.9016 - val_acc_1: 0.9016 - val_acc_2: 0.9016 - val_acc_3: 0.9016\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 2.6114e-04 - loss_2: 2.7095e-04 - loss_3: 2.7005e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3589 - val_loss_2: 0.3589 - val_loss_3: 0.3589 - val_acc_ensemble: 0.9018 - val_acc_1: 0.9018 - val_acc_2: 0.9018 - val_acc_3: 0.9018\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 1.9421e-04 - loss_2: 1.9390e-04 - loss_3: 1.9655e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3619 - val_loss_2: 0.3619 - val_loss_3: 0.3619 - val_acc_ensemble: 0.9022 - val_acc_1: 0.9022 - val_acc_2: 0.9022 - val_acc_3: 0.9022\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 1.5297e-04 - loss_2: 1.5097e-04 - loss_3: 1.4464e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3646 - val_loss_2: 0.3646 - val_loss_3: 0.3646 - val_acc_ensemble: 0.9028 - val_acc_1: 0.9028 - val_acc_2: 0.9028 - val_acc_3: 0.9028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      " - 1s - loss_1: 1.2324e-04 - loss_2: 1.2310e-04 - loss_3: 1.2309e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3672 - val_loss_2: 0.3672 - val_loss_3: 0.3672 - val_acc_ensemble: 0.9031 - val_acc_1: 0.9031 - val_acc_2: 0.9031 - val_acc_3: 0.9031\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 1.0146e-04 - loss_2: 1.0064e-04 - loss_3: 1.0414e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3695 - val_loss_2: 0.3695 - val_loss_3: 0.3695 - val_acc_ensemble: 0.9030 - val_acc_1: 0.9030 - val_acc_2: 0.9030 - val_acc_3: 0.9030\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 8.3910e-05 - loss_2: 8.4806e-05 - loss_3: 8.5145e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3717 - val_loss_2: 0.3717 - val_loss_3: 0.3717 - val_acc_ensemble: 0.9033 - val_acc_1: 0.9033 - val_acc_2: 0.9033 - val_acc_3: 0.9033\n",
      "sensitivity/vb-mnist-fcn3A/B3/S1.00\n",
      "i  Layer name                Output shape   Num param  Inbound  \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,512] []  401920     input    \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,512] []  1024       fc1      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,512] []  0          bn1      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,512] []  262656     relu1    \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,512] []  1024       fc2      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,512] []  0          bn2      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,512] []  262656     relu2    \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,512] []  1024       fc3      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,512] []  0          bn3      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]      5130       relu3    \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "----------------------------------------------------------------\n",
      "Total parameters: 935434\n",
      "Epoch 1/10\n",
      " - 1s - loss_1: 0.1037 - loss_2: 0.1064 - loss_3: 0.0871 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3371 - val_loss_2: 0.3371 - val_loss_3: 0.3371 - val_acc_ensemble: 0.8992 - val_acc_1: 0.8992 - val_acc_2: 0.8992 - val_acc_3: 0.8992\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 9.7995e-04 - loss_2: 9.7374e-04 - loss_3: 9.6039e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3422 - val_loss_2: 0.3422 - val_loss_3: 0.3422 - val_acc_ensemble: 0.9004 - val_acc_1: 0.9004 - val_acc_2: 0.9004 - val_acc_3: 0.9004\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 5.1254e-04 - loss_2: 5.2418e-04 - loss_3: 5.0530e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3475 - val_loss_2: 0.3475 - val_loss_3: 0.3475 - val_acc_ensemble: 0.9010 - val_acc_1: 0.9010 - val_acc_2: 0.9010 - val_acc_3: 0.9010\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 3.3304e-04 - loss_2: 3.2902e-04 - loss_3: 3.2511e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3518 - val_loss_2: 0.3518 - val_loss_3: 0.3518 - val_acc_ensemble: 0.9019 - val_acc_1: 0.9019 - val_acc_2: 0.9019 - val_acc_3: 0.9019\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 2.3589e-04 - loss_2: 2.3284e-04 - loss_3: 2.3687e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3553 - val_loss_2: 0.3553 - val_loss_3: 0.3553 - val_acc_ensemble: 0.9022 - val_acc_1: 0.9022 - val_acc_2: 0.9022 - val_acc_3: 0.9022\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 1.7487e-04 - loss_2: 1.7071e-04 - loss_3: 1.7279e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3595 - val_loss_2: 0.3595 - val_loss_3: 0.3595 - val_acc_ensemble: 0.9021 - val_acc_1: 0.9021 - val_acc_2: 0.9021 - val_acc_3: 0.9021\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 1.3308e-04 - loss_2: 1.3618e-04 - loss_3: 1.3525e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3625 - val_loss_2: 0.3625 - val_loss_3: 0.3625 - val_acc_ensemble: 0.9024 - val_acc_1: 0.9024 - val_acc_2: 0.9024 - val_acc_3: 0.9024\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 1.1066e-04 - loss_2: 1.0970e-04 - loss_3: 1.1243e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3661 - val_loss_2: 0.3661 - val_loss_3: 0.3661 - val_acc_ensemble: 0.9018 - val_acc_1: 0.9018 - val_acc_2: 0.9018 - val_acc_3: 0.9018\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 9.0588e-05 - loss_2: 9.0348e-05 - loss_3: 8.9073e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3687 - val_loss_2: 0.3687 - val_loss_3: 0.3687 - val_acc_ensemble: 0.9021 - val_acc_1: 0.9021 - val_acc_2: 0.9021 - val_acc_3: 0.9021\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 7.4489e-05 - loss_2: 7.7444e-05 - loss_3: 7.6468e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - val_loss_1: 0.3709 - val_loss_2: 0.3709 - val_loss_3: 0.3709 - val_acc_ensemble: 0.9023 - val_acc_1: 0.9023 - val_acc_2: 0.9023 - val_acc_3: 0.9023\n",
      "sensitivity/vb-mnist-fcn3A/B4/S0.00\n",
      "i  Layer name                Output shape   Num param  Inbound  \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "0  fc1 (Dense)               [] [None,512]  1607680    input    \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [] [None,512]  4096       fc1      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "2  relu1 (Activation)        [] [None,512]  0          bn1      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "3  fc2 (Dense)               [] [None,512]  1050624    relu1    \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [] [None,512]  4096       fc2      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "5  relu2 (Activation)        [] [None,512]  0          bn2      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "6  fc3 (Dense)               [] [None,512]  1050624    relu2    \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [] [None,512]  4096       fc3      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "8  relu3 (Activation)        [] [None,512]  0          bn3      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]      20520      relu3    \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "----------------------------------------------------------------\n",
      "Total parameters: 3741736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 2s - loss_1: 0.2718 - loss_2: 0.2565 - loss_3: 0.2583 - loss_4: 0.2364 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 0.9983 - acc_3: 0.9983 - acc_4: 0.9933 - val_loss_1: 0.4325 - val_loss_2: 0.4575 - val_loss_3: 0.4134 - val_loss_4: 0.4321 - val_acc_ensemble: 0.9062 - val_acc_1: 0.8823 - val_acc_2: 0.8769 - val_acc_3: 0.8808 - val_acc_4: 0.8819\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 0.0061 - loss_2: 0.0043 - loss_3: 0.0120 - loss_4: 0.0096 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4030 - val_loss_2: 0.4002 - val_loss_3: 0.4142 - val_loss_4: 0.4165 - val_acc_ensemble: 0.9099 - val_acc_1: 0.8937 - val_acc_2: 0.8955 - val_acc_3: 0.8904 - val_acc_4: 0.8940\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 8.3288e-04 - loss_2: 7.7189e-04 - loss_3: 9.3911e-04 - loss_4: 7.1010e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3984 - val_loss_2: 0.3981 - val_loss_3: 0.3887 - val_loss_4: 0.4059 - val_acc_ensemble: 0.9118 - val_acc_1: 0.8964 - val_acc_2: 0.8969 - val_acc_3: 0.8983 - val_acc_4: 0.8983\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 4.8777e-04 - loss_2: 4.7960e-04 - loss_3: 4.8451e-04 - loss_4: 4.0315e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3982 - val_loss_2: 0.3985 - val_loss_3: 0.3891 - val_loss_4: 0.4037 - val_acc_ensemble: 0.9124 - val_acc_1: 0.8977 - val_acc_2: 0.8981 - val_acc_3: 0.8993 - val_acc_4: 0.8994\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 3.4212e-04 - loss_2: 3.4314e-04 - loss_3: 3.6218e-04 - loss_4: 2.9780e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3983 - val_loss_2: 0.3995 - val_loss_3: 0.3874 - val_loss_4: 0.4032 - val_acc_ensemble: 0.9133 - val_acc_1: 0.8986 - val_acc_2: 0.8985 - val_acc_3: 0.9003 - val_acc_4: 0.9011\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 2.7594e-04 - loss_2: 2.6785e-04 - loss_3: 2.8511e-04 - loss_4: 2.4511e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4001 - val_loss_2: 0.4013 - val_loss_3: 0.3886 - val_loss_4: 0.4034 - val_acc_ensemble: 0.9139 - val_acc_1: 0.8997 - val_acc_2: 0.8989 - val_acc_3: 0.9010 - val_acc_4: 0.9022\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 2.2723e-04 - loss_2: 2.2903e-04 - loss_3: 2.2809e-04 - loss_4: 2.0285e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4016 - val_loss_2: 0.4027 - val_loss_3: 0.3896 - val_loss_4: 0.4045 - val_acc_ensemble: 0.9143 - val_acc_1: 0.9007 - val_acc_2: 0.8992 - val_acc_3: 0.9018 - val_acc_4: 0.9026\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 1.8206e-04 - loss_2: 1.8689e-04 - loss_3: 1.8825e-04 - loss_4: 1.6614e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4020 - val_loss_2: 0.4049 - val_loss_3: 0.3899 - val_loss_4: 0.4051 - val_acc_ensemble: 0.9147 - val_acc_1: 0.9012 - val_acc_2: 0.8996 - val_acc_3: 0.9019 - val_acc_4: 0.9033\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 1.5514e-04 - loss_2: 1.5934e-04 - loss_3: 1.5818e-04 - loss_4: 1.3996e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4039 - val_loss_2: 0.4058 - val_loss_3: 0.3914 - val_loss_4: 0.4061 - val_acc_ensemble: 0.9142 - val_acc_1: 0.9008 - val_acc_2: 0.8998 - val_acc_3: 0.9026 - val_acc_4: 0.9035\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 1.3492e-04 - loss_2: 1.3828e-04 - loss_3: 1.3657e-04 - loss_4: 1.2290e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4043 - val_loss_2: 0.4078 - val_loss_3: 0.3930 - val_loss_4: 0.4076 - val_acc_ensemble: 0.9145 - val_acc_1: 0.9013 - val_acc_2: 0.9000 - val_acc_3: 0.9024 - val_acc_4: 0.9036\n",
      "sensitivity/vb-mnist-fcn3A/B4/S0.00\n",
      "i  Layer name                Output shape   Num param  Inbound  \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "0  fc1 (Dense)               [] [None,512]  1607680    input    \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [] [None,512]  4096       fc1      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "2  relu1 (Activation)        [] [None,512]  0          bn1      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "3  fc2 (Dense)               [] [None,512]  1050624    relu1    \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [] [None,512]  4096       fc2      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "5  relu2 (Activation)        [] [None,512]  0          bn2      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "6  fc3 (Dense)               [] [None,512]  1050624    relu2    \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [] [None,512]  4096       fc3      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "8  relu3 (Activation)        [] [None,512]  0          bn3      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]      20520      relu3    \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "----------------------------------------------------------------\n",
      "Total parameters: 3741736\n",
      "Epoch 1/10\n",
      " - 2s - loss_1: 0.2470 - loss_2: 0.2356 - loss_3: 0.2335 - loss_4: 0.2354 - acc_ensemble: 1.0000 - acc_1: 0.9833 - acc_2: 1.0000 - acc_3: 0.9983 - acc_4: 0.9933 - val_loss_1: 0.5246 - val_loss_2: 0.4704 - val_loss_3: 0.4790 - val_loss_4: 0.4413 - val_acc_ensemble: 0.9017 - val_acc_1: 0.8580 - val_acc_2: 0.8704 - val_acc_3: 0.8678 - val_acc_4: 0.8770\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 0.0086 - loss_2: 0.0093 - loss_3: 0.0076 - loss_4: 0.0112 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 0.9967 - acc_3: 1.0000 - acc_4: 0.9983 - val_loss_1: 0.4026 - val_loss_2: 0.4652 - val_loss_3: 0.4004 - val_loss_4: 0.4606 - val_acc_ensemble: 0.9076 - val_acc_1: 0.8964 - val_acc_2: 0.8771 - val_acc_3: 0.8942 - val_acc_4: 0.8829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      " - 1s - loss_1: 8.2185e-04 - loss_2: 0.0018 - loss_3: 7.5865e-04 - loss_4: 8.0151e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3969 - val_loss_2: 0.4307 - val_loss_3: 0.3986 - val_loss_4: 0.4323 - val_acc_ensemble: 0.9100 - val_acc_1: 0.8985 - val_acc_2: 0.8923 - val_acc_3: 0.8972 - val_acc_4: 0.8899\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 4.6079e-04 - loss_2: 4.8510e-04 - loss_3: 4.5282e-04 - loss_4: 4.5975e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3953 - val_loss_2: 0.4271 - val_loss_3: 0.3980 - val_loss_4: 0.4307 - val_acc_ensemble: 0.9105 - val_acc_1: 0.8990 - val_acc_2: 0.8951 - val_acc_3: 0.8988 - val_acc_4: 0.8918\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 3.4033e-04 - loss_2: 3.4902e-04 - loss_3: 3.1850e-04 - loss_4: 3.1567e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3984 - val_loss_2: 0.4260 - val_loss_3: 0.3991 - val_loss_4: 0.4295 - val_acc_ensemble: 0.9108 - val_acc_1: 0.8993 - val_acc_2: 0.8959 - val_acc_3: 0.9000 - val_acc_4: 0.8938\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 2.7393e-04 - loss_2: 2.4278e-04 - loss_3: 2.4357e-04 - loss_4: 2.4798e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4000 - val_loss_2: 0.4263 - val_loss_3: 0.4008 - val_loss_4: 0.4299 - val_acc_ensemble: 0.9109 - val_acc_1: 0.8999 - val_acc_2: 0.8961 - val_acc_3: 0.8998 - val_acc_4: 0.8942\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 2.1768e-04 - loss_2: 2.0419e-04 - loss_3: 1.9129e-04 - loss_4: 2.0278e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4013 - val_loss_2: 0.4267 - val_loss_3: 0.4021 - val_loss_4: 0.4300 - val_acc_ensemble: 0.9108 - val_acc_1: 0.9004 - val_acc_2: 0.8974 - val_acc_3: 0.9001 - val_acc_4: 0.8957\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 1.7429e-04 - loss_2: 1.8028e-04 - loss_3: 1.6497e-04 - loss_4: 1.7022e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4026 - val_loss_2: 0.4273 - val_loss_3: 0.4031 - val_loss_4: 0.4311 - val_acc_ensemble: 0.9114 - val_acc_1: 0.9002 - val_acc_2: 0.8976 - val_acc_3: 0.9011 - val_acc_4: 0.8960\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 1.5679e-04 - loss_2: 1.4475e-04 - loss_3: 1.4221e-04 - loss_4: 1.4665e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4044 - val_loss_2: 0.4281 - val_loss_3: 0.4044 - val_loss_4: 0.4321 - val_acc_ensemble: 0.9113 - val_acc_1: 0.9010 - val_acc_2: 0.8987 - val_acc_3: 0.9015 - val_acc_4: 0.8969\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 1.3005e-04 - loss_2: 1.2594e-04 - loss_3: 1.2219e-04 - loss_4: 1.2296e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4059 - val_loss_2: 0.4296 - val_loss_3: 0.4059 - val_loss_4: 0.4333 - val_acc_ensemble: 0.9113 - val_acc_1: 0.9012 - val_acc_2: 0.8991 - val_acc_3: 0.9012 - val_acc_4: 0.8971\n",
      "sensitivity/vb-mnist-fcn3A/B4/S0.00\n",
      "i  Layer name                Output shape   Num param  Inbound  \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "0  fc1 (Dense)               [] [None,512]  1607680    input    \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [] [None,512]  4096       fc1      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "2  relu1 (Activation)        [] [None,512]  0          bn1      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "3  fc2 (Dense)               [] [None,512]  1050624    relu1    \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [] [None,512]  4096       fc2      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "5  relu2 (Activation)        [] [None,512]  0          bn2      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "6  fc3 (Dense)               [] [None,512]  1050624    relu2    \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [] [None,512]  4096       fc3      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "8  relu3 (Activation)        [] [None,512]  0          bn3      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]      20520      relu3    \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "----------------------------------------------------------------\n",
      "Total parameters: 3741736\n",
      "Epoch 1/10\n",
      " - 2s - loss_1: 0.2473 - loss_2: 0.2422 - loss_3: 0.2463 - loss_4: 0.2253 - acc_ensemble: 1.0000 - acc_1: 0.9983 - acc_2: 0.9983 - acc_3: 1.0000 - acc_4: 0.9967 - val_loss_1: 0.4158 - val_loss_2: 0.4006 - val_loss_3: 0.4495 - val_loss_4: 0.4643 - val_acc_ensemble: 0.9048 - val_acc_1: 0.8812 - val_acc_2: 0.8841 - val_acc_3: 0.8752 - val_acc_4: 0.8730\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 0.0049 - loss_2: 0.0075 - loss_3: 0.0038 - loss_4: 0.0072 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 0.9983 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3725 - val_loss_2: 0.3851 - val_loss_3: 0.3872 - val_loss_4: 0.4378 - val_acc_ensemble: 0.9118 - val_acc_1: 0.8988 - val_acc_2: 0.8979 - val_acc_3: 0.8998 - val_acc_4: 0.8859\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 7.9722e-04 - loss_2: 0.0023 - loss_3: 6.7159e-04 - loss_4: 8.6493e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3718 - val_loss_2: 0.3920 - val_loss_3: 0.3854 - val_loss_4: 0.4206 - val_acc_ensemble: 0.9112 - val_acc_1: 0.9004 - val_acc_2: 0.8982 - val_acc_3: 0.9022 - val_acc_4: 0.8927\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 5.1025e-04 - loss_2: 4.7922e-04 - loss_3: 3.8776e-04 - loss_4: 3.9836e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3715 - val_loss_2: 0.3917 - val_loss_3: 0.3847 - val_loss_4: 0.4194 - val_acc_ensemble: 0.9120 - val_acc_1: 0.9009 - val_acc_2: 0.8999 - val_acc_3: 0.9041 - val_acc_4: 0.8933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      " - 1s - loss_1: 3.4166e-04 - loss_2: 3.4705e-04 - loss_3: 3.0988e-04 - loss_4: 2.9044e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3738 - val_loss_2: 0.3905 - val_loss_3: 0.3852 - val_loss_4: 0.4177 - val_acc_ensemble: 0.9128 - val_acc_1: 0.9013 - val_acc_2: 0.9005 - val_acc_3: 0.9046 - val_acc_4: 0.8955\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 2.6610e-04 - loss_2: 2.6324e-04 - loss_3: 2.4644e-04 - loss_4: 2.2557e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3748 - val_loss_2: 0.3920 - val_loss_3: 0.3862 - val_loss_4: 0.4194 - val_acc_ensemble: 0.9127 - val_acc_1: 0.9025 - val_acc_2: 0.9009 - val_acc_3: 0.9056 - val_acc_4: 0.8955\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 2.2222e-04 - loss_2: 2.1562e-04 - loss_3: 1.9917e-04 - loss_4: 1.8430e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3771 - val_loss_2: 0.3934 - val_loss_3: 0.3880 - val_loss_4: 0.4205 - val_acc_ensemble: 0.9130 - val_acc_1: 0.9027 - val_acc_2: 0.9017 - val_acc_3: 0.9059 - val_acc_4: 0.8962\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 1.8777e-04 - loss_2: 1.6987e-04 - loss_3: 1.6229e-04 - loss_4: 1.5517e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3789 - val_loss_2: 0.3961 - val_loss_3: 0.3895 - val_loss_4: 0.4218 - val_acc_ensemble: 0.9128 - val_acc_1: 0.9030 - val_acc_2: 0.9025 - val_acc_3: 0.9065 - val_acc_4: 0.8970\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 1.5240e-04 - loss_2: 1.4925e-04 - loss_3: 1.3896e-04 - loss_4: 1.3152e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3804 - val_loss_2: 0.3971 - val_loss_3: 0.3910 - val_loss_4: 0.4225 - val_acc_ensemble: 0.9128 - val_acc_1: 0.9034 - val_acc_2: 0.9026 - val_acc_3: 0.9065 - val_acc_4: 0.8972\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 1.3879e-04 - loss_2: 1.2491e-04 - loss_3: 1.2369e-04 - loss_4: 1.1107e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3822 - val_loss_2: 0.3984 - val_loss_3: 0.3924 - val_loss_4: 0.4237 - val_acc_ensemble: 0.9130 - val_acc_1: 0.9035 - val_acc_2: 0.9031 - val_acc_3: 0.9072 - val_acc_4: 0.8981\n",
      "sensitivity/vb-mnist-fcn3A/B4/S0.00\n",
      "i  Layer name                Output shape   Num param  Inbound  \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "0  fc1 (Dense)               [] [None,512]  1607680    input    \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [] [None,512]  4096       fc1      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "2  relu1 (Activation)        [] [None,512]  0          bn1      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "3  fc2 (Dense)               [] [None,512]  1050624    relu1    \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [] [None,512]  4096       fc2      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "5  relu2 (Activation)        [] [None,512]  0          bn2      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "6  fc3 (Dense)               [] [None,512]  1050624    relu2    \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [] [None,512]  4096       fc3      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "8  relu3 (Activation)        [] [None,512]  0          bn3      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]      20520      relu3    \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "----------------------------------------------------------------\n",
      "Total parameters: 3741736\n",
      "Epoch 1/10\n",
      " - 2s - loss_1: 0.2473 - loss_2: 0.2413 - loss_3: 0.2338 - loss_4: 0.2523 - acc_ensemble: 1.0000 - acc_1: 0.9950 - acc_2: 0.9967 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4585 - val_loss_2: 0.4526 - val_loss_3: 0.4788 - val_loss_4: 0.3883 - val_acc_ensemble: 0.9062 - val_acc_1: 0.8717 - val_acc_2: 0.8832 - val_acc_3: 0.8727 - val_acc_4: 0.8912\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 0.0065 - loss_2: 0.0116 - loss_3: 0.0150 - loss_4: 0.0027 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 0.9917 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4123 - val_loss_2: 0.4952 - val_loss_3: 0.4247 - val_loss_4: 0.3754 - val_acc_ensemble: 0.9115 - val_acc_1: 0.8938 - val_acc_2: 0.8830 - val_acc_3: 0.8903 - val_acc_4: 0.9001\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 8.1180e-04 - loss_2: 0.0305 - loss_3: 9.3835e-04 - loss_4: 7.9099e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 0.9933 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4154 - val_loss_2: 0.5502 - val_loss_3: 0.4103 - val_loss_4: 0.3763 - val_acc_ensemble: 0.9096 - val_acc_1: 0.8930 - val_acc_2: 0.8640 - val_acc_3: 0.8972 - val_acc_4: 0.9022\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 4.4862e-04 - loss_2: 0.0183 - loss_3: 4.5976e-04 - loss_4: 4.6353e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 0.9933 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4141 - val_loss_2: 0.5029 - val_loss_3: 0.4108 - val_loss_4: 0.3780 - val_acc_ensemble: 0.9115 - val_acc_1: 0.8955 - val_acc_2: 0.8862 - val_acc_3: 0.8978 - val_acc_4: 0.9024\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 3.4991e-04 - loss_2: 0.0031 - loss_3: 3.2201e-04 - loss_4: 3.4007e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4165 - val_loss_2: 0.4801 - val_loss_3: 0.4120 - val_loss_4: 0.3804 - val_acc_ensemble: 0.9124 - val_acc_1: 0.8963 - val_acc_2: 0.8924 - val_acc_3: 0.8984 - val_acc_4: 0.9027\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 2.7003e-04 - loss_2: 4.3337e-04 - loss_3: 2.5433e-04 - loss_4: 2.7163e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4193 - val_loss_2: 0.4744 - val_loss_3: 0.4134 - val_loss_4: 0.3826 - val_acc_ensemble: 0.9123 - val_acc_1: 0.8971 - val_acc_2: 0.8943 - val_acc_3: 0.8993 - val_acc_4: 0.9030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      " - 1s - loss_1: 2.1536e-04 - loss_2: 2.7168e-04 - loss_3: 2.0577e-04 - loss_4: 2.2616e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4211 - val_loss_2: 0.4736 - val_loss_3: 0.4144 - val_loss_4: 0.3856 - val_acc_ensemble: 0.9122 - val_acc_1: 0.8973 - val_acc_2: 0.8958 - val_acc_3: 0.9000 - val_acc_4: 0.9019\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 1.7979e-04 - loss_2: 2.1431e-04 - loss_3: 1.7568e-04 - loss_4: 1.8193e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4227 - val_loss_2: 0.4731 - val_loss_3: 0.4153 - val_loss_4: 0.3875 - val_acc_ensemble: 0.9127 - val_acc_1: 0.8977 - val_acc_2: 0.8961 - val_acc_3: 0.9019 - val_acc_4: 0.9025\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 1.4659e-04 - loss_2: 1.6356e-04 - loss_3: 1.4636e-04 - loss_4: 1.5852e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4242 - val_loss_2: 0.4732 - val_loss_3: 0.4176 - val_loss_4: 0.3907 - val_acc_ensemble: 0.9128 - val_acc_1: 0.8983 - val_acc_2: 0.8970 - val_acc_3: 0.9022 - val_acc_4: 0.9023\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 1.2831e-04 - loss_2: 1.3732e-04 - loss_3: 1.2734e-04 - loss_4: 1.2885e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4255 - val_loss_2: 0.4737 - val_loss_3: 0.4189 - val_loss_4: 0.3921 - val_acc_ensemble: 0.9130 - val_acc_1: 0.8985 - val_acc_2: 0.8982 - val_acc_3: 0.9025 - val_acc_4: 0.9025\n",
      "sensitivity/vb-mnist-fcn3A/B4/S0.25\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,128] [None,384]  1306240    input    \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,128] [None,384]  3328       fc1      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,128] [None,384]  0          bn1      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,128] [None,384]  1003136    relu1    \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,128] [None,384]  3328       fc2      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,128] [None,384]  0          bn2      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,128] [None,384]  1003136    relu2    \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,128] [None,384]  3328       fc3      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,128] [None,384]  0          bn3      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              19786      relu3    \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 3342282\n",
      "Epoch 1/10\n",
      " - 5s - loss_1: 0.2332 - loss_2: 0.2372 - loss_3: 0.2300 - loss_4: 0.2508 - acc_ensemble: 1.0000 - acc_1: 0.9983 - acc_2: 0.9950 - acc_3: 0.9950 - acc_4: 0.9983 - val_loss_1: 0.4182 - val_loss_2: 0.4628 - val_loss_3: 0.4820 - val_loss_4: 0.4303 - val_acc_ensemble: 0.8997 - val_acc_1: 0.8864 - val_acc_2: 0.8782 - val_acc_3: 0.8768 - val_acc_4: 0.8876\n",
      "Epoch 2/10\n",
      " - 2s - loss_1: 0.0025 - loss_2: 0.0043 - loss_3: 0.0046 - loss_4: 0.0112 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 0.9950 - val_loss_1: 0.4043 - val_loss_2: 0.4063 - val_loss_3: 0.4470 - val_loss_4: 0.4903 - val_acc_ensemble: 0.9052 - val_acc_1: 0.8953 - val_acc_2: 0.8968 - val_acc_3: 0.8922 - val_acc_4: 0.8789\n",
      "Epoch 3/10\n",
      " - 2s - loss_1: 6.2209e-04 - loss_2: 7.6466e-04 - loss_3: 6.9230e-04 - loss_4: 0.0039 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4023 - val_loss_2: 0.4036 - val_loss_3: 0.4355 - val_loss_4: 0.4260 - val_acc_ensemble: 0.9078 - val_acc_1: 0.8977 - val_acc_2: 0.8983 - val_acc_3: 0.8932 - val_acc_4: 0.8938\n",
      "Epoch 4/10\n",
      " - 2s - loss_1: 3.9284e-04 - loss_2: 4.1353e-04 - loss_3: 3.8884e-04 - loss_4: 4.7659e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4030 - val_loss_2: 0.4036 - val_loss_3: 0.4325 - val_loss_4: 0.4205 - val_acc_ensemble: 0.9079 - val_acc_1: 0.8992 - val_acc_2: 0.9001 - val_acc_3: 0.8960 - val_acc_4: 0.8966\n",
      "Epoch 5/10\n",
      " - 2s - loss_1: 3.0550e-04 - loss_2: 2.9962e-04 - loss_3: 2.8593e-04 - loss_4: 2.9822e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4036 - val_loss_2: 0.4046 - val_loss_3: 0.4331 - val_loss_4: 0.4199 - val_acc_ensemble: 0.9084 - val_acc_1: 0.9001 - val_acc_2: 0.9016 - val_acc_3: 0.8975 - val_acc_4: 0.8979\n",
      "Epoch 6/10\n",
      " - 2s - loss_1: 2.2436e-04 - loss_2: 2.2551e-04 - loss_3: 2.2514e-04 - loss_4: 2.4211e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4047 - val_loss_2: 0.4058 - val_loss_3: 0.4334 - val_loss_4: 0.4187 - val_acc_ensemble: 0.9086 - val_acc_1: 0.8999 - val_acc_2: 0.9028 - val_acc_3: 0.8976 - val_acc_4: 0.8990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      " - 2s - loss_1: 1.8763e-04 - loss_2: 1.8208e-04 - loss_3: 1.7601e-04 - loss_4: 1.9110e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4064 - val_loss_2: 0.4075 - val_loss_3: 0.4338 - val_loss_4: 0.4190 - val_acc_ensemble: 0.9089 - val_acc_1: 0.8999 - val_acc_2: 0.9025 - val_acc_3: 0.8983 - val_acc_4: 0.9004\n",
      "Epoch 8/10\n",
      " - 2s - loss_1: 1.6277e-04 - loss_2: 1.6265e-04 - loss_3: 1.4810e-04 - loss_4: 1.6859e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4086 - val_loss_2: 0.4092 - val_loss_3: 0.4348 - val_loss_4: 0.4203 - val_acc_ensemble: 0.9095 - val_acc_1: 0.9003 - val_acc_2: 0.9028 - val_acc_3: 0.8985 - val_acc_4: 0.9004\n",
      "Epoch 9/10\n",
      " - 2s - loss_1: 1.3461e-04 - loss_2: 1.4001e-04 - loss_3: 1.2351e-04 - loss_4: 1.3791e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4098 - val_loss_2: 0.4113 - val_loss_3: 0.4367 - val_loss_4: 0.4210 - val_acc_ensemble: 0.9097 - val_acc_1: 0.9003 - val_acc_2: 0.9032 - val_acc_3: 0.8988 - val_acc_4: 0.9011\n",
      "Epoch 10/10\n",
      " - 2s - loss_1: 1.2130e-04 - loss_2: 1.1833e-04 - loss_3: 1.1801e-04 - loss_4: 1.2375e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4110 - val_loss_2: 0.4125 - val_loss_3: 0.4382 - val_loss_4: 0.4223 - val_acc_ensemble: 0.9092 - val_acc_1: 0.9009 - val_acc_2: 0.9033 - val_acc_3: 0.8986 - val_acc_4: 0.9017\n",
      "sensitivity/vb-mnist-fcn3A/B4/S0.25\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,128] [None,384]  1306240    input    \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,128] [None,384]  3328       fc1      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,128] [None,384]  0          bn1      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,128] [None,384]  1003136    relu1    \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,128] [None,384]  3328       fc2      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,128] [None,384]  0          bn2      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,128] [None,384]  1003136    relu2    \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,128] [None,384]  3328       fc3      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,128] [None,384]  0          bn3      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              19786      relu3    \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 3342282\n",
      "Epoch 1/10\n",
      " - 5s - loss_1: 0.2482 - loss_2: 0.2351 - loss_3: 0.2463 - loss_4: 0.2308 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 0.9983 - acc_3: 0.9883 - acc_4: 0.9967 - val_loss_1: 0.4229 - val_loss_2: 0.4536 - val_loss_3: 0.4563 - val_loss_4: 0.4374 - val_acc_ensemble: 0.9058 - val_acc_1: 0.8840 - val_acc_2: 0.8810 - val_acc_3: 0.8793 - val_acc_4: 0.8881\n",
      "Epoch 2/10\n",
      " - 2s - loss_1: 0.0025 - loss_2: 0.0037 - loss_3: 0.0044 - loss_4: 0.0034 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3935 - val_loss_2: 0.4216 - val_loss_3: 0.4072 - val_loss_4: 0.4281 - val_acc_ensemble: 0.9078 - val_acc_1: 0.8971 - val_acc_2: 0.8946 - val_acc_3: 0.8975 - val_acc_4: 0.8956\n",
      "Epoch 3/10\n",
      " - 2s - loss_1: 6.3924e-04 - loss_2: 7.7737e-04 - loss_3: 6.8069e-04 - loss_4: 6.4496e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3888 - val_loss_2: 0.4141 - val_loss_3: 0.4047 - val_loss_4: 0.4141 - val_acc_ensemble: 0.9096 - val_acc_1: 0.9001 - val_acc_2: 0.8990 - val_acc_3: 0.8990 - val_acc_4: 0.9000\n",
      "Epoch 4/10\n",
      " - 2s - loss_1: 4.2505e-04 - loss_2: 3.6736e-04 - loss_3: 4.1325e-04 - loss_4: 3.8225e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3897 - val_loss_2: 0.4111 - val_loss_3: 0.4051 - val_loss_4: 0.4145 - val_acc_ensemble: 0.9102 - val_acc_1: 0.9014 - val_acc_2: 0.9008 - val_acc_3: 0.9010 - val_acc_4: 0.9016\n",
      "Epoch 5/10\n",
      " - 2s - loss_1: 2.9685e-04 - loss_2: 2.6683e-04 - loss_3: 2.9619e-04 - loss_4: 2.6101e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3916 - val_loss_2: 0.4111 - val_loss_3: 0.4067 - val_loss_4: 0.4155 - val_acc_ensemble: 0.9100 - val_acc_1: 0.9018 - val_acc_2: 0.9022 - val_acc_3: 0.9014 - val_acc_4: 0.9026\n",
      "Epoch 6/10\n",
      " - 2s - loss_1: 2.3806e-04 - loss_2: 2.1929e-04 - loss_3: 2.3768e-04 - loss_4: 2.2831e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3941 - val_loss_2: 0.4118 - val_loss_3: 0.4085 - val_loss_4: 0.4172 - val_acc_ensemble: 0.9102 - val_acc_1: 0.9023 - val_acc_2: 0.9030 - val_acc_3: 0.9015 - val_acc_4: 0.9031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      " - 2s - loss_1: 1.9330e-04 - loss_2: 1.6806e-04 - loss_3: 1.9188e-04 - loss_4: 1.8266e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3964 - val_loss_2: 0.4127 - val_loss_3: 0.4100 - val_loss_4: 0.4184 - val_acc_ensemble: 0.9102 - val_acc_1: 0.9025 - val_acc_2: 0.9037 - val_acc_3: 0.9022 - val_acc_4: 0.9037\n",
      "Epoch 8/10\n",
      " - 2s - loss_1: 1.5604e-04 - loss_2: 1.5450e-04 - loss_3: 1.6025e-04 - loss_4: 1.4890e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3977 - val_loss_2: 0.4136 - val_loss_3: 0.4116 - val_loss_4: 0.4198 - val_acc_ensemble: 0.9101 - val_acc_1: 0.9030 - val_acc_2: 0.9040 - val_acc_3: 0.9025 - val_acc_4: 0.9046\n",
      "Epoch 9/10\n",
      " - 2s - loss_1: 1.3705e-04 - loss_2: 1.2465e-04 - loss_3: 1.4219e-04 - loss_4: 1.2790e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3991 - val_loss_2: 0.4145 - val_loss_3: 0.4131 - val_loss_4: 0.4220 - val_acc_ensemble: 0.9100 - val_acc_1: 0.9030 - val_acc_2: 0.9040 - val_acc_3: 0.9022 - val_acc_4: 0.9050\n",
      "Epoch 10/10\n",
      " - 2s - loss_1: 1.1954e-04 - loss_2: 1.0376e-04 - loss_3: 1.1444e-04 - loss_4: 1.0711e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4009 - val_loss_2: 0.4158 - val_loss_3: 0.4144 - val_loss_4: 0.4233 - val_acc_ensemble: 0.9102 - val_acc_1: 0.9032 - val_acc_2: 0.9043 - val_acc_3: 0.9028 - val_acc_4: 0.9049\n",
      "sensitivity/vb-mnist-fcn3A/B4/S0.25\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,128] [None,384]  1306240    input    \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,128] [None,384]  3328       fc1      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,128] [None,384]  0          bn1      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,128] [None,384]  1003136    relu1    \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,128] [None,384]  3328       fc2      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,128] [None,384]  0          bn2      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,128] [None,384]  1003136    relu2    \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,128] [None,384]  3328       fc3      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,128] [None,384]  0          bn3      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              19786      relu3    \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 3342282\n",
      "Epoch 1/10\n",
      " - 5s - loss_1: 0.2336 - loss_2: 0.2398 - loss_3: 0.2473 - loss_4: 0.2357 - acc_ensemble: 0.9983 - acc_1: 0.9967 - acc_2: 0.9967 - acc_3: 0.9967 - acc_4: 0.9950 - val_loss_1: 0.4465 - val_loss_2: 0.3978 - val_loss_3: 0.4227 - val_loss_4: 0.4325 - val_acc_ensemble: 0.9045 - val_acc_1: 0.8772 - val_acc_2: 0.8953 - val_acc_3: 0.8843 - val_acc_4: 0.8817\n",
      "Epoch 2/10\n",
      " - 2s - loss_1: 0.0100 - loss_2: 0.0303 - loss_3: 0.0087 - loss_4: 0.0055 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 0.9933 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4376 - val_loss_2: 0.5203 - val_loss_3: 0.4056 - val_loss_4: 0.4077 - val_acc_ensemble: 0.9026 - val_acc_1: 0.8839 - val_acc_2: 0.8731 - val_acc_3: 0.8961 - val_acc_4: 0.8928\n",
      "Epoch 3/10\n",
      " - 2s - loss_1: 7.2385e-04 - loss_2: 0.0066 - loss_3: 7.2196e-04 - loss_4: 6.9952e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4239 - val_loss_2: 0.4563 - val_loss_3: 0.3923 - val_loss_4: 0.3977 - val_acc_ensemble: 0.9077 - val_acc_1: 0.8910 - val_acc_2: 0.8912 - val_acc_3: 0.9024 - val_acc_4: 0.8975\n",
      "Epoch 4/10\n",
      " - 2s - loss_1: 4.2846e-04 - loss_2: 7.2097e-04 - loss_3: 4.0016e-04 - loss_4: 4.0211e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4240 - val_loss_2: 0.4504 - val_loss_3: 0.3938 - val_loss_4: 0.3965 - val_acc_ensemble: 0.9080 - val_acc_1: 0.8925 - val_acc_2: 0.8950 - val_acc_3: 0.9026 - val_acc_4: 0.8988\n",
      "Epoch 5/10\n",
      " - 2s - loss_1: 2.9227e-04 - loss_2: 3.5320e-04 - loss_3: 3.0261e-04 - loss_4: 2.7818e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4251 - val_loss_2: 0.4486 - val_loss_3: 0.3942 - val_loss_4: 0.3964 - val_acc_ensemble: 0.9088 - val_acc_1: 0.8935 - val_acc_2: 0.8959 - val_acc_3: 0.9033 - val_acc_4: 0.8998\n",
      "Epoch 6/10\n",
      " - 2s - loss_1: 2.3385e-04 - loss_2: 2.5108e-04 - loss_3: 2.3883e-04 - loss_4: 2.2745e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4256 - val_loss_2: 0.4483 - val_loss_3: 0.3950 - val_loss_4: 0.3971 - val_acc_ensemble: 0.9090 - val_acc_1: 0.8946 - val_acc_2: 0.8980 - val_acc_3: 0.9041 - val_acc_4: 0.9004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      " - 2s - loss_1: 1.8488e-04 - loss_2: 2.0572e-04 - loss_3: 1.9230e-04 - loss_4: 1.7567e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4270 - val_loss_2: 0.4478 - val_loss_3: 0.3967 - val_loss_4: 0.3981 - val_acc_ensemble: 0.9091 - val_acc_1: 0.8950 - val_acc_2: 0.8991 - val_acc_3: 0.9050 - val_acc_4: 0.9013\n",
      "Epoch 8/10\n",
      " - 2s - loss_1: 1.5887e-04 - loss_2: 1.7848e-04 - loss_3: 1.5212e-04 - loss_4: 1.4851e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4294 - val_loss_2: 0.4474 - val_loss_3: 0.3984 - val_loss_4: 0.3989 - val_acc_ensemble: 0.9093 - val_acc_1: 0.8948 - val_acc_2: 0.8995 - val_acc_3: 0.9051 - val_acc_4: 0.9015\n",
      "Epoch 9/10\n",
      " - 2s - loss_1: 1.3034e-04 - loss_2: 1.4692e-04 - loss_3: 1.3810e-04 - loss_4: 1.2435e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4310 - val_loss_2: 0.4480 - val_loss_3: 0.3998 - val_loss_4: 0.4005 - val_acc_ensemble: 0.9097 - val_acc_1: 0.8952 - val_acc_2: 0.9002 - val_acc_3: 0.9048 - val_acc_4: 0.9020\n",
      "Epoch 10/10\n",
      " - 2s - loss_1: 1.0891e-04 - loss_2: 1.2198e-04 - loss_3: 1.1557e-04 - loss_4: 1.1085e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4327 - val_loss_2: 0.4487 - val_loss_3: 0.4014 - val_loss_4: 0.4017 - val_acc_ensemble: 0.9100 - val_acc_1: 0.8951 - val_acc_2: 0.9003 - val_acc_3: 0.9050 - val_acc_4: 0.9027\n",
      "sensitivity/vb-mnist-fcn3A/B4/S0.25\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,128] [None,384]  1306240    input    \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,128] [None,384]  3328       fc1      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,128] [None,384]  0          bn1      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,128] [None,384]  1003136    relu1    \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,128] [None,384]  3328       fc2      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,128] [None,384]  0          bn2      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,128] [None,384]  1003136    relu2    \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,128] [None,384]  3328       fc3      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,128] [None,384]  0          bn3      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              19786      relu3    \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 3342282\n",
      "Epoch 1/10\n",
      " - 5s - loss_1: 0.2362 - loss_2: 0.2327 - loss_3: 0.2405 - loss_4: 0.2242 - acc_ensemble: 1.0000 - acc_1: 0.9967 - acc_2: 1.0000 - acc_3: 0.9983 - acc_4: 0.9900 - val_loss_1: 0.4251 - val_loss_2: 0.4026 - val_loss_3: 0.4337 - val_loss_4: 0.4842 - val_acc_ensemble: 0.9022 - val_acc_1: 0.8836 - val_acc_2: 0.8897 - val_acc_3: 0.8841 - val_acc_4: 0.8714\n",
      "Epoch 2/10\n",
      " - 2s - loss_1: 0.0041 - loss_2: 0.0023 - loss_3: 0.0115 - loss_4: 0.0117 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 0.9983 - acc_4: 1.0000 - val_loss_1: 0.3971 - val_loss_2: 0.4043 - val_loss_3: 0.4915 - val_loss_4: 0.4362 - val_acc_ensemble: 0.9048 - val_acc_1: 0.8989 - val_acc_2: 0.8950 - val_acc_3: 0.8789 - val_acc_4: 0.8882\n",
      "Epoch 3/10\n",
      " - 2s - loss_1: 6.7808e-04 - loss_2: 5.9686e-04 - loss_3: 0.0013 - loss_4: 9.4804e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3958 - val_loss_2: 0.4018 - val_loss_3: 0.4373 - val_loss_4: 0.4262 - val_acc_ensemble: 0.9072 - val_acc_1: 0.9005 - val_acc_2: 0.8985 - val_acc_3: 0.8948 - val_acc_4: 0.8957\n",
      "Epoch 4/10\n",
      " - 2s - loss_1: 4.1046e-04 - loss_2: 3.7907e-04 - loss_3: 4.6923e-04 - loss_4: 3.8582e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3985 - val_loss_2: 0.4040 - val_loss_3: 0.4320 - val_loss_4: 0.4259 - val_acc_ensemble: 0.9086 - val_acc_1: 0.9020 - val_acc_2: 0.8994 - val_acc_3: 0.8964 - val_acc_4: 0.8978\n",
      "Epoch 5/10\n",
      " - 2s - loss_1: 2.7759e-04 - loss_2: 2.9224e-04 - loss_3: 3.2083e-04 - loss_4: 2.6828e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3999 - val_loss_2: 0.4060 - val_loss_3: 0.4308 - val_loss_4: 0.4269 - val_acc_ensemble: 0.9087 - val_acc_1: 0.9025 - val_acc_2: 0.8999 - val_acc_3: 0.8973 - val_acc_4: 0.8985\n",
      "Epoch 6/10\n",
      " - 2s - loss_1: 2.2136e-04 - loss_2: 2.2316e-04 - loss_3: 2.3757e-04 - loss_4: 2.0102e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4016 - val_loss_2: 0.4081 - val_loss_3: 0.4312 - val_loss_4: 0.4266 - val_acc_ensemble: 0.9095 - val_acc_1: 0.9028 - val_acc_2: 0.9005 - val_acc_3: 0.8981 - val_acc_4: 0.8996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      " - 2s - loss_1: 1.7628e-04 - loss_2: 1.7762e-04 - loss_3: 1.9612e-04 - loss_4: 1.6650e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4033 - val_loss_2: 0.4106 - val_loss_3: 0.4314 - val_loss_4: 0.4276 - val_acc_ensemble: 0.9098 - val_acc_1: 0.9030 - val_acc_2: 0.9009 - val_acc_3: 0.8980 - val_acc_4: 0.8992\n",
      "Epoch 8/10\n",
      " - 2s - loss_1: 1.4673e-04 - loss_2: 1.5436e-04 - loss_3: 1.7218e-04 - loss_4: 1.3839e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4044 - val_loss_2: 0.4124 - val_loss_3: 0.4319 - val_loss_4: 0.4287 - val_acc_ensemble: 0.9099 - val_acc_1: 0.9034 - val_acc_2: 0.9010 - val_acc_3: 0.8986 - val_acc_4: 0.8996\n",
      "Epoch 9/10\n",
      " - 2s - loss_1: 1.3187e-04 - loss_2: 1.3315e-04 - loss_3: 1.4732e-04 - loss_4: 1.2083e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4057 - val_loss_2: 0.4137 - val_loss_3: 0.4326 - val_loss_4: 0.4298 - val_acc_ensemble: 0.9103 - val_acc_1: 0.9033 - val_acc_2: 0.9014 - val_acc_3: 0.8990 - val_acc_4: 0.9010\n",
      "Epoch 10/10\n",
      " - 2s - loss_1: 1.1245e-04 - loss_2: 1.1599e-04 - loss_3: 1.2228e-04 - loss_4: 1.0819e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4078 - val_loss_2: 0.4155 - val_loss_3: 0.4340 - val_loss_4: 0.4306 - val_acc_ensemble: 0.9104 - val_acc_1: 0.9031 - val_acc_2: 0.9019 - val_acc_3: 0.8991 - val_acc_4: 0.9013\n",
      "sensitivity/vb-mnist-fcn3A/B4/S0.50\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,256] [None,256]  1004800    input    \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,256] [None,256]  2560       fc1      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,256] [None,256]  0          bn1      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,256] [None,256]  855296     relu1    \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,256] [None,256]  2560       fc2      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,256] [None,256]  0          bn2      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,256] [None,256]  855296     relu2    \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,256] [None,256]  2560       fc3      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,256] [None,256]  0          bn3      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              16705      relu3    \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 2739777\n",
      "Epoch 1/10\n",
      " - 5s - loss_1: 0.2097 - loss_2: 0.2225 - loss_3: 0.2146 - loss_4: 0.2165 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4230 - val_loss_2: 0.4179 - val_loss_3: 0.3843 - val_loss_4: 0.4040 - val_acc_ensemble: 0.9043 - val_acc_1: 0.8889 - val_acc_2: 0.8912 - val_acc_3: 0.8935 - val_acc_4: 0.8906\n",
      "Epoch 2/10\n",
      " - 2s - loss_1: 0.0016 - loss_2: 0.0018 - loss_3: 0.0012 - loss_4: 0.0023 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3970 - val_loss_2: 0.4059 - val_loss_3: 0.3805 - val_loss_4: 0.3854 - val_acc_ensemble: 0.9091 - val_acc_1: 0.8989 - val_acc_2: 0.8999 - val_acc_3: 0.8985 - val_acc_4: 0.9005\n",
      "Epoch 3/10\n",
      " - 2s - loss_1: 5.2788e-04 - loss_2: 4.5280e-04 - loss_3: 5.2097e-04 - loss_4: 5.4568e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3963 - val_loss_2: 0.4082 - val_loss_3: 0.3846 - val_loss_4: 0.3875 - val_acc_ensemble: 0.9096 - val_acc_1: 0.9013 - val_acc_2: 0.9000 - val_acc_3: 0.8993 - val_acc_4: 0.9006\n",
      "Epoch 4/10\n",
      " - 2s - loss_1: 3.2711e-04 - loss_2: 3.2366e-04 - loss_3: 3.5995e-04 - loss_4: 3.4389e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3981 - val_loss_2: 0.4088 - val_loss_3: 0.3879 - val_loss_4: 0.3893 - val_acc_ensemble: 0.9093 - val_acc_1: 0.9018 - val_acc_2: 0.9007 - val_acc_3: 0.8997 - val_acc_4: 0.9009\n",
      "Epoch 5/10\n",
      " - 2s - loss_1: 2.4411e-04 - loss_2: 2.3301e-04 - loss_3: 2.6365e-04 - loss_4: 2.7631e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4000 - val_loss_2: 0.4112 - val_loss_3: 0.3910 - val_loss_4: 0.3912 - val_acc_ensemble: 0.9097 - val_acc_1: 0.9025 - val_acc_2: 0.9020 - val_acc_3: 0.9002 - val_acc_4: 0.9017\n",
      "Epoch 6/10\n",
      " - 2s - loss_1: 1.8015e-04 - loss_2: 1.7824e-04 - loss_3: 2.1337e-04 - loss_4: 2.1129e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4019 - val_loss_2: 0.4134 - val_loss_3: 0.3941 - val_loss_4: 0.3945 - val_acc_ensemble: 0.9100 - val_acc_1: 0.9028 - val_acc_2: 0.9015 - val_acc_3: 0.9004 - val_acc_4: 0.9023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      " - 2s - loss_1: 1.6141e-04 - loss_2: 1.6084e-04 - loss_3: 1.6225e-04 - loss_4: 1.6765e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4042 - val_loss_2: 0.4156 - val_loss_3: 0.3969 - val_loss_4: 0.3976 - val_acc_ensemble: 0.9094 - val_acc_1: 0.9030 - val_acc_2: 0.9020 - val_acc_3: 0.9003 - val_acc_4: 0.9021\n",
      "Epoch 8/10\n",
      " - 2s - loss_1: 1.3200e-04 - loss_2: 1.2726e-04 - loss_3: 1.3999e-04 - loss_4: 1.4677e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4060 - val_loss_2: 0.4175 - val_loss_3: 0.3989 - val_loss_4: 0.4000 - val_acc_ensemble: 0.9094 - val_acc_1: 0.9034 - val_acc_2: 0.9025 - val_acc_3: 0.9003 - val_acc_4: 0.9023\n",
      "Epoch 9/10\n",
      " - 2s - loss_1: 1.0980e-04 - loss_2: 1.0823e-04 - loss_3: 1.1816e-04 - loss_4: 1.2590e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4077 - val_loss_2: 0.4192 - val_loss_3: 0.4008 - val_loss_4: 0.4015 - val_acc_ensemble: 0.9094 - val_acc_1: 0.9036 - val_acc_2: 0.9030 - val_acc_3: 0.9008 - val_acc_4: 0.9030\n",
      "Epoch 10/10\n",
      " - 2s - loss_1: 1.0033e-04 - loss_2: 9.9489e-05 - loss_3: 1.0183e-04 - loss_4: 1.0876e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4100 - val_loss_2: 0.4211 - val_loss_3: 0.4031 - val_loss_4: 0.4037 - val_acc_ensemble: 0.9088 - val_acc_1: 0.9035 - val_acc_2: 0.9028 - val_acc_3: 0.9010 - val_acc_4: 0.9032\n",
      "sensitivity/vb-mnist-fcn3A/B4/S0.50\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,256] [None,256]  1004800    input    \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,256] [None,256]  2560       fc1      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,256] [None,256]  0          bn1      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,256] [None,256]  855296     relu1    \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,256] [None,256]  2560       fc2      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,256] [None,256]  0          bn2      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,256] [None,256]  855296     relu2    \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,256] [None,256]  2560       fc3      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,256] [None,256]  0          bn3      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              16705      relu3    \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 2739777\n",
      "Epoch 1/10\n",
      " - 5s - loss_1: 0.2368 - loss_2: 0.2336 - loss_3: 0.2300 - loss_4: 0.2282 - acc_ensemble: 1.0000 - acc_1: 0.9983 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4527 - val_loss_2: 0.4287 - val_loss_3: 0.4093 - val_loss_4: 0.4019 - val_acc_ensemble: 0.9065 - val_acc_1: 0.8820 - val_acc_2: 0.8901 - val_acc_3: 0.8882 - val_acc_4: 0.8970\n",
      "Epoch 2/10\n",
      " - 2s - loss_1: 0.0037 - loss_2: 0.0023 - loss_3: 0.0016 - loss_4: 0.0030 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4306 - val_loss_2: 0.4201 - val_loss_3: 0.3991 - val_loss_4: 0.4087 - val_acc_ensemble: 0.9056 - val_acc_1: 0.8936 - val_acc_2: 0.8937 - val_acc_3: 0.8965 - val_acc_4: 0.8986\n",
      "Epoch 3/10\n",
      " - 2s - loss_1: 6.6048e-04 - loss_2: 6.5100e-04 - loss_3: 4.8963e-04 - loss_4: 5.8842e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4227 - val_loss_2: 0.4131 - val_loss_3: 0.3987 - val_loss_4: 0.4056 - val_acc_ensemble: 0.9078 - val_acc_1: 0.8964 - val_acc_2: 0.8969 - val_acc_3: 0.8987 - val_acc_4: 0.9014\n",
      "Epoch 4/10\n",
      " - 2s - loss_1: 3.8415e-04 - loss_2: 3.3505e-04 - loss_3: 3.2371e-04 - loss_4: 3.4989e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4221 - val_loss_2: 0.4133 - val_loss_3: 0.4018 - val_loss_4: 0.4065 - val_acc_ensemble: 0.9084 - val_acc_1: 0.8981 - val_acc_2: 0.8983 - val_acc_3: 0.9000 - val_acc_4: 0.9021\n",
      "Epoch 5/10\n",
      " - 2s - loss_1: 2.7467e-04 - loss_2: 2.5315e-04 - loss_3: 2.5536e-04 - loss_4: 2.8935e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4219 - val_loss_2: 0.4141 - val_loss_3: 0.4045 - val_loss_4: 0.4080 - val_acc_ensemble: 0.9084 - val_acc_1: 0.8985 - val_acc_2: 0.8991 - val_acc_3: 0.9004 - val_acc_4: 0.9025\n",
      "Epoch 6/10\n",
      " - 2s - loss_1: 2.4232e-04 - loss_2: 2.1682e-04 - loss_3: 1.9895e-04 - loss_4: 2.0764e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4223 - val_loss_2: 0.4157 - val_loss_3: 0.4064 - val_loss_4: 0.4097 - val_acc_ensemble: 0.9082 - val_acc_1: 0.8988 - val_acc_2: 0.8998 - val_acc_3: 0.9006 - val_acc_4: 0.9025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      " - 2s - loss_1: 1.6600e-04 - loss_2: 1.6234e-04 - loss_3: 1.7049e-04 - loss_4: 1.7138e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4234 - val_loss_2: 0.4173 - val_loss_3: 0.4091 - val_loss_4: 0.4114 - val_acc_ensemble: 0.9082 - val_acc_1: 0.8997 - val_acc_2: 0.9001 - val_acc_3: 0.9010 - val_acc_4: 0.9031\n",
      "Epoch 8/10\n",
      " - 2s - loss_1: 1.4890e-04 - loss_2: 1.5254e-04 - loss_3: 1.4228e-04 - loss_4: 1.3965e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4249 - val_loss_2: 0.4191 - val_loss_3: 0.4116 - val_loss_4: 0.4135 - val_acc_ensemble: 0.9082 - val_acc_1: 0.8998 - val_acc_2: 0.9002 - val_acc_3: 0.9020 - val_acc_4: 0.9035\n",
      "Epoch 9/10\n",
      " - 2s - loss_1: 1.3532e-04 - loss_2: 1.2030e-04 - loss_3: 1.1399e-04 - loss_4: 1.3238e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4260 - val_loss_2: 0.4209 - val_loss_3: 0.4135 - val_loss_4: 0.4155 - val_acc_ensemble: 0.9086 - val_acc_1: 0.9001 - val_acc_2: 0.9003 - val_acc_3: 0.9023 - val_acc_4: 0.9038\n",
      "Epoch 10/10\n",
      " - 2s - loss_1: 1.1065e-04 - loss_2: 1.0696e-04 - loss_3: 1.0295e-04 - loss_4: 1.1052e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4270 - val_loss_2: 0.4221 - val_loss_3: 0.4152 - val_loss_4: 0.4174 - val_acc_ensemble: 0.9085 - val_acc_1: 0.9002 - val_acc_2: 0.9005 - val_acc_3: 0.9025 - val_acc_4: 0.9040\n",
      "sensitivity/vb-mnist-fcn3A/B4/S0.50\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,256] [None,256]  1004800    input    \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,256] [None,256]  2560       fc1      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,256] [None,256]  0          bn1      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,256] [None,256]  855296     relu1    \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,256] [None,256]  2560       fc2      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,256] [None,256]  0          bn2      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,256] [None,256]  855296     relu2    \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,256] [None,256]  2560       fc3      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,256] [None,256]  0          bn3      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              16705      relu3    \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 2739777\n",
      "Epoch 1/10\n",
      " - 5s - loss_1: 0.2004 - loss_2: 0.2094 - loss_3: 0.2141 - loss_4: 0.2285 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 0.9983 - acc_4: 0.9983 - val_loss_1: 0.4047 - val_loss_2: 0.4456 - val_loss_3: 0.4577 - val_loss_4: 0.4519 - val_acc_ensemble: 0.8984 - val_acc_1: 0.8900 - val_acc_2: 0.8804 - val_acc_3: 0.8802 - val_acc_4: 0.8797\n",
      "Epoch 2/10\n",
      " - 2s - loss_1: 0.0014 - loss_2: 0.0047 - loss_3: 0.0015 - loss_4: 0.0018 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4027 - val_loss_2: 0.4312 - val_loss_3: 0.4373 - val_loss_4: 0.4171 - val_acc_ensemble: 0.9035 - val_acc_1: 0.8945 - val_acc_2: 0.8918 - val_acc_3: 0.8913 - val_acc_4: 0.8935\n",
      "Epoch 3/10\n",
      " - 2s - loss_1: 4.7960e-04 - loss_2: 5.5659e-04 - loss_3: 4.5661e-04 - loss_4: 4.4849e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3991 - val_loss_2: 0.4219 - val_loss_3: 0.4317 - val_loss_4: 0.4128 - val_acc_ensemble: 0.9055 - val_acc_1: 0.8975 - val_acc_2: 0.8951 - val_acc_3: 0.8935 - val_acc_4: 0.8965\n",
      "Epoch 4/10\n",
      " - 2s - loss_1: 3.2028e-04 - loss_2: 3.1703e-04 - loss_3: 2.9258e-04 - loss_4: 3.1787e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4010 - val_loss_2: 0.4210 - val_loss_3: 0.4311 - val_loss_4: 0.4147 - val_acc_ensemble: 0.9055 - val_acc_1: 0.8979 - val_acc_2: 0.8976 - val_acc_3: 0.8941 - val_acc_4: 0.8971\n",
      "Epoch 5/10\n",
      " - 2s - loss_1: 2.3253e-04 - loss_2: 2.4646e-04 - loss_3: 2.2357e-04 - loss_4: 2.3586e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4023 - val_loss_2: 0.4214 - val_loss_3: 0.4309 - val_loss_4: 0.4157 - val_acc_ensemble: 0.9058 - val_acc_1: 0.8988 - val_acc_2: 0.8979 - val_acc_3: 0.8953 - val_acc_4: 0.8986\n",
      "Epoch 6/10\n",
      " - 2s - loss_1: 1.7923e-04 - loss_2: 1.9437e-04 - loss_3: 1.7143e-04 - loss_4: 1.7169e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4039 - val_loss_2: 0.4225 - val_loss_3: 0.4327 - val_loss_4: 0.4162 - val_acc_ensemble: 0.9063 - val_acc_1: 0.8988 - val_acc_2: 0.8987 - val_acc_3: 0.8956 - val_acc_4: 0.8999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      " - 2s - loss_1: 1.4724e-04 - loss_2: 1.5756e-04 - loss_3: 1.4197e-04 - loss_4: 1.5316e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4054 - val_loss_2: 0.4231 - val_loss_3: 0.4340 - val_loss_4: 0.4180 - val_acc_ensemble: 0.9065 - val_acc_1: 0.8989 - val_acc_2: 0.8994 - val_acc_3: 0.8961 - val_acc_4: 0.9005\n",
      "Epoch 8/10\n",
      " - 2s - loss_1: 1.2810e-04 - loss_2: 1.3298e-04 - loss_3: 1.2171e-04 - loss_4: 1.1737e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4076 - val_loss_2: 0.4242 - val_loss_3: 0.4347 - val_loss_4: 0.4192 - val_acc_ensemble: 0.9069 - val_acc_1: 0.8992 - val_acc_2: 0.8996 - val_acc_3: 0.8968 - val_acc_4: 0.9004\n",
      "Epoch 9/10\n",
      " - 2s - loss_1: 1.0108e-04 - loss_2: 1.1412e-04 - loss_3: 1.0674e-04 - loss_4: 1.0937e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4095 - val_loss_2: 0.4253 - val_loss_3: 0.4366 - val_loss_4: 0.4210 - val_acc_ensemble: 0.9071 - val_acc_1: 0.8996 - val_acc_2: 0.8998 - val_acc_3: 0.8974 - val_acc_4: 0.9004\n",
      "Epoch 10/10\n",
      " - 2s - loss_1: 9.4158e-05 - loss_2: 9.8233e-05 - loss_3: 9.0402e-05 - loss_4: 9.5098e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4114 - val_loss_2: 0.4270 - val_loss_3: 0.4390 - val_loss_4: 0.4229 - val_acc_ensemble: 0.9074 - val_acc_1: 0.8994 - val_acc_2: 0.9004 - val_acc_3: 0.8974 - val_acc_4: 0.9005\n",
      "sensitivity/vb-mnist-fcn3A/B4/S0.50\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,256] [None,256]  1004800    input    \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,256] [None,256]  2560       fc1      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,256] [None,256]  0          bn1      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,256] [None,256]  855296     relu1    \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,256] [None,256]  2560       fc2      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,256] [None,256]  0          bn2      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,256] [None,256]  855296     relu2    \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,256] [None,256]  2560       fc3      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,256] [None,256]  0          bn3      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              16705      relu3    \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 2739777\n",
      "Epoch 1/10\n",
      " - 5s - loss_1: 0.2222 - loss_2: 0.1997 - loss_3: 0.2164 - loss_4: 0.2165 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 0.9983 - acc_4: 1.0000 - val_loss_1: 0.4249 - val_loss_2: 0.4334 - val_loss_3: 0.4865 - val_loss_4: 0.3881 - val_acc_ensemble: 0.8989 - val_acc_1: 0.8876 - val_acc_2: 0.8863 - val_acc_3: 0.8710 - val_acc_4: 0.8913\n",
      "Epoch 2/10\n",
      " - 2s - loss_1: 0.0013 - loss_2: 0.0020 - loss_3: 0.0032 - loss_4: 0.0015 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4072 - val_loss_2: 0.4040 - val_loss_3: 0.4205 - val_loss_4: 0.3873 - val_acc_ensemble: 0.9034 - val_acc_1: 0.8959 - val_acc_2: 0.8969 - val_acc_3: 0.8939 - val_acc_4: 0.8959\n",
      "Epoch 3/10\n",
      " - 2s - loss_1: 5.3176e-04 - loss_2: 5.4396e-04 - loss_3: 5.0888e-04 - loss_4: 5.4737e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4064 - val_loss_2: 0.4026 - val_loss_3: 0.4174 - val_loss_4: 0.3900 - val_acc_ensemble: 0.9049 - val_acc_1: 0.8970 - val_acc_2: 0.8982 - val_acc_3: 0.8974 - val_acc_4: 0.8980\n",
      "Epoch 4/10\n",
      " - 2s - loss_1: 3.4518e-04 - loss_2: 3.3268e-04 - loss_3: 3.3326e-04 - loss_4: 3.7007e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4083 - val_loss_2: 0.4050 - val_loss_3: 0.4177 - val_loss_4: 0.3937 - val_acc_ensemble: 0.9055 - val_acc_1: 0.8976 - val_acc_2: 0.8987 - val_acc_3: 0.8978 - val_acc_4: 0.8989\n",
      "Epoch 5/10\n",
      " - 2s - loss_1: 2.4973e-04 - loss_2: 2.5839e-04 - loss_3: 2.4352e-04 - loss_4: 2.6628e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4110 - val_loss_2: 0.4080 - val_loss_3: 0.4198 - val_loss_4: 0.3967 - val_acc_ensemble: 0.9063 - val_acc_1: 0.8985 - val_acc_2: 0.8994 - val_acc_3: 0.8990 - val_acc_4: 0.8993\n",
      "Epoch 6/10\n",
      " - 2s - loss_1: 2.1245e-04 - loss_2: 1.9785e-04 - loss_3: 1.9996e-04 - loss_4: 2.1836e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4130 - val_loss_2: 0.4100 - val_loss_3: 0.4211 - val_loss_4: 0.3996 - val_acc_ensemble: 0.9069 - val_acc_1: 0.8994 - val_acc_2: 0.9004 - val_acc_3: 0.8994 - val_acc_4: 0.9002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      " - 2s - loss_1: 1.7463e-04 - loss_2: 1.5861e-04 - loss_3: 1.5938e-04 - loss_4: 1.8020e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4154 - val_loss_2: 0.4131 - val_loss_3: 0.4225 - val_loss_4: 0.4030 - val_acc_ensemble: 0.9072 - val_acc_1: 0.8996 - val_acc_2: 0.9007 - val_acc_3: 0.8999 - val_acc_4: 0.9007\n",
      "Epoch 8/10\n",
      " - 2s - loss_1: 1.3410e-04 - loss_2: 1.3419e-04 - loss_3: 1.3203e-04 - loss_4: 1.4865e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4177 - val_loss_2: 0.4156 - val_loss_3: 0.4247 - val_loss_4: 0.4064 - val_acc_ensemble: 0.9069 - val_acc_1: 0.9001 - val_acc_2: 0.9004 - val_acc_3: 0.8999 - val_acc_4: 0.9008\n",
      "Epoch 9/10\n",
      " - 2s - loss_1: 1.1566e-04 - loss_2: 1.1108e-04 - loss_3: 1.1302e-04 - loss_4: 1.2490e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4188 - val_loss_2: 0.4176 - val_loss_3: 0.4262 - val_loss_4: 0.4088 - val_acc_ensemble: 0.9072 - val_acc_1: 0.9006 - val_acc_2: 0.9008 - val_acc_3: 0.9001 - val_acc_4: 0.9009\n",
      "Epoch 10/10\n",
      " - 2s - loss_1: 1.0244e-04 - loss_2: 1.0198e-04 - loss_3: 9.9616e-05 - loss_4: 1.0694e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4205 - val_loss_2: 0.4195 - val_loss_3: 0.4275 - val_loss_4: 0.4101 - val_acc_ensemble: 0.9074 - val_acc_1: 0.9007 - val_acc_2: 0.9004 - val_acc_3: 0.9008 - val_acc_4: 0.9008\n",
      "sensitivity/vb-mnist-fcn3A/B4/S0.75\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,384] [None,128]  703360     input    \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,384] [None,128]  1792       fc1      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,384] [None,128]  0          bn1      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,384] [None,128]  609152     relu1    \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,384] [None,128]  1792       fc2      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,384] [None,128]  0          bn2      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,384] [None,128]  609152     relu2    \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,384] [None,128]  1792       fc3      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,384] [None,128]  0          bn3      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              12475      relu3    \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 1939515\n",
      "Epoch 1/10\n",
      " - 5s - loss_1: 0.1885 - loss_2: 0.2039 - loss_3: 0.1806 - loss_4: 0.1649 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4072 - val_loss_2: 0.4008 - val_loss_3: 0.3896 - val_loss_4: 0.4231 - val_acc_ensemble: 0.8973 - val_acc_1: 0.8905 - val_acc_2: 0.8933 - val_acc_3: 0.8952 - val_acc_4: 0.8886\n",
      "Epoch 2/10\n",
      " - 2s - loss_1: 8.5806e-04 - loss_2: 0.0011 - loss_3: 7.5176e-04 - loss_4: 8.7144e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3947 - val_loss_2: 0.3893 - val_loss_3: 0.3817 - val_loss_4: 0.4010 - val_acc_ensemble: 0.9025 - val_acc_1: 0.8970 - val_acc_2: 0.8984 - val_acc_3: 0.8992 - val_acc_4: 0.8984\n",
      "Epoch 3/10\n",
      " - 2s - loss_1: 4.0660e-04 - loss_2: 4.6480e-04 - loss_3: 3.8232e-04 - loss_4: 3.9853e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3969 - val_loss_2: 0.3919 - val_loss_3: 0.3839 - val_loss_4: 0.4019 - val_acc_ensemble: 0.9031 - val_acc_1: 0.8984 - val_acc_2: 0.9001 - val_acc_3: 0.9016 - val_acc_4: 0.8995\n",
      "Epoch 4/10\n",
      " - 2s - loss_1: 2.8646e-04 - loss_2: 3.2861e-04 - loss_3: 2.6816e-04 - loss_4: 2.7309e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3992 - val_loss_2: 0.3954 - val_loss_3: 0.3871 - val_loss_4: 0.4043 - val_acc_ensemble: 0.9035 - val_acc_1: 0.8990 - val_acc_2: 0.9014 - val_acc_3: 0.9017 - val_acc_4: 0.9010\n",
      "Epoch 5/10\n",
      " - 2s - loss_1: 2.1656e-04 - loss_2: 2.2512e-04 - loss_3: 2.0974e-04 - loss_4: 1.9662e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4008 - val_loss_2: 0.3983 - val_loss_3: 0.3897 - val_loss_4: 0.4068 - val_acc_ensemble: 0.9047 - val_acc_1: 0.9002 - val_acc_2: 0.9019 - val_acc_3: 0.9020 - val_acc_4: 0.9015\n",
      "Epoch 6/10\n",
      " - 2s - loss_1: 1.6744e-04 - loss_2: 1.8262e-04 - loss_3: 1.5610e-04 - loss_4: 1.5534e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4036 - val_loss_2: 0.4008 - val_loss_3: 0.3926 - val_loss_4: 0.4094 - val_acc_ensemble: 0.9048 - val_acc_1: 0.9001 - val_acc_2: 0.9014 - val_acc_3: 0.9028 - val_acc_4: 0.9018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      " - 2s - loss_1: 1.3779e-04 - loss_2: 1.4619e-04 - loss_3: 1.2684e-04 - loss_4: 1.2499e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4055 - val_loss_2: 0.4027 - val_loss_3: 0.3945 - val_loss_4: 0.4112 - val_acc_ensemble: 0.9057 - val_acc_1: 0.9006 - val_acc_2: 0.9025 - val_acc_3: 0.9034 - val_acc_4: 0.9025\n",
      "Epoch 8/10\n",
      " - 2s - loss_1: 1.1414e-04 - loss_2: 1.2108e-04 - loss_3: 1.1174e-04 - loss_4: 1.0140e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4077 - val_loss_2: 0.4052 - val_loss_3: 0.3964 - val_loss_4: 0.4128 - val_acc_ensemble: 0.9061 - val_acc_1: 0.9011 - val_acc_2: 0.9021 - val_acc_3: 0.9039 - val_acc_4: 0.9035\n",
      "Epoch 9/10\n",
      " - 2s - loss_1: 9.6345e-05 - loss_2: 1.0454e-04 - loss_3: 9.5232e-05 - loss_4: 8.7368e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4098 - val_loss_2: 0.4077 - val_loss_3: 0.3991 - val_loss_4: 0.4157 - val_acc_ensemble: 0.9067 - val_acc_1: 0.9018 - val_acc_2: 0.9022 - val_acc_3: 0.9040 - val_acc_4: 0.9039\n",
      "Epoch 10/10\n",
      " - 2s - loss_1: 8.6148e-05 - loss_2: 9.1385e-05 - loss_3: 8.0836e-05 - loss_4: 7.4282e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4119 - val_loss_2: 0.4098 - val_loss_3: 0.4011 - val_loss_4: 0.4175 - val_acc_ensemble: 0.9068 - val_acc_1: 0.9018 - val_acc_2: 0.9027 - val_acc_3: 0.9047 - val_acc_4: 0.9040\n",
      "sensitivity/vb-mnist-fcn3A/B4/S0.75\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,384] [None,128]  703360     input    \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,384] [None,128]  1792       fc1      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,384] [None,128]  0          bn1      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,384] [None,128]  609152     relu1    \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,384] [None,128]  1792       fc2      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,384] [None,128]  0          bn2      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,384] [None,128]  609152     relu2    \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,384] [None,128]  1792       fc3      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,384] [None,128]  0          bn3      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              12475      relu3    \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 1939515\n",
      "Epoch 1/10\n",
      " - 5s - loss_1: 0.1637 - loss_2: 0.1833 - loss_3: 0.1560 - loss_4: 0.1667 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3958 - val_loss_2: 0.4100 - val_loss_3: 0.3973 - val_loss_4: 0.3997 - val_acc_ensemble: 0.9009 - val_acc_1: 0.8956 - val_acc_2: 0.8917 - val_acc_3: 0.8946 - val_acc_4: 0.8946\n",
      "Epoch 2/10\n",
      " - 2s - loss_1: 8.7114e-04 - loss_2: 7.2863e-04 - loss_3: 8.2639e-04 - loss_4: 7.7441e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3923 - val_loss_2: 0.3986 - val_loss_3: 0.3880 - val_loss_4: 0.3869 - val_acc_ensemble: 0.9047 - val_acc_1: 0.9007 - val_acc_2: 0.8979 - val_acc_3: 0.8998 - val_acc_4: 0.8997\n",
      "Epoch 3/10\n",
      " - 2s - loss_1: 4.0562e-04 - loss_2: 3.9121e-04 - loss_3: 3.7005e-04 - loss_4: 3.7794e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3965 - val_loss_2: 0.3994 - val_loss_3: 0.3909 - val_loss_4: 0.3890 - val_acc_ensemble: 0.9054 - val_acc_1: 0.9010 - val_acc_2: 0.8996 - val_acc_3: 0.9003 - val_acc_4: 0.9007\n",
      "Epoch 4/10\n",
      " - 2s - loss_1: 2.6811e-04 - loss_2: 2.7754e-04 - loss_3: 2.4481e-04 - loss_4: 2.4697e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4004 - val_loss_2: 0.4008 - val_loss_3: 0.3938 - val_loss_4: 0.3911 - val_acc_ensemble: 0.9061 - val_acc_1: 0.9012 - val_acc_2: 0.9004 - val_acc_3: 0.9011 - val_acc_4: 0.9019\n",
      "Epoch 5/10\n",
      " - 2s - loss_1: 2.0002e-04 - loss_2: 1.9709e-04 - loss_3: 1.8372e-04 - loss_4: 1.9343e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4044 - val_loss_2: 0.4049 - val_loss_3: 0.3983 - val_loss_4: 0.3950 - val_acc_ensemble: 0.9057 - val_acc_1: 0.9016 - val_acc_2: 0.9012 - val_acc_3: 0.9011 - val_acc_4: 0.9023\n",
      "Epoch 6/10\n",
      " - 2s - loss_1: 1.5855e-04 - loss_2: 1.6114e-04 - loss_3: 1.5507e-04 - loss_4: 1.5425e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4081 - val_loss_2: 0.4074 - val_loss_3: 0.4015 - val_loss_4: 0.3975 - val_acc_ensemble: 0.9060 - val_acc_1: 0.9024 - val_acc_2: 0.9024 - val_acc_3: 0.9014 - val_acc_4: 0.9027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      " - 2s - loss_1: 1.2698e-04 - loss_2: 1.2757e-04 - loss_3: 1.2401e-04 - loss_4: 1.3190e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4121 - val_loss_2: 0.4104 - val_loss_3: 0.4056 - val_loss_4: 0.4010 - val_acc_ensemble: 0.9056 - val_acc_1: 0.9022 - val_acc_2: 0.9023 - val_acc_3: 0.9015 - val_acc_4: 0.9027\n",
      "Epoch 8/10\n",
      " - 2s - loss_1: 1.0669e-04 - loss_2: 1.0524e-04 - loss_3: 1.0444e-04 - loss_4: 1.0814e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4147 - val_loss_2: 0.4121 - val_loss_3: 0.4077 - val_loss_4: 0.4031 - val_acc_ensemble: 0.9060 - val_acc_1: 0.9024 - val_acc_2: 0.9023 - val_acc_3: 0.9015 - val_acc_4: 0.9031\n",
      "Epoch 9/10\n",
      " - 2s - loss_1: 9.6371e-05 - loss_2: 9.0825e-05 - loss_3: 8.7269e-05 - loss_4: 8.4902e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4175 - val_loss_2: 0.4143 - val_loss_3: 0.4106 - val_loss_4: 0.4051 - val_acc_ensemble: 0.9065 - val_acc_1: 0.9024 - val_acc_2: 0.9028 - val_acc_3: 0.9017 - val_acc_4: 0.9029\n",
      "Epoch 10/10\n",
      " - 2s - loss_1: 7.7730e-05 - loss_2: 7.4858e-05 - loss_3: 7.5715e-05 - loss_4: 7.7488e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4200 - val_loss_2: 0.4160 - val_loss_3: 0.4129 - val_loss_4: 0.4076 - val_acc_ensemble: 0.9066 - val_acc_1: 0.9025 - val_acc_2: 0.9031 - val_acc_3: 0.9020 - val_acc_4: 0.9029\n",
      "sensitivity/vb-mnist-fcn3A/B4/S0.75\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,384] [None,128]  703360     input    \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,384] [None,128]  1792       fc1      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,384] [None,128]  0          bn1      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,384] [None,128]  609152     relu1    \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,384] [None,128]  1792       fc2      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,384] [None,128]  0          bn2      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,384] [None,128]  609152     relu2    \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,384] [None,128]  1792       fc3      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,384] [None,128]  0          bn3      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              12475      relu3    \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 1939515\n",
      "Epoch 1/10\n",
      " - 4s - loss_1: 0.1669 - loss_2: 0.1734 - loss_3: 0.1938 - loss_4: 0.1757 - acc_ensemble: 1.0000 - acc_1: 0.9983 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4339 - val_loss_2: 0.4051 - val_loss_3: 0.4049 - val_loss_4: 0.4249 - val_acc_ensemble: 0.8989 - val_acc_1: 0.8880 - val_acc_2: 0.8917 - val_acc_3: 0.8949 - val_acc_4: 0.8891\n",
      "Epoch 2/10\n",
      " - 2s - loss_1: 0.0011 - loss_2: 8.0988e-04 - loss_3: 9.1690e-04 - loss_4: 9.2864e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4124 - val_loss_2: 0.3960 - val_loss_3: 0.4011 - val_loss_4: 0.4201 - val_acc_ensemble: 0.9022 - val_acc_1: 0.8966 - val_acc_2: 0.8986 - val_acc_3: 0.9006 - val_acc_4: 0.8936\n",
      "Epoch 3/10\n",
      " - 2s - loss_1: 3.4776e-04 - loss_2: 3.9060e-04 - loss_3: 4.1682e-04 - loss_4: 3.8144e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4146 - val_loss_2: 0.4013 - val_loss_3: 0.4059 - val_loss_4: 0.4235 - val_acc_ensemble: 0.9027 - val_acc_1: 0.8976 - val_acc_2: 0.8990 - val_acc_3: 0.9014 - val_acc_4: 0.8945\n",
      "Epoch 4/10\n",
      " - 2s - loss_1: 2.4105e-04 - loss_2: 2.5958e-04 - loss_3: 2.7397e-04 - loss_4: 2.4339e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4168 - val_loss_2: 0.4037 - val_loss_3: 0.4090 - val_loss_4: 0.4260 - val_acc_ensemble: 0.9036 - val_acc_1: 0.8988 - val_acc_2: 0.8998 - val_acc_3: 0.9021 - val_acc_4: 0.8960\n",
      "Epoch 5/10\n",
      " - 2s - loss_1: 1.7408e-04 - loss_2: 1.9985e-04 - loss_3: 2.0352e-04 - loss_4: 1.8392e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4193 - val_loss_2: 0.4067 - val_loss_3: 0.4123 - val_loss_4: 0.4284 - val_acc_ensemble: 0.9044 - val_acc_1: 0.9000 - val_acc_2: 0.9000 - val_acc_3: 0.9024 - val_acc_4: 0.8959\n",
      "Epoch 6/10\n",
      " - 2s - loss_1: 1.3169e-04 - loss_2: 1.5307e-04 - loss_3: 1.5635e-04 - loss_4: 1.5957e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4219 - val_loss_2: 0.4096 - val_loss_3: 0.4160 - val_loss_4: 0.4311 - val_acc_ensemble: 0.9048 - val_acc_1: 0.9005 - val_acc_2: 0.9003 - val_acc_3: 0.9027 - val_acc_4: 0.8964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      " - 2s - loss_1: 1.1219e-04 - loss_2: 1.1815e-04 - loss_3: 1.2873e-04 - loss_4: 1.1993e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4242 - val_loss_2: 0.4118 - val_loss_3: 0.4192 - val_loss_4: 0.4332 - val_acc_ensemble: 0.9052 - val_acc_1: 0.9007 - val_acc_2: 0.9008 - val_acc_3: 0.9028 - val_acc_4: 0.8973\n",
      "Epoch 8/10\n",
      " - 2s - loss_1: 9.2986e-05 - loss_2: 1.0104e-04 - loss_3: 1.1126e-04 - loss_4: 1.0516e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4263 - val_loss_2: 0.4140 - val_loss_3: 0.4218 - val_loss_4: 0.4352 - val_acc_ensemble: 0.9054 - val_acc_1: 0.9011 - val_acc_2: 0.9014 - val_acc_3: 0.9027 - val_acc_4: 0.8975\n",
      "Epoch 9/10\n",
      " - 2s - loss_1: 8.0841e-05 - loss_2: 8.4377e-05 - loss_3: 8.9593e-05 - loss_4: 8.9121e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4292 - val_loss_2: 0.4172 - val_loss_3: 0.4247 - val_loss_4: 0.4385 - val_acc_ensemble: 0.9054 - val_acc_1: 0.9009 - val_acc_2: 0.9005 - val_acc_3: 0.9022 - val_acc_4: 0.8971\n",
      "Epoch 10/10\n",
      " - 2s - loss_1: 7.3460e-05 - loss_2: 7.1565e-05 - loss_3: 8.0766e-05 - loss_4: 7.8113e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4312 - val_loss_2: 0.4190 - val_loss_3: 0.4268 - val_loss_4: 0.4409 - val_acc_ensemble: 0.9058 - val_acc_1: 0.9016 - val_acc_2: 0.9007 - val_acc_3: 0.9029 - val_acc_4: 0.8971\n",
      "sensitivity/vb-mnist-fcn3A/B4/S0.75\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,384] [None,128]  703360     input    \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,384] [None,128]  1792       fc1      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,384] [None,128]  0          bn1      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,384] [None,128]  609152     relu1    \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,384] [None,128]  1792       fc2      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,384] [None,128]  0          bn2      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,384] [None,128]  609152     relu2    \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,384] [None,128]  1792       fc3      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,384] [None,128]  0          bn3      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              12475      relu3    \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 1939515\n",
      "Epoch 1/10\n",
      " - 4s - loss_1: 0.1794 - loss_2: 0.1859 - loss_3: 0.1839 - loss_4: 0.1637 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 0.9967 - acc_4: 1.0000 - val_loss_1: 0.3782 - val_loss_2: 0.3799 - val_loss_3: 0.3975 - val_loss_4: 0.3892 - val_acc_ensemble: 0.9012 - val_acc_1: 0.8995 - val_acc_2: 0.8965 - val_acc_3: 0.8924 - val_acc_4: 0.8984\n",
      "Epoch 2/10\n",
      " - 2s - loss_1: 9.5311e-04 - loss_2: 8.6074e-04 - loss_3: 0.0014 - loss_4: 8.8869e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3768 - val_loss_2: 0.3743 - val_loss_3: 0.3779 - val_loss_4: 0.3803 - val_acc_ensemble: 0.9049 - val_acc_1: 0.9011 - val_acc_2: 0.9019 - val_acc_3: 0.8992 - val_acc_4: 0.9037\n",
      "Epoch 3/10\n",
      " - 2s - loss_1: 4.0959e-04 - loss_2: 3.8426e-04 - loss_3: 4.4791e-04 - loss_4: 4.2780e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3796 - val_loss_2: 0.3780 - val_loss_3: 0.3801 - val_loss_4: 0.3838 - val_acc_ensemble: 0.9054 - val_acc_1: 0.9019 - val_acc_2: 0.9033 - val_acc_3: 0.9000 - val_acc_4: 0.9042\n",
      "Epoch 4/10\n",
      " - 2s - loss_1: 2.7748e-04 - loss_2: 2.5481e-04 - loss_3: 2.8777e-04 - loss_4: 2.7834e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3816 - val_loss_2: 0.3799 - val_loss_3: 0.3821 - val_loss_4: 0.3869 - val_acc_ensemble: 0.9058 - val_acc_1: 0.9023 - val_acc_2: 0.9045 - val_acc_3: 0.9013 - val_acc_4: 0.9047\n",
      "Epoch 5/10\n",
      " - 2s - loss_1: 2.0421e-04 - loss_2: 1.9870e-04 - loss_3: 2.2978e-04 - loss_4: 1.9838e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3847 - val_loss_2: 0.3835 - val_loss_3: 0.3855 - val_loss_4: 0.3892 - val_acc_ensemble: 0.9063 - val_acc_1: 0.9032 - val_acc_2: 0.9048 - val_acc_3: 0.9009 - val_acc_4: 0.9048\n",
      "Epoch 6/10\n",
      " - 2s - loss_1: 1.5578e-04 - loss_2: 1.5069e-04 - loss_3: 1.7592e-04 - loss_4: 1.5508e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3869 - val_loss_2: 0.3861 - val_loss_3: 0.3882 - val_loss_4: 0.3927 - val_acc_ensemble: 0.9070 - val_acc_1: 0.9040 - val_acc_2: 0.9047 - val_acc_3: 0.9015 - val_acc_4: 0.9046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      " - 2s - loss_1: 1.3420e-04 - loss_2: 1.2381e-04 - loss_3: 1.3677e-04 - loss_4: 1.2725e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3897 - val_loss_2: 0.3891 - val_loss_3: 0.3908 - val_loss_4: 0.3950 - val_acc_ensemble: 0.9067 - val_acc_1: 0.9047 - val_acc_2: 0.9050 - val_acc_3: 0.9019 - val_acc_4: 0.9046\n",
      "Epoch 8/10\n",
      " - 2s - loss_1: 1.1797e-04 - loss_2: 1.0345e-04 - loss_3: 1.2328e-04 - loss_4: 1.0613e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3918 - val_loss_2: 0.3917 - val_loss_3: 0.3932 - val_loss_4: 0.3973 - val_acc_ensemble: 0.9065 - val_acc_1: 0.9048 - val_acc_2: 0.9054 - val_acc_3: 0.9019 - val_acc_4: 0.9049\n",
      "Epoch 9/10\n",
      " - 2s - loss_1: 8.8917e-05 - loss_2: 8.9953e-05 - loss_3: 1.0334e-04 - loss_4: 9.0095e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3943 - val_loss_2: 0.3943 - val_loss_3: 0.3954 - val_loss_4: 0.3997 - val_acc_ensemble: 0.9067 - val_acc_1: 0.9051 - val_acc_2: 0.9053 - val_acc_3: 0.9020 - val_acc_4: 0.9052\n",
      "Epoch 10/10\n",
      " - 2s - loss_1: 8.4276e-05 - loss_2: 8.1445e-05 - loss_3: 8.8508e-05 - loss_4: 8.3605e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3965 - val_loss_2: 0.3967 - val_loss_3: 0.3971 - val_loss_4: 0.4023 - val_acc_ensemble: 0.9068 - val_acc_1: 0.9051 - val_acc_2: 0.9053 - val_acc_3: 0.9023 - val_acc_4: 0.9051\n",
      "sensitivity/vb-mnist-fcn3A/B4/S1.00\n",
      "i  Layer name                Output shape   Num param  Inbound  \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,512] []  401920     input    \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,512] []  1024       fc1      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,512] []  0          bn1      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,512] []  262656     relu1    \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,512] []  1024       fc2      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,512] []  0          bn2      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,512] []  262656     relu2    \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,512] []  1024       fc3      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,512] []  0          bn3      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]      5130       relu3    \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "----------------------------------------------------------------\n",
      "Total parameters: 935434\n",
      "Epoch 1/10\n",
      " - 1s - loss_1: 0.0812 - loss_2: 0.0805 - loss_3: 0.1013 - loss_4: 0.0851 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3433 - val_loss_2: 0.3433 - val_loss_3: 0.3433 - val_loss_4: 0.3433 - val_acc_ensemble: 0.8980 - val_acc_1: 0.8980 - val_acc_2: 0.8980 - val_acc_3: 0.8980 - val_acc_4: 0.8980\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 8.4160e-04 - loss_2: 8.5123e-04 - loss_3: 9.1369e-04 - loss_4: 8.5036e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3509 - val_loss_2: 0.3509 - val_loss_3: 0.3509 - val_loss_4: 0.3509 - val_acc_ensemble: 0.9000 - val_acc_1: 0.9000 - val_acc_2: 0.9000 - val_acc_3: 0.9000 - val_acc_4: 0.9000\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 4.5089e-04 - loss_2: 4.3314e-04 - loss_3: 4.5173e-04 - loss_4: 4.4228e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3573 - val_loss_2: 0.3573 - val_loss_3: 0.3573 - val_loss_4: 0.3573 - val_acc_ensemble: 0.9007 - val_acc_1: 0.9007 - val_acc_2: 0.9007 - val_acc_3: 0.9007 - val_acc_4: 0.9007\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 2.7714e-04 - loss_2: 2.8329e-04 - loss_3: 2.8910e-04 - loss_4: 2.8933e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3620 - val_loss_2: 0.3620 - val_loss_3: 0.3620 - val_loss_4: 0.3620 - val_acc_ensemble: 0.9014 - val_acc_1: 0.9014 - val_acc_2: 0.9014 - val_acc_3: 0.9014 - val_acc_4: 0.9014\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 1.9472e-04 - loss_2: 1.9269e-04 - loss_3: 2.0677e-04 - loss_4: 1.9688e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3653 - val_loss_2: 0.3653 - val_loss_3: 0.3653 - val_loss_4: 0.3653 - val_acc_ensemble: 0.9025 - val_acc_1: 0.9025 - val_acc_2: 0.9025 - val_acc_3: 0.9025 - val_acc_4: 0.9025\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 1.5330e-04 - loss_2: 1.4356e-04 - loss_3: 1.4834e-04 - loss_4: 1.4989e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3695 - val_loss_2: 0.3695 - val_loss_3: 0.3695 - val_loss_4: 0.3695 - val_acc_ensemble: 0.9027 - val_acc_1: 0.9027 - val_acc_2: 0.9027 - val_acc_3: 0.9027 - val_acc_4: 0.9027\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 1.1480e-04 - loss_2: 1.1851e-04 - loss_3: 1.2088e-04 - loss_4: 1.1519e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3729 - val_loss_2: 0.3729 - val_loss_3: 0.3729 - val_loss_4: 0.3729 - val_acc_ensemble: 0.9028 - val_acc_1: 0.9028 - val_acc_2: 0.9028 - val_acc_3: 0.9028 - val_acc_4: 0.9028\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 9.3734e-05 - loss_2: 8.9111e-05 - loss_3: 9.0752e-05 - loss_4: 9.5449e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3760 - val_loss_2: 0.3760 - val_loss_3: 0.3760 - val_loss_4: 0.3760 - val_acc_ensemble: 0.9035 - val_acc_1: 0.9035 - val_acc_2: 0.9035 - val_acc_3: 0.9035 - val_acc_4: 0.9035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      " - 1s - loss_1: 7.3856e-05 - loss_2: 7.9145e-05 - loss_3: 7.6024e-05 - loss_4: 7.8058e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3790 - val_loss_2: 0.3790 - val_loss_3: 0.3790 - val_loss_4: 0.3790 - val_acc_ensemble: 0.9042 - val_acc_1: 0.9042 - val_acc_2: 0.9042 - val_acc_3: 0.9042 - val_acc_4: 0.9042\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 6.1158e-05 - loss_2: 6.2250e-05 - loss_3: 6.4274e-05 - loss_4: 6.3618e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3813 - val_loss_2: 0.3813 - val_loss_3: 0.3813 - val_loss_4: 0.3813 - val_acc_ensemble: 0.9043 - val_acc_1: 0.9043 - val_acc_2: 0.9043 - val_acc_3: 0.9043 - val_acc_4: 0.9043\n",
      "sensitivity/vb-mnist-fcn3A/B4/S1.00\n",
      "i  Layer name                Output shape   Num param  Inbound  \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,512] []  401920     input    \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,512] []  1024       fc1      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,512] []  0          bn1      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,512] []  262656     relu1    \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,512] []  1024       fc2      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,512] []  0          bn2      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,512] []  262656     relu2    \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,512] []  1024       fc3      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,512] []  0          bn3      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]      5130       relu3    \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "----------------------------------------------------------------\n",
      "Total parameters: 935434\n",
      "Epoch 1/10\n",
      " - 2s - loss_1: 0.0840 - loss_2: 0.0898 - loss_3: 0.0895 - loss_4: 0.0881 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3634 - val_loss_2: 0.3634 - val_loss_3: 0.3634 - val_loss_4: 0.3634 - val_acc_ensemble: 0.8983 - val_acc_1: 0.8983 - val_acc_2: 0.8983 - val_acc_3: 0.8983 - val_acc_4: 0.8983\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 8.7962e-04 - loss_2: 8.4841e-04 - loss_3: 8.1219e-04 - loss_4: 8.4219e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3674 - val_loss_2: 0.3674 - val_loss_3: 0.3674 - val_loss_4: 0.3674 - val_acc_ensemble: 0.8998 - val_acc_1: 0.8998 - val_acc_2: 0.8998 - val_acc_3: 0.8998 - val_acc_4: 0.8998\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 4.3876e-04 - loss_2: 4.4505e-04 - loss_3: 4.5391e-04 - loss_4: 4.4054e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3723 - val_loss_2: 0.3723 - val_loss_3: 0.3723 - val_loss_4: 0.3723 - val_acc_ensemble: 0.9005 - val_acc_1: 0.9005 - val_acc_2: 0.9005 - val_acc_3: 0.9005 - val_acc_4: 0.9005\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 2.7359e-04 - loss_2: 2.7832e-04 - loss_3: 2.8003e-04 - loss_4: 2.8150e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3774 - val_loss_2: 0.3774 - val_loss_3: 0.3774 - val_loss_4: 0.3774 - val_acc_ensemble: 0.9013 - val_acc_1: 0.9013 - val_acc_2: 0.9013 - val_acc_3: 0.9013 - val_acc_4: 0.9013\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 2.0442e-04 - loss_2: 1.9855e-04 - loss_3: 1.9224e-04 - loss_4: 1.9508e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3819 - val_loss_2: 0.3819 - val_loss_3: 0.3819 - val_loss_4: 0.3819 - val_acc_ensemble: 0.9016 - val_acc_1: 0.9016 - val_acc_2: 0.9016 - val_acc_3: 0.9016 - val_acc_4: 0.9016\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 1.5233e-04 - loss_2: 1.5380e-04 - loss_3: 1.5057e-04 - loss_4: 1.4600e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3854 - val_loss_2: 0.3854 - val_loss_3: 0.3854 - val_loss_4: 0.3854 - val_acc_ensemble: 0.9023 - val_acc_1: 0.9023 - val_acc_2: 0.9023 - val_acc_3: 0.9023 - val_acc_4: 0.9023\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 1.1503e-04 - loss_2: 1.1603e-04 - loss_3: 1.1562e-04 - loss_4: 1.1618e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3887 - val_loss_2: 0.3887 - val_loss_3: 0.3887 - val_loss_4: 0.3887 - val_acc_ensemble: 0.9028 - val_acc_1: 0.9028 - val_acc_2: 0.9028 - val_acc_3: 0.9028 - val_acc_4: 0.9028\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 9.6571e-05 - loss_2: 9.4923e-05 - loss_3: 9.2724e-05 - loss_4: 8.9816e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3922 - val_loss_2: 0.3922 - val_loss_3: 0.3922 - val_loss_4: 0.3922 - val_acc_ensemble: 0.9025 - val_acc_1: 0.9025 - val_acc_2: 0.9025 - val_acc_3: 0.9025 - val_acc_4: 0.9025\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 7.5927e-05 - loss_2: 7.6015e-05 - loss_3: 7.5298e-05 - loss_4: 7.7474e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3951 - val_loss_2: 0.3951 - val_loss_3: 0.3951 - val_loss_4: 0.3951 - val_acc_ensemble: 0.9028 - val_acc_1: 0.9028 - val_acc_2: 0.9028 - val_acc_3: 0.9028 - val_acc_4: 0.9028\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 6.2806e-05 - loss_2: 6.6594e-05 - loss_3: 6.1653e-05 - loss_4: 6.4051e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3978 - val_loss_2: 0.3978 - val_loss_3: 0.3978 - val_loss_4: 0.3978 - val_acc_ensemble: 0.9031 - val_acc_1: 0.9031 - val_acc_2: 0.9031 - val_acc_3: 0.9031 - val_acc_4: 0.9031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensitivity/vb-mnist-fcn3A/B4/S1.00\n",
      "i  Layer name                Output shape   Num param  Inbound  \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,512] []  401920     input    \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,512] []  1024       fc1      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,512] []  0          bn1      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,512] []  262656     relu1    \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,512] []  1024       fc2      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,512] []  0          bn2      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,512] []  262656     relu2    \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,512] []  1024       fc3      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,512] []  0          bn3      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]      5130       relu3    \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "----------------------------------------------------------------\n",
      "Total parameters: 935434\n",
      "Epoch 1/10\n",
      " - 1s - loss_1: 0.0913 - loss_2: 0.0914 - loss_3: 0.0835 - loss_4: 0.0913 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3533 - val_loss_2: 0.3533 - val_loss_3: 0.3533 - val_loss_4: 0.3533 - val_acc_ensemble: 0.8988 - val_acc_1: 0.8988 - val_acc_2: 0.8988 - val_acc_3: 0.8988 - val_acc_4: 0.8988\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 8.4347e-04 - loss_2: 8.2319e-04 - loss_3: 8.5746e-04 - loss_4: 8.4914e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3603 - val_loss_2: 0.3603 - val_loss_3: 0.3603 - val_loss_4: 0.3603 - val_acc_ensemble: 0.8999 - val_acc_1: 0.8999 - val_acc_2: 0.8999 - val_acc_3: 0.8999 - val_acc_4: 0.8999\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 4.4226e-04 - loss_2: 4.3077e-04 - loss_3: 4.3567e-04 - loss_4: 4.3951e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3664 - val_loss_2: 0.3664 - val_loss_3: 0.3664 - val_loss_4: 0.3664 - val_acc_ensemble: 0.9003 - val_acc_1: 0.9003 - val_acc_2: 0.9003 - val_acc_3: 0.9003 - val_acc_4: 0.9003\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 2.8593e-04 - loss_2: 2.9125e-04 - loss_3: 2.9241e-04 - loss_4: 2.8259e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3708 - val_loss_2: 0.3708 - val_loss_3: 0.3708 - val_loss_4: 0.3708 - val_acc_ensemble: 0.9007 - val_acc_1: 0.9007 - val_acc_2: 0.9007 - val_acc_3: 0.9007 - val_acc_4: 0.9007\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 2.0104e-04 - loss_2: 2.0119e-04 - loss_3: 1.9815e-04 - loss_4: 1.9753e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3756 - val_loss_2: 0.3756 - val_loss_3: 0.3756 - val_loss_4: 0.3756 - val_acc_ensemble: 0.9012 - val_acc_1: 0.9012 - val_acc_2: 0.9012 - val_acc_3: 0.9012 - val_acc_4: 0.9012\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 1.4858e-04 - loss_2: 1.5194e-04 - loss_3: 1.4912e-04 - loss_4: 1.5505e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3795 - val_loss_2: 0.3795 - val_loss_3: 0.3795 - val_loss_4: 0.3795 - val_acc_ensemble: 0.9013 - val_acc_1: 0.9013 - val_acc_2: 0.9013 - val_acc_3: 0.9013 - val_acc_4: 0.9013\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 1.2085e-04 - loss_2: 1.1367e-04 - loss_3: 1.1197e-04 - loss_4: 1.1239e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3833 - val_loss_2: 0.3833 - val_loss_3: 0.3833 - val_loss_4: 0.3833 - val_acc_ensemble: 0.9008 - val_acc_1: 0.9008 - val_acc_2: 0.9008 - val_acc_3: 0.9008 - val_acc_4: 0.9008\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 9.6162e-05 - loss_2: 9.4187e-05 - loss_3: 9.2193e-05 - loss_4: 9.2481e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3871 - val_loss_2: 0.3871 - val_loss_3: 0.3871 - val_loss_4: 0.3871 - val_acc_ensemble: 0.9006 - val_acc_1: 0.9006 - val_acc_2: 0.9006 - val_acc_3: 0.9006 - val_acc_4: 0.9006\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 7.8005e-05 - loss_2: 8.1805e-05 - loss_3: 7.7209e-05 - loss_4: 7.4851e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3904 - val_loss_2: 0.3904 - val_loss_3: 0.3904 - val_loss_4: 0.3904 - val_acc_ensemble: 0.9003 - val_acc_1: 0.9003 - val_acc_2: 0.9003 - val_acc_3: 0.9003 - val_acc_4: 0.9003\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 6.4099e-05 - loss_2: 6.7278e-05 - loss_3: 6.4158e-05 - loss_4: 6.4673e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3932 - val_loss_2: 0.3932 - val_loss_3: 0.3932 - val_loss_4: 0.3932 - val_acc_ensemble: 0.9003 - val_acc_1: 0.9003 - val_acc_2: 0.9003 - val_acc_3: 0.9003 - val_acc_4: 0.9003\n",
      "sensitivity/vb-mnist-fcn3A/B4/S1.00\n",
      "i  Layer name                Output shape   Num param  Inbound  \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,512] []  401920     input    \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,512] []  1024       fc1      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,512] []  0          bn1      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,512] []  262656     relu1    \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,512] []  1024       fc2      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,512] []  0          bn2      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,512] []  262656     relu2    \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,512] []  1024       fc3      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,512] []  0          bn3      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]      5130       relu3    \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "----------------------------------------------------------------\n",
      "Total parameters: 935434\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss_1: 0.0904 - loss_2: 0.0884 - loss_3: 0.0752 - loss_4: 0.0946 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3672 - val_loss_2: 0.3672 - val_loss_3: 0.3672 - val_loss_4: 0.3672 - val_acc_ensemble: 0.8952 - val_acc_1: 0.8952 - val_acc_2: 0.8952 - val_acc_3: 0.8952 - val_acc_4: 0.8952\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 8.2518e-04 - loss_2: 8.2157e-04 - loss_3: 8.1102e-04 - loss_4: 7.6354e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3699 - val_loss_2: 0.3699 - val_loss_3: 0.3699 - val_loss_4: 0.3699 - val_acc_ensemble: 0.8969 - val_acc_1: 0.8969 - val_acc_2: 0.8969 - val_acc_3: 0.8969 - val_acc_4: 0.8969\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 4.2615e-04 - loss_2: 4.2980e-04 - loss_3: 4.4247e-04 - loss_4: 4.2814e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3753 - val_loss_2: 0.3753 - val_loss_3: 0.3753 - val_loss_4: 0.3753 - val_acc_ensemble: 0.8968 - val_acc_1: 0.8968 - val_acc_2: 0.8968 - val_acc_3: 0.8968 - val_acc_4: 0.8968\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 2.7913e-04 - loss_2: 2.7394e-04 - loss_3: 2.7015e-04 - loss_4: 2.6653e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3793 - val_loss_2: 0.3793 - val_loss_3: 0.3793 - val_loss_4: 0.3793 - val_acc_ensemble: 0.8972 - val_acc_1: 0.8972 - val_acc_2: 0.8972 - val_acc_3: 0.8972 - val_acc_4: 0.8972\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 2.0063e-04 - loss_2: 1.8809e-04 - loss_3: 1.9334e-04 - loss_4: 1.9713e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3838 - val_loss_2: 0.3838 - val_loss_3: 0.3838 - val_loss_4: 0.3838 - val_acc_ensemble: 0.8971 - val_acc_1: 0.8971 - val_acc_2: 0.8971 - val_acc_3: 0.8971 - val_acc_4: 0.8971\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 1.4884e-04 - loss_2: 1.4562e-04 - loss_3: 1.4695e-04 - loss_4: 1.4511e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3874 - val_loss_2: 0.3874 - val_loss_3: 0.3874 - val_loss_4: 0.3874 - val_acc_ensemble: 0.8973 - val_acc_1: 0.8973 - val_acc_2: 0.8973 - val_acc_3: 0.8973 - val_acc_4: 0.8973\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 1.1238e-04 - loss_2: 1.1367e-04 - loss_3: 1.1419e-04 - loss_4: 1.1589e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3910 - val_loss_2: 0.3910 - val_loss_3: 0.3910 - val_loss_4: 0.3910 - val_acc_ensemble: 0.8974 - val_acc_1: 0.8974 - val_acc_2: 0.8974 - val_acc_3: 0.8974 - val_acc_4: 0.8974\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 9.3689e-05 - loss_2: 9.4879e-05 - loss_3: 9.2725e-05 - loss_4: 9.2053e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3950 - val_loss_2: 0.3950 - val_loss_3: 0.3950 - val_loss_4: 0.3950 - val_acc_ensemble: 0.8973 - val_acc_1: 0.8973 - val_acc_2: 0.8973 - val_acc_3: 0.8973 - val_acc_4: 0.8973\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 7.2458e-05 - loss_2: 7.8189e-05 - loss_3: 7.5706e-05 - loss_4: 7.5115e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.3980 - val_loss_2: 0.3980 - val_loss_3: 0.3980 - val_loss_4: 0.3980 - val_acc_ensemble: 0.8977 - val_acc_1: 0.8977 - val_acc_2: 0.8977 - val_acc_3: 0.8977 - val_acc_4: 0.8977\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 6.5249e-05 - loss_2: 6.2967e-05 - loss_3: 6.3817e-05 - loss_4: 6.1127e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - val_loss_1: 0.4006 - val_loss_2: 0.4006 - val_loss_3: 0.4006 - val_loss_4: 0.4006 - val_acc_ensemble: 0.8981 - val_acc_1: 0.8981 - val_acc_2: 0.8981 - val_acc_3: 0.8981 - val_acc_4: 0.8981\n",
      "sensitivity/vb-mnist-fcn3A/B5/S0.00\n",
      "i  Layer name                Output shape   Num param  Inbound  \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "0  fc1 (Dense)               [] [None,512]  2009600    input    \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [] [None,512]  5120       fc1      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "2  relu1 (Activation)        [] [None,512]  0          bn1      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "3  fc2 (Dense)               [] [None,512]  1313280    relu1    \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [] [None,512]  5120       fc2      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "5  relu2 (Activation)        [] [None,512]  0          bn2      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "6  fc3 (Dense)               [] [None,512]  1313280    relu2    \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [] [None,512]  5120       fc3      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "8  relu3 (Activation)        [] [None,512]  0          bn3      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]      25650      relu3    \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "----------------------------------------------------------------\n",
      "Total parameters: 4677170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 2s - loss_1: 0.2435 - loss_2: 0.2558 - loss_3: 0.2364 - loss_4: 0.2779 - loss_5: 0.2483 - acc_ensemble: 1.0000 - acc_1: 0.9983 - acc_2: 0.9983 - acc_3: 0.9883 - acc_4: 0.9917 - acc_5: 0.9950 - val_loss_1: 0.4550 - val_loss_2: 0.4162 - val_loss_3: 0.5104 - val_loss_4: 0.4107 - val_loss_5: 0.4696 - val_acc_ensemble: 0.9082 - val_acc_1: 0.8768 - val_acc_2: 0.8872 - val_acc_3: 0.8655 - val_acc_4: 0.8846 - val_acc_5: 0.8783\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 0.0073 - loss_2: 0.0148 - loss_3: 0.0090 - loss_4: 0.0104 - loss_5: 0.0073 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 0.9967 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 0.9983 - val_loss_1: 0.4010 - val_loss_2: 0.4416 - val_loss_3: 0.4058 - val_loss_4: 0.4025 - val_loss_5: 0.4134 - val_acc_ensemble: 0.9111 - val_acc_1: 0.8937 - val_acc_2: 0.8842 - val_acc_3: 0.8957 - val_acc_4: 0.8934 - val_acc_5: 0.8990\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 6.7813e-04 - loss_2: 0.0020 - loss_3: 0.0011 - loss_4: 9.1190e-04 - loss_5: 9.8124e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3962 - val_loss_2: 0.4163 - val_loss_3: 0.3999 - val_loss_4: 0.4011 - val_loss_5: 0.4011 - val_acc_ensemble: 0.9120 - val_acc_1: 0.8968 - val_acc_2: 0.8959 - val_acc_3: 0.8993 - val_acc_4: 0.8976 - val_acc_5: 0.9029\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 4.3344e-04 - loss_2: 5.2522e-04 - loss_3: 4.5467e-04 - loss_4: 4.2358e-04 - loss_5: 4.3648e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3946 - val_loss_2: 0.4165 - val_loss_3: 0.3992 - val_loss_4: 0.4001 - val_loss_5: 0.4019 - val_acc_ensemble: 0.9123 - val_acc_1: 0.8978 - val_acc_2: 0.8974 - val_acc_3: 0.9001 - val_acc_4: 0.8983 - val_acc_5: 0.9037\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 3.1162e-04 - loss_2: 3.3243e-04 - loss_3: 3.0917e-04 - loss_4: 3.1203e-04 - loss_5: 3.1619e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3959 - val_loss_2: 0.4161 - val_loss_3: 0.4006 - val_loss_4: 0.4007 - val_loss_5: 0.4034 - val_acc_ensemble: 0.9124 - val_acc_1: 0.8987 - val_acc_2: 0.8975 - val_acc_3: 0.9012 - val_acc_4: 0.8998 - val_acc_5: 0.9046\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 2.5600e-04 - loss_2: 2.5551e-04 - loss_3: 2.3667e-04 - loss_4: 2.4290e-04 - loss_5: 2.4753e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3970 - val_loss_2: 0.4176 - val_loss_3: 0.4018 - val_loss_4: 0.4014 - val_loss_5: 0.4052 - val_acc_ensemble: 0.9128 - val_acc_1: 0.8992 - val_acc_2: 0.8980 - val_acc_3: 0.9014 - val_acc_4: 0.9011 - val_acc_5: 0.9044\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 1.9140e-04 - loss_2: 2.0126e-04 - loss_3: 1.9045e-04 - loss_4: 2.1351e-04 - loss_5: 2.0230e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3991 - val_loss_2: 0.4196 - val_loss_3: 0.4032 - val_loss_4: 0.4032 - val_loss_5: 0.4077 - val_acc_ensemble: 0.9130 - val_acc_1: 0.8995 - val_acc_2: 0.8979 - val_acc_3: 0.9024 - val_acc_4: 0.9010 - val_acc_5: 0.9040\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 1.6855e-04 - loss_2: 1.6658e-04 - loss_3: 1.6462e-04 - loss_4: 1.6643e-04 - loss_5: 1.6497e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4005 - val_loss_2: 0.4212 - val_loss_3: 0.4051 - val_loss_4: 0.4048 - val_loss_5: 0.4088 - val_acc_ensemble: 0.9129 - val_acc_1: 0.8999 - val_acc_2: 0.8981 - val_acc_3: 0.9022 - val_acc_4: 0.9016 - val_acc_5: 0.9043\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 1.3945e-04 - loss_2: 1.4869e-04 - loss_3: 1.3593e-04 - loss_4: 1.4649e-04 - loss_5: 1.3903e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4011 - val_loss_2: 0.4229 - val_loss_3: 0.4064 - val_loss_4: 0.4061 - val_loss_5: 0.4109 - val_acc_ensemble: 0.9132 - val_acc_1: 0.9003 - val_acc_2: 0.8978 - val_acc_3: 0.9022 - val_acc_4: 0.9021 - val_acc_5: 0.9042\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 1.2813e-04 - loss_2: 1.2187e-04 - loss_3: 1.2106e-04 - loss_4: 1.2358e-04 - loss_5: 1.2149e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4025 - val_loss_2: 0.4236 - val_loss_3: 0.4080 - val_loss_4: 0.4079 - val_loss_5: 0.4119 - val_acc_ensemble: 0.9133 - val_acc_1: 0.9006 - val_acc_2: 0.8977 - val_acc_3: 0.9025 - val_acc_4: 0.9025 - val_acc_5: 0.9045\n",
      "sensitivity/vb-mnist-fcn3A/B5/S0.00\n",
      "i  Layer name                Output shape   Num param  Inbound  \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "0  fc1 (Dense)               [] [None,512]  2009600    input    \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [] [None,512]  5120       fc1      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "2  relu1 (Activation)        [] [None,512]  0          bn1      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "3  fc2 (Dense)               [] [None,512]  1313280    relu1    \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [] [None,512]  5120       fc2      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "5  relu2 (Activation)        [] [None,512]  0          bn2      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "6  fc3 (Dense)               [] [None,512]  1313280    relu2    \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [] [None,512]  5120       fc3      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "8  relu3 (Activation)        [] [None,512]  0          bn3      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]      25650      relu3    \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "----------------------------------------------------------------\n",
      "Total parameters: 4677170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 2s - loss_1: 0.2568 - loss_2: 0.2572 - loss_3: 0.2522 - loss_4: 0.2648 - loss_5: 0.2455 - acc_ensemble: 1.0000 - acc_1: 0.9983 - acc_2: 0.9983 - acc_3: 1.0000 - acc_4: 0.9950 - acc_5: 0.9900 - val_loss_1: 0.4094 - val_loss_2: 0.4505 - val_loss_3: 0.4270 - val_loss_4: 0.4319 - val_loss_5: 0.4813 - val_acc_ensemble: 0.9080 - val_acc_1: 0.8858 - val_acc_2: 0.8769 - val_acc_3: 0.8796 - val_acc_4: 0.8751 - val_acc_5: 0.8638\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 0.0054 - loss_2: 0.0188 - loss_3: 0.0071 - loss_4: 0.0051 - loss_5: 0.0090 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 0.9983 - acc_4: 0.9983 - acc_5: 1.0000 - val_loss_1: 0.3959 - val_loss_2: 0.4707 - val_loss_3: 0.4297 - val_loss_4: 0.3915 - val_loss_5: 0.4239 - val_acc_ensemble: 0.9108 - val_acc_1: 0.8976 - val_acc_2: 0.8745 - val_acc_3: 0.8889 - val_acc_4: 0.8919 - val_acc_5: 0.8899\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 7.5492e-04 - loss_2: 0.0016 - loss_3: 0.0040 - loss_4: 7.3384e-04 - loss_5: 7.9162e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3913 - val_loss_2: 0.4198 - val_loss_3: 0.3925 - val_loss_4: 0.3754 - val_loss_5: 0.4085 - val_acc_ensemble: 0.9133 - val_acc_1: 0.8998 - val_acc_2: 0.8913 - val_acc_3: 0.8993 - val_acc_4: 0.8992 - val_acc_5: 0.8967\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 4.5655e-04 - loss_2: 4.6440e-04 - loss_3: 4.9530e-04 - loss_4: 4.5062e-04 - loss_5: 4.5514e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3899 - val_loss_2: 0.4161 - val_loss_3: 0.3893 - val_loss_4: 0.3747 - val_loss_5: 0.4064 - val_acc_ensemble: 0.9137 - val_acc_1: 0.9015 - val_acc_2: 0.8939 - val_acc_3: 0.9003 - val_acc_4: 0.8997 - val_acc_5: 0.8982\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 3.2191e-04 - loss_2: 0.0105 - loss_3: 3.3156e-04 - loss_4: 3.2683e-04 - loss_5: 3.2494e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3913 - val_loss_2: 0.5170 - val_loss_3: 0.3884 - val_loss_4: 0.3762 - val_loss_5: 0.4056 - val_acc_ensemble: 0.9144 - val_acc_1: 0.9017 - val_acc_2: 0.8690 - val_acc_3: 0.9014 - val_acc_4: 0.9003 - val_acc_5: 0.9000\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 2.5154e-04 - loss_2: 0.0018 - loss_3: 2.7417e-04 - loss_4: 2.6146e-04 - loss_5: 2.5616e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3926 - val_loss_2: 0.4244 - val_loss_3: 0.3883 - val_loss_4: 0.3779 - val_loss_5: 0.4060 - val_acc_ensemble: 0.9153 - val_acc_1: 0.9030 - val_acc_2: 0.8930 - val_acc_3: 0.9019 - val_acc_4: 0.9006 - val_acc_5: 0.9014\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 2.0461e-04 - loss_2: 3.9273e-04 - loss_3: 2.1265e-04 - loss_4: 2.0670e-04 - loss_5: 2.1303e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3942 - val_loss_2: 0.4162 - val_loss_3: 0.3891 - val_loss_4: 0.3789 - val_loss_5: 0.4065 - val_acc_ensemble: 0.9156 - val_acc_1: 0.9029 - val_acc_2: 0.8965 - val_acc_3: 0.9026 - val_acc_4: 0.9010 - val_acc_5: 0.9017\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 1.7548e-04 - loss_2: 2.4655e-04 - loss_3: 1.7463e-04 - loss_4: 1.7348e-04 - loss_5: 1.6604e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3953 - val_loss_2: 0.4156 - val_loss_3: 0.3898 - val_loss_4: 0.3799 - val_loss_5: 0.4077 - val_acc_ensemble: 0.9155 - val_acc_1: 0.9037 - val_acc_2: 0.8982 - val_acc_3: 0.9031 - val_acc_4: 0.9015 - val_acc_5: 0.9020\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 1.5028e-04 - loss_2: 1.8740e-04 - loss_3: 1.4875e-04 - loss_4: 1.4830e-04 - loss_5: 1.5327e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3964 - val_loss_2: 0.4160 - val_loss_3: 0.3918 - val_loss_4: 0.3814 - val_loss_5: 0.4076 - val_acc_ensemble: 0.9155 - val_acc_1: 0.9035 - val_acc_2: 0.8991 - val_acc_3: 0.9032 - val_acc_4: 0.9019 - val_acc_5: 0.9024\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 1.2946e-04 - loss_2: 1.5894e-04 - loss_3: 1.2549e-04 - loss_4: 1.3053e-04 - loss_5: 1.2553e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3969 - val_loss_2: 0.4174 - val_loss_3: 0.3929 - val_loss_4: 0.3828 - val_loss_5: 0.4086 - val_acc_ensemble: 0.9157 - val_acc_1: 0.9046 - val_acc_2: 0.8997 - val_acc_3: 0.9032 - val_acc_4: 0.9016 - val_acc_5: 0.9027\n",
      "sensitivity/vb-mnist-fcn3A/B5/S0.00\n",
      "i  Layer name                Output shape   Num param  Inbound  \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "0  fc1 (Dense)               [] [None,512]  2009600    input    \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [] [None,512]  5120       fc1      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "2  relu1 (Activation)        [] [None,512]  0          bn1      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "3  fc2 (Dense)               [] [None,512]  1313280    relu1    \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [] [None,512]  5120       fc2      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "5  relu2 (Activation)        [] [None,512]  0          bn2      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "6  fc3 (Dense)               [] [None,512]  1313280    relu2    \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [] [None,512]  5120       fc3      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "8  relu3 (Activation)        [] [None,512]  0          bn3      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]      25650      relu3    \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "----------------------------------------------------------------\n",
      "Total parameters: 4677170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 2s - loss_1: 0.2777 - loss_2: 0.2586 - loss_3: 0.2481 - loss_4: 0.2338 - loss_5: 0.2586 - acc_ensemble: 1.0000 - acc_1: 0.9917 - acc_2: 0.9983 - acc_3: 0.9900 - acc_4: 1.0000 - acc_5: 0.9983 - val_loss_1: 0.4272 - val_loss_2: 0.4193 - val_loss_3: 0.4988 - val_loss_4: 0.4271 - val_loss_5: 0.4291 - val_acc_ensemble: 0.9047 - val_acc_1: 0.8832 - val_acc_2: 0.8846 - val_acc_3: 0.8592 - val_acc_4: 0.8816 - val_acc_5: 0.8805\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 0.0129 - loss_2: 0.0028 - loss_3: 0.0101 - loss_4: 0.0125 - loss_5: 0.0055 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 0.9917 - acc_5: 1.0000 - val_loss_1: 0.3965 - val_loss_2: 0.3808 - val_loss_3: 0.3895 - val_loss_4: 0.5148 - val_loss_5: 0.3865 - val_acc_ensemble: 0.9106 - val_acc_1: 0.8970 - val_acc_2: 0.9000 - val_acc_3: 0.8977 - val_acc_4: 0.8767 - val_acc_5: 0.8967\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 9.5198e-04 - loss_2: 7.4809e-04 - loss_3: 8.4822e-04 - loss_4: 0.0066 - loss_5: 7.6972e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3909 - val_loss_2: 0.3790 - val_loss_3: 0.3824 - val_loss_4: 0.4377 - val_loss_5: 0.3863 - val_acc_ensemble: 0.9113 - val_acc_1: 0.8985 - val_acc_2: 0.9030 - val_acc_3: 0.8995 - val_acc_4: 0.8910 - val_acc_5: 0.8985\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 5.1218e-04 - loss_2: 4.3952e-04 - loss_3: 5.0577e-04 - loss_4: 5.4448e-04 - loss_5: 4.3470e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3911 - val_loss_2: 0.3792 - val_loss_3: 0.3818 - val_loss_4: 0.4284 - val_loss_5: 0.3873 - val_acc_ensemble: 0.9125 - val_acc_1: 0.8990 - val_acc_2: 0.9037 - val_acc_3: 0.9014 - val_acc_4: 0.8957 - val_acc_5: 0.9005\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 3.7188e-04 - loss_2: 3.3801e-04 - loss_3: 3.5386e-04 - loss_4: 3.3934e-04 - loss_5: 3.2870e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3921 - val_loss_2: 0.3818 - val_loss_3: 0.3823 - val_loss_4: 0.4297 - val_loss_5: 0.3901 - val_acc_ensemble: 0.9128 - val_acc_1: 0.8997 - val_acc_2: 0.9045 - val_acc_3: 0.9015 - val_acc_4: 0.8953 - val_acc_5: 0.9008\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 2.8746e-04 - loss_2: 2.4480e-04 - loss_3: 2.6290e-04 - loss_4: 2.3988e-04 - loss_5: 2.5853e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3931 - val_loss_2: 0.3837 - val_loss_3: 0.3838 - val_loss_4: 0.4292 - val_loss_5: 0.3911 - val_acc_ensemble: 0.9129 - val_acc_1: 0.9005 - val_acc_2: 0.9049 - val_acc_3: 0.9016 - val_acc_4: 0.8962 - val_acc_5: 0.9014\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 2.2571e-04 - loss_2: 2.2068e-04 - loss_3: 2.0451e-04 - loss_4: 1.9653e-04 - loss_5: 2.1171e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3947 - val_loss_2: 0.3856 - val_loss_3: 0.3855 - val_loss_4: 0.4309 - val_loss_5: 0.3938 - val_acc_ensemble: 0.9130 - val_acc_1: 0.9010 - val_acc_2: 0.9055 - val_acc_3: 0.9022 - val_acc_4: 0.8970 - val_acc_5: 0.9017\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 1.9541e-04 - loss_2: 1.8112e-04 - loss_3: 1.7862e-04 - loss_4: 1.6170e-04 - loss_5: 1.6941e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3960 - val_loss_2: 0.3872 - val_loss_3: 0.3868 - val_loss_4: 0.4316 - val_loss_5: 0.3958 - val_acc_ensemble: 0.9126 - val_acc_1: 0.9014 - val_acc_2: 0.9055 - val_acc_3: 0.9027 - val_acc_4: 0.8976 - val_acc_5: 0.9021\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 1.6273e-04 - loss_2: 1.5404e-04 - loss_3: 1.5237e-04 - loss_4: 1.3291e-04 - loss_5: 1.4567e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3977 - val_loss_2: 0.3891 - val_loss_3: 0.3887 - val_loss_4: 0.4330 - val_loss_5: 0.3979 - val_acc_ensemble: 0.9126 - val_acc_1: 0.9017 - val_acc_2: 0.9053 - val_acc_3: 0.9029 - val_acc_4: 0.8977 - val_acc_5: 0.9023\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 1.4398e-04 - loss_2: 1.3431e-04 - loss_3: 1.3406e-04 - loss_4: 1.1465e-04 - loss_5: 1.2901e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3989 - val_loss_2: 0.3905 - val_loss_3: 0.3904 - val_loss_4: 0.4338 - val_loss_5: 0.4005 - val_acc_ensemble: 0.9131 - val_acc_1: 0.9019 - val_acc_2: 0.9056 - val_acc_3: 0.9031 - val_acc_4: 0.8983 - val_acc_5: 0.9019\n",
      "sensitivity/vb-mnist-fcn3A/B5/S0.00\n",
      "i  Layer name                Output shape   Num param  Inbound  \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "0  fc1 (Dense)               [] [None,512]  2009600    input    \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [] [None,512]  5120       fc1      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "2  relu1 (Activation)        [] [None,512]  0          bn1      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "3  fc2 (Dense)               [] [None,512]  1313280    relu1    \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [] [None,512]  5120       fc2      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "5  relu2 (Activation)        [] [None,512]  0          bn2      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "6  fc3 (Dense)               [] [None,512]  1313280    relu2    \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [] [None,512]  5120       fc3      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "8  relu3 (Activation)        [] [None,512]  0          bn3      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]      25650      relu3    \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "----------------------------------------------------------------\n",
      "Total parameters: 4677170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 2s - loss_1: 0.2578 - loss_2: 0.2563 - loss_3: 0.2544 - loss_4: 0.2302 - loss_5: 0.2691 - acc_ensemble: 1.0000 - acc_1: 0.9950 - acc_2: 0.9983 - acc_3: 0.9883 - acc_4: 0.9933 - acc_5: 0.9983 - val_loss_1: 0.4386 - val_loss_2: 0.4270 - val_loss_3: 0.5071 - val_loss_4: 0.4385 - val_loss_5: 0.4762 - val_acc_ensemble: 0.9014 - val_acc_1: 0.8770 - val_acc_2: 0.8822 - val_acc_3: 0.8655 - val_acc_4: 0.8759 - val_acc_5: 0.8696\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 0.0066 - loss_2: 0.0026 - loss_3: 0.0233 - loss_4: 0.0126 - loss_5: 0.0113 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 0.9983 - acc_5: 1.0000 - val_loss_1: 0.3839 - val_loss_2: 0.3967 - val_loss_3: 0.4306 - val_loss_4: 0.4208 - val_loss_5: 0.4081 - val_acc_ensemble: 0.9097 - val_acc_1: 0.8996 - val_acc_2: 0.8952 - val_acc_3: 0.8913 - val_acc_4: 0.8875 - val_acc_5: 0.8940\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 7.2304e-04 - loss_2: 7.6602e-04 - loss_3: 0.0022 - loss_4: 0.0018 - loss_5: 0.0010 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3856 - val_loss_2: 0.3874 - val_loss_3: 0.4069 - val_loss_4: 0.3944 - val_loss_5: 0.3957 - val_acc_ensemble: 0.9105 - val_acc_1: 0.8998 - val_acc_2: 0.8999 - val_acc_3: 0.8972 - val_acc_4: 0.8976 - val_acc_5: 0.9004\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 4.4614e-04 - loss_2: 4.6116e-04 - loss_3: 5.2158e-04 - loss_4: 5.3379e-04 - loss_5: 5.0412e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3851 - val_loss_2: 0.3860 - val_loss_3: 0.4071 - val_loss_4: 0.3943 - val_loss_5: 0.3970 - val_acc_ensemble: 0.9112 - val_acc_1: 0.9014 - val_acc_2: 0.9013 - val_acc_3: 0.8977 - val_acc_4: 0.8983 - val_acc_5: 0.9012\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 3.0755e-04 - loss_2: 3.3627e-04 - loss_3: 3.6286e-04 - loss_4: 3.4234e-04 - loss_5: 3.7518e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3853 - val_loss_2: 0.3848 - val_loss_3: 0.4065 - val_loss_4: 0.3960 - val_loss_5: 0.3982 - val_acc_ensemble: 0.9118 - val_acc_1: 0.9024 - val_acc_2: 0.9015 - val_acc_3: 0.8984 - val_acc_4: 0.8986 - val_acc_5: 0.9017\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 2.4813e-04 - loss_2: 2.6278e-04 - loss_3: 2.8397e-04 - loss_4: 2.6508e-04 - loss_5: 2.8641e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3878 - val_loss_2: 0.3848 - val_loss_3: 0.4080 - val_loss_4: 0.3969 - val_loss_5: 0.3995 - val_acc_ensemble: 0.9119 - val_acc_1: 0.9033 - val_acc_2: 0.9019 - val_acc_3: 0.8990 - val_acc_4: 0.8992 - val_acc_5: 0.9020\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 2.1668e-04 - loss_2: 2.1219e-04 - loss_3: 2.2967e-04 - loss_4: 2.1458e-04 - loss_5: 2.4020e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3887 - val_loss_2: 0.3855 - val_loss_3: 0.4093 - val_loss_4: 0.3978 - val_loss_5: 0.4005 - val_acc_ensemble: 0.9118 - val_acc_1: 0.9035 - val_acc_2: 0.9032 - val_acc_3: 0.8992 - val_acc_4: 0.8998 - val_acc_5: 0.9025\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 1.7447e-04 - loss_2: 1.7845e-04 - loss_3: 1.8348e-04 - loss_4: 1.7968e-04 - loss_5: 1.8494e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3896 - val_loss_2: 0.3868 - val_loss_3: 0.4102 - val_loss_4: 0.3993 - val_loss_5: 0.4015 - val_acc_ensemble: 0.9123 - val_acc_1: 0.9041 - val_acc_2: 0.9032 - val_acc_3: 0.8999 - val_acc_4: 0.9001 - val_acc_5: 0.9025\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 1.4331e-04 - loss_2: 1.5011e-04 - loss_3: 1.5423e-04 - loss_4: 1.5135e-04 - loss_5: 1.6429e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3910 - val_loss_2: 0.3880 - val_loss_3: 0.4114 - val_loss_4: 0.4002 - val_loss_5: 0.4026 - val_acc_ensemble: 0.9123 - val_acc_1: 0.9048 - val_acc_2: 0.9041 - val_acc_3: 0.9006 - val_acc_4: 0.9003 - val_acc_5: 0.9029\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 1.2930e-04 - loss_2: 1.2742e-04 - loss_3: 1.3842e-04 - loss_4: 1.3151e-04 - loss_5: 1.4637e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3923 - val_loss_2: 0.3893 - val_loss_3: 0.4125 - val_loss_4: 0.4011 - val_loss_5: 0.4043 - val_acc_ensemble: 0.9126 - val_acc_1: 0.9048 - val_acc_2: 0.9040 - val_acc_3: 0.9011 - val_acc_4: 0.9012 - val_acc_5: 0.9027\n",
      "sensitivity/vb-mnist-fcn3A/B5/S0.25\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,128] [None,384]  1607680    input    \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,128] [None,384]  4096       fc1      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,128] [None,384]  0          bn1      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,128] [None,384]  1249792    relu1    \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,128] [None,384]  4096       fc2      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,128] [None,384]  0          bn2      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,128] [None,384]  1249792    relu2    \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,128] [None,384]  4096       fc3      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,128] [None,384]  0          bn3      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              24668      relu3    \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 4144220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 6s - loss_1: 0.2510 - loss_2: 0.2430 - loss_3: 0.2479 - loss_4: 0.2464 - loss_5: 0.2411 - acc_ensemble: 1.0000 - acc_1: 0.9950 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 0.9983 - acc_5: 0.9967 - val_loss_1: 0.4582 - val_loss_2: 0.4765 - val_loss_3: 0.4533 - val_loss_4: 0.4413 - val_loss_5: 0.4322 - val_acc_ensemble: 0.9042 - val_acc_1: 0.8768 - val_acc_2: 0.8764 - val_acc_3: 0.8765 - val_acc_4: 0.8791 - val_acc_5: 0.8840\n",
      "Epoch 2/10\n",
      " - 2s - loss_1: 0.0053 - loss_2: 0.0020 - loss_3: 0.0026 - loss_4: 0.0034 - loss_5: 0.0062 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4361 - val_loss_2: 0.4232 - val_loss_3: 0.4101 - val_loss_4: 0.4084 - val_loss_5: 0.3925 - val_acc_ensemble: 0.9080 - val_acc_1: 0.8911 - val_acc_2: 0.8921 - val_acc_3: 0.8963 - val_acc_4: 0.8945 - val_acc_5: 0.8983\n",
      "Epoch 3/10\n",
      " - 2s - loss_1: 7.2114e-04 - loss_2: 5.4612e-04 - loss_3: 5.7567e-04 - loss_4: 7.1653e-04 - loss_5: 7.5616e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4312 - val_loss_2: 0.4217 - val_loss_3: 0.4072 - val_loss_4: 0.4042 - val_loss_5: 0.3859 - val_acc_ensemble: 0.9078 - val_acc_1: 0.8944 - val_acc_2: 0.8934 - val_acc_3: 0.8970 - val_acc_4: 0.8972 - val_acc_5: 0.9031\n",
      "Epoch 4/10\n",
      " - 2s - loss_1: 3.8003e-04 - loss_2: 3.7728e-04 - loss_3: 3.9284e-04 - loss_4: 4.1480e-04 - loss_5: 4.1865e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4301 - val_loss_2: 0.4235 - val_loss_3: 0.4093 - val_loss_4: 0.4044 - val_loss_5: 0.3877 - val_acc_ensemble: 0.9086 - val_acc_1: 0.8963 - val_acc_2: 0.8947 - val_acc_3: 0.8980 - val_acc_4: 0.8988 - val_acc_5: 0.9045\n",
      "Epoch 5/10\n",
      " - 2s - loss_1: 2.7354e-04 - loss_2: 2.7975e-04 - loss_3: 2.9150e-04 - loss_4: 3.0980e-04 - loss_5: 3.1342e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4308 - val_loss_2: 0.4262 - val_loss_3: 0.4106 - val_loss_4: 0.4066 - val_loss_5: 0.3900 - val_acc_ensemble: 0.9090 - val_acc_1: 0.8967 - val_acc_2: 0.8948 - val_acc_3: 0.8986 - val_acc_4: 0.8988 - val_acc_5: 0.9052\n",
      "Epoch 6/10\n",
      " - 2s - loss_1: 2.0611e-04 - loss_2: 2.0487e-04 - loss_3: 2.2559e-04 - loss_4: 2.4866e-04 - loss_5: 2.3314e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4321 - val_loss_2: 0.4282 - val_loss_3: 0.4120 - val_loss_4: 0.4081 - val_loss_5: 0.3917 - val_acc_ensemble: 0.9093 - val_acc_1: 0.8974 - val_acc_2: 0.8953 - val_acc_3: 0.8991 - val_acc_4: 0.8996 - val_acc_5: 0.9055\n",
      "Epoch 7/10\n",
      " - 2s - loss_1: 1.6986e-04 - loss_2: 1.8670e-04 - loss_3: 1.8460e-04 - loss_4: 2.0744e-04 - loss_5: 1.9474e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4333 - val_loss_2: 0.4301 - val_loss_3: 0.4135 - val_loss_4: 0.4107 - val_loss_5: 0.3940 - val_acc_ensemble: 0.9099 - val_acc_1: 0.8982 - val_acc_2: 0.8965 - val_acc_3: 0.8990 - val_acc_4: 0.8996 - val_acc_5: 0.9058\n",
      "Epoch 8/10\n",
      " - 2s - loss_1: 1.4786e-04 - loss_2: 1.5466e-04 - loss_3: 1.6081e-04 - loss_4: 1.5871e-04 - loss_5: 1.5851e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4345 - val_loss_2: 0.4311 - val_loss_3: 0.4147 - val_loss_4: 0.4123 - val_loss_5: 0.3957 - val_acc_ensemble: 0.9099 - val_acc_1: 0.8984 - val_acc_2: 0.8968 - val_acc_3: 0.8996 - val_acc_4: 0.8999 - val_acc_5: 0.9056\n",
      "Epoch 9/10\n",
      " - 2s - loss_1: 1.2246e-04 - loss_2: 1.3348e-04 - loss_3: 1.3616e-04 - loss_4: 1.3827e-04 - loss_5: 1.3165e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4356 - val_loss_2: 0.4329 - val_loss_3: 0.4165 - val_loss_4: 0.4139 - val_loss_5: 0.3971 - val_acc_ensemble: 0.9102 - val_acc_1: 0.8985 - val_acc_2: 0.8970 - val_acc_3: 0.9000 - val_acc_4: 0.9003 - val_acc_5: 0.9061\n",
      "Epoch 10/10\n",
      " - 2s - loss_1: 1.1153e-04 - loss_2: 1.1560e-04 - loss_3: 1.2252e-04 - loss_4: 1.1471e-04 - loss_5: 1.0854e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4374 - val_loss_2: 0.4346 - val_loss_3: 0.4179 - val_loss_4: 0.4154 - val_loss_5: 0.3987 - val_acc_ensemble: 0.9102 - val_acc_1: 0.8984 - val_acc_2: 0.8974 - val_acc_3: 0.8999 - val_acc_4: 0.9007 - val_acc_5: 0.9064\n",
      "sensitivity/vb-mnist-fcn3A/B5/S0.25\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,128] [None,384]  1607680    input    \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,128] [None,384]  4096       fc1      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,128] [None,384]  0          bn1      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,128] [None,384]  1249792    relu1    \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,128] [None,384]  4096       fc2      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,128] [None,384]  0          bn2      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,128] [None,384]  1249792    relu2    \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,128] [None,384]  4096       fc3      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,128] [None,384]  0          bn3      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              24668      relu3    \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 4144220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 5s - loss_1: 0.2385 - loss_2: 0.2545 - loss_3: 0.2354 - loss_4: 0.2343 - loss_5: 0.2363 - acc_ensemble: 1.0000 - acc_1: 0.9983 - acc_2: 0.9933 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 0.9950 - val_loss_1: 0.4214 - val_loss_2: 0.4493 - val_loss_3: 0.4054 - val_loss_4: 0.4724 - val_loss_5: 0.4441 - val_acc_ensemble: 0.9083 - val_acc_1: 0.8852 - val_acc_2: 0.8845 - val_acc_3: 0.8890 - val_acc_4: 0.8731 - val_acc_5: 0.8829\n",
      "Epoch 2/10\n",
      " - 2s - loss_1: 0.0024 - loss_2: 0.0055 - loss_3: 0.0028 - loss_4: 0.0063 - loss_5: 0.0276 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 0.9900 - val_loss_1: 0.4001 - val_loss_2: 0.4104 - val_loss_3: 0.3707 - val_loss_4: 0.4275 - val_loss_5: 0.5026 - val_acc_ensemble: 0.9092 - val_acc_1: 0.8946 - val_acc_2: 0.8984 - val_acc_3: 0.9034 - val_acc_4: 0.8928 - val_acc_5: 0.8755\n",
      "Epoch 3/10\n",
      " - 2s - loss_1: 6.0709e-04 - loss_2: 7.4979e-04 - loss_3: 5.9280e-04 - loss_4: 6.0945e-04 - loss_5: 0.0057 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3988 - val_loss_2: 0.4084 - val_loss_3: 0.3681 - val_loss_4: 0.4137 - val_loss_5: 0.4135 - val_acc_ensemble: 0.9118 - val_acc_1: 0.8974 - val_acc_2: 0.8992 - val_acc_3: 0.9058 - val_acc_4: 0.8978 - val_acc_5: 0.9006\n",
      "Epoch 4/10\n",
      " - 2s - loss_1: 3.6716e-04 - loss_2: 4.0798e-04 - loss_3: 3.7620e-04 - loss_4: 3.7916e-04 - loss_5: 5.1651e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3993 - val_loss_2: 0.4098 - val_loss_3: 0.3704 - val_loss_4: 0.4137 - val_loss_5: 0.4142 - val_acc_ensemble: 0.9123 - val_acc_1: 0.8975 - val_acc_2: 0.9006 - val_acc_3: 0.9059 - val_acc_4: 0.9000 - val_acc_5: 0.9021\n",
      "Epoch 5/10\n",
      " - 2s - loss_1: 2.6471e-04 - loss_2: 3.0070e-04 - loss_3: 2.8422e-04 - loss_4: 2.4234e-04 - loss_5: 3.3683e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4002 - val_loss_2: 0.4103 - val_loss_3: 0.3716 - val_loss_4: 0.4141 - val_loss_5: 0.4146 - val_acc_ensemble: 0.9127 - val_acc_1: 0.8982 - val_acc_2: 0.9016 - val_acc_3: 0.9071 - val_acc_4: 0.9009 - val_acc_5: 0.9031\n",
      "Epoch 6/10\n",
      " - 2s - loss_1: 2.0224e-04 - loss_2: 2.3019e-04 - loss_3: 2.3675e-04 - loss_4: 2.0028e-04 - loss_5: 2.5452e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4018 - val_loss_2: 0.4120 - val_loss_3: 0.3725 - val_loss_4: 0.4155 - val_loss_5: 0.4153 - val_acc_ensemble: 0.9127 - val_acc_1: 0.8986 - val_acc_2: 0.9016 - val_acc_3: 0.9079 - val_acc_4: 0.9007 - val_acc_5: 0.9035\n",
      "Epoch 7/10\n",
      " - 2s - loss_1: 1.7179e-04 - loss_2: 1.8267e-04 - loss_3: 1.8625e-04 - loss_4: 1.5920e-04 - loss_5: 2.0863e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4035 - val_loss_2: 0.4135 - val_loss_3: 0.3740 - val_loss_4: 0.4169 - val_loss_5: 0.4168 - val_acc_ensemble: 0.9131 - val_acc_1: 0.8993 - val_acc_2: 0.9019 - val_acc_3: 0.9083 - val_acc_4: 0.9014 - val_acc_5: 0.9046\n",
      "Epoch 8/10\n",
      " - 2s - loss_1: 1.5368e-04 - loss_2: 1.6683e-04 - loss_3: 1.6316e-04 - loss_4: 1.3628e-04 - loss_5: 1.6441e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4056 - val_loss_2: 0.4152 - val_loss_3: 0.3760 - val_loss_4: 0.4183 - val_loss_5: 0.4185 - val_acc_ensemble: 0.9127 - val_acc_1: 0.8995 - val_acc_2: 0.9021 - val_acc_3: 0.9082 - val_acc_4: 0.9016 - val_acc_5: 0.9045\n",
      "Epoch 9/10\n",
      " - 2s - loss_1: 1.2654e-04 - loss_2: 1.4114e-04 - loss_3: 1.4247e-04 - loss_4: 1.1627e-04 - loss_5: 1.4435e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4071 - val_loss_2: 0.4167 - val_loss_3: 0.3779 - val_loss_4: 0.4198 - val_loss_5: 0.4200 - val_acc_ensemble: 0.9128 - val_acc_1: 0.9001 - val_acc_2: 0.9022 - val_acc_3: 0.9081 - val_acc_4: 0.9021 - val_acc_5: 0.9049\n",
      "Epoch 10/10\n",
      " - 2s - loss_1: 1.1406e-04 - loss_2: 1.2378e-04 - loss_3: 1.1847e-04 - loss_4: 1.0360e-04 - loss_5: 1.2232e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4087 - val_loss_2: 0.4184 - val_loss_3: 0.3792 - val_loss_4: 0.4210 - val_loss_5: 0.4216 - val_acc_ensemble: 0.9125 - val_acc_1: 0.9002 - val_acc_2: 0.9024 - val_acc_3: 0.9088 - val_acc_4: 0.9025 - val_acc_5: 0.9051\n",
      "sensitivity/vb-mnist-fcn3A/B5/S0.25\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,128] [None,384]  1607680    input    \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,128] [None,384]  4096       fc1      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,128] [None,384]  0          bn1      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,128] [None,384]  1249792    relu1    \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,128] [None,384]  4096       fc2      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,128] [None,384]  0          bn2      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,128] [None,384]  1249792    relu2    \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,128] [None,384]  4096       fc3      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,128] [None,384]  0          bn3      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              24668      relu3    \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 4144220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 5s - loss_1: 0.2365 - loss_2: 0.2327 - loss_3: 0.2346 - loss_4: 0.2607 - loss_5: 0.2326 - acc_ensemble: 1.0000 - acc_1: 0.9967 - acc_2: 0.9950 - acc_3: 0.9967 - acc_4: 0.9867 - acc_5: 0.9967 - val_loss_1: 0.5143 - val_loss_2: 0.4453 - val_loss_3: 0.4147 - val_loss_4: 0.5238 - val_loss_5: 0.4538 - val_acc_ensemble: 0.9032 - val_acc_1: 0.8675 - val_acc_2: 0.8834 - val_acc_3: 0.8901 - val_acc_4: 0.8677 - val_acc_5: 0.8796\n",
      "Epoch 2/10\n",
      " - 2s - loss_1: 0.0039 - loss_2: 0.0075 - loss_3: 0.0035 - loss_4: 0.0046 - loss_5: 0.0035 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4700 - val_loss_2: 0.4103 - val_loss_3: 0.4340 - val_loss_4: 0.4344 - val_loss_5: 0.4137 - val_acc_ensemble: 0.9063 - val_acc_1: 0.8882 - val_acc_2: 0.8945 - val_acc_3: 0.8947 - val_acc_4: 0.8929 - val_acc_5: 0.8963\n",
      "Epoch 3/10\n",
      " - 2s - loss_1: 5.9525e-04 - loss_2: 8.9105e-04 - loss_3: 5.3079e-04 - loss_4: 6.1982e-04 - loss_5: 6.0720e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4603 - val_loss_2: 0.3974 - val_loss_3: 0.4266 - val_loss_4: 0.4271 - val_loss_5: 0.4042 - val_acc_ensemble: 0.9091 - val_acc_1: 0.8932 - val_acc_2: 0.9012 - val_acc_3: 0.8965 - val_acc_4: 0.8955 - val_acc_5: 0.8994\n",
      "Epoch 4/10\n",
      " - 2s - loss_1: 3.6299e-04 - loss_2: 4.0184e-04 - loss_3: 3.6216e-04 - loss_4: 3.9504e-04 - loss_5: 3.6378e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4568 - val_loss_2: 0.3981 - val_loss_3: 0.4252 - val_loss_4: 0.4266 - val_loss_5: 0.4018 - val_acc_ensemble: 0.9096 - val_acc_1: 0.8963 - val_acc_2: 0.9024 - val_acc_3: 0.8986 - val_acc_4: 0.8958 - val_acc_5: 0.9008\n",
      "Epoch 5/10\n",
      " - 2s - loss_1: 2.5621e-04 - loss_2: 2.8726e-04 - loss_3: 2.6146e-04 - loss_4: 3.0176e-04 - loss_5: 2.7135e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4566 - val_loss_2: 0.3993 - val_loss_3: 0.4258 - val_loss_4: 0.4276 - val_loss_5: 0.4033 - val_acc_ensemble: 0.9101 - val_acc_1: 0.8968 - val_acc_2: 0.9032 - val_acc_3: 0.8991 - val_acc_4: 0.8962 - val_acc_5: 0.9023\n",
      "Epoch 6/10\n",
      " - 2s - loss_1: 2.0621e-04 - loss_2: 2.2252e-04 - loss_3: 2.2293e-04 - loss_4: 2.3623e-04 - loss_5: 2.2634e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4560 - val_loss_2: 0.4016 - val_loss_3: 0.4265 - val_loss_4: 0.4288 - val_loss_5: 0.4042 - val_acc_ensemble: 0.9108 - val_acc_1: 0.8973 - val_acc_2: 0.9028 - val_acc_3: 0.8999 - val_acc_4: 0.8964 - val_acc_5: 0.9022\n",
      "Epoch 7/10\n",
      " - 2s - loss_1: 1.7913e-04 - loss_2: 1.8430e-04 - loss_3: 1.7038e-04 - loss_4: 1.9218e-04 - loss_5: 1.7871e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4568 - val_loss_2: 0.4039 - val_loss_3: 0.4279 - val_loss_4: 0.4290 - val_loss_5: 0.4056 - val_acc_ensemble: 0.9103 - val_acc_1: 0.8982 - val_acc_2: 0.9037 - val_acc_3: 0.8998 - val_acc_4: 0.8963 - val_acc_5: 0.9028\n",
      "Epoch 8/10\n",
      " - 2s - loss_1: 1.4100e-04 - loss_2: 1.4756e-04 - loss_3: 1.5126e-04 - loss_4: 1.6856e-04 - loss_5: 1.4930e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4577 - val_loss_2: 0.4061 - val_loss_3: 0.4291 - val_loss_4: 0.4301 - val_loss_5: 0.4072 - val_acc_ensemble: 0.9104 - val_acc_1: 0.8987 - val_acc_2: 0.9034 - val_acc_3: 0.8999 - val_acc_4: 0.8967 - val_acc_5: 0.9031\n",
      "Epoch 9/10\n",
      " - 2s - loss_1: 1.2509e-04 - loss_2: 1.2823e-04 - loss_3: 1.2226e-04 - loss_4: 1.4663e-04 - loss_5: 1.3506e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4585 - val_loss_2: 0.4080 - val_loss_3: 0.4299 - val_loss_4: 0.4319 - val_loss_5: 0.4086 - val_acc_ensemble: 0.9105 - val_acc_1: 0.8990 - val_acc_2: 0.9030 - val_acc_3: 0.9005 - val_acc_4: 0.8973 - val_acc_5: 0.9035\n",
      "Epoch 10/10\n",
      " - 2s - loss_1: 1.0962e-04 - loss_2: 1.1367e-04 - loss_3: 1.1444e-04 - loss_4: 1.2300e-04 - loss_5: 1.1386e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4593 - val_loss_2: 0.4096 - val_loss_3: 0.4310 - val_loss_4: 0.4329 - val_loss_5: 0.4098 - val_acc_ensemble: 0.9105 - val_acc_1: 0.8989 - val_acc_2: 0.9029 - val_acc_3: 0.9007 - val_acc_4: 0.8967 - val_acc_5: 0.9036\n",
      "sensitivity/vb-mnist-fcn3A/B5/S0.25\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,128] [None,384]  1607680    input    \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,128] [None,384]  4096       fc1      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,128] [None,384]  0          bn1      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,128] [None,384]  1249792    relu1    \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,128] [None,384]  4096       fc2      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,128] [None,384]  0          bn2      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,128] [None,384]  1249792    relu2    \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,128] [None,384]  4096       fc3      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,128] [None,384]  0          bn3      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              24668      relu3    \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 4144220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 5s - loss_1: 0.2346 - loss_2: 0.2308 - loss_3: 0.2339 - loss_4: 0.2338 - loss_5: 0.2234 - acc_ensemble: 1.0000 - acc_1: 0.9950 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 0.9950 - acc_5: 1.0000 - val_loss_1: 0.4635 - val_loss_2: 0.4203 - val_loss_3: 0.4073 - val_loss_4: 0.4267 - val_loss_5: 0.4137 - val_acc_ensemble: 0.9060 - val_acc_1: 0.8786 - val_acc_2: 0.8873 - val_acc_3: 0.8892 - val_acc_4: 0.8853 - val_acc_5: 0.8890\n",
      "Epoch 2/10\n",
      " - 2s - loss_1: 0.0031 - loss_2: 0.0018 - loss_3: 0.0022 - loss_4: 0.0042 - loss_5: 0.0015 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4221 - val_loss_2: 0.3951 - val_loss_3: 0.3900 - val_loss_4: 0.3948 - val_loss_5: 0.3985 - val_acc_ensemble: 0.9087 - val_acc_1: 0.8953 - val_acc_2: 0.8977 - val_acc_3: 0.8957 - val_acc_4: 0.8972 - val_acc_5: 0.8986\n",
      "Epoch 3/10\n",
      " - 2s - loss_1: 5.8598e-04 - loss_2: 5.8292e-04 - loss_3: 6.1135e-04 - loss_4: 5.9174e-04 - loss_5: 5.5549e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4207 - val_loss_2: 0.3978 - val_loss_3: 0.3877 - val_loss_4: 0.3891 - val_loss_5: 0.4008 - val_acc_ensemble: 0.9091 - val_acc_1: 0.8978 - val_acc_2: 0.8983 - val_acc_3: 0.8997 - val_acc_4: 0.8995 - val_acc_5: 0.8978\n",
      "Epoch 4/10\n",
      " - 2s - loss_1: 3.6541e-04 - loss_2: 4.0548e-04 - loss_3: 3.7450e-04 - loss_4: 3.7104e-04 - loss_5: 3.8261e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4218 - val_loss_2: 0.4030 - val_loss_3: 0.3889 - val_loss_4: 0.3909 - val_loss_5: 0.4045 - val_acc_ensemble: 0.9084 - val_acc_1: 0.8980 - val_acc_2: 0.8993 - val_acc_3: 0.9006 - val_acc_4: 0.9009 - val_acc_5: 0.8983\n",
      "Epoch 5/10\n",
      " - 2s - loss_1: 2.9301e-04 - loss_2: 2.8716e-04 - loss_3: 2.8515e-04 - loss_4: 2.6499e-04 - loss_5: 2.7364e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4220 - val_loss_2: 0.4044 - val_loss_3: 0.3921 - val_loss_4: 0.3926 - val_loss_5: 0.4058 - val_acc_ensemble: 0.9088 - val_acc_1: 0.9000 - val_acc_2: 0.8995 - val_acc_3: 0.9009 - val_acc_4: 0.9026 - val_acc_5: 0.8992\n",
      "Epoch 6/10\n",
      " - 2s - loss_1: 2.2717e-04 - loss_2: 2.3292e-04 - loss_3: 2.1928e-04 - loss_4: 2.1939e-04 - loss_5: 2.2213e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4238 - val_loss_2: 0.4064 - val_loss_3: 0.3948 - val_loss_4: 0.3954 - val_loss_5: 0.4077 - val_acc_ensemble: 0.9089 - val_acc_1: 0.9005 - val_acc_2: 0.9002 - val_acc_3: 0.9017 - val_acc_4: 0.9034 - val_acc_5: 0.8997\n",
      "Epoch 7/10\n",
      " - 2s - loss_1: 1.7848e-04 - loss_2: 1.8836e-04 - loss_3: 1.7442e-04 - loss_4: 1.8384e-04 - loss_5: 1.8124e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4249 - val_loss_2: 0.4083 - val_loss_3: 0.3968 - val_loss_4: 0.3972 - val_loss_5: 0.4099 - val_acc_ensemble: 0.9087 - val_acc_1: 0.9010 - val_acc_2: 0.9004 - val_acc_3: 0.9023 - val_acc_4: 0.9040 - val_acc_5: 0.8994\n",
      "Epoch 8/10\n",
      " - 2s - loss_1: 1.5588e-04 - loss_2: 1.6769e-04 - loss_3: 1.5914e-04 - loss_4: 1.5607e-04 - loss_5: 1.5353e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4262 - val_loss_2: 0.4106 - val_loss_3: 0.3988 - val_loss_4: 0.3983 - val_loss_5: 0.4114 - val_acc_ensemble: 0.9089 - val_acc_1: 0.9012 - val_acc_2: 0.9006 - val_acc_3: 0.9023 - val_acc_4: 0.9047 - val_acc_5: 0.8997\n",
      "Epoch 9/10\n",
      " - 2s - loss_1: 1.3871e-04 - loss_2: 1.3173e-04 - loss_3: 1.2825e-04 - loss_4: 1.3042e-04 - loss_5: 1.2830e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4285 - val_loss_2: 0.4131 - val_loss_3: 0.4007 - val_loss_4: 0.3999 - val_loss_5: 0.4137 - val_acc_ensemble: 0.9092 - val_acc_1: 0.9011 - val_acc_2: 0.9004 - val_acc_3: 0.9031 - val_acc_4: 0.9043 - val_acc_5: 0.8994\n",
      "Epoch 10/10\n",
      " - 2s - loss_1: 1.1531e-04 - loss_2: 1.1579e-04 - loss_3: 1.1732e-04 - loss_4: 1.0545e-04 - loss_5: 1.1029e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4297 - val_loss_2: 0.4144 - val_loss_3: 0.4024 - val_loss_4: 0.4013 - val_loss_5: 0.4145 - val_acc_ensemble: 0.9094 - val_acc_1: 0.9012 - val_acc_2: 0.9004 - val_acc_3: 0.9033 - val_acc_4: 0.9039 - val_acc_5: 0.9002\n",
      "sensitivity/vb-mnist-fcn3A/B5/S0.50\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,256] [None,256]  1205760    input    \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,256] [None,256]  3072       fc1      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,256] [None,256]  0          bn1      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,256] [None,256]  1052672    relu1    \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,256] [None,256]  3072       fc2      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,256] [None,256]  0          bn2      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,256] [None,256]  1052672    relu2    \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,256] [None,256]  3072       fc3      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,256] [None,256]  0          bn3      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              20560      relu3    \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 3340880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 5s - loss_1: 0.2246 - loss_2: 0.2119 - loss_3: 0.2074 - loss_4: 0.2061 - loss_5: 0.2032 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 0.9983 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4374 - val_loss_2: 0.3981 - val_loss_3: 0.4510 - val_loss_4: 0.4324 - val_loss_5: 0.4228 - val_acc_ensemble: 0.9029 - val_acc_1: 0.8867 - val_acc_2: 0.8931 - val_acc_3: 0.8855 - val_acc_4: 0.8874 - val_acc_5: 0.8868\n",
      "Epoch 2/10\n",
      " - 2s - loss_1: 0.0018 - loss_2: 0.0011 - loss_3: 0.0020 - loss_4: 0.0024 - loss_5: 0.0022 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4149 - val_loss_2: 0.3916 - val_loss_3: 0.4247 - val_loss_4: 0.4227 - val_loss_5: 0.4081 - val_acc_ensemble: 0.9069 - val_acc_1: 0.8964 - val_acc_2: 0.8989 - val_acc_3: 0.8977 - val_acc_4: 0.8961 - val_acc_5: 0.8975\n",
      "Epoch 3/10\n",
      " - 2s - loss_1: 4.4383e-04 - loss_2: 4.7655e-04 - loss_3: 4.2527e-04 - loss_4: 4.8484e-04 - loss_5: 4.4955e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4143 - val_loss_2: 0.3924 - val_loss_3: 0.4247 - val_loss_4: 0.4220 - val_loss_5: 0.4121 - val_acc_ensemble: 0.9071 - val_acc_1: 0.8987 - val_acc_2: 0.9000 - val_acc_3: 0.8993 - val_acc_4: 0.8978 - val_acc_5: 0.8979\n",
      "Epoch 4/10\n",
      " - 2s - loss_1: 2.8924e-04 - loss_2: 3.1172e-04 - loss_3: 2.8567e-04 - loss_4: 3.2085e-04 - loss_5: 2.9896e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4157 - val_loss_2: 0.3952 - val_loss_3: 0.4262 - val_loss_4: 0.4237 - val_loss_5: 0.4150 - val_acc_ensemble: 0.9079 - val_acc_1: 0.8998 - val_acc_2: 0.8998 - val_acc_3: 0.8993 - val_acc_4: 0.8983 - val_acc_5: 0.8989\n",
      "Epoch 5/10\n",
      " - 2s - loss_1: 2.1065e-04 - loss_2: 2.3855e-04 - loss_3: 2.0993e-04 - loss_4: 2.3612e-04 - loss_5: 2.1374e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4183 - val_loss_2: 0.3978 - val_loss_3: 0.4277 - val_loss_4: 0.4257 - val_loss_5: 0.4167 - val_acc_ensemble: 0.9084 - val_acc_1: 0.8998 - val_acc_2: 0.8996 - val_acc_3: 0.8992 - val_acc_4: 0.8993 - val_acc_5: 0.8995\n",
      "Epoch 6/10\n",
      " - 2s - loss_1: 1.8323e-04 - loss_2: 1.9091e-04 - loss_3: 1.6800e-04 - loss_4: 1.8635e-04 - loss_5: 1.6931e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4211 - val_loss_2: 0.4004 - val_loss_3: 0.4297 - val_loss_4: 0.4274 - val_loss_5: 0.4189 - val_acc_ensemble: 0.9083 - val_acc_1: 0.9002 - val_acc_2: 0.9008 - val_acc_3: 0.9000 - val_acc_4: 0.8993 - val_acc_5: 0.9003\n",
      "Epoch 7/10\n",
      " - 2s - loss_1: 1.4329e-04 - loss_2: 1.5340e-04 - loss_3: 1.4549e-04 - loss_4: 1.5063e-04 - loss_5: 1.4235e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4236 - val_loss_2: 0.4029 - val_loss_3: 0.4319 - val_loss_4: 0.4293 - val_loss_5: 0.4224 - val_acc_ensemble: 0.9081 - val_acc_1: 0.9006 - val_acc_2: 0.9005 - val_acc_3: 0.8998 - val_acc_4: 0.8997 - val_acc_5: 0.8999\n",
      "Epoch 8/10\n",
      " - 2s - loss_1: 1.1823e-04 - loss_2: 1.2915e-04 - loss_3: 1.1830e-04 - loss_4: 1.3137e-04 - loss_5: 1.2585e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4259 - val_loss_2: 0.4050 - val_loss_3: 0.4337 - val_loss_4: 0.4313 - val_loss_5: 0.4251 - val_acc_ensemble: 0.9084 - val_acc_1: 0.9004 - val_acc_2: 0.9010 - val_acc_3: 0.8996 - val_acc_4: 0.9000 - val_acc_5: 0.8994\n",
      "Epoch 9/10\n",
      " - 2s - loss_1: 1.0674e-04 - loss_2: 1.1172e-04 - loss_3: 1.0117e-04 - loss_4: 1.0814e-04 - loss_5: 1.0264e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4271 - val_loss_2: 0.4070 - val_loss_3: 0.4354 - val_loss_4: 0.4330 - val_loss_5: 0.4278 - val_acc_ensemble: 0.9082 - val_acc_1: 0.9007 - val_acc_2: 0.9009 - val_acc_3: 0.9001 - val_acc_4: 0.9003 - val_acc_5: 0.8995\n",
      "Epoch 10/10\n",
      " - 2s - loss_1: 9.2229e-05 - loss_2: 9.8875e-05 - loss_3: 9.0088e-05 - loss_4: 9.5356e-05 - loss_5: 8.7204e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4290 - val_loss_2: 0.4092 - val_loss_3: 0.4372 - val_loss_4: 0.4350 - val_loss_5: 0.4297 - val_acc_ensemble: 0.9083 - val_acc_1: 0.9008 - val_acc_2: 0.9011 - val_acc_3: 0.8998 - val_acc_4: 0.9005 - val_acc_5: 0.9000\n",
      "sensitivity/vb-mnist-fcn3A/B5/S0.50\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,256] [None,256]  1205760    input    \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,256] [None,256]  3072       fc1      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,256] [None,256]  0          bn1      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,256] [None,256]  1052672    relu1    \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,256] [None,256]  3072       fc2      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,256] [None,256]  0          bn2      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,256] [None,256]  1052672    relu2    \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,256] [None,256]  3072       fc3      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,256] [None,256]  0          bn3      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              20560      relu3    \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 3340880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 5s - loss_1: 0.2229 - loss_2: 0.2149 - loss_3: 0.2196 - loss_4: 0.2110 - loss_5: 0.2098 - acc_ensemble: 1.0000 - acc_1: 0.9983 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4012 - val_loss_2: 0.4421 - val_loss_3: 0.4514 - val_loss_4: 0.4432 - val_loss_5: 0.4224 - val_acc_ensemble: 0.9033 - val_acc_1: 0.8948 - val_acc_2: 0.8867 - val_acc_3: 0.8889 - val_acc_4: 0.8821 - val_acc_5: 0.8947\n",
      "Epoch 2/10\n",
      " - 2s - loss_1: 0.0016 - loss_2: 0.0022 - loss_3: 0.0016 - loss_4: 0.0018 - loss_5: 0.0021 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4130 - val_loss_2: 0.4209 - val_loss_3: 0.4175 - val_loss_4: 0.4260 - val_loss_5: 0.4424 - val_acc_ensemble: 0.9056 - val_acc_1: 0.8939 - val_acc_2: 0.8953 - val_acc_3: 0.8985 - val_acc_4: 0.8929 - val_acc_5: 0.8929\n",
      "Epoch 3/10\n",
      " - 2s - loss_1: 4.7621e-04 - loss_2: 4.9417e-04 - loss_3: 4.3703e-04 - loss_4: 5.0360e-04 - loss_5: 4.4593e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4086 - val_loss_2: 0.4185 - val_loss_3: 0.4138 - val_loss_4: 0.4221 - val_loss_5: 0.4380 - val_acc_ensemble: 0.9071 - val_acc_1: 0.8964 - val_acc_2: 0.8968 - val_acc_3: 0.9001 - val_acc_4: 0.8957 - val_acc_5: 0.8956\n",
      "Epoch 4/10\n",
      " - 2s - loss_1: 3.1512e-04 - loss_2: 3.3023e-04 - loss_3: 2.8542e-04 - loss_4: 3.1450e-04 - loss_5: 3.0087e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4108 - val_loss_2: 0.4187 - val_loss_3: 0.4129 - val_loss_4: 0.4218 - val_loss_5: 0.4381 - val_acc_ensemble: 0.9068 - val_acc_1: 0.8977 - val_acc_2: 0.8977 - val_acc_3: 0.9018 - val_acc_4: 0.8986 - val_acc_5: 0.8962\n",
      "Epoch 5/10\n",
      " - 2s - loss_1: 2.3774e-04 - loss_2: 2.2904e-04 - loss_3: 2.1866e-04 - loss_4: 2.3804e-04 - loss_5: 2.0769e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4132 - val_loss_2: 0.4207 - val_loss_3: 0.4137 - val_loss_4: 0.4229 - val_loss_5: 0.4383 - val_acc_ensemble: 0.9074 - val_acc_1: 0.8975 - val_acc_2: 0.8983 - val_acc_3: 0.9020 - val_acc_4: 0.8983 - val_acc_5: 0.8966\n",
      "Epoch 6/10\n",
      " - 2s - loss_1: 1.8375e-04 - loss_2: 1.8716e-04 - loss_3: 1.7111e-04 - loss_4: 1.8214e-04 - loss_5: 1.6730e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4155 - val_loss_2: 0.4231 - val_loss_3: 0.4152 - val_loss_4: 0.4254 - val_loss_5: 0.4403 - val_acc_ensemble: 0.9079 - val_acc_1: 0.8983 - val_acc_2: 0.8987 - val_acc_3: 0.9028 - val_acc_4: 0.8987 - val_acc_5: 0.8970\n",
      "Epoch 7/10\n",
      " - 2s - loss_1: 1.4992e-04 - loss_2: 1.4880e-04 - loss_3: 1.4442e-04 - loss_4: 1.5509e-04 - loss_5: 1.4536e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4168 - val_loss_2: 0.4242 - val_loss_3: 0.4159 - val_loss_4: 0.4265 - val_loss_5: 0.4410 - val_acc_ensemble: 0.9079 - val_acc_1: 0.8987 - val_acc_2: 0.8998 - val_acc_3: 0.9035 - val_acc_4: 0.8987 - val_acc_5: 0.8975\n",
      "Epoch 8/10\n",
      " - 2s - loss_1: 1.2474e-04 - loss_2: 1.3138e-04 - loss_3: 1.1886e-04 - loss_4: 1.3663e-04 - loss_5: 1.2156e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4190 - val_loss_2: 0.4265 - val_loss_3: 0.4173 - val_loss_4: 0.4278 - val_loss_5: 0.4425 - val_acc_ensemble: 0.9082 - val_acc_1: 0.8992 - val_acc_2: 0.9001 - val_acc_3: 0.9035 - val_acc_4: 0.8990 - val_acc_5: 0.8987\n",
      "Epoch 9/10\n",
      " - 2s - loss_1: 1.1567e-04 - loss_2: 1.1220e-04 - loss_3: 1.0114e-04 - loss_4: 1.0707e-04 - loss_5: 9.9828e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4208 - val_loss_2: 0.4278 - val_loss_3: 0.4188 - val_loss_4: 0.4284 - val_loss_5: 0.4436 - val_acc_ensemble: 0.9083 - val_acc_1: 0.8996 - val_acc_2: 0.9002 - val_acc_3: 0.9035 - val_acc_4: 0.8997 - val_acc_5: 0.8990\n",
      "Epoch 10/10\n",
      " - 2s - loss_1: 9.5501e-05 - loss_2: 9.6662e-05 - loss_3: 9.2966e-05 - loss_4: 9.8364e-05 - loss_5: 8.7390e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4230 - val_loss_2: 0.4294 - val_loss_3: 0.4202 - val_loss_4: 0.4301 - val_loss_5: 0.4452 - val_acc_ensemble: 0.9081 - val_acc_1: 0.8994 - val_acc_2: 0.9002 - val_acc_3: 0.9040 - val_acc_4: 0.8997 - val_acc_5: 0.8992\n",
      "sensitivity/vb-mnist-fcn3A/B5/S0.50\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,256] [None,256]  1205760    input    \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,256] [None,256]  3072       fc1      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,256] [None,256]  0          bn1      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,256] [None,256]  1052672    relu1    \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,256] [None,256]  3072       fc2      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,256] [None,256]  0          bn2      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,256] [None,256]  1052672    relu2    \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,256] [None,256]  3072       fc3      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,256] [None,256]  0          bn3      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              20560      relu3    \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 3340880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 5s - loss_1: 0.2161 - loss_2: 0.2027 - loss_3: 0.2062 - loss_4: 0.2250 - loss_5: 0.2190 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 0.9983 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4280 - val_loss_2: 0.4348 - val_loss_3: 0.4610 - val_loss_4: 0.4695 - val_loss_5: 0.4320 - val_acc_ensemble: 0.8992 - val_acc_1: 0.8873 - val_acc_2: 0.8885 - val_acc_3: 0.8787 - val_acc_4: 0.8776 - val_acc_5: 0.8882\n",
      "Epoch 2/10\n",
      " - 2s - loss_1: 0.0011 - loss_2: 0.0015 - loss_3: 0.0016 - loss_4: 0.0016 - loss_5: 0.0019 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4198 - val_loss_2: 0.4211 - val_loss_3: 0.4273 - val_loss_4: 0.4291 - val_loss_5: 0.4343 - val_acc_ensemble: 0.9025 - val_acc_1: 0.8947 - val_acc_2: 0.8949 - val_acc_3: 0.8937 - val_acc_4: 0.8912 - val_acc_5: 0.8940\n",
      "Epoch 3/10\n",
      " - 2s - loss_1: 4.8422e-04 - loss_2: 4.2813e-04 - loss_3: 4.6626e-04 - loss_4: 4.8252e-04 - loss_5: 5.2554e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4169 - val_loss_2: 0.4189 - val_loss_3: 0.4236 - val_loss_4: 0.4264 - val_loss_5: 0.4288 - val_acc_ensemble: 0.9041 - val_acc_1: 0.8981 - val_acc_2: 0.8966 - val_acc_3: 0.8949 - val_acc_4: 0.8937 - val_acc_5: 0.8962\n",
      "Epoch 4/10\n",
      " - 2s - loss_1: 3.1466e-04 - loss_2: 3.0429e-04 - loss_3: 3.0899e-04 - loss_4: 3.0624e-04 - loss_5: 3.2554e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4171 - val_loss_2: 0.4210 - val_loss_3: 0.4242 - val_loss_4: 0.4261 - val_loss_5: 0.4291 - val_acc_ensemble: 0.9043 - val_acc_1: 0.8990 - val_acc_2: 0.8982 - val_acc_3: 0.8962 - val_acc_4: 0.8948 - val_acc_5: 0.8974\n",
      "Epoch 5/10\n",
      " - 2s - loss_1: 2.3318e-04 - loss_2: 2.2491e-04 - loss_3: 2.4242e-04 - loss_4: 2.3481e-04 - loss_5: 2.3669e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4176 - val_loss_2: 0.4223 - val_loss_3: 0.4258 - val_loss_4: 0.4269 - val_loss_5: 0.4304 - val_acc_ensemble: 0.9047 - val_acc_1: 0.9007 - val_acc_2: 0.8989 - val_acc_3: 0.8963 - val_acc_4: 0.8954 - val_acc_5: 0.8977\n",
      "Epoch 6/10\n",
      " - 2s - loss_1: 1.8858e-04 - loss_2: 1.7787e-04 - loss_3: 1.7465e-04 - loss_4: 1.7611e-04 - loss_5: 1.8267e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4192 - val_loss_2: 0.4242 - val_loss_3: 0.4276 - val_loss_4: 0.4280 - val_loss_5: 0.4314 - val_acc_ensemble: 0.9049 - val_acc_1: 0.9010 - val_acc_2: 0.8998 - val_acc_3: 0.8964 - val_acc_4: 0.8954 - val_acc_5: 0.8991\n",
      "Epoch 7/10\n",
      " - 2s - loss_1: 1.4740e-04 - loss_2: 1.4697e-04 - loss_3: 1.4811e-04 - loss_4: 1.5207e-04 - loss_5: 1.5085e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4206 - val_loss_2: 0.4263 - val_loss_3: 0.4292 - val_loss_4: 0.4291 - val_loss_5: 0.4330 - val_acc_ensemble: 0.9049 - val_acc_1: 0.9012 - val_acc_2: 0.9006 - val_acc_3: 0.8975 - val_acc_4: 0.8959 - val_acc_5: 0.8992\n",
      "Epoch 8/10\n",
      " - 2s - loss_1: 1.2574e-04 - loss_2: 1.2124e-04 - loss_3: 1.2837e-04 - loss_4: 1.2918e-04 - loss_5: 1.2730e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4224 - val_loss_2: 0.4287 - val_loss_3: 0.4308 - val_loss_4: 0.4305 - val_loss_5: 0.4347 - val_acc_ensemble: 0.9050 - val_acc_1: 0.9015 - val_acc_2: 0.9001 - val_acc_3: 0.8978 - val_acc_4: 0.8958 - val_acc_5: 0.8991\n",
      "Epoch 9/10\n",
      " - 2s - loss_1: 1.0686e-04 - loss_2: 1.0753e-04 - loss_3: 1.0551e-04 - loss_4: 1.0700e-04 - loss_5: 1.0449e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4241 - val_loss_2: 0.4306 - val_loss_3: 0.4321 - val_loss_4: 0.4318 - val_loss_5: 0.4361 - val_acc_ensemble: 0.9051 - val_acc_1: 0.9017 - val_acc_2: 0.9006 - val_acc_3: 0.8980 - val_acc_4: 0.8970 - val_acc_5: 0.8994\n",
      "Epoch 10/10\n",
      " - 2s - loss_1: 9.2198e-05 - loss_2: 9.3595e-05 - loss_3: 9.2659e-05 - loss_4: 9.3807e-05 - loss_5: 9.6785e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4260 - val_loss_2: 0.4325 - val_loss_3: 0.4337 - val_loss_4: 0.4336 - val_loss_5: 0.4380 - val_acc_ensemble: 0.9054 - val_acc_1: 0.9016 - val_acc_2: 0.9015 - val_acc_3: 0.8984 - val_acc_4: 0.8975 - val_acc_5: 0.8997\n",
      "sensitivity/vb-mnist-fcn3A/B5/S0.50\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,256] [None,256]  1205760    input    \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,256] [None,256]  3072       fc1      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,256] [None,256]  0          bn1      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,256] [None,256]  1052672    relu1    \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,256] [None,256]  3072       fc2      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,256] [None,256]  0          bn2      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,256] [None,256]  1052672    relu2    \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,256] [None,256]  3072       fc3      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,256] [None,256]  0          bn3      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              20560      relu3    \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 3340880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 5s - loss_1: 0.2189 - loss_2: 0.2286 - loss_3: 0.2005 - loss_4: 0.2152 - loss_5: 0.2036 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 0.9983 - acc_3: 1.0000 - acc_4: 0.9983 - acc_5: 1.0000 - val_loss_1: 0.4184 - val_loss_2: 0.4025 - val_loss_3: 0.4608 - val_loss_4: 0.3980 - val_loss_5: 0.4611 - val_acc_ensemble: 0.9027 - val_acc_1: 0.8835 - val_acc_2: 0.8919 - val_acc_3: 0.8773 - val_acc_4: 0.8934 - val_acc_5: 0.8799\n",
      "Epoch 2/10\n",
      " - 2s - loss_1: 0.0016 - loss_2: 0.0022 - loss_3: 0.0014 - loss_4: 0.0014 - loss_5: 0.0015 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3908 - val_loss_2: 0.3751 - val_loss_3: 0.4151 - val_loss_4: 0.3911 - val_loss_5: 0.4169 - val_acc_ensemble: 0.9061 - val_acc_1: 0.8987 - val_acc_2: 0.9027 - val_acc_3: 0.8928 - val_acc_4: 0.9009 - val_acc_5: 0.8944\n",
      "Epoch 3/10\n",
      " - 2s - loss_1: 4.7670e-04 - loss_2: 5.1121e-04 - loss_3: 4.2786e-04 - loss_4: 4.7278e-04 - loss_5: 5.0722e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3896 - val_loss_2: 0.3763 - val_loss_3: 0.4163 - val_loss_4: 0.3952 - val_loss_5: 0.4149 - val_acc_ensemble: 0.9074 - val_acc_1: 0.9001 - val_acc_2: 0.9039 - val_acc_3: 0.8944 - val_acc_4: 0.9018 - val_acc_5: 0.8971\n",
      "Epoch 4/10\n",
      " - 2s - loss_1: 3.1714e-04 - loss_2: 3.1847e-04 - loss_3: 2.8617e-04 - loss_4: 3.0059e-04 - loss_5: 3.0929e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3920 - val_loss_2: 0.3783 - val_loss_3: 0.4171 - val_loss_4: 0.3977 - val_loss_5: 0.4161 - val_acc_ensemble: 0.9082 - val_acc_1: 0.9018 - val_acc_2: 0.9048 - val_acc_3: 0.8954 - val_acc_4: 0.9027 - val_acc_5: 0.8978\n",
      "Epoch 5/10\n",
      " - 2s - loss_1: 2.3959e-04 - loss_2: 2.4156e-04 - loss_3: 2.1219e-04 - loss_4: 2.3351e-04 - loss_5: 2.3079e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3945 - val_loss_2: 0.3813 - val_loss_3: 0.4193 - val_loss_4: 0.4007 - val_loss_5: 0.4181 - val_acc_ensemble: 0.9077 - val_acc_1: 0.9029 - val_acc_2: 0.9055 - val_acc_3: 0.8956 - val_acc_4: 0.9030 - val_acc_5: 0.8985\n",
      "Epoch 6/10\n",
      " - 2s - loss_1: 1.7832e-04 - loss_2: 1.8512e-04 - loss_3: 1.7640e-04 - loss_4: 1.8426e-04 - loss_5: 1.8097e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3970 - val_loss_2: 0.3837 - val_loss_3: 0.4217 - val_loss_4: 0.4041 - val_loss_5: 0.4200 - val_acc_ensemble: 0.9077 - val_acc_1: 0.9029 - val_acc_2: 0.9056 - val_acc_3: 0.8959 - val_acc_4: 0.9035 - val_acc_5: 0.8986\n",
      "Epoch 7/10\n",
      " - 2s - loss_1: 1.5778e-04 - loss_2: 1.5742e-04 - loss_3: 1.3849e-04 - loss_4: 1.5009e-04 - loss_5: 1.4797e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4000 - val_loss_2: 0.3860 - val_loss_3: 0.4235 - val_loss_4: 0.4064 - val_loss_5: 0.4216 - val_acc_ensemble: 0.9078 - val_acc_1: 0.9030 - val_acc_2: 0.9061 - val_acc_3: 0.8966 - val_acc_4: 0.9035 - val_acc_5: 0.8993\n",
      "Epoch 8/10\n",
      " - 2s - loss_1: 1.2976e-04 - loss_2: 1.2818e-04 - loss_3: 1.2638e-04 - loss_4: 1.2541e-04 - loss_5: 1.1813e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4026 - val_loss_2: 0.3880 - val_loss_3: 0.4259 - val_loss_4: 0.4087 - val_loss_5: 0.4238 - val_acc_ensemble: 0.9077 - val_acc_1: 0.9033 - val_acc_2: 0.9066 - val_acc_3: 0.8970 - val_acc_4: 0.9034 - val_acc_5: 0.9001\n",
      "Epoch 9/10\n",
      " - 2s - loss_1: 1.0830e-04 - loss_2: 1.1146e-04 - loss_3: 1.1093e-04 - loss_4: 1.0582e-04 - loss_5: 1.1246e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4045 - val_loss_2: 0.3899 - val_loss_3: 0.4278 - val_loss_4: 0.4108 - val_loss_5: 0.4257 - val_acc_ensemble: 0.9082 - val_acc_1: 0.9032 - val_acc_2: 0.9063 - val_acc_3: 0.8974 - val_acc_4: 0.9034 - val_acc_5: 0.9005\n",
      "Epoch 10/10\n",
      " - 2s - loss_1: 9.5776e-05 - loss_2: 9.7164e-05 - loss_3: 9.1603e-05 - loss_4: 9.5858e-05 - loss_5: 9.4573e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4065 - val_loss_2: 0.3916 - val_loss_3: 0.4296 - val_loss_4: 0.4131 - val_loss_5: 0.4277 - val_acc_ensemble: 0.9081 - val_acc_1: 0.9035 - val_acc_2: 0.9061 - val_acc_3: 0.8975 - val_acc_4: 0.9038 - val_acc_5: 0.9014\n",
      "sensitivity/vb-mnist-fcn3A/B5/S0.75\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,384] [None,128]  803840     input    \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,384] [None,128]  2048       fc1      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,384] [None,128]  0          bn1      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,384] [None,128]  724480     relu1    \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,384] [None,128]  2048       fc2      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,384] [None,128]  0          bn2      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,384] [None,128]  724480     relu2    \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,384] [None,128]  2048       fc3      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,384] [None,128]  0          bn3      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              14920      relu3    \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 2273864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 5s - loss_1: 0.1843 - loss_2: 0.1601 - loss_3: 0.1638 - loss_4: 0.1509 - loss_5: 0.1679 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4265 - val_loss_2: 0.4096 - val_loss_3: 0.4109 - val_loss_4: 0.4207 - val_loss_5: 0.4090 - val_acc_ensemble: 0.8958 - val_acc_1: 0.8907 - val_acc_2: 0.8880 - val_acc_3: 0.8903 - val_acc_4: 0.8895 - val_acc_5: 0.8938\n",
      "Epoch 2/10\n",
      " - 2s - loss_1: 7.3577e-04 - loss_2: 7.3377e-04 - loss_3: 7.5179e-04 - loss_4: 5.9506e-04 - loss_5: 8.1762e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4197 - val_loss_2: 0.4042 - val_loss_3: 0.4009 - val_loss_4: 0.4152 - val_loss_5: 0.4058 - val_acc_ensemble: 0.8999 - val_acc_1: 0.8956 - val_acc_2: 0.8943 - val_acc_3: 0.8964 - val_acc_4: 0.8934 - val_acc_5: 0.8970\n",
      "Epoch 3/10\n",
      " - 2s - loss_1: 3.5748e-04 - loss_2: 3.4149e-04 - loss_3: 3.5895e-04 - loss_4: 3.4085e-04 - loss_5: 3.4215e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4213 - val_loss_2: 0.4077 - val_loss_3: 0.4043 - val_loss_4: 0.4176 - val_loss_5: 0.4071 - val_acc_ensemble: 0.9006 - val_acc_1: 0.8967 - val_acc_2: 0.8968 - val_acc_3: 0.8977 - val_acc_4: 0.8955 - val_acc_5: 0.8978\n",
      "Epoch 4/10\n",
      " - 2s - loss_1: 2.6178e-04 - loss_2: 2.2785e-04 - loss_3: 2.2678e-04 - loss_4: 2.2231e-04 - loss_5: 2.3961e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4241 - val_loss_2: 0.4115 - val_loss_3: 0.4078 - val_loss_4: 0.4207 - val_loss_5: 0.4098 - val_acc_ensemble: 0.9004 - val_acc_1: 0.8977 - val_acc_2: 0.8971 - val_acc_3: 0.8984 - val_acc_4: 0.8962 - val_acc_5: 0.8989\n",
      "Epoch 5/10\n",
      " - 2s - loss_1: 1.8691e-04 - loss_2: 1.7334e-04 - loss_3: 1.7289e-04 - loss_4: 1.6495e-04 - loss_5: 1.7454e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4272 - val_loss_2: 0.4156 - val_loss_3: 0.4111 - val_loss_4: 0.4234 - val_loss_5: 0.4120 - val_acc_ensemble: 0.9006 - val_acc_1: 0.8985 - val_acc_2: 0.8973 - val_acc_3: 0.8993 - val_acc_4: 0.8971 - val_acc_5: 0.8994\n",
      "Epoch 6/10\n",
      " - 2s - loss_1: 1.4196e-04 - loss_2: 1.5195e-04 - loss_3: 1.4710e-04 - loss_4: 1.2848e-04 - loss_5: 1.4431e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4305 - val_loss_2: 0.4192 - val_loss_3: 0.4143 - val_loss_4: 0.4262 - val_loss_5: 0.4148 - val_acc_ensemble: 0.9009 - val_acc_1: 0.8982 - val_acc_2: 0.8974 - val_acc_3: 0.8995 - val_acc_4: 0.8969 - val_acc_5: 0.8994\n",
      "Epoch 7/10\n",
      " - 2s - loss_1: 1.2288e-04 - loss_2: 1.1395e-04 - loss_3: 1.1142e-04 - loss_4: 1.1011e-04 - loss_5: 1.1973e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4330 - val_loss_2: 0.4222 - val_loss_3: 0.4166 - val_loss_4: 0.4284 - val_loss_5: 0.4171 - val_acc_ensemble: 0.9009 - val_acc_1: 0.8989 - val_acc_2: 0.8975 - val_acc_3: 0.8995 - val_acc_4: 0.8974 - val_acc_5: 0.8999\n",
      "Epoch 8/10\n",
      " - 2s - loss_1: 1.0098e-04 - loss_2: 9.9196e-05 - loss_3: 9.8041e-05 - loss_4: 9.6249e-05 - loss_5: 9.7172e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4359 - val_loss_2: 0.4247 - val_loss_3: 0.4190 - val_loss_4: 0.4312 - val_loss_5: 0.4190 - val_acc_ensemble: 0.9011 - val_acc_1: 0.8995 - val_acc_2: 0.8980 - val_acc_3: 0.8997 - val_acc_4: 0.8972 - val_acc_5: 0.9000\n",
      "Epoch 9/10\n",
      " - 2s - loss_1: 8.6227e-05 - loss_2: 8.6532e-05 - loss_3: 8.2166e-05 - loss_4: 8.4867e-05 - loss_5: 8.4059e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4386 - val_loss_2: 0.4273 - val_loss_3: 0.4217 - val_loss_4: 0.4337 - val_loss_5: 0.4212 - val_acc_ensemble: 0.9010 - val_acc_1: 0.9000 - val_acc_2: 0.8982 - val_acc_3: 0.8997 - val_acc_4: 0.8976 - val_acc_5: 0.9002\n",
      "Epoch 10/10\n",
      " - 2s - loss_1: 7.3752e-05 - loss_2: 7.3261e-05 - loss_3: 6.8557e-05 - loss_4: 6.8738e-05 - loss_5: 7.3330e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4410 - val_loss_2: 0.4299 - val_loss_3: 0.4236 - val_loss_4: 0.4360 - val_loss_5: 0.4231 - val_acc_ensemble: 0.9015 - val_acc_1: 0.8999 - val_acc_2: 0.8982 - val_acc_3: 0.9000 - val_acc_4: 0.8971 - val_acc_5: 0.9006\n",
      "sensitivity/vb-mnist-fcn3A/B5/S0.75\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,384] [None,128]  803840     input    \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,384] [None,128]  2048       fc1      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,384] [None,128]  0          bn1      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,384] [None,128]  724480     relu1    \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,384] [None,128]  2048       fc2      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,384] [None,128]  0          bn2      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,384] [None,128]  724480     relu2    \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,384] [None,128]  2048       fc3      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,384] [None,128]  0          bn3      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              14920      relu3    \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 2273864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 5s - loss_1: 0.1760 - loss_2: 0.1682 - loss_3: 0.1823 - loss_4: 0.1732 - loss_5: 0.1937 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4808 - val_loss_2: 0.4310 - val_loss_3: 0.4318 - val_loss_4: 0.4493 - val_loss_5: 0.3951 - val_acc_ensemble: 0.8950 - val_acc_1: 0.8823 - val_acc_2: 0.8899 - val_acc_3: 0.8903 - val_acc_4: 0.8854 - val_acc_5: 0.8982\n",
      "Epoch 2/10\n",
      " - 2s - loss_1: 7.0723e-04 - loss_2: 8.6645e-04 - loss_3: 7.4608e-04 - loss_4: 7.4572e-04 - loss_5: 7.7941e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4568 - val_loss_2: 0.4207 - val_loss_3: 0.4216 - val_loss_4: 0.4288 - val_loss_5: 0.3919 - val_acc_ensemble: 0.9006 - val_acc_1: 0.8910 - val_acc_2: 0.8963 - val_acc_3: 0.8957 - val_acc_4: 0.8945 - val_acc_5: 0.9031\n",
      "Epoch 3/10\n",
      " - 2s - loss_1: 3.2710e-04 - loss_2: 3.6899e-04 - loss_3: 3.4961e-04 - loss_4: 3.3718e-04 - loss_5: 3.7625e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4556 - val_loss_2: 0.4223 - val_loss_3: 0.4239 - val_loss_4: 0.4300 - val_loss_5: 0.3947 - val_acc_ensemble: 0.9027 - val_acc_1: 0.8921 - val_acc_2: 0.8976 - val_acc_3: 0.8981 - val_acc_4: 0.8961 - val_acc_5: 0.9038\n",
      "Epoch 4/10\n",
      " - 2s - loss_1: 2.1286e-04 - loss_2: 2.6223e-04 - loss_3: 2.2293e-04 - loss_4: 2.4119e-04 - loss_5: 2.5263e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4575 - val_loss_2: 0.4251 - val_loss_3: 0.4274 - val_loss_4: 0.4333 - val_loss_5: 0.3988 - val_acc_ensemble: 0.9029 - val_acc_1: 0.8934 - val_acc_2: 0.8986 - val_acc_3: 0.8988 - val_acc_4: 0.8971 - val_acc_5: 0.9042\n",
      "Epoch 5/10\n",
      " - 2s - loss_1: 1.5619e-04 - loss_2: 1.8973e-04 - loss_3: 1.7744e-04 - loss_4: 1.7663e-04 - loss_5: 1.9891e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4589 - val_loss_2: 0.4276 - val_loss_3: 0.4301 - val_loss_4: 0.4363 - val_loss_5: 0.4026 - val_acc_ensemble: 0.9025 - val_acc_1: 0.8944 - val_acc_2: 0.8993 - val_acc_3: 0.8991 - val_acc_4: 0.8980 - val_acc_5: 0.9051\n",
      "Epoch 6/10\n",
      " - 2s - loss_1: 1.2802e-04 - loss_2: 1.4926e-04 - loss_3: 1.3302e-04 - loss_4: 1.3651e-04 - loss_5: 1.5584e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4612 - val_loss_2: 0.4308 - val_loss_3: 0.4331 - val_loss_4: 0.4395 - val_loss_5: 0.4059 - val_acc_ensemble: 0.9026 - val_acc_1: 0.8950 - val_acc_2: 0.8996 - val_acc_3: 0.8994 - val_acc_4: 0.8978 - val_acc_5: 0.9046\n",
      "Epoch 7/10\n",
      " - 2s - loss_1: 1.0774e-04 - loss_2: 1.0962e-04 - loss_3: 1.2207e-04 - loss_4: 1.1596e-04 - loss_5: 1.3280e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4637 - val_loss_2: 0.4336 - val_loss_3: 0.4366 - val_loss_4: 0.4422 - val_loss_5: 0.4093 - val_acc_ensemble: 0.9023 - val_acc_1: 0.8953 - val_acc_2: 0.9000 - val_acc_3: 0.8994 - val_acc_4: 0.8978 - val_acc_5: 0.9046\n",
      "Epoch 8/10\n",
      " - 2s - loss_1: 8.7538e-05 - loss_2: 9.5807e-05 - loss_3: 8.9563e-05 - loss_4: 9.3705e-05 - loss_5: 1.0686e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4657 - val_loss_2: 0.4361 - val_loss_3: 0.4388 - val_loss_4: 0.4450 - val_loss_5: 0.4119 - val_acc_ensemble: 0.9026 - val_acc_1: 0.8953 - val_acc_2: 0.9001 - val_acc_3: 0.8994 - val_acc_4: 0.8980 - val_acc_5: 0.9048\n",
      "Epoch 9/10\n",
      " - 2s - loss_1: 7.8804e-05 - loss_2: 8.9515e-05 - loss_3: 8.3866e-05 - loss_4: 8.2474e-05 - loss_5: 9.2655e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4676 - val_loss_2: 0.4378 - val_loss_3: 0.4411 - val_loss_4: 0.4471 - val_loss_5: 0.4141 - val_acc_ensemble: 0.9033 - val_acc_1: 0.8958 - val_acc_2: 0.9003 - val_acc_3: 0.8993 - val_acc_4: 0.8985 - val_acc_5: 0.9049\n",
      "Epoch 10/10\n",
      " - 2s - loss_1: 6.7762e-05 - loss_2: 7.5459e-05 - loss_3: 7.1864e-05 - loss_4: 7.1589e-05 - loss_5: 7.8546e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4692 - val_loss_2: 0.4397 - val_loss_3: 0.4429 - val_loss_4: 0.4489 - val_loss_5: 0.4162 - val_acc_ensemble: 0.9034 - val_acc_1: 0.8965 - val_acc_2: 0.9008 - val_acc_3: 0.8993 - val_acc_4: 0.8986 - val_acc_5: 0.9051\n",
      "sensitivity/vb-mnist-fcn3A/B5/S0.75\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,384] [None,128]  803840     input    \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,384] [None,128]  2048       fc1      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,384] [None,128]  0          bn1      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,384] [None,128]  724480     relu1    \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,384] [None,128]  2048       fc2      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,384] [None,128]  0          bn2      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,384] [None,128]  724480     relu2    \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,384] [None,128]  2048       fc3      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,384] [None,128]  0          bn3      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              14920      relu3    \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 2273864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 5s - loss_1: 0.1681 - loss_2: 0.1745 - loss_3: 0.1722 - loss_4: 0.1554 - loss_5: 0.1588 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4630 - val_loss_2: 0.4190 - val_loss_3: 0.4186 - val_loss_4: 0.4334 - val_loss_5: 0.4424 - val_acc_ensemble: 0.8984 - val_acc_1: 0.8841 - val_acc_2: 0.8917 - val_acc_3: 0.8926 - val_acc_4: 0.8893 - val_acc_5: 0.8850\n",
      "Epoch 2/10\n",
      " - 2s - loss_1: 8.3132e-04 - loss_2: 8.2877e-04 - loss_3: 8.0967e-04 - loss_4: 7.8467e-04 - loss_5: 7.3752e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4392 - val_loss_2: 0.4075 - val_loss_3: 0.4093 - val_loss_4: 0.4170 - val_loss_5: 0.4250 - val_acc_ensemble: 0.9009 - val_acc_1: 0.8927 - val_acc_2: 0.8982 - val_acc_3: 0.9010 - val_acc_4: 0.8978 - val_acc_5: 0.8949\n",
      "Epoch 3/10\n",
      " - 2s - loss_1: 3.1523e-04 - loss_2: 3.5973e-04 - loss_3: 3.3565e-04 - loss_4: 3.4024e-04 - loss_5: 3.1439e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4379 - val_loss_2: 0.4096 - val_loss_3: 0.4109 - val_loss_4: 0.4156 - val_loss_5: 0.4260 - val_acc_ensemble: 0.9026 - val_acc_1: 0.8950 - val_acc_2: 0.8995 - val_acc_3: 0.9033 - val_acc_4: 0.8994 - val_acc_5: 0.8954\n",
      "Epoch 4/10\n",
      " - 2s - loss_1: 2.1253e-04 - loss_2: 2.3473e-04 - loss_3: 2.3185e-04 - loss_4: 2.3009e-04 - loss_5: 2.0534e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4388 - val_loss_2: 0.4127 - val_loss_3: 0.4139 - val_loss_4: 0.4172 - val_loss_5: 0.4270 - val_acc_ensemble: 0.9029 - val_acc_1: 0.8972 - val_acc_2: 0.8996 - val_acc_3: 0.9035 - val_acc_4: 0.8994 - val_acc_5: 0.8963\n",
      "Epoch 5/10\n",
      " - 2s - loss_1: 1.6090e-04 - loss_2: 1.6775e-04 - loss_3: 1.8300e-04 - loss_4: 1.8088e-04 - loss_5: 1.5609e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4399 - val_loss_2: 0.4151 - val_loss_3: 0.4171 - val_loss_4: 0.4188 - val_loss_5: 0.4286 - val_acc_ensemble: 0.9032 - val_acc_1: 0.8977 - val_acc_2: 0.9000 - val_acc_3: 0.9036 - val_acc_4: 0.9003 - val_acc_5: 0.8967\n",
      "Epoch 6/10\n",
      " - 2s - loss_1: 1.3047e-04 - loss_2: 1.4143e-04 - loss_3: 1.4138e-04 - loss_4: 1.4376e-04 - loss_5: 1.3681e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4411 - val_loss_2: 0.4179 - val_loss_3: 0.4196 - val_loss_4: 0.4205 - val_loss_5: 0.4305 - val_acc_ensemble: 0.9035 - val_acc_1: 0.8975 - val_acc_2: 0.9003 - val_acc_3: 0.9037 - val_acc_4: 0.9011 - val_acc_5: 0.8972\n",
      "Epoch 7/10\n",
      " - 2s - loss_1: 1.1271e-04 - loss_2: 1.1121e-04 - loss_3: 1.1035e-04 - loss_4: 1.1007e-04 - loss_5: 1.1009e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4431 - val_loss_2: 0.4204 - val_loss_3: 0.4227 - val_loss_4: 0.4229 - val_loss_5: 0.4326 - val_acc_ensemble: 0.9030 - val_acc_1: 0.8978 - val_acc_2: 0.9004 - val_acc_3: 0.9040 - val_acc_4: 0.9012 - val_acc_5: 0.8977\n",
      "Epoch 8/10\n",
      " - 2s - loss_1: 9.1736e-05 - loss_2: 9.5936e-05 - loss_3: 9.2520e-05 - loss_4: 9.4174e-05 - loss_5: 9.0515e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4451 - val_loss_2: 0.4231 - val_loss_3: 0.4254 - val_loss_4: 0.4255 - val_loss_5: 0.4347 - val_acc_ensemble: 0.9031 - val_acc_1: 0.8980 - val_acc_2: 0.9005 - val_acc_3: 0.9043 - val_acc_4: 0.9005 - val_acc_5: 0.8976\n",
      "Epoch 9/10\n",
      " - 2s - loss_1: 7.6825e-05 - loss_2: 8.9684e-05 - loss_3: 8.3060e-05 - loss_4: 8.1837e-05 - loss_5: 7.8661e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4468 - val_loss_2: 0.4251 - val_loss_3: 0.4274 - val_loss_4: 0.4269 - val_loss_5: 0.4360 - val_acc_ensemble: 0.9034 - val_acc_1: 0.8977 - val_acc_2: 0.9001 - val_acc_3: 0.9044 - val_acc_4: 0.9013 - val_acc_5: 0.8984\n",
      "Epoch 10/10\n",
      " - 2s - loss_1: 6.8678e-05 - loss_2: 7.3252e-05 - loss_3: 7.3053e-05 - loss_4: 6.9344e-05 - loss_5: 6.8085e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4484 - val_loss_2: 0.4273 - val_loss_3: 0.4297 - val_loss_4: 0.4288 - val_loss_5: 0.4382 - val_acc_ensemble: 0.9029 - val_acc_1: 0.8982 - val_acc_2: 0.9001 - val_acc_3: 0.9045 - val_acc_4: 0.9015 - val_acc_5: 0.8984\n",
      "sensitivity/vb-mnist-fcn3A/B5/S0.75\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,384] [None,128]  803840     input    \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,384] [None,128]  2048       fc1      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,384] [None,128]  0          bn1      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,384] [None,128]  724480     relu1    \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,384] [None,128]  2048       fc2      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,384] [None,128]  0          bn2      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,384] [None,128]  724480     relu2    \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,384] [None,128]  2048       fc3      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,384] [None,128]  0          bn3      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              14920      relu3    \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 2273864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 5s - loss_1: 0.1616 - loss_2: 0.1721 - loss_3: 0.1624 - loss_4: 0.1644 - loss_5: 0.1757 - acc_ensemble: 1.0000 - acc_1: 0.9983 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4555 - val_loss_2: 0.4144 - val_loss_3: 0.4548 - val_loss_4: 0.4339 - val_loss_5: 0.4297 - val_acc_ensemble: 0.8954 - val_acc_1: 0.8854 - val_acc_2: 0.8896 - val_acc_3: 0.8863 - val_acc_4: 0.8920 - val_acc_5: 0.8910\n",
      "Epoch 2/10\n",
      " - 2s - loss_1: 8.7229e-04 - loss_2: 7.5139e-04 - loss_3: 6.4587e-04 - loss_4: 7.5036e-04 - loss_5: 8.0661e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4256 - val_loss_2: 0.4026 - val_loss_3: 0.4252 - val_loss_4: 0.4145 - val_loss_5: 0.4148 - val_acc_ensemble: 0.9007 - val_acc_1: 0.8945 - val_acc_2: 0.8978 - val_acc_3: 0.8950 - val_acc_4: 0.8968 - val_acc_5: 0.8946\n",
      "Epoch 3/10\n",
      " - 2s - loss_1: 3.6211e-04 - loss_2: 3.5056e-04 - loss_3: 3.2938e-04 - loss_4: 3.3378e-04 - loss_5: 3.5994e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4250 - val_loss_2: 0.4035 - val_loss_3: 0.4235 - val_loss_4: 0.4151 - val_loss_5: 0.4154 - val_acc_ensemble: 0.9017 - val_acc_1: 0.8966 - val_acc_2: 0.8996 - val_acc_3: 0.8978 - val_acc_4: 0.8977 - val_acc_5: 0.8958\n",
      "Epoch 4/10\n",
      " - 2s - loss_1: 2.5375e-04 - loss_2: 2.3215e-04 - loss_3: 2.2819e-04 - loss_4: 2.2432e-04 - loss_5: 2.2744e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4258 - val_loss_2: 0.4060 - val_loss_3: 0.4246 - val_loss_4: 0.4181 - val_loss_5: 0.4173 - val_acc_ensemble: 0.9017 - val_acc_1: 0.8971 - val_acc_2: 0.9003 - val_acc_3: 0.8987 - val_acc_4: 0.8985 - val_acc_5: 0.8970\n",
      "Epoch 5/10\n",
      " - 2s - loss_1: 1.6944e-04 - loss_2: 1.9507e-04 - loss_3: 1.6514e-04 - loss_4: 1.6649e-04 - loss_5: 1.9750e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4282 - val_loss_2: 0.4093 - val_loss_3: 0.4265 - val_loss_4: 0.4212 - val_loss_5: 0.4199 - val_acc_ensemble: 0.9023 - val_acc_1: 0.8967 - val_acc_2: 0.9014 - val_acc_3: 0.8992 - val_acc_4: 0.8987 - val_acc_5: 0.8971\n",
      "Epoch 6/10\n",
      " - 2s - loss_1: 1.4452e-04 - loss_2: 1.5027e-04 - loss_3: 1.2991e-04 - loss_4: 1.4001e-04 - loss_5: 1.4731e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4308 - val_loss_2: 0.4126 - val_loss_3: 0.4287 - val_loss_4: 0.4239 - val_loss_5: 0.4227 - val_acc_ensemble: 0.9027 - val_acc_1: 0.8971 - val_acc_2: 0.9017 - val_acc_3: 0.9000 - val_acc_4: 0.8993 - val_acc_5: 0.8975\n",
      "Epoch 7/10\n",
      " - 2s - loss_1: 1.1600e-04 - loss_2: 1.2281e-04 - loss_3: 1.0892e-04 - loss_4: 1.1003e-04 - loss_5: 1.2044e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4322 - val_loss_2: 0.4150 - val_loss_3: 0.4299 - val_loss_4: 0.4258 - val_loss_5: 0.4247 - val_acc_ensemble: 0.9031 - val_acc_1: 0.8975 - val_acc_2: 0.9018 - val_acc_3: 0.9007 - val_acc_4: 0.9001 - val_acc_5: 0.8976\n",
      "Epoch 8/10\n",
      " - 2s - loss_1: 1.0015e-04 - loss_2: 1.0266e-04 - loss_3: 8.7537e-05 - loss_4: 9.4477e-05 - loss_5: 1.0130e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4344 - val_loss_2: 0.4177 - val_loss_3: 0.4318 - val_loss_4: 0.4278 - val_loss_5: 0.4271 - val_acc_ensemble: 0.9032 - val_acc_1: 0.8981 - val_acc_2: 0.9023 - val_acc_3: 0.9011 - val_acc_4: 0.8994 - val_acc_5: 0.8977\n",
      "Epoch 9/10\n",
      " - 2s - loss_1: 8.4168e-05 - loss_2: 8.7550e-05 - loss_3: 7.7515e-05 - loss_4: 8.3888e-05 - loss_5: 9.0708e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4361 - val_loss_2: 0.4198 - val_loss_3: 0.4338 - val_loss_4: 0.4298 - val_loss_5: 0.4294 - val_acc_ensemble: 0.9033 - val_acc_1: 0.8980 - val_acc_2: 0.9030 - val_acc_3: 0.9010 - val_acc_4: 0.8993 - val_acc_5: 0.8983\n",
      "Epoch 10/10\n",
      " - 2s - loss_1: 7.0477e-05 - loss_2: 7.5004e-05 - loss_3: 6.9653e-05 - loss_4: 7.0275e-05 - loss_5: 8.1846e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4383 - val_loss_2: 0.4219 - val_loss_3: 0.4356 - val_loss_4: 0.4322 - val_loss_5: 0.4313 - val_acc_ensemble: 0.9034 - val_acc_1: 0.8980 - val_acc_2: 0.9027 - val_acc_3: 0.9012 - val_acc_4: 0.8999 - val_acc_5: 0.8983\n",
      "sensitivity/vb-mnist-fcn3A/B5/S1.00\n",
      "i  Layer name                Output shape   Num param  Inbound  \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,512] []  401920     input    \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,512] []  1024       fc1      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,512] []  0          bn1      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,512] []  262656     relu1    \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,512] []  1024       fc2      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,512] []  0          bn2      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,512] []  262656     relu2    \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,512] []  1024       fc3      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,512] []  0          bn3      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]      5130       relu3    \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "----------------------------------------------------------------\n",
      "Total parameters: 935434\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 2s - loss_1: 0.0765 - loss_2: 0.0734 - loss_3: 0.0829 - loss_4: 0.0944 - loss_5: 0.0888 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3500 - val_loss_2: 0.3500 - val_loss_3: 0.3500 - val_loss_4: 0.3500 - val_loss_5: 0.3500 - val_acc_ensemble: 0.9009 - val_acc_1: 0.9009 - val_acc_2: 0.9009 - val_acc_3: 0.9009 - val_acc_4: 0.9009 - val_acc_5: 0.9009\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 7.5870e-04 - loss_2: 7.5949e-04 - loss_3: 7.1964e-04 - loss_4: 7.5616e-04 - loss_5: 7.3291e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3506 - val_loss_2: 0.3506 - val_loss_3: 0.3506 - val_loss_4: 0.3506 - val_loss_5: 0.3506 - val_acc_ensemble: 0.9008 - val_acc_1: 0.9008 - val_acc_2: 0.9008 - val_acc_3: 0.9008 - val_acc_4: 0.9008 - val_acc_5: 0.9008\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 3.8603e-04 - loss_2: 4.0354e-04 - loss_3: 3.8788e-04 - loss_4: 3.8953e-04 - loss_5: 3.9039e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3540 - val_loss_2: 0.3540 - val_loss_3: 0.3540 - val_loss_4: 0.3540 - val_loss_5: 0.3540 - val_acc_ensemble: 0.9004 - val_acc_1: 0.9004 - val_acc_2: 0.9004 - val_acc_3: 0.9004 - val_acc_4: 0.9004 - val_acc_5: 0.9004\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 2.5110e-04 - loss_2: 2.5340e-04 - loss_3: 2.5917e-04 - loss_4: 2.5013e-04 - loss_5: 2.5401e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3589 - val_loss_2: 0.3589 - val_loss_3: 0.3589 - val_loss_4: 0.3589 - val_loss_5: 0.3589 - val_acc_ensemble: 0.9007 - val_acc_1: 0.9007 - val_acc_2: 0.9007 - val_acc_3: 0.9007 - val_acc_4: 0.9007 - val_acc_5: 0.9007\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 1.7999e-04 - loss_2: 1.7637e-04 - loss_3: 1.7779e-04 - loss_4: 1.7864e-04 - loss_5: 1.8468e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3629 - val_loss_2: 0.3629 - val_loss_3: 0.3629 - val_loss_4: 0.3629 - val_loss_5: 0.3629 - val_acc_ensemble: 0.9013 - val_acc_1: 0.9013 - val_acc_2: 0.9013 - val_acc_3: 0.9013 - val_acc_4: 0.9013 - val_acc_5: 0.9013\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 1.3665e-04 - loss_2: 1.3315e-04 - loss_3: 1.3526e-04 - loss_4: 1.3444e-04 - loss_5: 1.3007e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3650 - val_loss_2: 0.3650 - val_loss_3: 0.3650 - val_loss_4: 0.3650 - val_loss_5: 0.3650 - val_acc_ensemble: 0.9020 - val_acc_1: 0.9020 - val_acc_2: 0.9020 - val_acc_3: 0.9020 - val_acc_4: 0.9020 - val_acc_5: 0.9020\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 1.0730e-04 - loss_2: 1.0417e-04 - loss_3: 1.0310e-04 - loss_4: 1.0470e-04 - loss_5: 1.0640e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3682 - val_loss_2: 0.3682 - val_loss_3: 0.3682 - val_loss_4: 0.3682 - val_loss_5: 0.3682 - val_acc_ensemble: 0.9022 - val_acc_1: 0.9022 - val_acc_2: 0.9022 - val_acc_3: 0.9022 - val_acc_4: 0.9022 - val_acc_5: 0.9022\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 8.3744e-05 - loss_2: 8.5075e-05 - loss_3: 8.2942e-05 - loss_4: 8.2163e-05 - loss_5: 8.1808e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3707 - val_loss_2: 0.3707 - val_loss_3: 0.3707 - val_loss_4: 0.3707 - val_loss_5: 0.3707 - val_acc_ensemble: 0.9021 - val_acc_1: 0.9021 - val_acc_2: 0.9021 - val_acc_3: 0.9021 - val_acc_4: 0.9021 - val_acc_5: 0.9021\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 6.8212e-05 - loss_2: 7.0475e-05 - loss_3: 6.8992e-05 - loss_4: 6.9456e-05 - loss_5: 6.9294e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3734 - val_loss_2: 0.3734 - val_loss_3: 0.3734 - val_loss_4: 0.3734 - val_loss_5: 0.3734 - val_acc_ensemble: 0.9022 - val_acc_1: 0.9022 - val_acc_2: 0.9022 - val_acc_3: 0.9022 - val_acc_4: 0.9022 - val_acc_5: 0.9022\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 5.9236e-05 - loss_2: 5.7108e-05 - loss_3: 6.0161e-05 - loss_4: 5.7369e-05 - loss_5: 6.0275e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3759 - val_loss_2: 0.3759 - val_loss_3: 0.3759 - val_loss_4: 0.3759 - val_loss_5: 0.3759 - val_acc_ensemble: 0.9022 - val_acc_1: 0.9022 - val_acc_2: 0.9022 - val_acc_3: 0.9022 - val_acc_4: 0.9022 - val_acc_5: 0.9022\n",
      "sensitivity/vb-mnist-fcn3A/B5/S1.00\n",
      "i  Layer name                Output shape   Num param  Inbound  \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,512] []  401920     input    \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,512] []  1024       fc1      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,512] []  0          bn1      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,512] []  262656     relu1    \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,512] []  1024       fc2      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,512] []  0          bn2      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,512] []  262656     relu2    \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,512] []  1024       fc3      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,512] []  0          bn3      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]      5130       relu3    \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "----------------------------------------------------------------\n",
      "Total parameters: 935434\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 2s - loss_1: 0.0880 - loss_2: 0.1063 - loss_3: 0.0856 - loss_4: 0.0920 - loss_5: 0.1051 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3544 - val_loss_2: 0.3544 - val_loss_3: 0.3544 - val_loss_4: 0.3544 - val_loss_5: 0.3544 - val_acc_ensemble: 0.8991 - val_acc_1: 0.8991 - val_acc_2: 0.8991 - val_acc_3: 0.8991 - val_acc_4: 0.8991 - val_acc_5: 0.8991\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 8.8681e-04 - loss_2: 8.3690e-04 - loss_3: 9.0322e-04 - loss_4: 8.7832e-04 - loss_5: 8.8370e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3591 - val_loss_2: 0.3591 - val_loss_3: 0.3591 - val_loss_4: 0.3591 - val_loss_5: 0.3591 - val_acc_ensemble: 0.9002 - val_acc_1: 0.9002 - val_acc_2: 0.9002 - val_acc_3: 0.9002 - val_acc_4: 0.9002 - val_acc_5: 0.9002\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 4.3263e-04 - loss_2: 4.4033e-04 - loss_3: 4.5802e-04 - loss_4: 4.4510e-04 - loss_5: 4.5181e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3643 - val_loss_2: 0.3643 - val_loss_3: 0.3643 - val_loss_4: 0.3643 - val_loss_5: 0.3643 - val_acc_ensemble: 0.9002 - val_acc_1: 0.9002 - val_acc_2: 0.9002 - val_acc_3: 0.9002 - val_acc_4: 0.9002 - val_acc_5: 0.9002\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 2.8985e-04 - loss_2: 2.8863e-04 - loss_3: 2.8930e-04 - loss_4: 2.8271e-04 - loss_5: 2.8387e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3695 - val_loss_2: 0.3695 - val_loss_3: 0.3695 - val_loss_4: 0.3695 - val_loss_5: 0.3695 - val_acc_ensemble: 0.9009 - val_acc_1: 0.9009 - val_acc_2: 0.9009 - val_acc_3: 0.9009 - val_acc_4: 0.9009 - val_acc_5: 0.9009\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 2.0151e-04 - loss_2: 2.0026e-04 - loss_3: 1.9935e-04 - loss_4: 2.0033e-04 - loss_5: 2.0456e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3737 - val_loss_2: 0.3737 - val_loss_3: 0.3737 - val_loss_4: 0.3737 - val_loss_5: 0.3737 - val_acc_ensemble: 0.9011 - val_acc_1: 0.9011 - val_acc_2: 0.9011 - val_acc_3: 0.9011 - val_acc_4: 0.9011 - val_acc_5: 0.9011\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 1.4672e-04 - loss_2: 1.4994e-04 - loss_3: 1.5067e-04 - loss_4: 1.4812e-04 - loss_5: 1.5151e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3774 - val_loss_2: 0.3774 - val_loss_3: 0.3774 - val_loss_4: 0.3774 - val_loss_5: 0.3774 - val_acc_ensemble: 0.9016 - val_acc_1: 0.9016 - val_acc_2: 0.9016 - val_acc_3: 0.9016 - val_acc_4: 0.9016 - val_acc_5: 0.9016\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 1.1906e-04 - loss_2: 1.1384e-04 - loss_3: 1.1785e-04 - loss_4: 1.1820e-04 - loss_5: 1.1390e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3807 - val_loss_2: 0.3807 - val_loss_3: 0.3807 - val_loss_4: 0.3807 - val_loss_5: 0.3807 - val_acc_ensemble: 0.9012 - val_acc_1: 0.9012 - val_acc_2: 0.9012 - val_acc_3: 0.9012 - val_acc_4: 0.9012 - val_acc_5: 0.9012\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 9.8138e-05 - loss_2: 9.6672e-05 - loss_3: 9.3027e-05 - loss_4: 9.4010e-05 - loss_5: 9.4702e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3845 - val_loss_2: 0.3845 - val_loss_3: 0.3845 - val_loss_4: 0.3845 - val_loss_5: 0.3845 - val_acc_ensemble: 0.9011 - val_acc_1: 0.9011 - val_acc_2: 0.9011 - val_acc_3: 0.9011 - val_acc_4: 0.9011 - val_acc_5: 0.9011\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 7.6684e-05 - loss_2: 7.8576e-05 - loss_3: 7.6565e-05 - loss_4: 8.1048e-05 - loss_5: 7.7919e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3876 - val_loss_2: 0.3876 - val_loss_3: 0.3876 - val_loss_4: 0.3876 - val_loss_5: 0.3876 - val_acc_ensemble: 0.9011 - val_acc_1: 0.9011 - val_acc_2: 0.9011 - val_acc_3: 0.9011 - val_acc_4: 0.9011 - val_acc_5: 0.9011\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 6.6261e-05 - loss_2: 6.7315e-05 - loss_3: 6.6402e-05 - loss_4: 6.4643e-05 - loss_5: 6.5081e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3906 - val_loss_2: 0.3906 - val_loss_3: 0.3906 - val_loss_4: 0.3906 - val_loss_5: 0.3906 - val_acc_ensemble: 0.9013 - val_acc_1: 0.9013 - val_acc_2: 0.9013 - val_acc_3: 0.9013 - val_acc_4: 0.9013 - val_acc_5: 0.9013\n",
      "sensitivity/vb-mnist-fcn3A/B5/S1.00\n",
      "i  Layer name                Output shape   Num param  Inbound  \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,512] []  401920     input    \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,512] []  1024       fc1      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,512] []  0          bn1      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,512] []  262656     relu1    \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,512] []  1024       fc2      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,512] []  0          bn2      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,512] []  262656     relu2    \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,512] []  1024       fc3      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,512] []  0          bn3      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]      5130       relu3    \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "----------------------------------------------------------------\n",
      "Total parameters: 935434\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 2s - loss_1: 0.0725 - loss_2: 0.0802 - loss_3: 0.0900 - loss_4: 0.0671 - loss_5: 0.0736 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3655 - val_loss_2: 0.3655 - val_loss_3: 0.3655 - val_loss_4: 0.3655 - val_loss_5: 0.3655 - val_acc_ensemble: 0.8945 - val_acc_1: 0.8945 - val_acc_2: 0.8945 - val_acc_3: 0.8945 - val_acc_4: 0.8945 - val_acc_5: 0.8945\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 6.9325e-04 - loss_2: 6.8337e-04 - loss_3: 6.7937e-04 - loss_4: 6.6185e-04 - loss_5: 6.8044e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3701 - val_loss_2: 0.3701 - val_loss_3: 0.3701 - val_loss_4: 0.3701 - val_loss_5: 0.3701 - val_acc_ensemble: 0.8963 - val_acc_1: 0.8963 - val_acc_2: 0.8963 - val_acc_3: 0.8963 - val_acc_4: 0.8963 - val_acc_5: 0.8963\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 3.5546e-04 - loss_2: 3.5314e-04 - loss_3: 3.7623e-04 - loss_4: 3.4840e-04 - loss_5: 3.5268e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3757 - val_loss_2: 0.3757 - val_loss_3: 0.3757 - val_loss_4: 0.3757 - val_loss_5: 0.3757 - val_acc_ensemble: 0.8968 - val_acc_1: 0.8968 - val_acc_2: 0.8968 - val_acc_3: 0.8968 - val_acc_4: 0.8968 - val_acc_5: 0.8968\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 2.2864e-04 - loss_2: 2.2611e-04 - loss_3: 2.2974e-04 - loss_4: 2.3412e-04 - loss_5: 2.3188e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3807 - val_loss_2: 0.3807 - val_loss_3: 0.3807 - val_loss_4: 0.3807 - val_loss_5: 0.3807 - val_acc_ensemble: 0.8969 - val_acc_1: 0.8969 - val_acc_2: 0.8969 - val_acc_3: 0.8969 - val_acc_4: 0.8969 - val_acc_5: 0.8969\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 1.5989e-04 - loss_2: 1.6828e-04 - loss_3: 1.6113e-04 - loss_4: 1.6130e-04 - loss_5: 1.5776e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3845 - val_loss_2: 0.3845 - val_loss_3: 0.3845 - val_loss_4: 0.3845 - val_loss_5: 0.3845 - val_acc_ensemble: 0.8972 - val_acc_1: 0.8972 - val_acc_2: 0.8972 - val_acc_3: 0.8972 - val_acc_4: 0.8972 - val_acc_5: 0.8972\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 1.1722e-04 - loss_2: 1.2040e-04 - loss_3: 1.2405e-04 - loss_4: 1.2352e-04 - loss_5: 1.2179e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3880 - val_loss_2: 0.3880 - val_loss_3: 0.3880 - val_loss_4: 0.3880 - val_loss_5: 0.3880 - val_acc_ensemble: 0.8976 - val_acc_1: 0.8976 - val_acc_2: 0.8976 - val_acc_3: 0.8976 - val_acc_4: 0.8976 - val_acc_5: 0.8976\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 9.7138e-05 - loss_2: 9.7812e-05 - loss_3: 9.5461e-05 - loss_4: 9.2447e-05 - loss_5: 9.4845e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3921 - val_loss_2: 0.3921 - val_loss_3: 0.3921 - val_loss_4: 0.3921 - val_loss_5: 0.3921 - val_acc_ensemble: 0.8976 - val_acc_1: 0.8976 - val_acc_2: 0.8976 - val_acc_3: 0.8976 - val_acc_4: 0.8976 - val_acc_5: 0.8976\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 7.2714e-05 - loss_2: 7.7656e-05 - loss_3: 7.5337e-05 - loss_4: 7.6121e-05 - loss_5: 7.5675e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3956 - val_loss_2: 0.3956 - val_loss_3: 0.3956 - val_loss_4: 0.3956 - val_loss_5: 0.3956 - val_acc_ensemble: 0.8977 - val_acc_1: 0.8977 - val_acc_2: 0.8977 - val_acc_3: 0.8977 - val_acc_4: 0.8977 - val_acc_5: 0.8977\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 6.2122e-05 - loss_2: 6.4088e-05 - loss_3: 6.4482e-05 - loss_4: 6.4251e-05 - loss_5: 6.2417e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3985 - val_loss_2: 0.3985 - val_loss_3: 0.3985 - val_loss_4: 0.3985 - val_loss_5: 0.3985 - val_acc_ensemble: 0.8976 - val_acc_1: 0.8976 - val_acc_2: 0.8976 - val_acc_3: 0.8976 - val_acc_4: 0.8976 - val_acc_5: 0.8976\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 5.1833e-05 - loss_2: 5.2070e-05 - loss_3: 5.1516e-05 - loss_4: 5.4184e-05 - loss_5: 5.1141e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4007 - val_loss_2: 0.4007 - val_loss_3: 0.4007 - val_loss_4: 0.4007 - val_loss_5: 0.4007 - val_acc_ensemble: 0.8981 - val_acc_1: 0.8981 - val_acc_2: 0.8981 - val_acc_3: 0.8981 - val_acc_4: 0.8981 - val_acc_5: 0.8981\n",
      "sensitivity/vb-mnist-fcn3A/B5/S1.00\n",
      "i  Layer name                Output shape   Num param  Inbound  \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,512] []  401920     input    \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,512] []  1024       fc1      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,512] []  0          bn1      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,512] []  262656     relu1    \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,512] []  1024       fc2      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,512] []  0          bn2      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,512] []  262656     relu2    \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,512] []  1024       fc3      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,512] []  0          bn3      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]      5130       relu3    \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "----------------------------------------------------------------\n",
      "Total parameters: 935434\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 2s - loss_1: 0.0882 - loss_2: 0.0754 - loss_3: 0.0856 - loss_4: 0.0750 - loss_5: 0.0754 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3663 - val_loss_2: 0.3663 - val_loss_3: 0.3663 - val_loss_4: 0.3663 - val_loss_5: 0.3663 - val_acc_ensemble: 0.8936 - val_acc_1: 0.8936 - val_acc_2: 0.8936 - val_acc_3: 0.8936 - val_acc_4: 0.8936 - val_acc_5: 0.8936\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 7.3111e-04 - loss_2: 7.4088e-04 - loss_3: 7.1335e-04 - loss_4: 7.2939e-04 - loss_5: 7.4706e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3730 - val_loss_2: 0.3730 - val_loss_3: 0.3730 - val_loss_4: 0.3730 - val_loss_5: 0.3730 - val_acc_ensemble: 0.8955 - val_acc_1: 0.8955 - val_acc_2: 0.8955 - val_acc_3: 0.8955 - val_acc_4: 0.8955 - val_acc_5: 0.8955\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 3.8981e-04 - loss_2: 3.8815e-04 - loss_3: 3.7897e-04 - loss_4: 3.7322e-04 - loss_5: 3.7766e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3812 - val_loss_2: 0.3812 - val_loss_3: 0.3812 - val_loss_4: 0.3812 - val_loss_5: 0.3812 - val_acc_ensemble: 0.8964 - val_acc_1: 0.8964 - val_acc_2: 0.8964 - val_acc_3: 0.8964 - val_acc_4: 0.8964 - val_acc_5: 0.8964\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 2.3132e-04 - loss_2: 2.4186e-04 - loss_3: 2.4775e-04 - loss_4: 2.4653e-04 - loss_5: 2.5776e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3863 - val_loss_2: 0.3863 - val_loss_3: 0.3863 - val_loss_4: 0.3863 - val_loss_5: 0.3863 - val_acc_ensemble: 0.8971 - val_acc_1: 0.8971 - val_acc_2: 0.8971 - val_acc_3: 0.8971 - val_acc_4: 0.8971 - val_acc_5: 0.8971\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 1.7345e-04 - loss_2: 1.7142e-04 - loss_3: 1.6676e-04 - loss_4: 1.6990e-04 - loss_5: 1.7787e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3912 - val_loss_2: 0.3912 - val_loss_3: 0.3912 - val_loss_4: 0.3912 - val_loss_5: 0.3912 - val_acc_ensemble: 0.8972 - val_acc_1: 0.8972 - val_acc_2: 0.8972 - val_acc_3: 0.8972 - val_acc_4: 0.8972 - val_acc_5: 0.8972\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 1.3222e-04 - loss_2: 1.2899e-04 - loss_3: 1.2699e-04 - loss_4: 1.2223e-04 - loss_5: 1.3260e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3957 - val_loss_2: 0.3957 - val_loss_3: 0.3957 - val_loss_4: 0.3957 - val_loss_5: 0.3957 - val_acc_ensemble: 0.8973 - val_acc_1: 0.8973 - val_acc_2: 0.8973 - val_acc_3: 0.8973 - val_acc_4: 0.8973 - val_acc_5: 0.8973\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 1.0006e-04 - loss_2: 1.0236e-04 - loss_3: 1.0066e-04 - loss_4: 1.0370e-04 - loss_5: 9.9873e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.3990 - val_loss_2: 0.3990 - val_loss_3: 0.3990 - val_loss_4: 0.3990 - val_loss_5: 0.3990 - val_acc_ensemble: 0.8977 - val_acc_1: 0.8977 - val_acc_2: 0.8977 - val_acc_3: 0.8977 - val_acc_4: 0.8977 - val_acc_5: 0.8977\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 8.1695e-05 - loss_2: 8.0965e-05 - loss_3: 8.3375e-05 - loss_4: 8.1665e-05 - loss_5: 7.8516e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4021 - val_loss_2: 0.4021 - val_loss_3: 0.4021 - val_loss_4: 0.4021 - val_loss_5: 0.4021 - val_acc_ensemble: 0.8980 - val_acc_1: 0.8980 - val_acc_2: 0.8980 - val_acc_3: 0.8980 - val_acc_4: 0.8980 - val_acc_5: 0.8980\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 6.7195e-05 - loss_2: 6.3785e-05 - loss_3: 6.7904e-05 - loss_4: 6.4721e-05 - loss_5: 6.7047e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4053 - val_loss_2: 0.4053 - val_loss_3: 0.4053 - val_loss_4: 0.4053 - val_loss_5: 0.4053 - val_acc_ensemble: 0.8984 - val_acc_1: 0.8984 - val_acc_2: 0.8984 - val_acc_3: 0.8984 - val_acc_4: 0.8984 - val_acc_5: 0.8984\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 5.2875e-05 - loss_2: 5.6684e-05 - loss_3: 5.5414e-05 - loss_4: 5.4338e-05 - loss_5: 5.8061e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - val_loss_1: 0.4085 - val_loss_2: 0.4085 - val_loss_3: 0.4085 - val_loss_4: 0.4085 - val_loss_5: 0.4085 - val_acc_ensemble: 0.8986 - val_acc_1: 0.8986 - val_acc_2: 0.8986 - val_acc_3: 0.8986 - val_acc_4: 0.8986 - val_acc_5: 0.8986\n",
      "sensitivity/vb-mnist-fcn3A/B6/S0.00\n",
      "i  Layer name                Output shape   Num param  Inbound  \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "0  fc1 (Dense)               [] [None,512]  2411520    input    \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [] [None,512]  6144       fc1      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "2  relu1 (Activation)        [] [None,512]  0          bn1      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "3  fc2 (Dense)               [] [None,512]  1575936    relu1    \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [] [None,512]  6144       fc2      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "5  relu2 (Activation)        [] [None,512]  0          bn2      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "6  fc3 (Dense)               [] [None,512]  1575936    relu2    \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [] [None,512]  6144       fc3      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "8  relu3 (Activation)        [] [None,512]  0          bn3      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]      30780      relu3    \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "----------------------------------------------------------------\n",
      "Total parameters: 5612604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 2s - loss_1: 0.2955 - loss_2: 0.2582 - loss_3: 0.2515 - loss_4: 0.2475 - loss_5: 0.2596 - loss_6: 0.2414 - acc_ensemble: 1.0000 - acc_1: 0.9950 - acc_2: 0.9983 - acc_3: 0.9917 - acc_4: 0.9950 - acc_5: 0.9983 - acc_6: 0.9983 - val_loss_1: 0.4564 - val_loss_2: 0.4451 - val_loss_3: 0.4796 - val_loss_4: 0.4278 - val_loss_5: 0.4384 - val_loss_6: 0.4406 - val_acc_ensemble: 0.9091 - val_acc_1: 0.8728 - val_acc_2: 0.8819 - val_acc_3: 0.8766 - val_acc_4: 0.8850 - val_acc_5: 0.8736 - val_acc_6: 0.8811\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 0.0052 - loss_2: 0.0040 - loss_3: 0.0164 - loss_4: 0.0183 - loss_5: 0.0251 - loss_6: 0.0051 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 0.9950 - acc_4: 1.0000 - acc_5: 0.9983 - acc_6: 1.0000 - val_loss_1: 0.4193 - val_loss_2: 0.3880 - val_loss_3: 0.4974 - val_loss_4: 0.4453 - val_loss_5: 0.4638 - val_loss_6: 0.4149 - val_acc_ensemble: 0.9097 - val_acc_1: 0.8929 - val_acc_2: 0.8987 - val_acc_3: 0.8777 - val_acc_4: 0.8893 - val_acc_5: 0.8858 - val_acc_6: 0.8933\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 9.4327e-04 - loss_2: 7.6304e-04 - loss_3: 0.0118 - loss_4: 0.0086 - loss_5: 0.0030 - loss_6: 7.4932e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 0.9933 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4138 - val_loss_2: 0.3873 - val_loss_3: 0.4737 - val_loss_4: 0.4911 - val_loss_5: 0.4235 - val_loss_6: 0.4090 - val_acc_ensemble: 0.9102 - val_acc_1: 0.8957 - val_acc_2: 0.8985 - val_acc_3: 0.8850 - val_acc_4: 0.8825 - val_acc_5: 0.8960 - val_acc_6: 0.8971\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 5.6052e-04 - loss_2: 4.3108e-04 - loss_3: 9.6394e-04 - loss_4: 0.0056 - loss_5: 5.3655e-04 - loss_6: 4.1817e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 0.9883 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4129 - val_loss_2: 0.3877 - val_loss_3: 0.4523 - val_loss_4: 0.5599 - val_loss_5: 0.4163 - val_loss_6: 0.4086 - val_acc_ensemble: 0.9123 - val_acc_1: 0.8974 - val_acc_2: 0.8996 - val_acc_3: 0.8902 - val_acc_4: 0.8754 - val_acc_5: 0.8990 - val_acc_6: 0.8980\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 4.2772e-04 - loss_2: 2.9306e-04 - loss_3: 4.0477e-04 - loss_4: 0.0102 - loss_5: 3.5427e-04 - loss_6: 2.9886e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4143 - val_loss_2: 0.3897 - val_loss_3: 0.4470 - val_loss_4: 0.4548 - val_loss_5: 0.4154 - val_loss_6: 0.4087 - val_acc_ensemble: 0.9124 - val_acc_1: 0.8986 - val_acc_2: 0.8996 - val_acc_3: 0.8936 - val_acc_4: 0.8936 - val_acc_5: 0.9002 - val_acc_6: 0.9001\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 3.1389e-04 - loss_2: 2.4605e-04 - loss_3: 2.8802e-04 - loss_4: 4.1484e-04 - loss_5: 2.4745e-04 - loss_6: 2.3973e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4163 - val_loss_2: 0.3920 - val_loss_3: 0.4445 - val_loss_4: 0.4489 - val_loss_5: 0.4160 - val_loss_6: 0.4093 - val_acc_ensemble: 0.9137 - val_acc_1: 0.8994 - val_acc_2: 0.9001 - val_acc_3: 0.8958 - val_acc_4: 0.8974 - val_acc_5: 0.9005 - val_acc_6: 0.9005\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 2.5760e-04 - loss_2: 2.0265e-04 - loss_3: 2.2126e-04 - loss_4: 2.8121e-04 - loss_5: 2.0868e-04 - loss_6: 1.9404e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4170 - val_loss_2: 0.3930 - val_loss_3: 0.4431 - val_loss_4: 0.4475 - val_loss_5: 0.4169 - val_loss_6: 0.4109 - val_acc_ensemble: 0.9141 - val_acc_1: 0.8999 - val_acc_2: 0.9013 - val_acc_3: 0.8958 - val_acc_4: 0.8986 - val_acc_5: 0.9000 - val_acc_6: 0.9008\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 2.1107e-04 - loss_2: 1.7560e-04 - loss_3: 1.8213e-04 - loss_4: 2.1425e-04 - loss_5: 1.7149e-04 - loss_6: 1.6172e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4193 - val_loss_2: 0.3957 - val_loss_3: 0.4438 - val_loss_4: 0.4482 - val_loss_5: 0.4173 - val_loss_6: 0.4120 - val_acc_ensemble: 0.9146 - val_acc_1: 0.9004 - val_acc_2: 0.9016 - val_acc_3: 0.8965 - val_acc_4: 0.8990 - val_acc_5: 0.9004 - val_acc_6: 0.9010\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 1.8833e-04 - loss_2: 1.3989e-04 - loss_3: 1.5689e-04 - loss_4: 1.7189e-04 - loss_5: 1.4728e-04 - loss_6: 1.4217e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4212 - val_loss_2: 0.3972 - val_loss_3: 0.4441 - val_loss_4: 0.4486 - val_loss_5: 0.4180 - val_loss_6: 0.4140 - val_acc_ensemble: 0.9143 - val_acc_1: 0.9010 - val_acc_2: 0.9024 - val_acc_3: 0.8970 - val_acc_4: 0.8996 - val_acc_5: 0.9008 - val_acc_6: 0.9014\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 1.5735e-04 - loss_2: 1.1946e-04 - loss_3: 1.3678e-04 - loss_4: 1.5373e-04 - loss_5: 1.3049e-04 - loss_6: 1.2379e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4224 - val_loss_2: 0.3987 - val_loss_3: 0.4446 - val_loss_4: 0.4504 - val_loss_5: 0.4187 - val_loss_6: 0.4153 - val_acc_ensemble: 0.9141 - val_acc_1: 0.9013 - val_acc_2: 0.9025 - val_acc_3: 0.8973 - val_acc_4: 0.8999 - val_acc_5: 0.9014 - val_acc_6: 0.9021\n",
      "sensitivity/vb-mnist-fcn3A/B6/S0.00\n",
      "i  Layer name                Output shape   Num param  Inbound  \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "0  fc1 (Dense)               [] [None,512]  2411520    input    \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [] [None,512]  6144       fc1      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "2  relu1 (Activation)        [] [None,512]  0          bn1      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "3  fc2 (Dense)               [] [None,512]  1575936    relu1    \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [] [None,512]  6144       fc2      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "5  relu2 (Activation)        [] [None,512]  0          bn2      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "6  fc3 (Dense)               [] [None,512]  1575936    relu2    \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [] [None,512]  6144       fc3      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "8  relu3 (Activation)        [] [None,512]  0          bn3      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]      30780      relu3    \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "----------------------------------------------------------------\n",
      "Total parameters: 5612604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 3s - loss_1: 0.2374 - loss_2: 0.2467 - loss_3: 0.2536 - loss_4: 0.2591 - loss_5: 0.2642 - loss_6: 0.2567 - acc_ensemble: 1.0000 - acc_1: 0.9933 - acc_2: 0.9883 - acc_3: 0.9933 - acc_4: 0.9967 - acc_5: 0.9983 - acc_6: 0.9983 - val_loss_1: 0.4670 - val_loss_2: 0.5578 - val_loss_3: 0.5200 - val_loss_4: 0.4368 - val_loss_5: 0.4633 - val_loss_6: 0.4882 - val_acc_ensemble: 0.9044 - val_acc_1: 0.8733 - val_acc_2: 0.8517 - val_acc_3: 0.8613 - val_acc_4: 0.8828 - val_acc_5: 0.8740 - val_acc_6: 0.8701\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 0.0054 - loss_2: 0.0087 - loss_3: 0.0053 - loss_4: 0.0096 - loss_5: 0.0044 - loss_6: 0.0124 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 0.9950 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4255 - val_loss_2: 0.4681 - val_loss_3: 0.4175 - val_loss_4: 0.3914 - val_loss_5: 0.4237 - val_loss_6: 0.4535 - val_acc_ensemble: 0.9102 - val_acc_1: 0.8912 - val_acc_2: 0.8833 - val_acc_3: 0.8938 - val_acc_4: 0.8986 - val_acc_5: 0.8902 - val_acc_6: 0.8839\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 7.5042e-04 - loss_2: 0.0054 - loss_3: 7.2593e-04 - loss_4: 6.3655e-04 - loss_5: 7.8850e-04 - loss_6: 8.0811e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4080 - val_loss_2: 0.4772 - val_loss_3: 0.4139 - val_loss_4: 0.3914 - val_loss_5: 0.4092 - val_loss_6: 0.4304 - val_acc_ensemble: 0.9112 - val_acc_1: 0.8977 - val_acc_2: 0.8836 - val_acc_3: 0.8979 - val_acc_4: 0.9006 - val_acc_5: 0.8960 - val_acc_6: 0.8915\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 4.0615e-04 - loss_2: 6.8743e-04 - loss_3: 4.1673e-04 - loss_4: 3.9940e-04 - loss_5: 4.4262e-04 - loss_6: 4.3296e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4051 - val_loss_2: 0.4477 - val_loss_3: 0.4165 - val_loss_4: 0.3927 - val_loss_5: 0.4073 - val_loss_6: 0.4283 - val_acc_ensemble: 0.9120 - val_acc_1: 0.8990 - val_acc_2: 0.8916 - val_acc_3: 0.8984 - val_acc_4: 0.9021 - val_acc_5: 0.8973 - val_acc_6: 0.8938\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 2.7870e-04 - loss_2: 3.4256e-04 - loss_3: 3.2507e-04 - loss_4: 2.8607e-04 - loss_5: 3.3534e-04 - loss_6: 3.1578e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4041 - val_loss_2: 0.4452 - val_loss_3: 0.4183 - val_loss_4: 0.3953 - val_loss_5: 0.4075 - val_loss_6: 0.4280 - val_acc_ensemble: 0.9126 - val_acc_1: 0.9014 - val_acc_2: 0.8944 - val_acc_3: 0.8985 - val_acc_4: 0.9025 - val_acc_5: 0.8986 - val_acc_6: 0.8940\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 2.3481e-04 - loss_2: 2.4988e-04 - loss_3: 2.5002e-04 - loss_4: 2.3554e-04 - loss_5: 2.5970e-04 - loss_6: 2.4770e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4050 - val_loss_2: 0.4448 - val_loss_3: 0.4197 - val_loss_4: 0.3969 - val_loss_5: 0.4085 - val_loss_6: 0.4282 - val_acc_ensemble: 0.9126 - val_acc_1: 0.9026 - val_acc_2: 0.8952 - val_acc_3: 0.8988 - val_acc_4: 0.9024 - val_acc_5: 0.8995 - val_acc_6: 0.8947\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 1.9475e-04 - loss_2: 2.0578e-04 - loss_3: 1.8707e-04 - loss_4: 1.9332e-04 - loss_5: 1.9749e-04 - loss_6: 1.9512e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4047 - val_loss_2: 0.4436 - val_loss_3: 0.4213 - val_loss_4: 0.3986 - val_loss_5: 0.4095 - val_loss_6: 0.4285 - val_acc_ensemble: 0.9134 - val_acc_1: 0.9027 - val_acc_2: 0.8965 - val_acc_3: 0.8994 - val_acc_4: 0.9028 - val_acc_5: 0.8990 - val_acc_6: 0.8957\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 1.5270e-04 - loss_2: 1.5978e-04 - loss_3: 1.6208e-04 - loss_4: 1.6541e-04 - loss_5: 1.8353e-04 - loss_6: 1.5934e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4062 - val_loss_2: 0.4443 - val_loss_3: 0.4236 - val_loss_4: 0.3998 - val_loss_5: 0.4108 - val_loss_6: 0.4295 - val_acc_ensemble: 0.9134 - val_acc_1: 0.9033 - val_acc_2: 0.8971 - val_acc_3: 0.8997 - val_acc_4: 0.9032 - val_acc_5: 0.8996 - val_acc_6: 0.8963\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 1.2857e-04 - loss_2: 1.4276e-04 - loss_3: 1.4524e-04 - loss_4: 1.4589e-04 - loss_5: 1.5252e-04 - loss_6: 1.3898e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4074 - val_loss_2: 0.4444 - val_loss_3: 0.4252 - val_loss_4: 0.4008 - val_loss_5: 0.4120 - val_loss_6: 0.4304 - val_acc_ensemble: 0.9134 - val_acc_1: 0.9040 - val_acc_2: 0.8979 - val_acc_3: 0.8998 - val_acc_4: 0.9033 - val_acc_5: 0.9002 - val_acc_6: 0.8968\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 1.0917e-04 - loss_2: 1.1988e-04 - loss_3: 1.2654e-04 - loss_4: 1.2340e-04 - loss_5: 1.3344e-04 - loss_6: 1.2591e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4085 - val_loss_2: 0.4450 - val_loss_3: 0.4281 - val_loss_4: 0.4025 - val_loss_5: 0.4136 - val_loss_6: 0.4313 - val_acc_ensemble: 0.9132 - val_acc_1: 0.9042 - val_acc_2: 0.8983 - val_acc_3: 0.8998 - val_acc_4: 0.9037 - val_acc_5: 0.9002 - val_acc_6: 0.8968\n",
      "sensitivity/vb-mnist-fcn3A/B6/S0.00\n",
      "i  Layer name                Output shape   Num param  Inbound  \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "0  fc1 (Dense)               [] [None,512]  2411520    input    \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [] [None,512]  6144       fc1      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "2  relu1 (Activation)        [] [None,512]  0          bn1      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "3  fc2 (Dense)               [] [None,512]  1575936    relu1    \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [] [None,512]  6144       fc2      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "5  relu2 (Activation)        [] [None,512]  0          bn2      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "6  fc3 (Dense)               [] [None,512]  1575936    relu2    \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [] [None,512]  6144       fc3      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "8  relu3 (Activation)        [] [None,512]  0          bn3      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]      30780      relu3    \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "----------------------------------------------------------------\n",
      "Total parameters: 5612604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 2s - loss_1: 0.2401 - loss_2: 0.2720 - loss_3: 0.2277 - loss_4: 0.2584 - loss_5: 0.2555 - loss_6: 0.2643 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 0.9867 - acc_3: 0.9950 - acc_4: 0.9950 - acc_5: 0.9967 - acc_6: 0.9967 - val_loss_1: 0.4416 - val_loss_2: 0.4868 - val_loss_3: 0.3912 - val_loss_4: 0.4408 - val_loss_5: 0.4315 - val_loss_6: 0.4470 - val_acc_ensemble: 0.9114 - val_acc_1: 0.8753 - val_acc_2: 0.8686 - val_acc_3: 0.8946 - val_acc_4: 0.8819 - val_acc_5: 0.8826 - val_acc_6: 0.8778\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 0.0035 - loss_2: 0.0124 - loss_3: 0.0089 - loss_4: 0.0093 - loss_5: 0.0046 - loss_6: 0.0110 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 0.9983 - acc_4: 0.9983 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3913 - val_loss_2: 0.4312 - val_loss_3: 0.5278 - val_loss_4: 0.4365 - val_loss_5: 0.3995 - val_loss_6: 0.4207 - val_acc_ensemble: 0.9138 - val_acc_1: 0.8953 - val_acc_2: 0.8899 - val_acc_3: 0.8766 - val_acc_4: 0.8905 - val_acc_5: 0.8960 - val_acc_6: 0.8892\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 6.6708e-04 - loss_2: 0.0018 - loss_3: 0.0060 - loss_4: 0.0138 - loss_5: 6.9300e-04 - loss_6: 8.6430e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3875 - val_loss_2: 0.4184 - val_loss_3: 0.4232 - val_loss_4: 0.4521 - val_loss_5: 0.3958 - val_loss_6: 0.4012 - val_acc_ensemble: 0.9130 - val_acc_1: 0.8987 - val_acc_2: 0.8956 - val_acc_3: 0.8958 - val_acc_4: 0.8897 - val_acc_5: 0.8987 - val_acc_6: 0.8968\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 4.1791e-04 - loss_2: 4.6624e-04 - loss_3: 4.9553e-04 - loss_4: 7.3854e-04 - loss_5: 4.0203e-04 - loss_6: 4.5523e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3880 - val_loss_2: 0.4141 - val_loss_3: 0.4094 - val_loss_4: 0.4556 - val_loss_5: 0.3980 - val_loss_6: 0.3981 - val_acc_ensemble: 0.9137 - val_acc_1: 0.8995 - val_acc_2: 0.8984 - val_acc_3: 0.9005 - val_acc_4: 0.8925 - val_acc_5: 0.8991 - val_acc_6: 0.8985\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 2.9177e-04 - loss_2: 3.3486e-04 - loss_3: 3.1768e-04 - loss_4: 3.5288e-04 - loss_5: 3.0531e-04 - loss_6: 3.0289e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3897 - val_loss_2: 0.4129 - val_loss_3: 0.4085 - val_loss_4: 0.4498 - val_loss_5: 0.4000 - val_loss_6: 0.3969 - val_acc_ensemble: 0.9140 - val_acc_1: 0.8998 - val_acc_2: 0.8997 - val_acc_3: 0.9008 - val_acc_4: 0.8944 - val_acc_5: 0.9006 - val_acc_6: 0.8997\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 2.3879e-04 - loss_2: 2.4149e-04 - loss_3: 2.3106e-04 - loss_4: 2.5007e-04 - loss_5: 2.4827e-04 - loss_6: 2.5211e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3922 - val_loss_2: 0.4133 - val_loss_3: 0.4084 - val_loss_4: 0.4474 - val_loss_5: 0.4023 - val_loss_6: 0.3974 - val_acc_ensemble: 0.9146 - val_acc_1: 0.9005 - val_acc_2: 0.9004 - val_acc_3: 0.9013 - val_acc_4: 0.8959 - val_acc_5: 0.9008 - val_acc_6: 0.9010\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 2.0059e-04 - loss_2: 2.0119e-04 - loss_3: 1.9194e-04 - loss_4: 1.8658e-04 - loss_5: 2.0178e-04 - loss_6: 1.9919e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3943 - val_loss_2: 0.4138 - val_loss_3: 0.4087 - val_loss_4: 0.4471 - val_loss_5: 0.4041 - val_loss_6: 0.3987 - val_acc_ensemble: 0.9149 - val_acc_1: 0.9013 - val_acc_2: 0.9016 - val_acc_3: 0.9025 - val_acc_4: 0.8968 - val_acc_5: 0.9006 - val_acc_6: 0.9013\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 1.5518e-04 - loss_2: 1.8036e-04 - loss_3: 1.5438e-04 - loss_4: 1.5493e-04 - loss_5: 1.6149e-04 - loss_6: 1.6444e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3955 - val_loss_2: 0.4146 - val_loss_3: 0.4093 - val_loss_4: 0.4474 - val_loss_5: 0.4059 - val_loss_6: 0.3996 - val_acc_ensemble: 0.9147 - val_acc_1: 0.9012 - val_acc_2: 0.9022 - val_acc_3: 0.9030 - val_acc_4: 0.8975 - val_acc_5: 0.9005 - val_acc_6: 0.9010\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 1.3577e-04 - loss_2: 1.4575e-04 - loss_3: 1.2899e-04 - loss_4: 1.3613e-04 - loss_5: 1.4885e-04 - loss_6: 1.5116e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3972 - val_loss_2: 0.4155 - val_loss_3: 0.4110 - val_loss_4: 0.4479 - val_loss_5: 0.4070 - val_loss_6: 0.4003 - val_acc_ensemble: 0.9147 - val_acc_1: 0.9014 - val_acc_2: 0.9026 - val_acc_3: 0.9035 - val_acc_4: 0.8985 - val_acc_5: 0.9006 - val_acc_6: 0.9012\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 1.2434e-04 - loss_2: 1.3351e-04 - loss_3: 1.1388e-04 - loss_4: 1.1552e-04 - loss_5: 1.3447e-04 - loss_6: 1.3151e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3992 - val_loss_2: 0.4172 - val_loss_3: 0.4117 - val_loss_4: 0.4485 - val_loss_5: 0.4079 - val_loss_6: 0.4006 - val_acc_ensemble: 0.9148 - val_acc_1: 0.9017 - val_acc_2: 0.9028 - val_acc_3: 0.9039 - val_acc_4: 0.8988 - val_acc_5: 0.9017 - val_acc_6: 0.9012\n",
      "sensitivity/vb-mnist-fcn3A/B6/S0.00\n",
      "i  Layer name                Output shape   Num param  Inbound  \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "0  fc1 (Dense)               [] [None,512]  2411520    input    \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [] [None,512]  6144       fc1      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "2  relu1 (Activation)        [] [None,512]  0          bn1      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "3  fc2 (Dense)               [] [None,512]  1575936    relu1    \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [] [None,512]  6144       fc2      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "5  relu2 (Activation)        [] [None,512]  0          bn2      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "6  fc3 (Dense)               [] [None,512]  1575936    relu2    \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [] [None,512]  6144       fc3      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "8  relu3 (Activation)        [] [None,512]  0          bn3      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]      30780      relu3    \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "----------------------------------------------------------------\n",
      "Total parameters: 5612604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 2s - loss_1: 0.2775 - loss_2: 0.2575 - loss_3: 0.2717 - loss_4: 0.2666 - loss_5: 0.2605 - loss_6: 0.2687 - acc_ensemble: 1.0000 - acc_1: 0.9917 - acc_2: 0.9983 - acc_3: 0.9950 - acc_4: 0.9950 - acc_5: 0.9967 - acc_6: 1.0000 - val_loss_1: 0.4182 - val_loss_2: 0.4339 - val_loss_3: 0.4333 - val_loss_4: 0.4728 - val_loss_5: 0.4517 - val_loss_6: 0.4521 - val_acc_ensemble: 0.9104 - val_acc_1: 0.8806 - val_acc_2: 0.8841 - val_acc_3: 0.8833 - val_acc_4: 0.8711 - val_acc_5: 0.8803 - val_acc_6: 0.8797\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 0.0037 - loss_2: 0.0030 - loss_3: 0.0071 - loss_4: 0.0031 - loss_5: 0.0081 - loss_6: 0.0099 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3649 - val_loss_2: 0.3996 - val_loss_3: 0.3778 - val_loss_4: 0.4023 - val_loss_5: 0.4164 - val_loss_6: 0.4049 - val_acc_ensemble: 0.9162 - val_acc_1: 0.9038 - val_acc_2: 0.8977 - val_acc_3: 0.9013 - val_acc_4: 0.8953 - val_acc_5: 0.8909 - val_acc_6: 0.8983\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 7.5741e-04 - loss_2: 7.1610e-04 - loss_3: 7.9005e-04 - loss_4: 7.0019e-04 - loss_5: 7.7415e-04 - loss_6: 9.9780e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3678 - val_loss_2: 0.4001 - val_loss_3: 0.3726 - val_loss_4: 0.3994 - val_loss_5: 0.4046 - val_loss_6: 0.4077 - val_acc_ensemble: 0.9163 - val_acc_1: 0.9045 - val_acc_2: 0.8994 - val_acc_3: 0.9038 - val_acc_4: 0.8978 - val_acc_5: 0.8967 - val_acc_6: 0.9009\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 4.5869e-04 - loss_2: 4.1983e-04 - loss_3: 4.1569e-04 - loss_4: 4.1946e-04 - loss_5: 4.7919e-04 - loss_6: 4.8665e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3675 - val_loss_2: 0.4019 - val_loss_3: 0.3738 - val_loss_4: 0.3996 - val_loss_5: 0.4046 - val_loss_6: 0.4071 - val_acc_ensemble: 0.9171 - val_acc_1: 0.9060 - val_acc_2: 0.9000 - val_acc_3: 0.9055 - val_acc_4: 0.8991 - val_acc_5: 0.8969 - val_acc_6: 0.9015\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 3.4151e-04 - loss_2: 3.2990e-04 - loss_3: 3.1014e-04 - loss_4: 3.2686e-04 - loss_5: 3.3104e-04 - loss_6: 3.4320e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3699 - val_loss_2: 0.4035 - val_loss_3: 0.3743 - val_loss_4: 0.4006 - val_loss_5: 0.4063 - val_loss_6: 0.4084 - val_acc_ensemble: 0.9168 - val_acc_1: 0.9066 - val_acc_2: 0.9006 - val_acc_3: 0.9065 - val_acc_4: 0.9003 - val_acc_5: 0.8977 - val_acc_6: 0.9029\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 2.6162e-04 - loss_2: 2.4207e-04 - loss_3: 2.3696e-04 - loss_4: 2.5465e-04 - loss_5: 2.6403e-04 - loss_6: 2.5822e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3705 - val_loss_2: 0.4049 - val_loss_3: 0.3760 - val_loss_4: 0.4015 - val_loss_5: 0.4078 - val_loss_6: 0.4091 - val_acc_ensemble: 0.9170 - val_acc_1: 0.9079 - val_acc_2: 0.9017 - val_acc_3: 0.9060 - val_acc_4: 0.9014 - val_acc_5: 0.8997 - val_acc_6: 0.9032\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 2.2381e-04 - loss_2: 2.0549e-04 - loss_3: 1.9960e-04 - loss_4: 2.2086e-04 - loss_5: 2.1434e-04 - loss_6: 2.1985e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3728 - val_loss_2: 0.4069 - val_loss_3: 0.3775 - val_loss_4: 0.4031 - val_loss_5: 0.4088 - val_loss_6: 0.4107 - val_acc_ensemble: 0.9170 - val_acc_1: 0.9084 - val_acc_2: 0.9021 - val_acc_3: 0.9070 - val_acc_4: 0.9023 - val_acc_5: 0.8996 - val_acc_6: 0.9036\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 1.8650e-04 - loss_2: 1.7696e-04 - loss_3: 1.6443e-04 - loss_4: 1.6645e-04 - loss_5: 1.7825e-04 - loss_6: 1.8262e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3740 - val_loss_2: 0.4088 - val_loss_3: 0.3784 - val_loss_4: 0.4039 - val_loss_5: 0.4096 - val_loss_6: 0.4119 - val_acc_ensemble: 0.9169 - val_acc_1: 0.9086 - val_acc_2: 0.9015 - val_acc_3: 0.9069 - val_acc_4: 0.9028 - val_acc_5: 0.8996 - val_acc_6: 0.9039\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 1.6020e-04 - loss_2: 1.5280e-04 - loss_3: 1.4919e-04 - loss_4: 1.5193e-04 - loss_5: 1.5444e-04 - loss_6: 1.5527e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3762 - val_loss_2: 0.4107 - val_loss_3: 0.3805 - val_loss_4: 0.4043 - val_loss_5: 0.4116 - val_loss_6: 0.4131 - val_acc_ensemble: 0.9167 - val_acc_1: 0.9086 - val_acc_2: 0.9016 - val_acc_3: 0.9069 - val_acc_4: 0.9033 - val_acc_5: 0.8997 - val_acc_6: 0.9039\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 1.3974e-04 - loss_2: 1.3047e-04 - loss_3: 1.2627e-04 - loss_4: 1.3205e-04 - loss_5: 1.3445e-04 - loss_6: 1.3446e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3777 - val_loss_2: 0.4126 - val_loss_3: 0.3824 - val_loss_4: 0.4054 - val_loss_5: 0.4131 - val_loss_6: 0.4139 - val_acc_ensemble: 0.9166 - val_acc_1: 0.9088 - val_acc_2: 0.9019 - val_acc_3: 0.9071 - val_acc_4: 0.9034 - val_acc_5: 0.9000 - val_acc_6: 0.9041\n",
      "sensitivity/vb-mnist-fcn3A/B6/S0.25\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,128] [None,384]  1909120    input    \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,128] [None,384]  4864       fc1      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,128] [None,384]  0          bn1      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,128] [None,384]  1496448    relu1    \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,128] [None,384]  4864       fc2      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,128] [None,384]  0          bn2      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,128] [None,384]  1496448    relu2    \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,128] [None,384]  4864       fc3      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,128] [None,384]  0          bn3      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              29550      relu3    \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 4946158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 7s - loss_1: 0.2205 - loss_2: 0.2589 - loss_3: 0.2315 - loss_4: 0.2344 - loss_5: 0.2275 - loss_6: 0.2262 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 0.9950 - acc_3: 0.9933 - acc_4: 1.0000 - acc_5: 0.9983 - acc_6: 1.0000 - val_loss_1: 0.4582 - val_loss_2: 0.4561 - val_loss_3: 0.5432 - val_loss_4: 0.4099 - val_loss_5: 0.4577 - val_loss_6: 0.4547 - val_acc_ensemble: 0.9058 - val_acc_1: 0.8833 - val_acc_2: 0.8836 - val_acc_3: 0.8633 - val_acc_4: 0.8914 - val_acc_5: 0.8829 - val_acc_6: 0.8834\n",
      "Epoch 2/10\n",
      " - 3s - loss_1: 0.0089 - loss_2: 0.0065 - loss_3: 0.0167 - loss_4: 0.0015 - loss_5: 0.0071 - loss_6: 0.0021 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 0.9983 - acc_6: 1.0000 - val_loss_1: 0.4484 - val_loss_2: 0.4313 - val_loss_3: 0.4858 - val_loss_4: 0.4019 - val_loss_5: 0.4350 - val_loss_6: 0.4157 - val_acc_ensemble: 0.9076 - val_acc_1: 0.8897 - val_acc_2: 0.8988 - val_acc_3: 0.8822 - val_acc_4: 0.8996 - val_acc_5: 0.8907 - val_acc_6: 0.9003\n",
      "Epoch 3/10\n",
      " - 3s - loss_1: 5.6873e-04 - loss_2: 6.2556e-04 - loss_3: 0.0011 - loss_4: 5.3015e-04 - loss_5: 9.2529e-04 - loss_6: 4.5769e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4328 - val_loss_2: 0.4257 - val_loss_3: 0.4524 - val_loss_4: 0.4002 - val_loss_5: 0.4266 - val_loss_6: 0.4171 - val_acc_ensemble: 0.9088 - val_acc_1: 0.8956 - val_acc_2: 0.9000 - val_acc_3: 0.8947 - val_acc_4: 0.9013 - val_acc_5: 0.8962 - val_acc_6: 0.9003\n",
      "Epoch 4/10\n",
      " - 2s - loss_1: 3.3433e-04 - loss_2: 3.8243e-04 - loss_3: 3.6678e-04 - loss_4: 3.3476e-04 - loss_5: 3.5194e-04 - loss_6: 3.3321e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4311 - val_loss_2: 0.4264 - val_loss_3: 0.4473 - val_loss_4: 0.4006 - val_loss_5: 0.4255 - val_loss_6: 0.4216 - val_acc_ensemble: 0.9086 - val_acc_1: 0.8960 - val_acc_2: 0.9010 - val_acc_3: 0.8965 - val_acc_4: 0.9021 - val_acc_5: 0.8983 - val_acc_6: 0.9005\n",
      "Epoch 5/10\n",
      " - 3s - loss_1: 2.5904e-04 - loss_2: 2.9113e-04 - loss_3: 2.5249e-04 - loss_4: 2.6697e-04 - loss_5: 2.5844e-04 - loss_6: 2.3782e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4306 - val_loss_2: 0.4268 - val_loss_3: 0.4460 - val_loss_4: 0.4016 - val_loss_5: 0.4254 - val_loss_6: 0.4238 - val_acc_ensemble: 0.9089 - val_acc_1: 0.8968 - val_acc_2: 0.9024 - val_acc_3: 0.8980 - val_acc_4: 0.9028 - val_acc_5: 0.8991 - val_acc_6: 0.9014\n",
      "Epoch 6/10\n",
      " - 2s - loss_1: 1.9035e-04 - loss_2: 2.1381e-04 - loss_3: 2.0578e-04 - loss_4: 2.0900e-04 - loss_5: 2.0354e-04 - loss_6: 1.9630e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4308 - val_loss_2: 0.4284 - val_loss_3: 0.4458 - val_loss_4: 0.4033 - val_loss_5: 0.4262 - val_loss_6: 0.4256 - val_acc_ensemble: 0.9088 - val_acc_1: 0.8980 - val_acc_2: 0.9026 - val_acc_3: 0.8988 - val_acc_4: 0.9034 - val_acc_5: 0.8999 - val_acc_6: 0.9010\n",
      "Epoch 7/10\n",
      " - 2s - loss_1: 1.6067e-04 - loss_2: 1.7083e-04 - loss_3: 1.6415e-04 - loss_4: 1.7637e-04 - loss_5: 1.6522e-04 - loss_6: 1.5818e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4324 - val_loss_2: 0.4302 - val_loss_3: 0.4465 - val_loss_4: 0.4056 - val_loss_5: 0.4276 - val_loss_6: 0.4275 - val_acc_ensemble: 0.9086 - val_acc_1: 0.8985 - val_acc_2: 0.9027 - val_acc_3: 0.8993 - val_acc_4: 0.9036 - val_acc_5: 0.9004 - val_acc_6: 0.9017\n",
      "Epoch 8/10\n",
      " - 2s - loss_1: 1.3836e-04 - loss_2: 1.5285e-04 - loss_3: 1.4123e-04 - loss_4: 1.5002e-04 - loss_5: 1.3790e-04 - loss_6: 1.3536e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4330 - val_loss_2: 0.4316 - val_loss_3: 0.4473 - val_loss_4: 0.4079 - val_loss_5: 0.4291 - val_loss_6: 0.4294 - val_acc_ensemble: 0.9085 - val_acc_1: 0.8993 - val_acc_2: 0.9030 - val_acc_3: 0.8991 - val_acc_4: 0.9037 - val_acc_5: 0.9011 - val_acc_6: 0.9019\n",
      "Epoch 9/10\n",
      " - 2s - loss_1: 1.1669e-04 - loss_2: 1.3139e-04 - loss_3: 1.1534e-04 - loss_4: 1.1772e-04 - loss_5: 1.1552e-04 - loss_6: 1.1797e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4348 - val_loss_2: 0.4330 - val_loss_3: 0.4484 - val_loss_4: 0.4098 - val_loss_5: 0.4306 - val_loss_6: 0.4312 - val_acc_ensemble: 0.9089 - val_acc_1: 0.8995 - val_acc_2: 0.9031 - val_acc_3: 0.8993 - val_acc_4: 0.9044 - val_acc_5: 0.9017 - val_acc_6: 0.9015\n",
      "Epoch 10/10\n",
      " - 2s - loss_1: 1.0199e-04 - loss_2: 1.1264e-04 - loss_3: 1.0992e-04 - loss_4: 1.1119e-04 - loss_5: 1.0596e-04 - loss_6: 1.1010e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4355 - val_loss_2: 0.4341 - val_loss_3: 0.4495 - val_loss_4: 0.4113 - val_loss_5: 0.4322 - val_loss_6: 0.4326 - val_acc_ensemble: 0.9091 - val_acc_1: 0.9003 - val_acc_2: 0.9032 - val_acc_3: 0.8989 - val_acc_4: 0.9047 - val_acc_5: 0.9022 - val_acc_6: 0.9017\n",
      "sensitivity/vb-mnist-fcn3A/B6/S0.25\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,128] [None,384]  1909120    input    \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,128] [None,384]  4864       fc1      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,128] [None,384]  0          bn1      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,128] [None,384]  1496448    relu1    \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,128] [None,384]  4864       fc2      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,128] [None,384]  0          bn2      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,128] [None,384]  1496448    relu2    \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,128] [None,384]  4864       fc3      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,128] [None,384]  0          bn3      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              29550      relu3    \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 4946158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 7s - loss_1: 0.2254 - loss_2: 0.2447 - loss_3: 0.2515 - loss_4: 0.2225 - loss_5: 0.2225 - loss_6: 0.2528 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 0.9983 - acc_5: 1.0000 - acc_6: 0.9983 - val_loss_1: 0.4337 - val_loss_2: 0.4388 - val_loss_3: 0.4373 - val_loss_4: 0.4446 - val_loss_5: 0.4256 - val_loss_6: 0.4453 - val_acc_ensemble: 0.9082 - val_acc_1: 0.8841 - val_acc_2: 0.8849 - val_acc_3: 0.8815 - val_acc_4: 0.8906 - val_acc_5: 0.8906 - val_acc_6: 0.8823\n",
      "Epoch 2/10\n",
      " - 2s - loss_1: 0.0016 - loss_2: 0.0031 - loss_3: 0.0038 - loss_4: 0.0069 - loss_5: 0.0016 - loss_6: 0.0022 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4127 - val_loss_2: 0.4316 - val_loss_3: 0.4276 - val_loss_4: 0.4167 - val_loss_5: 0.4020 - val_loss_6: 0.4209 - val_acc_ensemble: 0.9094 - val_acc_1: 0.8949 - val_acc_2: 0.8934 - val_acc_3: 0.8936 - val_acc_4: 0.8987 - val_acc_5: 0.8995 - val_acc_6: 0.8945\n",
      "Epoch 3/10\n",
      " - 2s - loss_1: 5.0039e-04 - loss_2: 5.9783e-04 - loss_3: 5.9425e-04 - loss_4: 5.1697e-04 - loss_5: 4.7517e-04 - loss_6: 5.4571e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4110 - val_loss_2: 0.4265 - val_loss_3: 0.4249 - val_loss_4: 0.4174 - val_loss_5: 0.4031 - val_loss_6: 0.4197 - val_acc_ensemble: 0.9097 - val_acc_1: 0.8973 - val_acc_2: 0.8951 - val_acc_3: 0.8955 - val_acc_4: 0.9008 - val_acc_5: 0.9012 - val_acc_6: 0.8963\n",
      "Epoch 4/10\n",
      " - 3s - loss_1: 3.1099e-04 - loss_2: 3.7900e-04 - loss_3: 3.9255e-04 - loss_4: 3.1670e-04 - loss_5: 3.0536e-04 - loss_6: 3.5588e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4131 - val_loss_2: 0.4283 - val_loss_3: 0.4260 - val_loss_4: 0.4190 - val_loss_5: 0.4049 - val_loss_6: 0.4209 - val_acc_ensemble: 0.9104 - val_acc_1: 0.8989 - val_acc_2: 0.8955 - val_acc_3: 0.8967 - val_acc_4: 0.9020 - val_acc_5: 0.9020 - val_acc_6: 0.8963\n",
      "Epoch 5/10\n",
      " - 2s - loss_1: 2.4395e-04 - loss_2: 2.8286e-04 - loss_3: 2.7683e-04 - loss_4: 2.5873e-04 - loss_5: 2.3277e-04 - loss_6: 2.6564e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4146 - val_loss_2: 0.4287 - val_loss_3: 0.4274 - val_loss_4: 0.4210 - val_loss_5: 0.4073 - val_loss_6: 0.4225 - val_acc_ensemble: 0.9103 - val_acc_1: 0.8993 - val_acc_2: 0.8962 - val_acc_3: 0.8973 - val_acc_4: 0.9024 - val_acc_5: 0.9030 - val_acc_6: 0.8974\n",
      "Epoch 6/10\n",
      " - 2s - loss_1: 1.9873e-04 - loss_2: 2.2666e-04 - loss_3: 2.3862e-04 - loss_4: 2.0334e-04 - loss_5: 1.9129e-04 - loss_6: 2.1981e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4163 - val_loss_2: 0.4303 - val_loss_3: 0.4302 - val_loss_4: 0.4222 - val_loss_5: 0.4096 - val_loss_6: 0.4235 - val_acc_ensemble: 0.9103 - val_acc_1: 0.8988 - val_acc_2: 0.8967 - val_acc_3: 0.8980 - val_acc_4: 0.9025 - val_acc_5: 0.9028 - val_acc_6: 0.8983\n",
      "Epoch 7/10\n",
      " - 2s - loss_1: 1.5938e-04 - loss_2: 1.8654e-04 - loss_3: 1.8535e-04 - loss_4: 1.6788e-04 - loss_5: 1.6274e-04 - loss_6: 1.8983e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4178 - val_loss_2: 0.4318 - val_loss_3: 0.4331 - val_loss_4: 0.4243 - val_loss_5: 0.4117 - val_loss_6: 0.4255 - val_acc_ensemble: 0.9104 - val_acc_1: 0.8997 - val_acc_2: 0.8975 - val_acc_3: 0.8982 - val_acc_4: 0.9036 - val_acc_5: 0.9026 - val_acc_6: 0.8982\n",
      "Epoch 8/10\n",
      " - 2s - loss_1: 1.2881e-04 - loss_2: 1.5905e-04 - loss_3: 1.5588e-04 - loss_4: 1.4443e-04 - loss_5: 1.3171e-04 - loss_6: 1.5236e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4194 - val_loss_2: 0.4331 - val_loss_3: 0.4352 - val_loss_4: 0.4260 - val_loss_5: 0.4138 - val_loss_6: 0.4270 - val_acc_ensemble: 0.9105 - val_acc_1: 0.8998 - val_acc_2: 0.8983 - val_acc_3: 0.8976 - val_acc_4: 0.9034 - val_acc_5: 0.9029 - val_acc_6: 0.8984\n",
      "Epoch 9/10\n",
      " - 3s - loss_1: 1.1850e-04 - loss_2: 1.3120e-04 - loss_3: 1.4278e-04 - loss_4: 1.2102e-04 - loss_5: 1.1720e-04 - loss_6: 1.2983e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4208 - val_loss_2: 0.4349 - val_loss_3: 0.4371 - val_loss_4: 0.4273 - val_loss_5: 0.4154 - val_loss_6: 0.4289 - val_acc_ensemble: 0.9107 - val_acc_1: 0.9003 - val_acc_2: 0.8988 - val_acc_3: 0.8985 - val_acc_4: 0.9034 - val_acc_5: 0.9033 - val_acc_6: 0.8985\n",
      "Epoch 10/10\n",
      " - 3s - loss_1: 1.0261e-04 - loss_2: 1.1719e-04 - loss_3: 1.1368e-04 - loss_4: 1.0708e-04 - loss_5: 9.7654e-05 - loss_6: 1.1435e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4222 - val_loss_2: 0.4364 - val_loss_3: 0.4391 - val_loss_4: 0.4290 - val_loss_5: 0.4175 - val_loss_6: 0.4310 - val_acc_ensemble: 0.9105 - val_acc_1: 0.9005 - val_acc_2: 0.8990 - val_acc_3: 0.8987 - val_acc_4: 0.9034 - val_acc_5: 0.9034 - val_acc_6: 0.8985\n",
      "sensitivity/vb-mnist-fcn3A/B6/S0.25\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,128] [None,384]  1909120    input    \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,128] [None,384]  4864       fc1      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,128] [None,384]  0          bn1      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,128] [None,384]  1496448    relu1    \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,128] [None,384]  4864       fc2      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,128] [None,384]  0          bn2      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,128] [None,384]  1496448    relu2    \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,128] [None,384]  4864       fc3      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,128] [None,384]  0          bn3      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              29550      relu3    \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 4946158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 7s - loss_1: 0.2524 - loss_2: 0.2441 - loss_3: 0.2227 - loss_4: 0.2385 - loss_5: 0.2473 - loss_6: 0.2244 - acc_ensemble: 1.0000 - acc_1: 0.9983 - acc_2: 0.9967 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 0.9983 - acc_6: 1.0000 - val_loss_1: 0.4756 - val_loss_2: 0.4749 - val_loss_3: 0.4335 - val_loss_4: 0.4615 - val_loss_5: 0.4545 - val_loss_6: 0.3928 - val_acc_ensemble: 0.9063 - val_acc_1: 0.8735 - val_acc_2: 0.8845 - val_acc_3: 0.8846 - val_acc_4: 0.8827 - val_acc_5: 0.8774 - val_acc_6: 0.8946\n",
      "Epoch 2/10\n",
      " - 2s - loss_1: 0.0056 - loss_2: 0.0093 - loss_3: 0.0013 - loss_4: 0.0023 - loss_5: 0.0060 - loss_6: 0.0028 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4383 - val_loss_2: 0.4317 - val_loss_3: 0.4118 - val_loss_4: 0.4212 - val_loss_5: 0.4288 - val_loss_6: 0.4089 - val_acc_ensemble: 0.9102 - val_acc_1: 0.8943 - val_acc_2: 0.8960 - val_acc_3: 0.8959 - val_acc_4: 0.8974 - val_acc_5: 0.8926 - val_acc_6: 0.8972\n",
      "Epoch 3/10\n",
      " - 2s - loss_1: 5.9189e-04 - loss_2: 6.6820e-04 - loss_3: 5.3866e-04 - loss_4: 6.2615e-04 - loss_5: 7.4091e-04 - loss_6: 5.2907e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4347 - val_loss_2: 0.4277 - val_loss_3: 0.4103 - val_loss_4: 0.4253 - val_loss_5: 0.4186 - val_loss_6: 0.4066 - val_acc_ensemble: 0.9105 - val_acc_1: 0.8978 - val_acc_2: 0.8986 - val_acc_3: 0.8974 - val_acc_4: 0.8980 - val_acc_5: 0.8984 - val_acc_6: 0.8990\n",
      "Epoch 4/10\n",
      " - 2s - loss_1: 3.5905e-04 - loss_2: 4.1292e-04 - loss_3: 3.1689e-04 - loss_4: 3.5408e-04 - loss_5: 3.5984e-04 - loss_6: 3.2273e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4373 - val_loss_2: 0.4300 - val_loss_3: 0.4111 - val_loss_4: 0.4273 - val_loss_5: 0.4162 - val_loss_6: 0.4068 - val_acc_ensemble: 0.9104 - val_acc_1: 0.8985 - val_acc_2: 0.8991 - val_acc_3: 0.8988 - val_acc_4: 0.8987 - val_acc_5: 0.8997 - val_acc_6: 0.9007\n",
      "Epoch 5/10\n",
      " - 2s - loss_1: 2.6646e-04 - loss_2: 2.8304e-04 - loss_3: 2.4886e-04 - loss_4: 2.7158e-04 - loss_5: 2.5083e-04 - loss_6: 2.5061e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4398 - val_loss_2: 0.4316 - val_loss_3: 0.4128 - val_loss_4: 0.4297 - val_loss_5: 0.4170 - val_loss_6: 0.4086 - val_acc_ensemble: 0.9109 - val_acc_1: 0.8985 - val_acc_2: 0.8998 - val_acc_3: 0.8997 - val_acc_4: 0.8999 - val_acc_5: 0.9008 - val_acc_6: 0.9012\n",
      "Epoch 6/10\n",
      " - 2s - loss_1: 2.2105e-04 - loss_2: 2.0838e-04 - loss_3: 2.0542e-04 - loss_4: 2.0458e-04 - loss_5: 1.9228e-04 - loss_6: 1.8991e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4421 - val_loss_2: 0.4331 - val_loss_3: 0.4140 - val_loss_4: 0.4324 - val_loss_5: 0.4169 - val_loss_6: 0.4098 - val_acc_ensemble: 0.9106 - val_acc_1: 0.8992 - val_acc_2: 0.8998 - val_acc_3: 0.9000 - val_acc_4: 0.8999 - val_acc_5: 0.9017 - val_acc_6: 0.9018\n",
      "Epoch 7/10\n",
      " - 2s - loss_1: 1.6986e-04 - loss_2: 1.7464e-04 - loss_3: 1.6391e-04 - loss_4: 1.7233e-04 - loss_5: 1.6629e-04 - loss_6: 1.6328e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4439 - val_loss_2: 0.4357 - val_loss_3: 0.4155 - val_loss_4: 0.4347 - val_loss_5: 0.4174 - val_loss_6: 0.4111 - val_acc_ensemble: 0.9102 - val_acc_1: 0.9000 - val_acc_2: 0.9000 - val_acc_3: 0.9003 - val_acc_4: 0.9007 - val_acc_5: 0.9019 - val_acc_6: 0.9022\n",
      "Epoch 8/10\n",
      " - 3s - loss_1: 1.5223e-04 - loss_2: 1.5296e-04 - loss_3: 1.3613e-04 - loss_4: 1.4576e-04 - loss_5: 1.3889e-04 - loss_6: 1.3195e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4451 - val_loss_2: 0.4378 - val_loss_3: 0.4172 - val_loss_4: 0.4368 - val_loss_5: 0.4188 - val_loss_6: 0.4128 - val_acc_ensemble: 0.9100 - val_acc_1: 0.9000 - val_acc_2: 0.9006 - val_acc_3: 0.9008 - val_acc_4: 0.9010 - val_acc_5: 0.9021 - val_acc_6: 0.9025\n",
      "Epoch 9/10\n",
      " - 2s - loss_1: 1.3047e-04 - loss_2: 1.2841e-04 - loss_3: 1.2039e-04 - loss_4: 1.2551e-04 - loss_5: 1.2527e-04 - loss_6: 1.1577e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4462 - val_loss_2: 0.4395 - val_loss_3: 0.4193 - val_loss_4: 0.4392 - val_loss_5: 0.4197 - val_loss_6: 0.4147 - val_acc_ensemble: 0.9105 - val_acc_1: 0.9005 - val_acc_2: 0.9009 - val_acc_3: 0.9012 - val_acc_4: 0.9006 - val_acc_5: 0.9026 - val_acc_6: 0.9023\n",
      "Epoch 10/10\n",
      " - 2s - loss_1: 1.1254e-04 - loss_2: 1.1345e-04 - loss_3: 1.0338e-04 - loss_4: 1.1893e-04 - loss_5: 1.0715e-04 - loss_6: 1.0113e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4484 - val_loss_2: 0.4413 - val_loss_3: 0.4208 - val_loss_4: 0.4415 - val_loss_5: 0.4206 - val_loss_6: 0.4165 - val_acc_ensemble: 0.9105 - val_acc_1: 0.9007 - val_acc_2: 0.9010 - val_acc_3: 0.9014 - val_acc_4: 0.9007 - val_acc_5: 0.9025 - val_acc_6: 0.9029\n",
      "sensitivity/vb-mnist-fcn3A/B6/S0.25\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,128] [None,384]  1909120    input    \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,128] [None,384]  4864       fc1      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,128] [None,384]  0          bn1      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,128] [None,384]  1496448    relu1    \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,128] [None,384]  4864       fc2      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,128] [None,384]  0          bn2      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,128] [None,384]  1496448    relu2    \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,128] [None,384]  4864       fc3      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,128] [None,384]  0          bn3      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              29550      relu3    \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 4946158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 7s - loss_1: 0.2585 - loss_2: 0.2367 - loss_3: 0.2509 - loss_4: 0.2264 - loss_5: 0.2694 - loss_6: 0.2483 - acc_ensemble: 1.0000 - acc_1: 0.9983 - acc_2: 0.9967 - acc_3: 0.9983 - acc_4: 1.0000 - acc_5: 0.9917 - acc_6: 1.0000 - val_loss_1: 0.4771 - val_loss_2: 0.4618 - val_loss_3: 0.4242 - val_loss_4: 0.4458 - val_loss_5: 0.4842 - val_loss_6: 0.4115 - val_acc_ensemble: 0.9043 - val_acc_1: 0.8766 - val_acc_2: 0.8805 - val_acc_3: 0.8885 - val_acc_4: 0.8887 - val_acc_5: 0.8725 - val_acc_6: 0.8906\n",
      "Epoch 2/10\n",
      " - 2s - loss_1: 0.0032 - loss_2: 0.0037 - loss_3: 0.0030 - loss_4: 0.0018 - loss_5: 0.0147 - loss_6: 0.0023 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4246 - val_loss_2: 0.4129 - val_loss_3: 0.3955 - val_loss_4: 0.4031 - val_loss_5: 0.4611 - val_loss_6: 0.3864 - val_acc_ensemble: 0.9102 - val_acc_1: 0.8963 - val_acc_2: 0.8970 - val_acc_3: 0.8997 - val_acc_4: 0.9037 - val_acc_5: 0.8852 - val_acc_6: 0.9027\n",
      "Epoch 3/10\n",
      " - 2s - loss_1: 6.3859e-04 - loss_2: 5.4985e-04 - loss_3: 6.8625e-04 - loss_4: 5.0346e-04 - loss_5: 0.0011 - loss_6: 5.6229e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4207 - val_loss_2: 0.4091 - val_loss_3: 0.3947 - val_loss_4: 0.4035 - val_loss_5: 0.4370 - val_loss_6: 0.3895 - val_acc_ensemble: 0.9113 - val_acc_1: 0.8981 - val_acc_2: 0.8993 - val_acc_3: 0.9010 - val_acc_4: 0.9046 - val_acc_5: 0.8939 - val_acc_6: 0.9030\n",
      "Epoch 4/10\n",
      " - 3s - loss_1: 3.9860e-04 - loss_2: 3.6162e-04 - loss_3: 3.8914e-04 - loss_4: 3.2183e-04 - loss_5: 4.3388e-04 - loss_6: 3.7883e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4214 - val_loss_2: 0.4093 - val_loss_3: 0.3962 - val_loss_4: 0.4044 - val_loss_5: 0.4346 - val_loss_6: 0.3929 - val_acc_ensemble: 0.9112 - val_acc_1: 0.8998 - val_acc_2: 0.9006 - val_acc_3: 0.9020 - val_acc_4: 0.9048 - val_acc_5: 0.8954 - val_acc_6: 0.9039\n",
      "Epoch 5/10\n",
      " - 2s - loss_1: 2.8201e-04 - loss_2: 2.6772e-04 - loss_3: 3.0760e-04 - loss_4: 2.5149e-04 - loss_5: 3.0693e-04 - loss_6: 2.7732e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4228 - val_loss_2: 0.4104 - val_loss_3: 0.3986 - val_loss_4: 0.4061 - val_loss_5: 0.4368 - val_loss_6: 0.3961 - val_acc_ensemble: 0.9113 - val_acc_1: 0.9000 - val_acc_2: 0.9012 - val_acc_3: 0.9023 - val_acc_4: 0.9052 - val_acc_5: 0.8958 - val_acc_6: 0.9045\n",
      "Epoch 6/10\n",
      " - 2s - loss_1: 2.2139e-04 - loss_2: 2.0083e-04 - loss_3: 2.3379e-04 - loss_4: 2.0692e-04 - loss_5: 2.3810e-04 - loss_6: 2.2150e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4238 - val_loss_2: 0.4125 - val_loss_3: 0.4008 - val_loss_4: 0.4077 - val_loss_5: 0.4373 - val_loss_6: 0.3992 - val_acc_ensemble: 0.9110 - val_acc_1: 0.9008 - val_acc_2: 0.9012 - val_acc_3: 0.9027 - val_acc_4: 0.9057 - val_acc_5: 0.8978 - val_acc_6: 0.9048\n",
      "Epoch 7/10\n",
      " - 2s - loss_1: 1.8845e-04 - loss_2: 1.7507e-04 - loss_3: 1.9362e-04 - loss_4: 1.7114e-04 - loss_5: 2.0038e-04 - loss_6: 1.8573e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4247 - val_loss_2: 0.4152 - val_loss_3: 0.4036 - val_loss_4: 0.4096 - val_loss_5: 0.4387 - val_loss_6: 0.4016 - val_acc_ensemble: 0.9113 - val_acc_1: 0.9013 - val_acc_2: 0.9014 - val_acc_3: 0.9030 - val_acc_4: 0.9063 - val_acc_5: 0.8978 - val_acc_6: 0.9043\n",
      "Epoch 8/10\n",
      " - 2s - loss_1: 1.5870e-04 - loss_2: 1.4553e-04 - loss_3: 1.6241e-04 - loss_4: 1.4623e-04 - loss_5: 1.6648e-04 - loss_6: 1.5848e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4260 - val_loss_2: 0.4170 - val_loss_3: 0.4048 - val_loss_4: 0.4107 - val_loss_5: 0.4398 - val_loss_6: 0.4040 - val_acc_ensemble: 0.9114 - val_acc_1: 0.9014 - val_acc_2: 0.9014 - val_acc_3: 0.9034 - val_acc_4: 0.9062 - val_acc_5: 0.8984 - val_acc_6: 0.9040\n",
      "Epoch 9/10\n",
      " - 2s - loss_1: 1.4229e-04 - loss_2: 1.2601e-04 - loss_3: 1.3533e-04 - loss_4: 1.2462e-04 - loss_5: 1.3710e-04 - loss_6: 1.3191e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4274 - val_loss_2: 0.4183 - val_loss_3: 0.4064 - val_loss_4: 0.4128 - val_loss_5: 0.4409 - val_loss_6: 0.4057 - val_acc_ensemble: 0.9112 - val_acc_1: 0.9016 - val_acc_2: 0.9016 - val_acc_3: 0.9035 - val_acc_4: 0.9064 - val_acc_5: 0.8991 - val_acc_6: 0.9039\n",
      "Epoch 10/10\n",
      " - 2s - loss_1: 1.1539e-04 - loss_2: 1.1440e-04 - loss_3: 1.1591e-04 - loss_4: 1.1310e-04 - loss_5: 1.2478e-04 - loss_6: 1.1765e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4287 - val_loss_2: 0.4201 - val_loss_3: 0.4080 - val_loss_4: 0.4143 - val_loss_5: 0.4423 - val_loss_6: 0.4079 - val_acc_ensemble: 0.9109 - val_acc_1: 0.9016 - val_acc_2: 0.9018 - val_acc_3: 0.9033 - val_acc_4: 0.9066 - val_acc_5: 0.8989 - val_acc_6: 0.9038\n",
      "sensitivity/vb-mnist-fcn3A/B6/S0.50\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,256] [None,256]  1406720    input    \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,256] [None,256]  3584       fc1      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,256] [None,256]  0          bn1      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,256] [None,256]  1250048    relu1    \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,256] [None,256]  3584       fc2      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,256] [None,256]  0          bn2      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,256] [None,256]  1250048    relu2    \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,256] [None,256]  3584       fc3      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,256] [None,256]  0          bn3      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              24415      relu3    \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 3941983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 7s - loss_1: 0.2092 - loss_2: 0.1960 - loss_3: 0.2200 - loss_4: 0.2139 - loss_5: 0.2312 - loss_6: 0.2031 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 0.9933 - acc_3: 1.0000 - acc_4: 0.9983 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4384 - val_loss_2: 0.4586 - val_loss_3: 0.4761 - val_loss_4: 0.4511 - val_loss_5: 0.4694 - val_loss_6: 0.4341 - val_acc_ensemble: 0.9007 - val_acc_1: 0.8892 - val_acc_2: 0.8831 - val_acc_3: 0.8838 - val_acc_4: 0.8870 - val_acc_5: 0.8847 - val_acc_6: 0.8889\n",
      "Epoch 2/10\n",
      " - 3s - loss_1: 0.0011 - loss_2: 0.0018 - loss_3: 0.0012 - loss_4: 0.0014 - loss_5: 0.0013 - loss_6: 0.0010 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4197 - val_loss_2: 0.4035 - val_loss_3: 0.4401 - val_loss_4: 0.4162 - val_loss_5: 0.4417 - val_loss_6: 0.4217 - val_acc_ensemble: 0.9062 - val_acc_1: 0.8978 - val_acc_2: 0.8983 - val_acc_3: 0.8967 - val_acc_4: 0.8979 - val_acc_5: 0.8932 - val_acc_6: 0.8973\n",
      "Epoch 3/10\n",
      " - 2s - loss_1: 4.1822e-04 - loss_2: 3.9570e-04 - loss_3: 4.0577e-04 - loss_4: 3.7462e-04 - loss_5: 4.2447e-04 - loss_6: 3.7874e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4212 - val_loss_2: 0.4026 - val_loss_3: 0.4411 - val_loss_4: 0.4168 - val_loss_5: 0.4392 - val_loss_6: 0.4207 - val_acc_ensemble: 0.9068 - val_acc_1: 0.8999 - val_acc_2: 0.9014 - val_acc_3: 0.8974 - val_acc_4: 0.8998 - val_acc_5: 0.8947 - val_acc_6: 0.9001\n",
      "Epoch 4/10\n",
      " - 2s - loss_1: 2.8588e-04 - loss_2: 2.5242e-04 - loss_3: 2.7660e-04 - loss_4: 2.6862e-04 - loss_5: 2.9914e-04 - loss_6: 2.7912e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4235 - val_loss_2: 0.4033 - val_loss_3: 0.4422 - val_loss_4: 0.4193 - val_loss_5: 0.4389 - val_loss_6: 0.4230 - val_acc_ensemble: 0.9078 - val_acc_1: 0.9001 - val_acc_2: 0.9026 - val_acc_3: 0.8986 - val_acc_4: 0.9003 - val_acc_5: 0.8954 - val_acc_6: 0.9002\n",
      "Epoch 5/10\n",
      " - 2s - loss_1: 2.0012e-04 - loss_2: 1.9282e-04 - loss_3: 2.1391e-04 - loss_4: 2.1121e-04 - loss_5: 2.2543e-04 - loss_6: 2.1244e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4254 - val_loss_2: 0.4045 - val_loss_3: 0.4438 - val_loss_4: 0.4217 - val_loss_5: 0.4401 - val_loss_6: 0.4247 - val_acc_ensemble: 0.9077 - val_acc_1: 0.9007 - val_acc_2: 0.9032 - val_acc_3: 0.8992 - val_acc_4: 0.9009 - val_acc_5: 0.8961 - val_acc_6: 0.9009\n",
      "Epoch 6/10\n",
      " - 2s - loss_1: 1.7660e-04 - loss_2: 1.6130e-04 - loss_3: 1.6181e-04 - loss_4: 1.5810e-04 - loss_5: 1.8463e-04 - loss_6: 1.5791e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4281 - val_loss_2: 0.4063 - val_loss_3: 0.4457 - val_loss_4: 0.4237 - val_loss_5: 0.4414 - val_loss_6: 0.4273 - val_acc_ensemble: 0.9077 - val_acc_1: 0.9011 - val_acc_2: 0.9031 - val_acc_3: 0.8991 - val_acc_4: 0.9015 - val_acc_5: 0.8976 - val_acc_6: 0.9008\n",
      "Epoch 7/10\n",
      " - 2s - loss_1: 1.3952e-04 - loss_2: 1.3865e-04 - loss_3: 1.3055e-04 - loss_4: 1.3403e-04 - loss_5: 1.4339e-04 - loss_6: 1.3321e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4307 - val_loss_2: 0.4086 - val_loss_3: 0.4477 - val_loss_4: 0.4264 - val_loss_5: 0.4425 - val_loss_6: 0.4299 - val_acc_ensemble: 0.9080 - val_acc_1: 0.9012 - val_acc_2: 0.9030 - val_acc_3: 0.8989 - val_acc_4: 0.9013 - val_acc_5: 0.8977 - val_acc_6: 0.9012\n",
      "Epoch 8/10\n",
      " - 2s - loss_1: 1.1773e-04 - loss_2: 1.0812e-04 - loss_3: 1.1379e-04 - loss_4: 1.1427e-04 - loss_5: 1.2776e-04 - loss_6: 1.1129e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4325 - val_loss_2: 0.4100 - val_loss_3: 0.4493 - val_loss_4: 0.4280 - val_loss_5: 0.4433 - val_loss_6: 0.4321 - val_acc_ensemble: 0.9078 - val_acc_1: 0.9019 - val_acc_2: 0.9033 - val_acc_3: 0.8987 - val_acc_4: 0.9014 - val_acc_5: 0.8979 - val_acc_6: 0.9012\n",
      "Epoch 9/10\n",
      " - 2s - loss_1: 1.0136e-04 - loss_2: 9.7456e-05 - loss_3: 9.5114e-05 - loss_4: 9.5180e-05 - loss_5: 1.0619e-04 - loss_6: 9.8500e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4350 - val_loss_2: 0.4120 - val_loss_3: 0.4510 - val_loss_4: 0.4298 - val_loss_5: 0.4448 - val_loss_6: 0.4345 - val_acc_ensemble: 0.9079 - val_acc_1: 0.9019 - val_acc_2: 0.9034 - val_acc_3: 0.8986 - val_acc_4: 0.9021 - val_acc_5: 0.8982 - val_acc_6: 0.9013\n",
      "Epoch 10/10\n",
      " - 2s - loss_1: 8.2075e-05 - loss_2: 8.6049e-05 - loss_3: 8.5957e-05 - loss_4: 8.5437e-05 - loss_5: 9.5349e-05 - loss_6: 9.4087e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4370 - val_loss_2: 0.4136 - val_loss_3: 0.4525 - val_loss_4: 0.4320 - val_loss_5: 0.4461 - val_loss_6: 0.4368 - val_acc_ensemble: 0.9080 - val_acc_1: 0.9018 - val_acc_2: 0.9033 - val_acc_3: 0.8989 - val_acc_4: 0.9021 - val_acc_5: 0.8985 - val_acc_6: 0.9008\n",
      "sensitivity/vb-mnist-fcn3A/B6/S0.50\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,256] [None,256]  1406720    input    \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,256] [None,256]  3584       fc1      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,256] [None,256]  0          bn1      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,256] [None,256]  1250048    relu1    \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,256] [None,256]  3584       fc2      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,256] [None,256]  0          bn2      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,256] [None,256]  1250048    relu2    \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,256] [None,256]  3584       fc3      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,256] [None,256]  0          bn3      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              24415      relu3    \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 3941983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 7s - loss_1: 0.2053 - loss_2: 0.2065 - loss_3: 0.1905 - loss_4: 0.1979 - loss_5: 0.2004 - loss_6: 0.2105 - acc_ensemble: 1.0000 - acc_1: 0.9983 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4672 - val_loss_2: 0.4447 - val_loss_3: 0.4444 - val_loss_4: 0.4361 - val_loss_5: 0.4330 - val_loss_6: 0.3703 - val_acc_ensemble: 0.9037 - val_acc_1: 0.8839 - val_acc_2: 0.8863 - val_acc_3: 0.8876 - val_acc_4: 0.8885 - val_acc_5: 0.8888 - val_acc_6: 0.9028\n",
      "Epoch 2/10\n",
      " - 2s - loss_1: 0.0011 - loss_2: 9.2007e-04 - loss_3: 0.0012 - loss_4: 0.0038 - loss_5: 0.0013 - loss_6: 9.9724e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4433 - val_loss_2: 0.4378 - val_loss_3: 0.4342 - val_loss_4: 0.4515 - val_loss_5: 0.4214 - val_loss_6: 0.3654 - val_acc_ensemble: 0.9049 - val_acc_1: 0.8935 - val_acc_2: 0.8920 - val_acc_3: 0.8944 - val_acc_4: 0.8884 - val_acc_5: 0.8960 - val_acc_6: 0.9071\n",
      "Epoch 3/10\n",
      " - 2s - loss_1: 4.4789e-04 - loss_2: 5.8566e-04 - loss_3: 4.4205e-04 - loss_4: 6.4043e-04 - loss_5: 3.7871e-04 - loss_6: 3.7534e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4424 - val_loss_2: 0.4375 - val_loss_3: 0.4327 - val_loss_4: 0.4391 - val_loss_5: 0.4238 - val_loss_6: 0.3674 - val_acc_ensemble: 0.9057 - val_acc_1: 0.8941 - val_acc_2: 0.8934 - val_acc_3: 0.8967 - val_acc_4: 0.8937 - val_acc_5: 0.8975 - val_acc_6: 0.9064\n",
      "Epoch 4/10\n",
      " - 2s - loss_1: 2.8839e-04 - loss_2: 3.0494e-04 - loss_3: 2.7468e-04 - loss_4: 2.8635e-04 - loss_5: 2.4839e-04 - loss_6: 2.8493e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4432 - val_loss_2: 0.4396 - val_loss_3: 0.4331 - val_loss_4: 0.4391 - val_loss_5: 0.4251 - val_loss_6: 0.3706 - val_acc_ensemble: 0.9061 - val_acc_1: 0.8954 - val_acc_2: 0.8956 - val_acc_3: 0.8971 - val_acc_4: 0.8948 - val_acc_5: 0.8988 - val_acc_6: 0.9072\n",
      "Epoch 5/10\n",
      " - 2s - loss_1: 2.1369e-04 - loss_2: 2.1393e-04 - loss_3: 2.0726e-04 - loss_4: 2.0241e-04 - loss_5: 1.9251e-04 - loss_6: 2.1244e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4449 - val_loss_2: 0.4425 - val_loss_3: 0.4352 - val_loss_4: 0.4404 - val_loss_5: 0.4278 - val_loss_6: 0.3748 - val_acc_ensemble: 0.9060 - val_acc_1: 0.8965 - val_acc_2: 0.8955 - val_acc_3: 0.8980 - val_acc_4: 0.8961 - val_acc_5: 0.8997 - val_acc_6: 0.9075\n",
      "Epoch 6/10\n",
      " - 2s - loss_1: 1.7012e-04 - loss_2: 1.6518e-04 - loss_3: 1.5535e-04 - loss_4: 1.6350e-04 - loss_5: 1.4659e-04 - loss_6: 1.7349e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4474 - val_loss_2: 0.4454 - val_loss_3: 0.4371 - val_loss_4: 0.4410 - val_loss_5: 0.4300 - val_loss_6: 0.3782 - val_acc_ensemble: 0.9060 - val_acc_1: 0.8966 - val_acc_2: 0.8957 - val_acc_3: 0.8983 - val_acc_4: 0.8967 - val_acc_5: 0.9002 - val_acc_6: 0.9076\n",
      "Epoch 7/10\n",
      " - 2s - loss_1: 1.3852e-04 - loss_2: 1.3801e-04 - loss_3: 1.3336e-04 - loss_4: 1.3549e-04 - loss_5: 1.2695e-04 - loss_6: 1.3756e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4495 - val_loss_2: 0.4479 - val_loss_3: 0.4390 - val_loss_4: 0.4428 - val_loss_5: 0.4328 - val_loss_6: 0.3816 - val_acc_ensemble: 0.9057 - val_acc_1: 0.8963 - val_acc_2: 0.8959 - val_acc_3: 0.8994 - val_acc_4: 0.8967 - val_acc_5: 0.9006 - val_acc_6: 0.9075\n",
      "Epoch 8/10\n",
      " - 2s - loss_1: 1.2524e-04 - loss_2: 1.2006e-04 - loss_3: 1.1203e-04 - loss_4: 1.1150e-04 - loss_5: 1.0883e-04 - loss_6: 1.1825e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4517 - val_loss_2: 0.4504 - val_loss_3: 0.4404 - val_loss_4: 0.4445 - val_loss_5: 0.4349 - val_loss_6: 0.3842 - val_acc_ensemble: 0.9058 - val_acc_1: 0.8971 - val_acc_2: 0.8956 - val_acc_3: 0.9000 - val_acc_4: 0.8972 - val_acc_5: 0.8997 - val_acc_6: 0.9078\n",
      "Epoch 9/10\n",
      " - 3s - loss_1: 1.0172e-04 - loss_2: 1.0111e-04 - loss_3: 9.5324e-05 - loss_4: 9.7130e-05 - loss_5: 8.6880e-05 - loss_6: 9.8827e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4535 - val_loss_2: 0.4522 - val_loss_3: 0.4422 - val_loss_4: 0.4458 - val_loss_5: 0.4369 - val_loss_6: 0.3864 - val_acc_ensemble: 0.9059 - val_acc_1: 0.8971 - val_acc_2: 0.8960 - val_acc_3: 0.9004 - val_acc_4: 0.8975 - val_acc_5: 0.9005 - val_acc_6: 0.9077\n",
      "Epoch 10/10\n",
      " - 2s - loss_1: 8.8111e-05 - loss_2: 9.1469e-05 - loss_3: 8.5954e-05 - loss_4: 8.7671e-05 - loss_5: 7.9105e-05 - loss_6: 8.7406e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4552 - val_loss_2: 0.4545 - val_loss_3: 0.4444 - val_loss_4: 0.4474 - val_loss_5: 0.4388 - val_loss_6: 0.3884 - val_acc_ensemble: 0.9063 - val_acc_1: 0.8979 - val_acc_2: 0.8961 - val_acc_3: 0.9003 - val_acc_4: 0.8975 - val_acc_5: 0.9008 - val_acc_6: 0.9079\n",
      "sensitivity/vb-mnist-fcn3A/B6/S0.50\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,256] [None,256]  1406720    input    \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,256] [None,256]  3584       fc1      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,256] [None,256]  0          bn1      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,256] [None,256]  1250048    relu1    \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,256] [None,256]  3584       fc2      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,256] [None,256]  0          bn2      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,256] [None,256]  1250048    relu2    \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,256] [None,256]  3584       fc3      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,256] [None,256]  0          bn3      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              24415      relu3    \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 3941983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 7s - loss_1: 0.2372 - loss_2: 0.2121 - loss_3: 0.2063 - loss_4: 0.2119 - loss_5: 0.2058 - loss_6: 0.2011 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 0.9933 - acc_4: 1.0000 - acc_5: 0.9983 - acc_6: 0.9983 - val_loss_1: 0.4439 - val_loss_2: 0.4647 - val_loss_3: 0.4320 - val_loss_4: 0.4341 - val_loss_5: 0.4367 - val_loss_6: 0.4774 - val_acc_ensemble: 0.9020 - val_acc_1: 0.8869 - val_acc_2: 0.8829 - val_acc_3: 0.8865 - val_acc_4: 0.8874 - val_acc_5: 0.8870 - val_acc_6: 0.8819\n",
      "Epoch 2/10\n",
      " - 2s - loss_1: 9.2736e-04 - loss_2: 0.0018 - loss_3: 0.0046 - loss_4: 0.0015 - loss_5: 0.0014 - loss_6: 0.0020 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4215 - val_loss_2: 0.4251 - val_loss_3: 0.4301 - val_loss_4: 0.4245 - val_loss_5: 0.4247 - val_loss_6: 0.4248 - val_acc_ensemble: 0.9055 - val_acc_1: 0.8941 - val_acc_2: 0.8956 - val_acc_3: 0.8946 - val_acc_4: 0.8965 - val_acc_5: 0.8972 - val_acc_6: 0.8952\n",
      "Epoch 3/10\n",
      " - 3s - loss_1: 3.9891e-04 - loss_2: 4.3411e-04 - loss_3: 4.5947e-04 - loss_4: 3.7902e-04 - loss_5: 3.7037e-04 - loss_6: 4.3682e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4207 - val_loss_2: 0.4252 - val_loss_3: 0.4239 - val_loss_4: 0.4239 - val_loss_5: 0.4221 - val_loss_6: 0.4240 - val_acc_ensemble: 0.9064 - val_acc_1: 0.8965 - val_acc_2: 0.8978 - val_acc_3: 0.8969 - val_acc_4: 0.8967 - val_acc_5: 0.8990 - val_acc_6: 0.8963\n",
      "Epoch 4/10\n",
      " - 3s - loss_1: 2.8340e-04 - loss_2: 2.9123e-04 - loss_3: 3.0218e-04 - loss_4: 2.6773e-04 - loss_5: 2.6060e-04 - loss_6: 2.6329e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4219 - val_loss_2: 0.4280 - val_loss_3: 0.4235 - val_loss_4: 0.4246 - val_loss_5: 0.4219 - val_loss_6: 0.4257 - val_acc_ensemble: 0.9069 - val_acc_1: 0.8976 - val_acc_2: 0.8983 - val_acc_3: 0.8979 - val_acc_4: 0.8982 - val_acc_5: 0.9010 - val_acc_6: 0.8964\n",
      "Epoch 5/10\n",
      " - 3s - loss_1: 2.1022e-04 - loss_2: 2.2496e-04 - loss_3: 2.0662e-04 - loss_4: 1.9682e-04 - loss_5: 2.0701e-04 - loss_6: 1.9162e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4230 - val_loss_2: 0.4301 - val_loss_3: 0.4243 - val_loss_4: 0.4258 - val_loss_5: 0.4233 - val_loss_6: 0.4264 - val_acc_ensemble: 0.9071 - val_acc_1: 0.8983 - val_acc_2: 0.8990 - val_acc_3: 0.8987 - val_acc_4: 0.8986 - val_acc_5: 0.9010 - val_acc_6: 0.8978\n",
      "Epoch 6/10\n",
      " - 3s - loss_1: 1.8489e-04 - loss_2: 1.7188e-04 - loss_3: 1.6288e-04 - loss_4: 1.5420e-04 - loss_5: 1.5867e-04 - loss_6: 1.5904e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4243 - val_loss_2: 0.4321 - val_loss_3: 0.4249 - val_loss_4: 0.4280 - val_loss_5: 0.4253 - val_loss_6: 0.4286 - val_acc_ensemble: 0.9068 - val_acc_1: 0.8994 - val_acc_2: 0.9002 - val_acc_3: 0.8994 - val_acc_4: 0.8992 - val_acc_5: 0.9025 - val_acc_6: 0.8984\n",
      "Epoch 7/10\n",
      " - 2s - loss_1: 1.3656e-04 - loss_2: 1.4680e-04 - loss_3: 1.3368e-04 - loss_4: 1.2040e-04 - loss_5: 1.3035e-04 - loss_6: 1.3942e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4262 - val_loss_2: 0.4339 - val_loss_3: 0.4262 - val_loss_4: 0.4294 - val_loss_5: 0.4271 - val_loss_6: 0.4305 - val_acc_ensemble: 0.9068 - val_acc_1: 0.8997 - val_acc_2: 0.8997 - val_acc_3: 0.8994 - val_acc_4: 0.8994 - val_acc_5: 0.9031 - val_acc_6: 0.8980\n",
      "Epoch 8/10\n",
      " - 2s - loss_1: 1.2442e-04 - loss_2: 1.2516e-04 - loss_3: 1.1103e-04 - loss_4: 1.1016e-04 - loss_5: 1.0676e-04 - loss_6: 1.1419e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4274 - val_loss_2: 0.4354 - val_loss_3: 0.4275 - val_loss_4: 0.4307 - val_loss_5: 0.4285 - val_loss_6: 0.4328 - val_acc_ensemble: 0.9071 - val_acc_1: 0.8999 - val_acc_2: 0.9004 - val_acc_3: 0.8999 - val_acc_4: 0.8995 - val_acc_5: 0.9032 - val_acc_6: 0.8986\n",
      "Epoch 9/10\n",
      " - 2s - loss_1: 1.1001e-04 - loss_2: 1.0479e-04 - loss_3: 1.0299e-04 - loss_4: 9.4051e-05 - loss_5: 9.3768e-05 - loss_6: 1.0037e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4293 - val_loss_2: 0.4373 - val_loss_3: 0.4289 - val_loss_4: 0.4318 - val_loss_5: 0.4299 - val_loss_6: 0.4351 - val_acc_ensemble: 0.9074 - val_acc_1: 0.8999 - val_acc_2: 0.9009 - val_acc_3: 0.9000 - val_acc_4: 0.9003 - val_acc_5: 0.9032 - val_acc_6: 0.8985\n",
      "Epoch 10/10\n",
      " - 2s - loss_1: 9.2918e-05 - loss_2: 8.7081e-05 - loss_3: 8.9776e-05 - loss_4: 8.3395e-05 - loss_5: 8.7156e-05 - loss_6: 8.5484e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4312 - val_loss_2: 0.4390 - val_loss_3: 0.4307 - val_loss_4: 0.4336 - val_loss_5: 0.4318 - val_loss_6: 0.4372 - val_acc_ensemble: 0.9074 - val_acc_1: 0.9000 - val_acc_2: 0.9010 - val_acc_3: 0.9001 - val_acc_4: 0.9009 - val_acc_5: 0.9037 - val_acc_6: 0.8986\n",
      "sensitivity/vb-mnist-fcn3A/B6/S0.50\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,256] [None,256]  1406720    input    \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,256] [None,256]  3584       fc1      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,256] [None,256]  0          bn1      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,256] [None,256]  1250048    relu1    \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,256] [None,256]  3584       fc2      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,256] [None,256]  0          bn2      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,256] [None,256]  1250048    relu2    \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,256] [None,256]  3584       fc3      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,256] [None,256]  0          bn3      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              24415      relu3    \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 3941983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 7s - loss_1: 0.2028 - loss_2: 0.2167 - loss_3: 0.2179 - loss_4: 0.2200 - loss_5: 0.2143 - loss_6: 0.2130 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4289 - val_loss_2: 0.4461 - val_loss_3: 0.4585 - val_loss_4: 0.4473 - val_loss_5: 0.4595 - val_loss_6: 0.4407 - val_acc_ensemble: 0.9024 - val_acc_1: 0.8961 - val_acc_2: 0.8849 - val_acc_3: 0.8855 - val_acc_4: 0.8851 - val_acc_5: 0.8873 - val_acc_6: 0.8854\n",
      "Epoch 2/10\n",
      " - 3s - loss_1: 0.0011 - loss_2: 0.0011 - loss_3: 0.0011 - loss_4: 0.0018 - loss_5: 0.0011 - loss_6: 0.0012 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4190 - val_loss_2: 0.4220 - val_loss_3: 0.4484 - val_loss_4: 0.4194 - val_loss_5: 0.4468 - val_loss_6: 0.4269 - val_acc_ensemble: 0.9050 - val_acc_1: 0.8998 - val_acc_2: 0.8964 - val_acc_3: 0.8909 - val_acc_4: 0.8985 - val_acc_5: 0.8943 - val_acc_6: 0.8933\n",
      "Epoch 3/10\n",
      " - 3s - loss_1: 3.6139e-04 - loss_2: 4.1445e-04 - loss_3: 4.6576e-04 - loss_4: 4.5968e-04 - loss_5: 4.1954e-04 - loss_6: 4.5879e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4220 - val_loss_2: 0.4257 - val_loss_3: 0.4468 - val_loss_4: 0.4225 - val_loss_5: 0.4481 - val_loss_6: 0.4293 - val_acc_ensemble: 0.9058 - val_acc_1: 0.9004 - val_acc_2: 0.8974 - val_acc_3: 0.8933 - val_acc_4: 0.8993 - val_acc_5: 0.8956 - val_acc_6: 0.8939\n",
      "Epoch 4/10\n",
      " - 2s - loss_1: 2.5992e-04 - loss_2: 2.9924e-04 - loss_3: 3.0276e-04 - loss_4: 3.0389e-04 - loss_5: 2.8638e-04 - loss_6: 2.9649e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4250 - val_loss_2: 0.4287 - val_loss_3: 0.4480 - val_loss_4: 0.4249 - val_loss_5: 0.4504 - val_loss_6: 0.4327 - val_acc_ensemble: 0.9060 - val_acc_1: 0.9016 - val_acc_2: 0.8981 - val_acc_3: 0.8950 - val_acc_4: 0.8997 - val_acc_5: 0.8965 - val_acc_6: 0.8949\n",
      "Epoch 5/10\n",
      " - 2s - loss_1: 1.9267e-04 - loss_2: 2.1307e-04 - loss_3: 2.3569e-04 - loss_4: 2.2806e-04 - loss_5: 2.1562e-04 - loss_6: 2.3482e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4274 - val_loss_2: 0.4318 - val_loss_3: 0.4490 - val_loss_4: 0.4274 - val_loss_5: 0.4528 - val_loss_6: 0.4357 - val_acc_ensemble: 0.9063 - val_acc_1: 0.9017 - val_acc_2: 0.8989 - val_acc_3: 0.8957 - val_acc_4: 0.8999 - val_acc_5: 0.8970 - val_acc_6: 0.8967\n",
      "Epoch 6/10\n",
      " - 2s - loss_1: 1.6114e-04 - loss_2: 1.7402e-04 - loss_3: 1.7977e-04 - loss_4: 1.7181e-04 - loss_5: 1.6404e-04 - loss_6: 1.9405e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4300 - val_loss_2: 0.4343 - val_loss_3: 0.4505 - val_loss_4: 0.4297 - val_loss_5: 0.4544 - val_loss_6: 0.4380 - val_acc_ensemble: 0.9066 - val_acc_1: 0.9021 - val_acc_2: 0.8991 - val_acc_3: 0.8960 - val_acc_4: 0.8997 - val_acc_5: 0.8974 - val_acc_6: 0.8971\n",
      "Epoch 7/10\n",
      " - 2s - loss_1: 1.2880e-04 - loss_2: 1.4170e-04 - loss_3: 1.5053e-04 - loss_4: 1.4865e-04 - loss_5: 1.3413e-04 - loss_6: 1.5576e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4331 - val_loss_2: 0.4368 - val_loss_3: 0.4530 - val_loss_4: 0.4319 - val_loss_5: 0.4569 - val_loss_6: 0.4409 - val_acc_ensemble: 0.9067 - val_acc_1: 0.9019 - val_acc_2: 0.8992 - val_acc_3: 0.8966 - val_acc_4: 0.8998 - val_acc_5: 0.8977 - val_acc_6: 0.8972\n",
      "Epoch 8/10\n",
      " - 2s - loss_1: 1.1632e-04 - loss_2: 1.2269e-04 - loss_3: 1.2945e-04 - loss_4: 1.2847e-04 - loss_5: 1.2634e-04 - loss_6: 1.2034e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4353 - val_loss_2: 0.4387 - val_loss_3: 0.4545 - val_loss_4: 0.4345 - val_loss_5: 0.4593 - val_loss_6: 0.4432 - val_acc_ensemble: 0.9071 - val_acc_1: 0.9022 - val_acc_2: 0.8996 - val_acc_3: 0.8971 - val_acc_4: 0.8997 - val_acc_5: 0.8978 - val_acc_6: 0.8980\n",
      "Epoch 9/10\n",
      " - 2s - loss_1: 9.1339e-05 - loss_2: 1.1295e-04 - loss_3: 1.0772e-04 - loss_4: 1.0788e-04 - loss_5: 1.0559e-04 - loss_6: 1.0899e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4372 - val_loss_2: 0.4417 - val_loss_3: 0.4560 - val_loss_4: 0.4366 - val_loss_5: 0.4614 - val_loss_6: 0.4454 - val_acc_ensemble: 0.9073 - val_acc_1: 0.9028 - val_acc_2: 0.8997 - val_acc_3: 0.8971 - val_acc_4: 0.9002 - val_acc_5: 0.8979 - val_acc_6: 0.8982\n",
      "Epoch 10/10\n",
      " - 2s - loss_1: 8.0634e-05 - loss_2: 9.0841e-05 - loss_3: 9.0290e-05 - loss_4: 9.2824e-05 - loss_5: 8.6015e-05 - loss_6: 9.8186e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4392 - val_loss_2: 0.4444 - val_loss_3: 0.4578 - val_loss_4: 0.4385 - val_loss_5: 0.4636 - val_loss_6: 0.4480 - val_acc_ensemble: 0.9074 - val_acc_1: 0.9031 - val_acc_2: 0.8995 - val_acc_3: 0.8972 - val_acc_4: 0.9005 - val_acc_5: 0.8982 - val_acc_6: 0.8979\n",
      "sensitivity/vb-mnist-fcn3A/B6/S0.75\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,384] [None,128]  904320     input    \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,384] [None,128]  2304       fc1      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,384] [None,128]  0          bn1      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,384] [None,128]  839808     relu1    \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,384] [None,128]  2304       fc2      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,384] [None,128]  0          bn2      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,384] [None,128]  839808     relu2    \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,384] [None,128]  2304       fc3      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,384] [None,128]  0          bn3      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              17365      relu3    \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 2608213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 7s - loss_1: 0.1611 - loss_2: 0.1468 - loss_3: 0.1635 - loss_4: 0.1559 - loss_5: 0.1521 - loss_6: 0.1714 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4089 - val_loss_2: 0.4101 - val_loss_3: 0.4197 - val_loss_4: 0.4470 - val_loss_5: 0.4159 - val_loss_6: 0.4205 - val_acc_ensemble: 0.9008 - val_acc_1: 0.8979 - val_acc_2: 0.8924 - val_acc_3: 0.8928 - val_acc_4: 0.8885 - val_acc_5: 0.8966 - val_acc_6: 0.8935\n",
      "Epoch 2/10\n",
      " - 2s - loss_1: 5.4337e-04 - loss_2: 6.1629e-04 - loss_3: 5.6451e-04 - loss_4: 5.7209e-04 - loss_5: 4.9917e-04 - loss_6: 5.1947e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4123 - val_loss_2: 0.4096 - val_loss_3: 0.4159 - val_loss_4: 0.4426 - val_loss_5: 0.4190 - val_loss_6: 0.4170 - val_acc_ensemble: 0.9019 - val_acc_1: 0.8992 - val_acc_2: 0.8955 - val_acc_3: 0.8958 - val_acc_4: 0.8926 - val_acc_5: 0.9001 - val_acc_6: 0.9005\n",
      "Epoch 3/10\n",
      " - 2s - loss_1: 2.9318e-04 - loss_2: 3.2210e-04 - loss_3: 2.7487e-04 - loss_4: 3.0851e-04 - loss_5: 2.9073e-04 - loss_6: 2.8141e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4151 - val_loss_2: 0.4135 - val_loss_3: 0.4186 - val_loss_4: 0.4429 - val_loss_5: 0.4225 - val_loss_6: 0.4195 - val_acc_ensemble: 0.9035 - val_acc_1: 0.8996 - val_acc_2: 0.8971 - val_acc_3: 0.8972 - val_acc_4: 0.8952 - val_acc_5: 0.9013 - val_acc_6: 0.9008\n",
      "Epoch 4/10\n",
      " - 3s - loss_1: 2.0255e-04 - loss_2: 2.1470e-04 - loss_3: 1.8664e-04 - loss_4: 2.0567e-04 - loss_5: 1.7970e-04 - loss_6: 1.9602e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4179 - val_loss_2: 0.4167 - val_loss_3: 0.4214 - val_loss_4: 0.4449 - val_loss_5: 0.4259 - val_loss_6: 0.4228 - val_acc_ensemble: 0.9032 - val_acc_1: 0.9002 - val_acc_2: 0.8972 - val_acc_3: 0.8977 - val_acc_4: 0.8966 - val_acc_5: 0.9017 - val_acc_6: 0.9014\n",
      "Epoch 5/10\n",
      " - 2s - loss_1: 1.4498e-04 - loss_2: 1.6875e-04 - loss_3: 1.3959e-04 - loss_4: 1.4926e-04 - loss_5: 1.3952e-04 - loss_6: 1.5044e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4211 - val_loss_2: 0.4205 - val_loss_3: 0.4247 - val_loss_4: 0.4476 - val_loss_5: 0.4296 - val_loss_6: 0.4263 - val_acc_ensemble: 0.9034 - val_acc_1: 0.9006 - val_acc_2: 0.8980 - val_acc_3: 0.8976 - val_acc_4: 0.8969 - val_acc_5: 0.9022 - val_acc_6: 0.9012\n",
      "Epoch 6/10\n",
      " - 3s - loss_1: 1.1931e-04 - loss_2: 1.2708e-04 - loss_3: 1.1165e-04 - loss_4: 1.2202e-04 - loss_5: 1.2192e-04 - loss_6: 1.1896e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4244 - val_loss_2: 0.4234 - val_loss_3: 0.4279 - val_loss_4: 0.4497 - val_loss_5: 0.4326 - val_loss_6: 0.4292 - val_acc_ensemble: 0.9028 - val_acc_1: 0.9006 - val_acc_2: 0.8980 - val_acc_3: 0.8983 - val_acc_4: 0.8975 - val_acc_5: 0.9022 - val_acc_6: 0.9012\n",
      "Epoch 7/10\n",
      " - 2s - loss_1: 9.6446e-05 - loss_2: 1.0812e-04 - loss_3: 9.8529e-05 - loss_4: 1.0562e-04 - loss_5: 1.0193e-04 - loss_6: 1.0393e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4271 - val_loss_2: 0.4259 - val_loss_3: 0.4304 - val_loss_4: 0.4515 - val_loss_5: 0.4350 - val_loss_6: 0.4315 - val_acc_ensemble: 0.9027 - val_acc_1: 0.9010 - val_acc_2: 0.8987 - val_acc_3: 0.8987 - val_acc_4: 0.8980 - val_acc_5: 0.9027 - val_acc_6: 0.9015\n",
      "Epoch 8/10\n",
      " - 2s - loss_1: 8.6216e-05 - loss_2: 9.2223e-05 - loss_3: 7.9352e-05 - loss_4: 8.4100e-05 - loss_5: 8.7064e-05 - loss_6: 8.6667e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4296 - val_loss_2: 0.4281 - val_loss_3: 0.4324 - val_loss_4: 0.4535 - val_loss_5: 0.4377 - val_loss_6: 0.4339 - val_acc_ensemble: 0.9034 - val_acc_1: 0.9010 - val_acc_2: 0.8986 - val_acc_3: 0.8992 - val_acc_4: 0.8988 - val_acc_5: 0.9027 - val_acc_6: 0.9016\n",
      "Epoch 9/10\n",
      " - 3s - loss_1: 7.6408e-05 - loss_2: 7.9380e-05 - loss_3: 6.9678e-05 - loss_4: 7.2882e-05 - loss_5: 6.9570e-05 - loss_6: 7.7057e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4323 - val_loss_2: 0.4304 - val_loss_3: 0.4352 - val_loss_4: 0.4553 - val_loss_5: 0.4402 - val_loss_6: 0.4365 - val_acc_ensemble: 0.9035 - val_acc_1: 0.9007 - val_acc_2: 0.8989 - val_acc_3: 0.8994 - val_acc_4: 0.8990 - val_acc_5: 0.9029 - val_acc_6: 0.9020\n",
      "Epoch 10/10\n",
      " - 2s - loss_1: 6.4239e-05 - loss_2: 6.7209e-05 - loss_3: 6.0258e-05 - loss_4: 6.0999e-05 - loss_5: 6.5018e-05 - loss_6: 6.9081e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4346 - val_loss_2: 0.4322 - val_loss_3: 0.4376 - val_loss_4: 0.4573 - val_loss_5: 0.4424 - val_loss_6: 0.4386 - val_acc_ensemble: 0.9036 - val_acc_1: 0.9006 - val_acc_2: 0.8991 - val_acc_3: 0.8990 - val_acc_4: 0.8988 - val_acc_5: 0.9033 - val_acc_6: 0.9021\n",
      "sensitivity/vb-mnist-fcn3A/B6/S0.75\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,384] [None,128]  904320     input    \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,384] [None,128]  2304       fc1      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,384] [None,128]  0          bn1      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,384] [None,128]  839808     relu1    \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,384] [None,128]  2304       fc2      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,384] [None,128]  0          bn2      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,384] [None,128]  839808     relu2    \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,384] [None,128]  2304       fc3      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,384] [None,128]  0          bn3      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              17365      relu3    \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 2608213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 7s - loss_1: 0.1503 - loss_2: 0.1704 - loss_3: 0.1498 - loss_4: 0.1778 - loss_5: 0.1515 - loss_6: 0.1593 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4265 - val_loss_2: 0.4055 - val_loss_3: 0.4096 - val_loss_4: 0.4036 - val_loss_5: 0.4162 - val_loss_6: 0.4150 - val_acc_ensemble: 0.9033 - val_acc_1: 0.8943 - val_acc_2: 0.8944 - val_acc_3: 0.8981 - val_acc_4: 0.8970 - val_acc_5: 0.8971 - val_acc_6: 0.8960\n",
      "Epoch 2/10\n",
      " - 2s - loss_1: 6.1659e-04 - loss_2: 6.5475e-04 - loss_3: 5.6603e-04 - loss_4: 5.9493e-04 - loss_5: 6.7479e-04 - loss_6: 6.5363e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4207 - val_loss_2: 0.4098 - val_loss_3: 0.4120 - val_loss_4: 0.4006 - val_loss_5: 0.4131 - val_loss_6: 0.4050 - val_acc_ensemble: 0.9056 - val_acc_1: 0.8983 - val_acc_2: 0.8965 - val_acc_3: 0.8997 - val_acc_4: 0.8990 - val_acc_5: 0.9006 - val_acc_6: 0.9030\n",
      "Epoch 3/10\n",
      " - 2s - loss_1: 2.7072e-04 - loss_2: 3.1704e-04 - loss_3: 2.8009e-04 - loss_4: 2.8842e-04 - loss_5: 3.0566e-04 - loss_6: 2.7816e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4194 - val_loss_2: 0.4105 - val_loss_3: 0.4123 - val_loss_4: 0.4019 - val_loss_5: 0.4156 - val_loss_6: 0.4075 - val_acc_ensemble: 0.9062 - val_acc_1: 0.8989 - val_acc_2: 0.8992 - val_acc_3: 0.9017 - val_acc_4: 0.9010 - val_acc_5: 0.9019 - val_acc_6: 0.9035\n",
      "Epoch 4/10\n",
      " - 2s - loss_1: 1.7333e-04 - loss_2: 2.1631e-04 - loss_3: 1.8516e-04 - loss_4: 1.9934e-04 - loss_5: 2.0757e-04 - loss_6: 1.9921e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4216 - val_loss_2: 0.4134 - val_loss_3: 0.4153 - val_loss_4: 0.4045 - val_loss_5: 0.4195 - val_loss_6: 0.4107 - val_acc_ensemble: 0.9063 - val_acc_1: 0.8999 - val_acc_2: 0.9003 - val_acc_3: 0.9028 - val_acc_4: 0.9016 - val_acc_5: 0.9014 - val_acc_6: 0.9036\n",
      "Epoch 5/10\n",
      " - 3s - loss_1: 1.4465e-04 - loss_2: 1.6065e-04 - loss_3: 1.4623e-04 - loss_4: 1.5028e-04 - loss_5: 1.6108e-04 - loss_6: 1.5492e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4246 - val_loss_2: 0.4163 - val_loss_3: 0.4191 - val_loss_4: 0.4075 - val_loss_5: 0.4230 - val_loss_6: 0.4139 - val_acc_ensemble: 0.9064 - val_acc_1: 0.9003 - val_acc_2: 0.9012 - val_acc_3: 0.9034 - val_acc_4: 0.9018 - val_acc_5: 0.9012 - val_acc_6: 0.9032\n",
      "Epoch 6/10\n",
      " - 2s - loss_1: 1.1439e-04 - loss_2: 1.2993e-04 - loss_3: 1.0924e-04 - loss_4: 1.2088e-04 - loss_5: 1.2584e-04 - loss_6: 1.2216e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4269 - val_loss_2: 0.4187 - val_loss_3: 0.4221 - val_loss_4: 0.4097 - val_loss_5: 0.4265 - val_loss_6: 0.4163 - val_acc_ensemble: 0.9069 - val_acc_1: 0.9011 - val_acc_2: 0.9015 - val_acc_3: 0.9035 - val_acc_4: 0.9024 - val_acc_5: 0.9010 - val_acc_6: 0.9035\n",
      "Epoch 7/10\n",
      " - 2s - loss_1: 9.4337e-05 - loss_2: 1.0664e-04 - loss_3: 9.5052e-05 - loss_4: 9.9455e-05 - loss_5: 1.0690e-04 - loss_6: 1.0189e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4292 - val_loss_2: 0.4214 - val_loss_3: 0.4248 - val_loss_4: 0.4121 - val_loss_5: 0.4288 - val_loss_6: 0.4192 - val_acc_ensemble: 0.9071 - val_acc_1: 0.9019 - val_acc_2: 0.9019 - val_acc_3: 0.9035 - val_acc_4: 0.9025 - val_acc_5: 0.9010 - val_acc_6: 0.9037\n",
      "Epoch 8/10\n",
      " - 3s - loss_1: 7.6373e-05 - loss_2: 8.7920e-05 - loss_3: 7.5813e-05 - loss_4: 8.2154e-05 - loss_5: 9.0829e-05 - loss_6: 8.4172e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4316 - val_loss_2: 0.4236 - val_loss_3: 0.4272 - val_loss_4: 0.4141 - val_loss_5: 0.4316 - val_loss_6: 0.4212 - val_acc_ensemble: 0.9070 - val_acc_1: 0.9023 - val_acc_2: 0.9022 - val_acc_3: 0.9034 - val_acc_4: 0.9028 - val_acc_5: 0.9015 - val_acc_6: 0.9040\n",
      "Epoch 9/10\n",
      " - 3s - loss_1: 6.4477e-05 - loss_2: 7.8114e-05 - loss_3: 7.0324e-05 - loss_4: 6.8925e-05 - loss_5: 7.4886e-05 - loss_6: 7.8293e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4336 - val_loss_2: 0.4261 - val_loss_3: 0.4297 - val_loss_4: 0.4160 - val_loss_5: 0.4340 - val_loss_6: 0.4234 - val_acc_ensemble: 0.9071 - val_acc_1: 0.9023 - val_acc_2: 0.9022 - val_acc_3: 0.9031 - val_acc_4: 0.9032 - val_acc_5: 0.9016 - val_acc_6: 0.9039\n",
      "Epoch 10/10\n",
      " - 3s - loss_1: 5.7118e-05 - loss_2: 6.7947e-05 - loss_3: 6.1342e-05 - loss_4: 6.3108e-05 - loss_5: 6.6226e-05 - loss_6: 6.2794e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4358 - val_loss_2: 0.4284 - val_loss_3: 0.4320 - val_loss_4: 0.4182 - val_loss_5: 0.4364 - val_loss_6: 0.4255 - val_acc_ensemble: 0.9072 - val_acc_1: 0.9026 - val_acc_2: 0.9026 - val_acc_3: 0.9033 - val_acc_4: 0.9032 - val_acc_5: 0.9017 - val_acc_6: 0.9040\n",
      "sensitivity/vb-mnist-fcn3A/B6/S0.75\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,384] [None,128]  904320     input    \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,384] [None,128]  2304       fc1      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,384] [None,128]  0          bn1      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,384] [None,128]  839808     relu1    \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,384] [None,128]  2304       fc2      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,384] [None,128]  0          bn2      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,384] [None,128]  839808     relu2    \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,384] [None,128]  2304       fc3      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,384] [None,128]  0          bn3      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              17365      relu3    \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 2608213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 7s - loss_1: 0.1580 - loss_2: 0.1580 - loss_3: 0.1536 - loss_4: 0.1802 - loss_5: 0.1571 - loss_6: 0.1477 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4312 - val_loss_2: 0.4288 - val_loss_3: 0.4402 - val_loss_4: 0.4229 - val_loss_5: 0.4255 - val_loss_6: 0.4433 - val_acc_ensemble: 0.9003 - val_acc_1: 0.8911 - val_acc_2: 0.8952 - val_acc_3: 0.8919 - val_acc_4: 0.8938 - val_acc_5: 0.8938 - val_acc_6: 0.8947\n",
      "Epoch 2/10\n",
      " - 2s - loss_1: 6.7026e-04 - loss_2: 5.7602e-04 - loss_3: 6.1558e-04 - loss_4: 6.8475e-04 - loss_5: 7.2512e-04 - loss_6: 6.3457e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4243 - val_loss_2: 0.4223 - val_loss_3: 0.4364 - val_loss_4: 0.4164 - val_loss_5: 0.4190 - val_loss_6: 0.4333 - val_acc_ensemble: 0.9032 - val_acc_1: 0.8965 - val_acc_2: 0.9007 - val_acc_3: 0.8965 - val_acc_4: 0.8980 - val_acc_5: 0.8986 - val_acc_6: 0.8984\n",
      "Epoch 3/10\n",
      " - 2s - loss_1: 3.2049e-04 - loss_2: 2.8693e-04 - loss_3: 3.0318e-04 - loss_4: 3.5803e-04 - loss_5: 3.2667e-04 - loss_6: 2.6426e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4266 - val_loss_2: 0.4245 - val_loss_3: 0.4396 - val_loss_4: 0.4204 - val_loss_5: 0.4222 - val_loss_6: 0.4367 - val_acc_ensemble: 0.9047 - val_acc_1: 0.8976 - val_acc_2: 0.9021 - val_acc_3: 0.8981 - val_acc_4: 0.8992 - val_acc_5: 0.8990 - val_acc_6: 0.8992\n",
      "Epoch 4/10\n",
      " - 2s - loss_1: 2.1276e-04 - loss_2: 2.0731e-04 - loss_3: 2.1387e-04 - loss_4: 2.3367e-04 - loss_5: 2.0853e-04 - loss_6: 1.7992e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4294 - val_loss_2: 0.4273 - val_loss_3: 0.4423 - val_loss_4: 0.4243 - val_loss_5: 0.4258 - val_loss_6: 0.4397 - val_acc_ensemble: 0.9045 - val_acc_1: 0.8983 - val_acc_2: 0.9024 - val_acc_3: 0.8989 - val_acc_4: 0.8986 - val_acc_5: 0.8994 - val_acc_6: 0.9008\n",
      "Epoch 5/10\n",
      " - 3s - loss_1: 1.7052e-04 - loss_2: 1.6041e-04 - loss_3: 1.6189e-04 - loss_4: 1.7756e-04 - loss_5: 1.6625e-04 - loss_6: 1.3231e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4327 - val_loss_2: 0.4308 - val_loss_3: 0.4456 - val_loss_4: 0.4278 - val_loss_5: 0.4304 - val_loss_6: 0.4431 - val_acc_ensemble: 0.9041 - val_acc_1: 0.8985 - val_acc_2: 0.9028 - val_acc_3: 0.8990 - val_acc_4: 0.8988 - val_acc_5: 0.8992 - val_acc_6: 0.9013\n",
      "Epoch 6/10\n",
      " - 3s - loss_1: 1.3505e-04 - loss_2: 1.2901e-04 - loss_3: 1.2667e-04 - loss_4: 1.3326e-04 - loss_5: 1.3121e-04 - loss_6: 1.1552e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4362 - val_loss_2: 0.4339 - val_loss_3: 0.4491 - val_loss_4: 0.4308 - val_loss_5: 0.4338 - val_loss_6: 0.4464 - val_acc_ensemble: 0.9045 - val_acc_1: 0.8986 - val_acc_2: 0.9030 - val_acc_3: 0.8991 - val_acc_4: 0.8988 - val_acc_5: 0.8996 - val_acc_6: 0.9017\n",
      "Epoch 7/10\n",
      " - 2s - loss_1: 1.1179e-04 - loss_2: 1.0911e-04 - loss_3: 1.0192e-04 - loss_4: 1.1221e-04 - loss_5: 1.0247e-04 - loss_6: 9.2307e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4388 - val_loss_2: 0.4365 - val_loss_3: 0.4515 - val_loss_4: 0.4335 - val_loss_5: 0.4368 - val_loss_6: 0.4487 - val_acc_ensemble: 0.9046 - val_acc_1: 0.8990 - val_acc_2: 0.9030 - val_acc_3: 0.9000 - val_acc_4: 0.8986 - val_acc_5: 0.8994 - val_acc_6: 0.9019\n",
      "Epoch 8/10\n",
      " - 2s - loss_1: 8.8949e-05 - loss_2: 9.1110e-05 - loss_3: 8.2103e-05 - loss_4: 9.4024e-05 - loss_5: 9.2838e-05 - loss_6: 7.9994e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4408 - val_loss_2: 0.4388 - val_loss_3: 0.4534 - val_loss_4: 0.4360 - val_loss_5: 0.4395 - val_loss_6: 0.4509 - val_acc_ensemble: 0.9050 - val_acc_1: 0.8997 - val_acc_2: 0.9033 - val_acc_3: 0.9002 - val_acc_4: 0.8987 - val_acc_5: 0.8998 - val_acc_6: 0.9020\n",
      "Epoch 9/10\n",
      " - 2s - loss_1: 7.8995e-05 - loss_2: 7.1972e-05 - loss_3: 7.2507e-05 - loss_4: 8.2078e-05 - loss_5: 8.1102e-05 - loss_6: 6.5399e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4430 - val_loss_2: 0.4410 - val_loss_3: 0.4558 - val_loss_4: 0.4382 - val_loss_5: 0.4422 - val_loss_6: 0.4530 - val_acc_ensemble: 0.9049 - val_acc_1: 0.8999 - val_acc_2: 0.9038 - val_acc_3: 0.9001 - val_acc_4: 0.8990 - val_acc_5: 0.8991 - val_acc_6: 0.9023\n",
      "Epoch 10/10\n",
      " - 2s - loss_1: 6.8803e-05 - loss_2: 6.8108e-05 - loss_3: 6.4076e-05 - loss_4: 7.2710e-05 - loss_5: 6.7257e-05 - loss_6: 5.7977e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4455 - val_loss_2: 0.4431 - val_loss_3: 0.4580 - val_loss_4: 0.4404 - val_loss_5: 0.4447 - val_loss_6: 0.4554 - val_acc_ensemble: 0.9049 - val_acc_1: 0.8999 - val_acc_2: 0.9038 - val_acc_3: 0.9006 - val_acc_4: 0.8997 - val_acc_5: 0.8995 - val_acc_6: 0.9023\n",
      "sensitivity/vb-mnist-fcn3A/B6/S0.75\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,384] [None,128]  904320     input    \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,384] [None,128]  2304       fc1      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,384] [None,128]  0          bn1      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,384] [None,128]  839808     relu1    \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,384] [None,128]  2304       fc2      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,384] [None,128]  0          bn2      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,384] [None,128]  839808     relu2    \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,384] [None,128]  2304       fc3      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,384] [None,128]  0          bn3      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]              17365      relu3    \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 2608213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 7s - loss_1: 0.1530 - loss_2: 0.1581 - loss_3: 0.1625 - loss_4: 0.1674 - loss_5: 0.1539 - loss_6: 0.1664 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4330 - val_loss_2: 0.4051 - val_loss_3: 0.4053 - val_loss_4: 0.4191 - val_loss_5: 0.4225 - val_loss_6: 0.3972 - val_acc_ensemble: 0.9023 - val_acc_1: 0.8929 - val_acc_2: 0.8972 - val_acc_3: 0.8970 - val_acc_4: 0.8949 - val_acc_5: 0.8946 - val_acc_6: 0.8978\n",
      "Epoch 2/10\n",
      " - 3s - loss_1: 5.8345e-04 - loss_2: 5.5625e-04 - loss_3: 5.5499e-04 - loss_4: 5.7086e-04 - loss_5: 5.8922e-04 - loss_6: 6.2100e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4343 - val_loss_2: 0.4082 - val_loss_3: 0.4071 - val_loss_4: 0.4189 - val_loss_5: 0.4238 - val_loss_6: 0.4002 - val_acc_ensemble: 0.9036 - val_acc_1: 0.8969 - val_acc_2: 0.9002 - val_acc_3: 0.9003 - val_acc_4: 0.8979 - val_acc_5: 0.8961 - val_acc_6: 0.8999\n",
      "Epoch 3/10\n",
      " - 3s - loss_1: 3.3780e-04 - loss_2: 3.1377e-04 - loss_3: 2.9233e-04 - loss_4: 3.1346e-04 - loss_5: 3.1296e-04 - loss_6: 3.1596e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4359 - val_loss_2: 0.4125 - val_loss_3: 0.4102 - val_loss_4: 0.4212 - val_loss_5: 0.4267 - val_loss_6: 0.4043 - val_acc_ensemble: 0.9049 - val_acc_1: 0.8986 - val_acc_2: 0.9012 - val_acc_3: 0.9013 - val_acc_4: 0.8992 - val_acc_5: 0.8979 - val_acc_6: 0.9018\n",
      "Epoch 4/10\n",
      " - 3s - loss_1: 2.0764e-04 - loss_2: 2.1307e-04 - loss_3: 2.1484e-04 - loss_4: 2.0964e-04 - loss_5: 2.1784e-04 - loss_6: 2.0728e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4411 - val_loss_2: 0.4181 - val_loss_3: 0.4156 - val_loss_4: 0.4255 - val_loss_5: 0.4312 - val_loss_6: 0.4089 - val_acc_ensemble: 0.9042 - val_acc_1: 0.8988 - val_acc_2: 0.9013 - val_acc_3: 0.9017 - val_acc_4: 0.8995 - val_acc_5: 0.8986 - val_acc_6: 0.9027\n",
      "Epoch 5/10\n",
      " - 2s - loss_1: 1.6449e-04 - loss_2: 1.6275e-04 - loss_3: 1.5968e-04 - loss_4: 1.6584e-04 - loss_5: 1.7162e-04 - loss_6: 1.7050e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4442 - val_loss_2: 0.4221 - val_loss_3: 0.4189 - val_loss_4: 0.4288 - val_loss_5: 0.4348 - val_loss_6: 0.4129 - val_acc_ensemble: 0.9049 - val_acc_1: 0.8992 - val_acc_2: 0.9017 - val_acc_3: 0.9018 - val_acc_4: 0.8997 - val_acc_5: 0.8988 - val_acc_6: 0.9027\n",
      "Epoch 6/10\n",
      " - 2s - loss_1: 1.1436e-04 - loss_2: 1.3318e-04 - loss_3: 1.3034e-04 - loss_4: 1.2809e-04 - loss_5: 1.3383e-04 - loss_6: 1.2987e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4469 - val_loss_2: 0.4251 - val_loss_3: 0.4215 - val_loss_4: 0.4315 - val_loss_5: 0.4379 - val_loss_6: 0.4160 - val_acc_ensemble: 0.9054 - val_acc_1: 0.8994 - val_acc_2: 0.9017 - val_acc_3: 0.9024 - val_acc_4: 0.9000 - val_acc_5: 0.8992 - val_acc_6: 0.9029\n",
      "Epoch 7/10\n",
      " - 3s - loss_1: 1.0729e-04 - loss_2: 1.0620e-04 - loss_3: 1.0609e-04 - loss_4: 1.0841e-04 - loss_5: 1.0479e-04 - loss_6: 1.0302e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4488 - val_loss_2: 0.4277 - val_loss_3: 0.4234 - val_loss_4: 0.4341 - val_loss_5: 0.4402 - val_loss_6: 0.4183 - val_acc_ensemble: 0.9052 - val_acc_1: 0.9004 - val_acc_2: 0.9017 - val_acc_3: 0.9027 - val_acc_4: 0.9003 - val_acc_5: 0.8999 - val_acc_6: 0.9032\n",
      "Epoch 8/10\n",
      " - 2s - loss_1: 8.6978e-05 - loss_2: 9.0429e-05 - loss_3: 9.3241e-05 - loss_4: 8.9609e-05 - loss_5: 9.0072e-05 - loss_6: 8.8401e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4514 - val_loss_2: 0.4307 - val_loss_3: 0.4263 - val_loss_4: 0.4366 - val_loss_5: 0.4428 - val_loss_6: 0.4212 - val_acc_ensemble: 0.9057 - val_acc_1: 0.9008 - val_acc_2: 0.9016 - val_acc_3: 0.9033 - val_acc_4: 0.9011 - val_acc_5: 0.8996 - val_acc_6: 0.9033\n",
      "Epoch 9/10\n",
      " - 3s - loss_1: 7.3618e-05 - loss_2: 7.3816e-05 - loss_3: 7.6542e-05 - loss_4: 8.0097e-05 - loss_5: 7.4559e-05 - loss_6: 7.7048e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4544 - val_loss_2: 0.4336 - val_loss_3: 0.4289 - val_loss_4: 0.4396 - val_loss_5: 0.4453 - val_loss_6: 0.4237 - val_acc_ensemble: 0.9054 - val_acc_1: 0.9010 - val_acc_2: 0.9020 - val_acc_3: 0.9035 - val_acc_4: 0.9008 - val_acc_5: 0.8995 - val_acc_6: 0.9033\n",
      "Epoch 10/10\n",
      " - 3s - loss_1: 6.4297e-05 - loss_2: 6.6761e-05 - loss_3: 6.8408e-05 - loss_4: 6.7304e-05 - loss_5: 7.1000e-05 - loss_6: 6.8715e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.4561 - val_loss_2: 0.4361 - val_loss_3: 0.4309 - val_loss_4: 0.4416 - val_loss_5: 0.4476 - val_loss_6: 0.4260 - val_acc_ensemble: 0.9054 - val_acc_1: 0.9013 - val_acc_2: 0.9021 - val_acc_3: 0.9032 - val_acc_4: 0.9016 - val_acc_5: 0.9000 - val_acc_6: 0.9031\n",
      "sensitivity/vb-mnist-fcn3A/B6/S1.00\n",
      "i  Layer name                Output shape   Num param  Inbound  \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,512] []  401920     input    \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,512] []  1024       fc1      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,512] []  0          bn1      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,512] []  262656     relu1    \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,512] []  1024       fc2      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,512] []  0          bn2      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,512] []  262656     relu2    \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,512] []  1024       fc3      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,512] []  0          bn3      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]      5130       relu3    \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "----------------------------------------------------------------\n",
      "Total parameters: 935434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 2s - loss_1: 0.0723 - loss_2: 0.0822 - loss_3: 0.0848 - loss_4: 0.0753 - loss_5: 0.0898 - loss_6: 0.0968 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3545 - val_loss_2: 0.3545 - val_loss_3: 0.3545 - val_loss_4: 0.3545 - val_loss_5: 0.3545 - val_loss_6: 0.3545 - val_acc_ensemble: 0.8979 - val_acc_1: 0.8979 - val_acc_2: 0.8979 - val_acc_3: 0.8979 - val_acc_4: 0.8979 - val_acc_5: 0.8979 - val_acc_6: 0.8979\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 7.4404e-04 - loss_2: 7.6555e-04 - loss_3: 7.1527e-04 - loss_4: 7.6218e-04 - loss_5: 7.4241e-04 - loss_6: 7.3462e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3599 - val_loss_2: 0.3599 - val_loss_3: 0.3599 - val_loss_4: 0.3599 - val_loss_5: 0.3599 - val_loss_6: 0.3599 - val_acc_ensemble: 0.8985 - val_acc_1: 0.8985 - val_acc_2: 0.8985 - val_acc_3: 0.8985 - val_acc_4: 0.8985 - val_acc_5: 0.8985 - val_acc_6: 0.8985\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 3.9416e-04 - loss_2: 3.8477e-04 - loss_3: 3.9820e-04 - loss_4: 3.9319e-04 - loss_5: 3.7854e-04 - loss_6: 3.7828e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3646 - val_loss_2: 0.3646 - val_loss_3: 0.3646 - val_loss_4: 0.3646 - val_loss_5: 0.3646 - val_loss_6: 0.3646 - val_acc_ensemble: 0.8997 - val_acc_1: 0.8997 - val_acc_2: 0.8997 - val_acc_3: 0.8997 - val_acc_4: 0.8997 - val_acc_5: 0.8997 - val_acc_6: 0.8997\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 2.4445e-04 - loss_2: 2.4493e-04 - loss_3: 2.5023e-04 - loss_4: 2.4385e-04 - loss_5: 2.4199e-04 - loss_6: 2.4797e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3700 - val_loss_2: 0.3700 - val_loss_3: 0.3700 - val_loss_4: 0.3700 - val_loss_5: 0.3700 - val_loss_6: 0.3700 - val_acc_ensemble: 0.8997 - val_acc_1: 0.8997 - val_acc_2: 0.8997 - val_acc_3: 0.8997 - val_acc_4: 0.8997 - val_acc_5: 0.8997 - val_acc_6: 0.8997\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 1.6735e-04 - loss_2: 1.7442e-04 - loss_3: 1.7396e-04 - loss_4: 1.6864e-04 - loss_5: 1.7252e-04 - loss_6: 1.6978e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3744 - val_loss_2: 0.3744 - val_loss_3: 0.3744 - val_loss_4: 0.3744 - val_loss_5: 0.3744 - val_loss_6: 0.3744 - val_acc_ensemble: 0.8997 - val_acc_1: 0.8997 - val_acc_2: 0.8997 - val_acc_3: 0.8997 - val_acc_4: 0.8997 - val_acc_5: 0.8997 - val_acc_6: 0.8997\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 1.2698e-04 - loss_2: 1.3215e-04 - loss_3: 1.3015e-04 - loss_4: 1.2815e-04 - loss_5: 1.2971e-04 - loss_6: 1.2960e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3775 - val_loss_2: 0.3775 - val_loss_3: 0.3775 - val_loss_4: 0.3775 - val_loss_5: 0.3775 - val_loss_6: 0.3775 - val_acc_ensemble: 0.9000 - val_acc_1: 0.9000 - val_acc_2: 0.9000 - val_acc_3: 0.9000 - val_acc_4: 0.9000 - val_acc_5: 0.9000 - val_acc_6: 0.9000\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 9.7906e-05 - loss_2: 9.7393e-05 - loss_3: 9.7339e-05 - loss_4: 9.6525e-05 - loss_5: 1.0113e-04 - loss_6: 9.8127e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3809 - val_loss_2: 0.3809 - val_loss_3: 0.3809 - val_loss_4: 0.3809 - val_loss_5: 0.3809 - val_loss_6: 0.3809 - val_acc_ensemble: 0.9005 - val_acc_1: 0.9005 - val_acc_2: 0.9005 - val_acc_3: 0.9005 - val_acc_4: 0.9005 - val_acc_5: 0.9005 - val_acc_6: 0.9005\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 8.1282e-05 - loss_2: 8.2987e-05 - loss_3: 7.9426e-05 - loss_4: 8.4371e-05 - loss_5: 8.2513e-05 - loss_6: 7.8530e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3840 - val_loss_2: 0.3840 - val_loss_3: 0.3840 - val_loss_4: 0.3840 - val_loss_5: 0.3840 - val_loss_6: 0.3840 - val_acc_ensemble: 0.9006 - val_acc_1: 0.9006 - val_acc_2: 0.9006 - val_acc_3: 0.9006 - val_acc_4: 0.9006 - val_acc_5: 0.9006 - val_acc_6: 0.9006\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 6.6344e-05 - loss_2: 6.5590e-05 - loss_3: 6.8735e-05 - loss_4: 6.6703e-05 - loss_5: 6.6287e-05 - loss_6: 6.5475e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3864 - val_loss_2: 0.3864 - val_loss_3: 0.3864 - val_loss_4: 0.3864 - val_loss_5: 0.3864 - val_loss_6: 0.3864 - val_acc_ensemble: 0.9005 - val_acc_1: 0.9005 - val_acc_2: 0.9005 - val_acc_3: 0.9005 - val_acc_4: 0.9005 - val_acc_5: 0.9005 - val_acc_6: 0.9005\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 5.4857e-05 - loss_2: 5.4945e-05 - loss_3: 5.6260e-05 - loss_4: 5.5520e-05 - loss_5: 5.7009e-05 - loss_6: 5.7349e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3895 - val_loss_2: 0.3895 - val_loss_3: 0.3895 - val_loss_4: 0.3895 - val_loss_5: 0.3895 - val_loss_6: 0.3895 - val_acc_ensemble: 0.9008 - val_acc_1: 0.9008 - val_acc_2: 0.9008 - val_acc_3: 0.9008 - val_acc_4: 0.9008 - val_acc_5: 0.9008 - val_acc_6: 0.9008\n",
      "sensitivity/vb-mnist-fcn3A/B6/S1.00\n",
      "i  Layer name                Output shape   Num param  Inbound  \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,512] []  401920     input    \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,512] []  1024       fc1      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,512] []  0          bn1      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,512] []  262656     relu1    \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,512] []  1024       fc2      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,512] []  0          bn2      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,512] []  262656     relu2    \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,512] []  1024       fc3      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,512] []  0          bn3      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]      5130       relu3    \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "----------------------------------------------------------------\n",
      "Total parameters: 935434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 2s - loss_1: 0.0794 - loss_2: 0.0962 - loss_3: 0.0784 - loss_4: 0.0815 - loss_5: 0.0588 - loss_6: 0.0798 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3536 - val_loss_2: 0.3536 - val_loss_3: 0.3536 - val_loss_4: 0.3536 - val_loss_5: 0.3536 - val_loss_6: 0.3536 - val_acc_ensemble: 0.8997 - val_acc_1: 0.8997 - val_acc_2: 0.8997 - val_acc_3: 0.8997 - val_acc_4: 0.8997 - val_acc_5: 0.8997 - val_acc_6: 0.8997\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 7.1174e-04 - loss_2: 6.9752e-04 - loss_3: 6.7439e-04 - loss_4: 7.0431e-04 - loss_5: 6.7646e-04 - loss_6: 6.9183e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3619 - val_loss_2: 0.3619 - val_loss_3: 0.3619 - val_loss_4: 0.3619 - val_loss_5: 0.3619 - val_loss_6: 0.3619 - val_acc_ensemble: 0.8989 - val_acc_1: 0.8989 - val_acc_2: 0.8989 - val_acc_3: 0.8989 - val_acc_4: 0.8989 - val_acc_5: 0.8989 - val_acc_6: 0.8989\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 3.8220e-04 - loss_2: 3.7552e-04 - loss_3: 3.6935e-04 - loss_4: 3.5342e-04 - loss_5: 3.6787e-04 - loss_6: 3.6607e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3677 - val_loss_2: 0.3677 - val_loss_3: 0.3677 - val_loss_4: 0.3677 - val_loss_5: 0.3677 - val_loss_6: 0.3677 - val_acc_ensemble: 0.8984 - val_acc_1: 0.8984 - val_acc_2: 0.8984 - val_acc_3: 0.8984 - val_acc_4: 0.8984 - val_acc_5: 0.8984 - val_acc_6: 0.8984\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 2.3711e-04 - loss_2: 2.4051e-04 - loss_3: 2.3119e-04 - loss_4: 2.3671e-04 - loss_5: 2.3763e-04 - loss_6: 2.4380e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3727 - val_loss_2: 0.3727 - val_loss_3: 0.3727 - val_loss_4: 0.3727 - val_loss_5: 0.3727 - val_loss_6: 0.3727 - val_acc_ensemble: 0.8988 - val_acc_1: 0.8988 - val_acc_2: 0.8988 - val_acc_3: 0.8988 - val_acc_4: 0.8988 - val_acc_5: 0.8988 - val_acc_6: 0.8988\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 1.7196e-04 - loss_2: 1.7274e-04 - loss_3: 1.6589e-04 - loss_4: 1.7108e-04 - loss_5: 1.6960e-04 - loss_6: 1.6350e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3773 - val_loss_2: 0.3773 - val_loss_3: 0.3773 - val_loss_4: 0.3773 - val_loss_5: 0.3773 - val_loss_6: 0.3773 - val_acc_ensemble: 0.8988 - val_acc_1: 0.8988 - val_acc_2: 0.8988 - val_acc_3: 0.8988 - val_acc_4: 0.8988 - val_acc_5: 0.8988 - val_acc_6: 0.8988\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 1.2258e-04 - loss_2: 1.2313e-04 - loss_3: 1.2278e-04 - loss_4: 1.2157e-04 - loss_5: 1.2463e-04 - loss_6: 1.2389e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3813 - val_loss_2: 0.3813 - val_loss_3: 0.3813 - val_loss_4: 0.3813 - val_loss_5: 0.3813 - val_loss_6: 0.3813 - val_acc_ensemble: 0.8989 - val_acc_1: 0.8989 - val_acc_2: 0.8989 - val_acc_3: 0.8989 - val_acc_4: 0.8989 - val_acc_5: 0.8989 - val_acc_6: 0.8989\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 1.0054e-04 - loss_2: 9.6530e-05 - loss_3: 1.0030e-04 - loss_4: 9.8725e-05 - loss_5: 1.0060e-04 - loss_6: 9.7950e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3851 - val_loss_2: 0.3851 - val_loss_3: 0.3851 - val_loss_4: 0.3851 - val_loss_5: 0.3851 - val_loss_6: 0.3851 - val_acc_ensemble: 0.8987 - val_acc_1: 0.8987 - val_acc_2: 0.8987 - val_acc_3: 0.8987 - val_acc_4: 0.8987 - val_acc_5: 0.8987 - val_acc_6: 0.8987\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 7.9408e-05 - loss_2: 7.9290e-05 - loss_3: 7.6903e-05 - loss_4: 7.7410e-05 - loss_5: 8.1296e-05 - loss_6: 7.7746e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3884 - val_loss_2: 0.3884 - val_loss_3: 0.3884 - val_loss_4: 0.3884 - val_loss_5: 0.3884 - val_loss_6: 0.3884 - val_acc_ensemble: 0.8988 - val_acc_1: 0.8988 - val_acc_2: 0.8988 - val_acc_3: 0.8988 - val_acc_4: 0.8988 - val_acc_5: 0.8988 - val_acc_6: 0.8988\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 6.3267e-05 - loss_2: 6.5875e-05 - loss_3: 6.4576e-05 - loss_4: 6.5473e-05 - loss_5: 6.5186e-05 - loss_6: 6.6409e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3914 - val_loss_2: 0.3914 - val_loss_3: 0.3914 - val_loss_4: 0.3914 - val_loss_5: 0.3914 - val_loss_6: 0.3914 - val_acc_ensemble: 0.8990 - val_acc_1: 0.8990 - val_acc_2: 0.8990 - val_acc_3: 0.8990 - val_acc_4: 0.8990 - val_acc_5: 0.8990 - val_acc_6: 0.8990\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 5.3534e-05 - loss_2: 5.3423e-05 - loss_3: 5.4378e-05 - loss_4: 5.4930e-05 - loss_5: 5.4046e-05 - loss_6: 5.6724e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3943 - val_loss_2: 0.3943 - val_loss_3: 0.3943 - val_loss_4: 0.3943 - val_loss_5: 0.3943 - val_loss_6: 0.3943 - val_acc_ensemble: 0.8994 - val_acc_1: 0.8994 - val_acc_2: 0.8994 - val_acc_3: 0.8994 - val_acc_4: 0.8994 - val_acc_5: 0.8994 - val_acc_6: 0.8994\n",
      "sensitivity/vb-mnist-fcn3A/B6/S1.00\n",
      "i  Layer name                Output shape   Num param  Inbound  \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,512] []  401920     input    \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,512] []  1024       fc1      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,512] []  0          bn1      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,512] []  262656     relu1    \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,512] []  1024       fc2      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,512] []  0          bn2      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,512] []  262656     relu2    \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,512] []  1024       fc3      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,512] []  0          bn3      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]      5130       relu3    \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "----------------------------------------------------------------\n",
      "Total parameters: 935434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 2s - loss_1: 0.0666 - loss_2: 0.0848 - loss_3: 0.0800 - loss_4: 0.0763 - loss_5: 0.0705 - loss_6: 0.0661 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3463 - val_loss_2: 0.3463 - val_loss_3: 0.3463 - val_loss_4: 0.3463 - val_loss_5: 0.3463 - val_loss_6: 0.3463 - val_acc_ensemble: 0.9027 - val_acc_1: 0.9027 - val_acc_2: 0.9027 - val_acc_3: 0.9027 - val_acc_4: 0.9027 - val_acc_5: 0.9027 - val_acc_6: 0.9027\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 6.7743e-04 - loss_2: 6.5258e-04 - loss_3: 6.6223e-04 - loss_4: 6.5952e-04 - loss_5: 6.6266e-04 - loss_6: 6.8681e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3524 - val_loss_2: 0.3524 - val_loss_3: 0.3524 - val_loss_4: 0.3524 - val_loss_5: 0.3524 - val_loss_6: 0.3524 - val_acc_ensemble: 0.9042 - val_acc_1: 0.9042 - val_acc_2: 0.9042 - val_acc_3: 0.9042 - val_acc_4: 0.9042 - val_acc_5: 0.9042 - val_acc_6: 0.9042\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 3.6781e-04 - loss_2: 3.5486e-04 - loss_3: 3.7128e-04 - loss_4: 3.4424e-04 - loss_5: 3.6392e-04 - loss_6: 3.7208e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3584 - val_loss_2: 0.3584 - val_loss_3: 0.3584 - val_loss_4: 0.3584 - val_loss_5: 0.3584 - val_loss_6: 0.3584 - val_acc_ensemble: 0.9047 - val_acc_1: 0.9047 - val_acc_2: 0.9047 - val_acc_3: 0.9047 - val_acc_4: 0.9047 - val_acc_5: 0.9047 - val_acc_6: 0.9047\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 2.3099e-04 - loss_2: 2.3013e-04 - loss_3: 2.2805e-04 - loss_4: 2.3235e-04 - loss_5: 2.3188e-04 - loss_6: 2.2386e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3627 - val_loss_2: 0.3627 - val_loss_3: 0.3627 - val_loss_4: 0.3627 - val_loss_5: 0.3627 - val_loss_6: 0.3627 - val_acc_ensemble: 0.9047 - val_acc_1: 0.9047 - val_acc_2: 0.9047 - val_acc_3: 0.9047 - val_acc_4: 0.9047 - val_acc_5: 0.9047 - val_acc_6: 0.9047\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 1.5591e-04 - loss_2: 1.6074e-04 - loss_3: 1.5965e-04 - loss_4: 1.6062e-04 - loss_5: 1.5858e-04 - loss_6: 1.6536e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3670 - val_loss_2: 0.3670 - val_loss_3: 0.3670 - val_loss_4: 0.3670 - val_loss_5: 0.3670 - val_loss_6: 0.3670 - val_acc_ensemble: 0.9047 - val_acc_1: 0.9047 - val_acc_2: 0.9047 - val_acc_3: 0.9047 - val_acc_4: 0.9047 - val_acc_5: 0.9047 - val_acc_6: 0.9047\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 1.1969e-04 - loss_2: 1.2422e-04 - loss_3: 1.2180e-04 - loss_4: 1.2134e-04 - loss_5: 1.1592e-04 - loss_6: 1.1989e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3710 - val_loss_2: 0.3710 - val_loss_3: 0.3710 - val_loss_4: 0.3710 - val_loss_5: 0.3710 - val_loss_6: 0.3710 - val_acc_ensemble: 0.9052 - val_acc_1: 0.9052 - val_acc_2: 0.9052 - val_acc_3: 0.9052 - val_acc_4: 0.9052 - val_acc_5: 0.9052 - val_acc_6: 0.9052\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 9.6907e-05 - loss_2: 9.3120e-05 - loss_3: 9.5265e-05 - loss_4: 9.5773e-05 - loss_5: 9.1392e-05 - loss_6: 9.6487e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3745 - val_loss_2: 0.3745 - val_loss_3: 0.3745 - val_loss_4: 0.3745 - val_loss_5: 0.3745 - val_loss_6: 0.3745 - val_acc_ensemble: 0.9052 - val_acc_1: 0.9052 - val_acc_2: 0.9052 - val_acc_3: 0.9052 - val_acc_4: 0.9052 - val_acc_5: 0.9052 - val_acc_6: 0.9052\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 7.6959e-05 - loss_2: 7.4503e-05 - loss_3: 7.7094e-05 - loss_4: 7.5770e-05 - loss_5: 7.7537e-05 - loss_6: 7.7053e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3779 - val_loss_2: 0.3779 - val_loss_3: 0.3779 - val_loss_4: 0.3779 - val_loss_5: 0.3779 - val_loss_6: 0.3779 - val_acc_ensemble: 0.9054 - val_acc_1: 0.9054 - val_acc_2: 0.9054 - val_acc_3: 0.9054 - val_acc_4: 0.9054 - val_acc_5: 0.9054 - val_acc_6: 0.9054\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 6.6325e-05 - loss_2: 6.1685e-05 - loss_3: 5.9758e-05 - loss_4: 6.5975e-05 - loss_5: 6.2358e-05 - loss_6: 6.4357e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3808 - val_loss_2: 0.3808 - val_loss_3: 0.3808 - val_loss_4: 0.3808 - val_loss_5: 0.3808 - val_loss_6: 0.3808 - val_acc_ensemble: 0.9056 - val_acc_1: 0.9056 - val_acc_2: 0.9056 - val_acc_3: 0.9056 - val_acc_4: 0.9056 - val_acc_5: 0.9056 - val_acc_6: 0.9056\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 5.0728e-05 - loss_2: 5.4444e-05 - loss_3: 5.1238e-05 - loss_4: 5.1559e-05 - loss_5: 5.3894e-05 - loss_6: 5.2392e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3834 - val_loss_2: 0.3834 - val_loss_3: 0.3834 - val_loss_4: 0.3834 - val_loss_5: 0.3834 - val_loss_6: 0.3834 - val_acc_ensemble: 0.9056 - val_acc_1: 0.9056 - val_acc_2: 0.9056 - val_acc_3: 0.9056 - val_acc_4: 0.9056 - val_acc_5: 0.9056 - val_acc_6: 0.9056\n",
      "sensitivity/vb-mnist-fcn3A/B6/S1.00\n",
      "i  Layer name                Output shape   Num param  Inbound  \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,512] []  401920     input    \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,512] []  1024       fc1      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,512] []  0          bn1      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,512] []  262656     relu1    \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,512] []  1024       fc2      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,512] []  0          bn2      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "6  fc3 (Dense)               [None,512] []  262656     relu2    \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "7  bn3 (BatchNormalization)  [None,512] []  1024       fc3      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "8  relu3 (Activation)        [None,512] []  0          bn3      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "9  output (Dense)            [None,10]      5130       relu3    \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "                             [None,10]                          \n",
      "----------------------------------------------------------------\n",
      "Total parameters: 935434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 2s - loss_1: 0.0853 - loss_2: 0.0645 - loss_3: 0.0739 - loss_4: 0.0836 - loss_5: 0.0698 - loss_6: 0.0802 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3441 - val_loss_2: 0.3441 - val_loss_3: 0.3441 - val_loss_4: 0.3441 - val_loss_5: 0.3441 - val_loss_6: 0.3441 - val_acc_ensemble: 0.9010 - val_acc_1: 0.9010 - val_acc_2: 0.9010 - val_acc_3: 0.9010 - val_acc_4: 0.9010 - val_acc_5: 0.9010 - val_acc_6: 0.9010\n",
      "Epoch 2/10\n",
      " - 1s - loss_1: 6.8617e-04 - loss_2: 7.1643e-04 - loss_3: 7.0605e-04 - loss_4: 6.8308e-04 - loss_5: 6.8835e-04 - loss_6: 6.8042e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3522 - val_loss_2: 0.3522 - val_loss_3: 0.3522 - val_loss_4: 0.3522 - val_loss_5: 0.3522 - val_loss_6: 0.3522 - val_acc_ensemble: 0.9036 - val_acc_1: 0.9036 - val_acc_2: 0.9036 - val_acc_3: 0.9036 - val_acc_4: 0.9036 - val_acc_5: 0.9036 - val_acc_6: 0.9036\n",
      "Epoch 3/10\n",
      " - 1s - loss_1: 3.5271e-04 - loss_2: 3.5897e-04 - loss_3: 3.6134e-04 - loss_4: 3.6927e-04 - loss_5: 3.4736e-04 - loss_6: 3.5314e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3583 - val_loss_2: 0.3583 - val_loss_3: 0.3583 - val_loss_4: 0.3583 - val_loss_5: 0.3583 - val_loss_6: 0.3583 - val_acc_ensemble: 0.9046 - val_acc_1: 0.9046 - val_acc_2: 0.9046 - val_acc_3: 0.9046 - val_acc_4: 0.9046 - val_acc_5: 0.9046 - val_acc_6: 0.9046\n",
      "Epoch 4/10\n",
      " - 1s - loss_1: 2.2738e-04 - loss_2: 2.2800e-04 - loss_3: 2.2581e-04 - loss_4: 2.2928e-04 - loss_5: 2.2793e-04 - loss_6: 2.1755e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3629 - val_loss_2: 0.3629 - val_loss_3: 0.3629 - val_loss_4: 0.3629 - val_loss_5: 0.3629 - val_loss_6: 0.3629 - val_acc_ensemble: 0.9051 - val_acc_1: 0.9051 - val_acc_2: 0.9051 - val_acc_3: 0.9051 - val_acc_4: 0.9051 - val_acc_5: 0.9051 - val_acc_6: 0.9051\n",
      "Epoch 5/10\n",
      " - 1s - loss_1: 1.6768e-04 - loss_2: 1.6276e-04 - loss_3: 1.6200e-04 - loss_4: 1.6108e-04 - loss_5: 1.6301e-04 - loss_6: 1.5427e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3669 - val_loss_2: 0.3669 - val_loss_3: 0.3669 - val_loss_4: 0.3669 - val_loss_5: 0.3669 - val_loss_6: 0.3669 - val_acc_ensemble: 0.9052 - val_acc_1: 0.9052 - val_acc_2: 0.9052 - val_acc_3: 0.9052 - val_acc_4: 0.9052 - val_acc_5: 0.9052 - val_acc_6: 0.9052\n",
      "Epoch 6/10\n",
      " - 1s - loss_1: 1.2146e-04 - loss_2: 1.2213e-04 - loss_3: 1.1806e-04 - loss_4: 1.2081e-04 - loss_5: 1.2219e-04 - loss_6: 1.2087e-04 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3709 - val_loss_2: 0.3709 - val_loss_3: 0.3709 - val_loss_4: 0.3709 - val_loss_5: 0.3709 - val_loss_6: 0.3709 - val_acc_ensemble: 0.9050 - val_acc_1: 0.9050 - val_acc_2: 0.9050 - val_acc_3: 0.9050 - val_acc_4: 0.9050 - val_acc_5: 0.9050 - val_acc_6: 0.9050\n",
      "Epoch 7/10\n",
      " - 1s - loss_1: 9.4313e-05 - loss_2: 9.6452e-05 - loss_3: 9.0906e-05 - loss_4: 9.2757e-05 - loss_5: 9.2635e-05 - loss_6: 9.7102e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3742 - val_loss_2: 0.3742 - val_loss_3: 0.3742 - val_loss_4: 0.3742 - val_loss_5: 0.3742 - val_loss_6: 0.3742 - val_acc_ensemble: 0.9054 - val_acc_1: 0.9054 - val_acc_2: 0.9054 - val_acc_3: 0.9054 - val_acc_4: 0.9054 - val_acc_5: 0.9054 - val_acc_6: 0.9054\n",
      "Epoch 8/10\n",
      " - 1s - loss_1: 7.6120e-05 - loss_2: 7.2481e-05 - loss_3: 7.7491e-05 - loss_4: 7.5359e-05 - loss_5: 7.6362e-05 - loss_6: 7.6447e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3776 - val_loss_2: 0.3776 - val_loss_3: 0.3776 - val_loss_4: 0.3776 - val_loss_5: 0.3776 - val_loss_6: 0.3776 - val_acc_ensemble: 0.9052 - val_acc_1: 0.9052 - val_acc_2: 0.9052 - val_acc_3: 0.9052 - val_acc_4: 0.9052 - val_acc_5: 0.9052 - val_acc_6: 0.9052\n",
      "Epoch 9/10\n",
      " - 1s - loss_1: 6.2920e-05 - loss_2: 6.1893e-05 - loss_3: 6.1039e-05 - loss_4: 5.9756e-05 - loss_5: 6.1740e-05 - loss_6: 6.2312e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3806 - val_loss_2: 0.3806 - val_loss_3: 0.3806 - val_loss_4: 0.3806 - val_loss_5: 0.3806 - val_loss_6: 0.3806 - val_acc_ensemble: 0.9053 - val_acc_1: 0.9053 - val_acc_2: 0.9053 - val_acc_3: 0.9053 - val_acc_4: 0.9053 - val_acc_5: 0.9053 - val_acc_6: 0.9053\n",
      "Epoch 10/10\n",
      " - 1s - loss_1: 5.2308e-05 - loss_2: 5.2082e-05 - loss_3: 5.3663e-05 - loss_4: 5.1135e-05 - loss_5: 5.2887e-05 - loss_6: 5.1934e-05 - acc_ensemble: 1.0000 - acc_1: 1.0000 - acc_2: 1.0000 - acc_3: 1.0000 - acc_4: 1.0000 - acc_5: 1.0000 - acc_6: 1.0000 - val_loss_1: 0.3836 - val_loss_2: 0.3836 - val_loss_3: 0.3836 - val_loss_4: 0.3836 - val_loss_5: 0.3836 - val_loss_6: 0.3836 - val_acc_ensemble: 0.9056 - val_acc_1: 0.9056 - val_acc_2: 0.9056 - val_acc_3: 0.9056 - val_acc_4: 0.9056 - val_acc_5: 0.9056 - val_acc_6: 0.9056\n"
     ]
    }
   ],
   "source": [
    "for n_branches in range(2, 7):\n",
    "    for shared_frac in [0., 0.25, 0.5, 0.75, 1.]:\n",
    "        for t in range(4):\n",
    "            train(n_branches, shared_frac, model_id=t+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from vbranch.utils.generic import get_model_path, get_vb_model_path\n",
    "from vbranch.utils.test import baseline_classification, compute_correlation_strength, compute_acc_from_logits\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation and Strength"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For classification, we can compute the correlation between models and their strength. The formulas used are from the Random Forest paper:\n",
    "\n",
    "https://www.stat.berkeley.edu/~breiman/randomforest2001.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_strength(n_branches, shared_frac, model_id):\n",
    "    model_path = os.path.join('models', path(n_branches, shared_frac), \n",
    "                              'model_{}'.format(model_id))\n",
    "\n",
    "    test_init_ops = []\n",
    "    tensors = []\n",
    "    for i in range(n_branches):\n",
    "        test_init_ops.append('test_init_op_{}'.format(i+1))\n",
    "        tensors.append('model/output/vb{}/output:0'.format(i+1))\n",
    "\n",
    "    with TFSessionGrow() as sess:\n",
    "        restore_sess(sess, model_path)\n",
    "        sess.run(test_init_ops, feed_dict={'x:0':X_test, 'y:0': y_test, \n",
    "                                    'batch_size:0':len(X_test)})\n",
    "        outputs = sess.run(tensors)\n",
    "\n",
    "    return compute_correlation_strength(outputs, y_test, NUM_CLASSES, n_branches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/gong/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B2/S0.00/model_1/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B2/S0.00/model_2/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B2/S0.00/model_3/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B2/S0.00/model_4/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B2/S0.25/model_1/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B2/S0.25/model_2/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B2/S0.25/model_3/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B2/S0.25/model_4/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B2/S0.50/model_1/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B2/S0.50/model_2/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B2/S0.50/model_3/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B2/S0.50/model_4/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B2/S0.75/model_1/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B2/S0.75/model_2/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B2/S0.75/model_3/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B2/S0.75/model_4/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B2/S1.00/model_1/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B2/S1.00/model_2/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B2/S1.00/model_3/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B2/S1.00/model_4/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B3/S0.00/model_1/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B3/S0.00/model_2/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B3/S0.00/model_3/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B3/S0.00/model_4/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B3/S0.25/model_1/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B3/S0.25/model_2/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B3/S0.25/model_3/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B3/S0.25/model_4/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B3/S0.50/model_1/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B3/S0.50/model_2/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B3/S0.50/model_3/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B3/S0.50/model_4/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B3/S0.75/model_1/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B3/S0.75/model_2/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B3/S0.75/model_3/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B3/S0.75/model_4/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B3/S1.00/model_1/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B3/S1.00/model_2/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B3/S1.00/model_3/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B3/S1.00/model_4/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B4/S0.00/model_1/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B4/S0.00/model_2/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B4/S0.00/model_3/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B4/S0.00/model_4/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B4/S0.25/model_1/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B4/S0.25/model_2/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B4/S0.25/model_3/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B4/S0.25/model_4/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B4/S0.50/model_1/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B4/S0.50/model_2/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B4/S0.50/model_3/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B4/S0.50/model_4/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B4/S0.75/model_1/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B4/S0.75/model_2/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B4/S0.75/model_3/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B4/S0.75/model_4/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B4/S1.00/model_1/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B4/S1.00/model_2/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B4/S1.00/model_3/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B4/S1.00/model_4/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B5/S0.00/model_1/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B5/S0.00/model_2/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B5/S0.00/model_3/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B5/S0.00/model_4/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B5/S0.25/model_1/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B5/S0.25/model_2/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B5/S0.25/model_3/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B5/S0.25/model_4/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B5/S0.50/model_1/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B5/S0.50/model_2/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B5/S0.50/model_3/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B5/S0.50/model_4/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B5/S0.75/model_1/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B5/S0.75/model_2/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B5/S0.75/model_3/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B5/S0.75/model_4/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B5/S1.00/model_1/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B5/S1.00/model_2/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B5/S1.00/model_3/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B5/S1.00/model_4/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B6/S0.00/model_1/ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B6/S0.00/model_2/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B6/S0.00/model_3/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B6/S0.00/model_4/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B6/S0.25/model_1/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B6/S0.25/model_2/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B6/S0.25/model_3/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B6/S0.25/model_4/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B6/S0.50/model_1/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B6/S0.50/model_2/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B6/S0.50/model_3/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B6/S0.50/model_4/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B6/S0.75/model_1/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B6/S0.75/model_2/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B6/S0.75/model_3/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B6/S0.75/model_4/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B6/S1.00/model_1/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B6/S1.00/model_2/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B6/S1.00/model_3/ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/sensitivity/vb-mnist-fcn3A/B6/S1.00/model_4/ckpt\n"
     ]
    }
   ],
   "source": [
    "correlation_results = {}\n",
    "strength_results = {}\n",
    "\n",
    "# num_branches = 4\n",
    "shared_frac_list = [0., 0.25, 0.5, 0.75, 1.]\n",
    "# shared_correlation_list = []\n",
    "# shared_strength_list = []\n",
    "n_trials = 4\n",
    "\n",
    "for b in range(2, 7):\n",
    "    correlation_results[b] = {}\n",
    "    strength_results[b] = {}\n",
    "    \n",
    "    for shared in shared_frac_list:\n",
    "        correlation_list = []\n",
    "        strength_list = []\n",
    "\n",
    "        for model_id in range(1, n_trials + 1):\n",
    "            tf.reset_default_graph()\n",
    "            c, s = correlation_strength(b, shared, model_id)\n",
    "            correlation_list.append(c)\n",
    "            strength_list.append(s)\n",
    "\n",
    "        correlation_results[b][shared] = [np.mean(correlation_list), np.std(correlation_list)]\n",
    "        strength_results[b][shared] = [np.mean(strength_list), np.std(strength_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/sensitivity/correlation-mnist-{}.json'.format(ARCHITECTURE), 'w') as f:\n",
    "    json.dump(correlation_results, f, indent=4)\n",
    "with open('results/sensitivity/strength-mnist-{}.json'.format(ARCHITECTURE), 'w') as f:\n",
    "    json.dump(strength_results, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture = ['fcn', 'fcn2', 'fcn3', 'fcn2A', 'fcn3A']\n",
    "correlation = []\n",
    "strength = []\n",
    "\n",
    "for arch in architecture:\n",
    "    with open('results/sensitivity/correlation-mnist-{}.json'.format(arch), 'r') as f:\n",
    "        correlation.append(json.load(f))\n",
    "    with open('results/sensitivity/strength-mnist-{}.json'.format(arch), 'r') as f:\n",
    "        strength.append(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_corr_strength(n_branches):\n",
    "    def mean_std(data):\n",
    "        mean = []\n",
    "        std = []\n",
    "        for frac in shared_frac_list:\n",
    "            mean.append(data[str(frac)][0])\n",
    "            std.append(data[str(frac)][1])\n",
    "        return np.array(mean), np.array(std)\n",
    "    \n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.subplot(1,2,1)\n",
    "    for i, arch in enumerate(architecture):\n",
    "        data = correlation[i][str(n_branches)]\n",
    "        mean, std = mean_std(data)    \n",
    "        plt.errorbar(shared_frac_list, mean, 2*std / np.sqrt(n_trials), label=arch)\n",
    "        plt.legend()\n",
    "        \n",
    "    plt.subplot(1,2,2)\n",
    "    for i, arch in enumerate(architecture):\n",
    "        data = strength[i][str(n_branches)]\n",
    "        mean, std = mean_std(data)    \n",
    "        plt.errorbar(shared_frac_list, mean, 2*std / np.sqrt(n_trials), label=arch)    \n",
    "        plt.legend()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_corr_strength(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i  Layer name                Output shape   Num param  Inbound  \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "0  fc1 (Dense)               [] [None,512]  803840     input    \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [] [None,512]  2048       fc1      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "2  relu1 (Activation)        [] [None,512]  0          bn1      \n",
      "                             [] [None,512]                      \n",
      "----------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,512] []  262656     relu1    \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,512] []  1024       fc2      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,512] []  0          bn2      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "6  output (Dense)            [None,10]      5130       relu2    \n",
      "                             [None,10]                          \n",
      "----------------------------------------------------------------\n",
      "Total parameters: 1074698\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,128] [None,384]  703360     input    \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,128] [None,384]  1792       fc1      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,128] [None,384]  0          bn1      \n",
      "                             [None,128] [None,384]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,512] []          262656     relu1    \n",
      "                             [None,512] []                              \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,512] []          1024       fc2      \n",
      "                             [None,512] []                              \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,512] []          0          bn2      \n",
      "                             [None,512] []                              \n",
      "------------------------------------------------------------------------\n",
      "6  output (Dense)            [None,10]              5130       relu2    \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 973962\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,256] [None,256]  602880     input    \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,256] [None,256]  1536       fc1      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,256] [None,256]  0          bn1      \n",
      "                             [None,256] [None,256]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,512] []          262656     relu1    \n",
      "                             [None,512] []                              \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,512] []          1024       fc2      \n",
      "                             [None,512] []                              \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,512] []          0          bn2      \n",
      "                             [None,512] []                              \n",
      "------------------------------------------------------------------------\n",
      "6  output (Dense)            [None,10]              5130       relu2    \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 873226\n",
      "i  Layer name                Output shape           Num param  Inbound  \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                 \n",
      "------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,384] [None,128]  502400     input    \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,384] [None,128]  1280       fc1      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,384] [None,128]  0          bn1      \n",
      "                             [None,384] [None,128]                      \n",
      "------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,512] []          262656     relu1    \n",
      "                             [None,512] []                              \n",
      "------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,512] []          1024       fc2      \n",
      "                             [None,512] []                              \n",
      "------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,512] []          0          bn2      \n",
      "                             [None,512] []                              \n",
      "------------------------------------------------------------------------\n",
      "6  output (Dense)            [None,10]              5130       relu2    \n",
      "                             [None,10]                                  \n",
      "------------------------------------------------------------------------\n",
      "Total parameters: 772490\n",
      "i  Layer name                Output shape   Num param  Inbound  \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "   Input                     [None,784]                         \n",
      "----------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,512] []  401920     input    \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,512] []  1024       fc1      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,512] []  0          bn1      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,512] []  262656     relu1    \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,512] []  1024       fc2      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,512] []  0          bn2      \n",
      "                             [None,512] []                      \n",
      "----------------------------------------------------------------\n",
      "6  output (Dense)            [None,10]      5130       relu2    \n",
      "                             [None,10]                          \n",
      "----------------------------------------------------------------\n",
      "Total parameters: 671754\n"
     ]
    }
   ],
   "source": [
    "# Vbranch params\n",
    "shared_frac_list = [0., 0.25, 0.5, 0.75, 1.]\n",
    "num_branches = 2\n",
    "\n",
    "vbranch_params = []\n",
    "for frac in shared_frac_list:\n",
    "    tf.reset_default_graph()\n",
    "    inputs = tf.placeholder('float32', [None, 28,28,1])\n",
    "    model = build_model(num_branches, frac)\n",
    "#     model.summary()\n",
    "    vbranch_params.append(model.count_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_ratio = [p / vbranch_params[-1] for p in vbranch_params]\n",
    "ideal_ratio = num_branches - np.array(shared_frac_list)**2 * (num_branches-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(shared_frac_list, param_ratio, color='orange')\n",
    "# plt.plot(shared_frac_list, [1]*len(shared_frac_list))\n",
    "plt.plot(shared_frac_list, ideal_ratio)\n",
    "\n",
    "plt.xlabel('shared frac')\n",
    "plt.ylabel('params / baseline')\n",
    "plt.title('{} parameter count'.format(ARCHITECTURE))\n",
    "\n",
    "plt.savefig('figs/cnn-small-parameter-count.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
