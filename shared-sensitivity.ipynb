{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with Virtual Branching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from vbranch.callbacks import classification_acc\n",
    "from vbranch.applications.fcn import FCN\n",
    "from vbranch.applications.cnn import CNN\n",
    "from vbranch.losses import softmax_cross_entropy_with_logits\n",
    "\n",
    "from vbranch.utils import TFSessionGrow, restore_sess\n",
    "from vbranch.utils.training import get_data, bag_samples, get_data_iterator\n",
    "from vbranch.utils.generic import get_path, save_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = 1\n",
    "ARCHITECTURE = 'cnn'\n",
    "DATASET = 'cifar10'\n",
    "NUM_CLASSES = 10\n",
    "NUM_FEATURES = None\n",
    "SAMPLES_PER_CLASS = None\n",
    "BAGGING_SAMPLES = 1.\n",
    "TRAIN_FRAC = 1.\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 50\n",
    "STEPS_PER_EPOCH = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = get_data(DATASET, ARCHITECTURE, NUM_CLASSES,\n",
    "                                                NUM_FEATURES, SAMPLES_PER_CLASS, \n",
    "                                                train_frac=TRAIN_FRAC, preprocess=True)\n",
    "x_shape = (None,) + X_train.shape[1:]\n",
    "y_shape = (None, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 32, 32, 3), (50000, 10), (10000, 32, 32, 3), (10000, 10))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "print(X_train.min(), X_train.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path(n_branches, shared_frac):\n",
    "    return get_path(DATASET, ARCHITECTURE, 'sensitivity-Ba64', vb=True, \n",
    "                    B=n_branches, S=shared_frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_branches, shared_frac, name='model', compile_loss=True):\n",
    "    inputs, labels, train_init_op, test_init_op = get_data_iterator(x_shape, y_shape, \n",
    "                                                                    batch_size=BATCH_SIZE, \n",
    "                                                                    n=n_branches, \n",
    "                                                                    share_xy=BAGGING_SAMPLES == 0)\n",
    "#     with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n",
    "#         if ARCHITECTURE == 'fcn':\n",
    "#             layer_spec = [(512, shared_frac), NUM_CLASSES]\n",
    "#         elif ARCHITECTURE == 'fcn2':\n",
    "#             layer_spec = [(512, shared_frac), 512, NUM_CLASSES]\n",
    "#         elif ARCHITECTURE == 'fcn3':\n",
    "#             layer_spec = [(512, shared_frac), 512, 512, NUM_CLASSES]\n",
    "#         elif ARCHITECTURE == 'fcn2A':\n",
    "#             layer_spec = [(512, shared_frac), (512, shared_frac), (NUM_CLASSES, shared_frac)]\n",
    "#         elif ARCHITECTURE == 'fcn3A':\n",
    "#             layer_spec = [(512, shared_frac), (512, shared_frac), \n",
    "#                           (512, shared_frac), (NUM_CLASSES, shared_frac)]\n",
    "#         else:\n",
    "#             raise ValueError('invalid model')\n",
    "            \n",
    "#         model = FCN(inputs, *layer_spec, name=name, shared_frac=1)\n",
    "\n",
    "    with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n",
    "        if ARCHITECTURE == 'cnn':\n",
    "            layers = [32, 64, 128]\n",
    "        elif ARCHITECTURE == 'cnnx':\n",
    "            layers = [(32, shared_frac), (64, 1.0), (128, 1.0)]\n",
    "        else:\n",
    "            raise ValueError('invalid model')\n",
    "        model = CNN(inputs, NUM_CLASSES, *layers, name=name, shared_frac=shared_frac)\n",
    "        \n",
    "        if compile_loss:\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "            model.compile(optimizer, softmax_cross_entropy_with_logits(), \n",
    "                          train_init_op, test_init_op, labels=labels, \n",
    "                          callbacks={'acc':classification_acc(n_branches)})\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n_branches, shared_frac, model_id=1):\n",
    "    dirpath = path(n_branches, shared_frac)\n",
    "    model_path = os.path.join('models', dirpath, 'model_{}'.format(model_id))\n",
    "    os.system('mkdir -p ' + model_path)\n",
    "    print(model_path)\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    model = build_model(n_branches, shared_frac)\n",
    "    model.summary()\n",
    "    \n",
    "    # Bagging\n",
    "    if BAGGING_SAMPLES > 0:\n",
    "        x_train_list, y_train_list = bag_samples(X_train, y_train, n_branches, \n",
    "                                                 max_samples=BAGGING_SAMPLES)\n",
    "\n",
    "    if n_branches == 1 or BAGGING_SAMPLES == 0:\n",
    "        train_dict = {'x:0': X_train, 'y:0': y_train, 'batch_size:0': BATCH_SIZE}\n",
    "    else:\n",
    "        train_dict = {'x:0': X_train, 'y:0': y_train}\n",
    "        for i in range(n_branches):\n",
    "            train_dict['vb{}_x:0'.format(i+1)] = x_train_list[i]\n",
    "            train_dict['vb{}_y:0'.format(i+1)] = y_train_list[i]\n",
    "        train_dict['batch_size:0'] = BATCH_SIZE\n",
    "\n",
    "    val_dict = {'x:0': X_test, 'y:0': y_test, 'batch_size:0': len(X_test)}\n",
    "\n",
    "    history = model.fit(EPOCHS, STEPS_PER_EPOCH, train_dict=train_dict,\n",
    "                        val_dict=val_dict, log_path=model_path)\n",
    "    save_results(history, dirpath, 'train_{}.csv'.format(model_id))\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0804 12:14:34.166461 140571476088576 deprecation_wrapper.py:119] From /home/gong/research/vbranch/vbranch/utils/training.py:134: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0804 12:14:34.197612 140571476088576 deprecation_wrapper.py:119] From /home/gong/research/vbranch/vbranch/utils/training.py:156: The name tf.data.Iterator is deprecated. Please use tf.compat.v1.data.Iterator instead.\n",
      "\n",
      "W0804 12:14:34.203207 140571476088576 deprecation.py:323] From /home/gong/anaconda3/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py:348: Iterator.output_types (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_types(iterator)`.\n",
      "W0804 12:14:34.203778 140571476088576 deprecation.py:323] From /home/gong/anaconda3/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py:349: Iterator.output_shapes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_shapes(iterator)`.\n",
      "W0804 12:14:34.205476 140571476088576 deprecation.py:323] From /home/gong/anaconda3/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py:351: Iterator.output_classes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_classes(iterator)`.\n",
      "W0804 12:14:34.224341 140571476088576 deprecation_wrapper.py:119] From /home/gong/research/vbranch/vbranch/vb_layers/core.py:63: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
      "\n",
      "W0804 12:14:34.225161 140571476088576 deprecation_wrapper.py:119] From /home/gong/research/vbranch/vbranch/vb_layers/core.py:92: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W0804 12:14:34.226297 140571476088576 deprecation_wrapper.py:119] From /home/gong/research/vbranch/vbranch/layers/convolutional.py:36: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "W0804 12:14:34.227405 140571476088576 deprecation.py:506] From /home/gong/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0804 12:14:34.330758 140571476088576 deprecation_wrapper.py:119] From /home/gong/research/vbranch/vbranch/layers/pooling.py:22: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/sensitivity-Ba64/vb-cifar10-cnn/B2/S0.00/model_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0804 12:14:34.607282 140571476088576 deprecation_wrapper.py:119] From /home/gong/research/vbranch/vbranch/layers/core.py:83: The name tf.nn.xw_plus_b is deprecated. Please use tf.compat.v1.nn.xw_plus_b instead.\n",
      "\n",
      "W0804 12:14:34.699779 140571476088576 deprecation_wrapper.py:119] From /home/gong/research/vbranch/vbranch/engine/training.py:127: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i   Layer name                      Output shape        Num param  Inbound            \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                    \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                    \n",
      "--------------------------------------------------------------------------------------\n",
      "0   conv2d_1_1 (Conv2D)             [] [None,32,32,32]  1792       input              \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "1   bn_1_1 (BatchNormalization)     [] [None,32,32,32]  128        conv2d_1_1         \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "2   relu_1_1 (Activation)           [] [None,32,32,32]  0          bn_1_1             \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "3   conv2d_1_2 (Conv2D)             [] [None,32,32,32]  18496      relu_1_1           \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "4   bn_1_2 (BatchNormalization)     [] [None,32,32,32]  128        conv2d_1_2         \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "5   relu_1_2 (Activation)           [] [None,32,32,32]  0          bn_1_2             \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "6   avg_pool2d_1 (AveragePooling2D  [] [None,16,16,32]  0          relu_1_2           \n",
      "                                    [] [None,16,16,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "7   conv2d_2_1 (Conv2D)             [] [None,16,16,64]  36992      avg_pool2d_1       \n",
      "                                    [] [None,16,16,64]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "8   bn_2_1 (BatchNormalization)     [] [None,16,16,64]  256        conv2d_2_1         \n",
      "                                    [] [None,16,16,64]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "9   relu_2_1 (Activation)           [] [None,16,16,64]  0          bn_2_1             \n",
      "                                    [] [None,16,16,64]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "10  conv2d_2_2 (Conv2D)             [] [None,16,16,64]  73856      relu_2_1           \n",
      "                                    [] [None,16,16,64]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "11  bn_2_2 (BatchNormalization)     [] [None,16,16,64]  256        conv2d_2_2         \n",
      "                                    [] [None,16,16,64]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "12  relu_2_2 (Activation)           [] [None,16,16,64]  0          bn_2_2             \n",
      "                                    [] [None,16,16,64]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "13  avg_pool2d_2 (AveragePooling2D  [] [None,8,8,64]    0          relu_2_2           \n",
      "                                    [] [None,8,8,64]                                  \n",
      "--------------------------------------------------------------------------------------\n",
      "14  conv2d_3_1 (Conv2D)             [] [None,8,8,128]   147712     avg_pool2d_2       \n",
      "                                    [] [None,8,8,128]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "15  bn_3_1 (BatchNormalization)     [] [None,8,8,128]   512        conv2d_3_1         \n",
      "                                    [] [None,8,8,128]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "16  relu_3_1 (Activation)           [] [None,8,8,128]   0          bn_3_1             \n",
      "                                    [] [None,8,8,128]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "17  conv2d_3_2 (Conv2D)             [] [None,8,8,128]   295168     relu_3_1           \n",
      "                                    [] [None,8,8,128]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "18  bn_3_2 (BatchNormalization)     [] [None,8,8,128]   512        conv2d_3_2         \n",
      "                                    [] [None,8,8,128]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "19  relu_3_2 (Activation)           [] [None,8,8,128]   0          bn_3_2             \n",
      "                                    [] [None,8,8,128]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "20  global_avg_pool2d (GlobalAvera  [] [None,128]       0          relu_3_2           \n",
      "                                    [] [None,128]                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "21  fc1 (Dense)                     [] [None,128]       33024      global_avg_pool2d  \n",
      "                                    [] [None,128]                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "22  bn_fc1 (BatchNormalization)     [] [None,128]       512        fc1                \n",
      "                                    [] [None,128]                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "23  relu_fc1 (Activation)           [] [None,128]       0          bn_fc1             \n",
      "                                    [] [None,128]                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "24  output (Dense)                  [None,10]           2580       relu_fc1           \n",
      "                                    [None,10]                                         \n",
      "--------------------------------------------------------------------------------------\n",
      "Total parameters: 611924\n",
      "50000\n",
      "Epoch 1/50\n",
      "100/100 - 10s - loss_1: 1.8047 - loss_2: 1.7708 - acc_ensemble: 0.4660 - acc_1: 0.4160 - acc_2: 0.4380 - val_loss_1: 1.5901 - val_loss_2: 1.5526 - val_acc_ensemble: 0.4545 - val_acc_1: 0.4179 - val_acc_2: 0.4317\n",
      "Epoch 2/50\n",
      "100/100 - 6s - loss_1: 1.4858 - loss_2: 1.4861 - acc_ensemble: 0.5400 - acc_1: 0.4840 - acc_2: 0.5100 - val_loss_1: 1.4054 - val_loss_2: 1.3986 - val_acc_ensemble: 0.5120 - val_acc_1: 0.4697 - val_acc_2: 0.4878\n",
      "Epoch 3/50\n",
      "100/100 - 6s - loss_1: 1.3357 - loss_2: 1.3475 - acc_ensemble: 0.6000 - acc_1: 0.5860 - acc_2: 0.5520 - val_loss_1: 1.2309 - val_loss_2: 1.2459 - val_acc_ensemble: 0.5796 - val_acc_1: 0.5466 - val_acc_2: 0.5438\n",
      "Epoch 4/50\n",
      "100/100 - 6s - loss_1: 1.2335 - loss_2: 1.1859 - acc_ensemble: 0.6380 - acc_1: 0.5960 - acc_2: 0.6000 - val_loss_1: 1.1546 - val_loss_2: 1.1443 - val_acc_ensemble: 0.6115 - val_acc_1: 0.5796 - val_acc_2: 0.5801\n",
      "Epoch 5/50\n",
      "100/100 - 6s - loss_1: 1.1420 - loss_2: 1.0958 - acc_ensemble: 0.6500 - acc_1: 0.6080 - acc_2: 0.6260 - val_loss_1: 1.1154 - val_loss_2: 1.1108 - val_acc_ensemble: 0.6281 - val_acc_1: 0.5931 - val_acc_2: 0.5928\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 - 6s - loss_1: 1.0551 - loss_2: 1.0705 - acc_ensemble: 0.6920 - acc_1: 0.6440 - acc_2: 0.6620 - val_loss_1: 1.0465 - val_loss_2: 1.0321 - val_acc_ensemble: 0.6557 - val_acc_1: 0.6234 - val_acc_2: 0.6309\n",
      "Epoch 7/50\n",
      "100/100 - 6s - loss_1: 1.0091 - loss_2: 0.9894 - acc_ensemble: 0.7000 - acc_1: 0.6580 - acc_2: 0.6580 - val_loss_1: 0.9679 - val_loss_2: 0.9703 - val_acc_ensemble: 0.6771 - val_acc_1: 0.6513 - val_acc_2: 0.6510\n",
      "Epoch 8/50\n",
      "100/100 - 6s - loss_1: 0.9224 - loss_2: 0.9412 - acc_ensemble: 0.7120 - acc_1: 0.6440 - acc_2: 0.6960 - val_loss_1: 0.9648 - val_loss_2: 0.9554 - val_acc_ensemble: 0.6866 - val_acc_1: 0.6523 - val_acc_2: 0.6558\n",
      "Epoch 9/50\n",
      "100/100 - 6s - loss_1: 0.8611 - loss_2: 0.9112 - acc_ensemble: 0.7200 - acc_1: 0.6860 - acc_2: 0.6700 - val_loss_1: 0.9452 - val_loss_2: 0.9141 - val_acc_ensemble: 0.7012 - val_acc_1: 0.6618 - val_acc_2: 0.6661\n",
      "Epoch 10/50\n",
      "100/100 - 6s - loss_1: 0.8257 - loss_2: 0.8553 - acc_ensemble: 0.7340 - acc_1: 0.7160 - acc_2: 0.7040 - val_loss_1: 0.8937 - val_loss_2: 0.8674 - val_acc_ensemble: 0.7153 - val_acc_1: 0.6862 - val_acc_2: 0.6845\n",
      "Epoch 11/50\n",
      "100/100 - 6s - loss_1: 0.7912 - loss_2: 0.8105 - acc_ensemble: 0.7360 - acc_1: 0.6880 - acc_2: 0.6960 - val_loss_1: 0.8943 - val_loss_2: 0.8664 - val_acc_ensemble: 0.7253 - val_acc_1: 0.6839 - val_acc_2: 0.6950\n",
      "Epoch 12/50\n",
      "100/100 - 6s - loss_1: 0.7736 - loss_2: 0.7612 - acc_ensemble: 0.7500 - acc_1: 0.7160 - acc_2: 0.7000 - val_loss_1: 0.8353 - val_loss_2: 0.8167 - val_acc_ensemble: 0.7368 - val_acc_1: 0.7074 - val_acc_2: 0.7088\n",
      "Epoch 13/50\n",
      "100/100 - 6s - loss_1: 0.7219 - loss_2: 0.7265 - acc_ensemble: 0.7580 - acc_1: 0.7440 - acc_2: 0.7020 - val_loss_1: 0.8053 - val_loss_2: 0.8521 - val_acc_ensemble: 0.7376 - val_acc_1: 0.7186 - val_acc_2: 0.6997\n",
      "Epoch 14/50\n",
      "100/100 - 6s - loss_1: 0.6947 - loss_2: 0.7167 - acc_ensemble: 0.7820 - acc_1: 0.7740 - acc_2: 0.7480 - val_loss_1: 0.7870 - val_loss_2: 0.7793 - val_acc_ensemble: 0.7524 - val_acc_1: 0.7215 - val_acc_2: 0.7236\n",
      "Epoch 15/50\n",
      "100/100 - 6s - loss_1: 0.6387 - loss_2: 0.6450 - acc_ensemble: 0.7900 - acc_1: 0.7840 - acc_2: 0.7720 - val_loss_1: 0.7603 - val_loss_2: 0.7510 - val_acc_ensemble: 0.7625 - val_acc_1: 0.7352 - val_acc_2: 0.7339\n",
      "Epoch 16/50\n",
      "100/100 - 6s - loss_1: 0.6182 - loss_2: 0.6467 - acc_ensemble: 0.8140 - acc_1: 0.7940 - acc_2: 0.7560 - val_loss_1: 0.7494 - val_loss_2: 0.7619 - val_acc_ensemble: 0.7623 - val_acc_1: 0.7364 - val_acc_2: 0.7265\n",
      "Epoch 17/50\n",
      "100/100 - 6s - loss_1: 0.5870 - loss_2: 0.6391 - acc_ensemble: 0.8240 - acc_1: 0.8020 - acc_2: 0.7400 - val_loss_1: 0.7263 - val_loss_2: 0.7379 - val_acc_ensemble: 0.7781 - val_acc_1: 0.7434 - val_acc_2: 0.7396\n",
      "Epoch 18/50\n",
      "100/100 - 6s - loss_1: 0.5683 - loss_2: 0.6052 - acc_ensemble: 0.8080 - acc_1: 0.7960 - acc_2: 0.7600 - val_loss_1: 0.7495 - val_loss_2: 0.7450 - val_acc_ensemble: 0.7736 - val_acc_1: 0.7420 - val_acc_2: 0.7368\n",
      "Epoch 19/50\n",
      "100/100 - 6s - loss_1: 0.5293 - loss_2: 0.5425 - acc_ensemble: 0.8060 - acc_1: 0.7780 - acc_2: 0.7820 - val_loss_1: 0.7556 - val_loss_2: 0.7249 - val_acc_ensemble: 0.7721 - val_acc_1: 0.7393 - val_acc_2: 0.7452\n",
      "Epoch 20/50\n",
      "100/100 - 6s - loss_1: 0.5213 - loss_2: 0.5340 - acc_ensemble: 0.8320 - acc_1: 0.8020 - acc_2: 0.7800 - val_loss_1: 0.7147 - val_loss_2: 0.6952 - val_acc_ensemble: 0.7917 - val_acc_1: 0.7514 - val_acc_2: 0.7575\n",
      "Epoch 21/50\n",
      "100/100 - 6s - loss_1: 0.4860 - loss_2: 0.4923 - acc_ensemble: 0.8320 - acc_1: 0.8300 - acc_2: 0.7960 - val_loss_1: 0.6761 - val_loss_2: 0.7238 - val_acc_ensemble: 0.7919 - val_acc_1: 0.7679 - val_acc_2: 0.7476\n",
      "Epoch 22/50\n",
      "100/100 - 6s - loss_1: 0.4496 - loss_2: 0.4937 - acc_ensemble: 0.8580 - acc_1: 0.8140 - acc_2: 0.8120 - val_loss_1: 0.6935 - val_loss_2: 0.7145 - val_acc_ensemble: 0.7895 - val_acc_1: 0.7627 - val_acc_2: 0.7524\n",
      "Epoch 23/50\n",
      "100/100 - 6s - loss_1: 0.4487 - loss_2: 0.4931 - acc_ensemble: 0.8520 - acc_1: 0.8020 - acc_2: 0.8100 - val_loss_1: 0.7016 - val_loss_2: 0.7070 - val_acc_ensemble: 0.7892 - val_acc_1: 0.7591 - val_acc_2: 0.7544\n",
      "Epoch 24/50\n",
      "100/100 - 6s - loss_1: 0.4298 - loss_2: 0.4315 - acc_ensemble: 0.8400 - acc_1: 0.8140 - acc_2: 0.7780 - val_loss_1: 0.6767 - val_loss_2: 0.7264 - val_acc_ensemble: 0.7964 - val_acc_1: 0.7741 - val_acc_2: 0.7515\n",
      "Epoch 25/50\n",
      "100/100 - 6s - loss_1: 0.4034 - loss_2: 0.4225 - acc_ensemble: 0.8440 - acc_1: 0.7960 - acc_2: 0.8040 - val_loss_1: 0.7025 - val_loss_2: 0.6934 - val_acc_ensemble: 0.7956 - val_acc_1: 0.7643 - val_acc_2: 0.7646\n",
      "Epoch 26/50\n",
      "100/100 - 6s - loss_1: 0.3632 - loss_2: 0.4032 - acc_ensemble: 0.8680 - acc_1: 0.8340 - acc_2: 0.8100 - val_loss_1: 0.6777 - val_loss_2: 0.6670 - val_acc_ensemble: 0.8023 - val_acc_1: 0.7713 - val_acc_2: 0.7730\n",
      "Epoch 27/50\n",
      "100/100 - 6s - loss_1: 0.3767 - loss_2: 0.4169 - acc_ensemble: 0.8600 - acc_1: 0.8280 - acc_2: 0.8120 - val_loss_1: 0.7056 - val_loss_2: 0.6796 - val_acc_ensemble: 0.7996 - val_acc_1: 0.7710 - val_acc_2: 0.7714\n",
      "Epoch 28/50\n",
      "100/100 - 6s - loss_1: 0.3687 - loss_2: 0.3743 - acc_ensemble: 0.8680 - acc_1: 0.8320 - acc_2: 0.8140 - val_loss_1: 0.7324 - val_loss_2: 0.6916 - val_acc_ensemble: 0.8006 - val_acc_1: 0.7605 - val_acc_2: 0.7696\n",
      "Epoch 29/50\n",
      "100/100 - 6s - loss_1: 0.3390 - loss_2: 0.3500 - acc_ensemble: 0.8520 - acc_1: 0.8300 - acc_2: 0.8100 - val_loss_1: 0.6996 - val_loss_2: 0.6960 - val_acc_ensemble: 0.8068 - val_acc_1: 0.7668 - val_acc_2: 0.7706\n",
      "Epoch 30/50\n",
      "100/100 - 6s - loss_1: 0.3169 - loss_2: 0.3618 - acc_ensemble: 0.8900 - acc_1: 0.8520 - acc_2: 0.8420 - val_loss_1: 0.6870 - val_loss_2: 0.6458 - val_acc_ensemble: 0.8121 - val_acc_1: 0.7711 - val_acc_2: 0.7858\n",
      "Epoch 31/50\n",
      "100/100 - 6s - loss_1: 0.3047 - loss_2: 0.3137 - acc_ensemble: 0.8780 - acc_1: 0.8380 - acc_2: 0.8620 - val_loss_1: 0.6808 - val_loss_2: 0.6888 - val_acc_ensemble: 0.8107 - val_acc_1: 0.7793 - val_acc_2: 0.7747\n",
      "Epoch 32/50\n",
      "100/100 - 6s - loss_1: 0.3010 - loss_2: 0.3007 - acc_ensemble: 0.8820 - acc_1: 0.8420 - acc_2: 0.8320 - val_loss_1: 0.6821 - val_loss_2: 0.6782 - val_acc_ensemble: 0.8113 - val_acc_1: 0.7808 - val_acc_2: 0.7760\n",
      "Epoch 33/50\n",
      "100/100 - 6s - loss_1: 0.2779 - loss_2: 0.2826 - acc_ensemble: 0.8840 - acc_1: 0.8320 - acc_2: 0.8320 - val_loss_1: 0.7023 - val_loss_2: 0.6632 - val_acc_ensemble: 0.8179 - val_acc_1: 0.7747 - val_acc_2: 0.7838\n",
      "Epoch 34/50\n",
      "100/100 - 6s - loss_1: 0.2747 - loss_2: 0.2739 - acc_ensemble: 0.8940 - acc_1: 0.8320 - acc_2: 0.8700 - val_loss_1: 0.7066 - val_loss_2: 0.6981 - val_acc_ensemble: 0.8127 - val_acc_1: 0.7742 - val_acc_2: 0.7822\n",
      "Epoch 35/50\n",
      "100/100 - 6s - loss_1: 0.2689 - loss_2: 0.2388 - acc_ensemble: 0.8900 - acc_1: 0.8320 - acc_2: 0.8400 - val_loss_1: 0.6995 - val_loss_2: 0.6992 - val_acc_ensemble: 0.8165 - val_acc_1: 0.7787 - val_acc_2: 0.7813\n",
      "Epoch 36/50\n",
      "100/100 - 6s - loss_1: 0.2152 - loss_2: 0.2577 - acc_ensemble: 0.8760 - acc_1: 0.8520 - acc_2: 0.8340 - val_loss_1: 0.7148 - val_loss_2: 0.6940 - val_acc_ensemble: 0.8175 - val_acc_1: 0.7793 - val_acc_2: 0.7830\n",
      "Epoch 37/50\n",
      "100/100 - 6s - loss_1: 0.2153 - loss_2: 0.2394 - acc_ensemble: 0.9100 - acc_1: 0.8580 - acc_2: 0.8520 - val_loss_1: 0.7086 - val_loss_2: 0.7225 - val_acc_ensemble: 0.8164 - val_acc_1: 0.7830 - val_acc_2: 0.7732\n",
      "Epoch 38/50\n",
      "100/100 - 6s - loss_1: 0.1850 - loss_2: 0.2277 - acc_ensemble: 0.9000 - acc_1: 0.8540 - acc_2: 0.8520 - val_loss_1: 0.7228 - val_loss_2: 0.7125 - val_acc_ensemble: 0.8175 - val_acc_1: 0.7830 - val_acc_2: 0.7792\n",
      "Epoch 39/50\n",
      "100/100 - 6s - loss_1: 0.2189 - loss_2: 0.1887 - acc_ensemble: 0.8920 - acc_1: 0.8420 - acc_2: 0.8540 - val_loss_1: 0.7455 - val_loss_2: 0.7578 - val_acc_ensemble: 0.8100 - val_acc_1: 0.7763 - val_acc_2: 0.7722\n",
      "Epoch 40/50\n",
      "100/100 - 6s - loss_1: 0.2114 - loss_2: 0.1783 - acc_ensemble: 0.9120 - acc_1: 0.8520 - acc_2: 0.8620 - val_loss_1: 0.7102 - val_loss_2: 0.7569 - val_acc_ensemble: 0.8194 - val_acc_1: 0.7861 - val_acc_2: 0.7792\n",
      "Epoch 41/50\n",
      "100/100 - 6s - loss_1: 0.1814 - loss_2: 0.1789 - acc_ensemble: 0.9160 - acc_1: 0.8680 - acc_2: 0.8560 - val_loss_1: 0.7180 - val_loss_2: 0.7793 - val_acc_ensemble: 0.8153 - val_acc_1: 0.7850 - val_acc_2: 0.7767\n",
      "Epoch 42/50\n",
      "100/100 - 6s - loss_1: 0.1710 - loss_2: 0.2053 - acc_ensemble: 0.9040 - acc_1: 0.8700 - acc_2: 0.8460 - val_loss_1: 0.7458 - val_loss_2: 0.7590 - val_acc_ensemble: 0.8186 - val_acc_1: 0.7810 - val_acc_2: 0.7774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50\n",
      "100/100 - 6s - loss_1: 0.1568 - loss_2: 0.1518 - acc_ensemble: 0.9000 - acc_1: 0.8540 - acc_2: 0.8760 - val_loss_1: 0.7390 - val_loss_2: 0.7226 - val_acc_ensemble: 0.8221 - val_acc_1: 0.7854 - val_acc_2: 0.7885\n",
      "Epoch 44/50\n",
      "100/100 - 6s - loss_1: 0.1368 - loss_2: 0.1429 - acc_ensemble: 0.9100 - acc_1: 0.8680 - acc_2: 0.8560 - val_loss_1: 0.7434 - val_loss_2: 0.7818 - val_acc_ensemble: 0.8190 - val_acc_1: 0.7874 - val_acc_2: 0.7757\n",
      "Epoch 45/50\n",
      "100/100 - 6s - loss_1: 0.1381 - loss_2: 0.1446 - acc_ensemble: 0.9220 - acc_1: 0.8600 - acc_2: 0.8820 - val_loss_1: 0.7621 - val_loss_2: 0.7410 - val_acc_ensemble: 0.8227 - val_acc_1: 0.7874 - val_acc_2: 0.7895\n",
      "Epoch 46/50\n",
      "100/100 - 6s - loss_1: 0.1148 - loss_2: 0.1367 - acc_ensemble: 0.9000 - acc_1: 0.8500 - acc_2: 0.8740 - val_loss_1: 0.8297 - val_loss_2: 0.7746 - val_acc_ensemble: 0.8182 - val_acc_1: 0.7764 - val_acc_2: 0.7832\n",
      "Epoch 47/50\n",
      "100/100 - 6s - loss_1: 0.1452 - loss_2: 0.1446 - acc_ensemble: 0.9220 - acc_1: 0.8660 - acc_2: 0.8440 - val_loss_1: 0.7550 - val_loss_2: 0.7766 - val_acc_ensemble: 0.8209 - val_acc_1: 0.7872 - val_acc_2: 0.7883\n",
      "Epoch 48/50\n",
      "100/100 - 6s - loss_1: 0.1370 - loss_2: 0.1680 - acc_ensemble: 0.9080 - acc_1: 0.8640 - acc_2: 0.8800 - val_loss_1: 0.8155 - val_loss_2: 0.7910 - val_acc_ensemble: 0.8180 - val_acc_1: 0.7779 - val_acc_2: 0.7780\n",
      "Epoch 49/50\n",
      "100/100 - 6s - loss_1: 0.1426 - loss_2: 0.1375 - acc_ensemble: 0.9260 - acc_1: 0.8620 - acc_2: 0.8860 - val_loss_1: 0.7888 - val_loss_2: 0.7866 - val_acc_ensemble: 0.8229 - val_acc_1: 0.7880 - val_acc_2: 0.7880\n",
      "Epoch 50/50\n",
      "100/100 - 6s - loss_1: 0.1216 - loss_2: 0.1466 - acc_ensemble: 0.9140 - acc_1: 0.8680 - acc_2: 0.8700 - val_loss_1: 0.7763 - val_loss_2: 0.7852 - val_acc_ensemble: 0.8258 - val_acc_1: 0.7903 - val_acc_2: 0.7894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0804 12:19:50.046411 140571476088576 deprecation_wrapper.py:119] From /home/gong/research/vbranch/vbranch/engine/training.py:265: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/sensitivity-Ba64/vb-cifar10-cnn/B2/S0.00/model_2\n",
      "i   Layer name                      Output shape        Num param  Inbound            \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                    \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                    \n",
      "--------------------------------------------------------------------------------------\n",
      "0   conv2d_1_1 (Conv2D)             [] [None,32,32,32]  1792       input              \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "1   bn_1_1 (BatchNormalization)     [] [None,32,32,32]  128        conv2d_1_1         \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "2   relu_1_1 (Activation)           [] [None,32,32,32]  0          bn_1_1             \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "3   conv2d_1_2 (Conv2D)             [] [None,32,32,32]  18496      relu_1_1           \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "4   bn_1_2 (BatchNormalization)     [] [None,32,32,32]  128        conv2d_1_2         \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "5   relu_1_2 (Activation)           [] [None,32,32,32]  0          bn_1_2             \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "6   avg_pool2d_1 (AveragePooling2D  [] [None,16,16,32]  0          relu_1_2           \n",
      "                                    [] [None,16,16,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "7   conv2d_2_1 (Conv2D)             [] [None,16,16,64]  36992      avg_pool2d_1       \n",
      "                                    [] [None,16,16,64]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "8   bn_2_1 (BatchNormalization)     [] [None,16,16,64]  256        conv2d_2_1         \n",
      "                                    [] [None,16,16,64]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "9   relu_2_1 (Activation)           [] [None,16,16,64]  0          bn_2_1             \n",
      "                                    [] [None,16,16,64]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "10  conv2d_2_2 (Conv2D)             [] [None,16,16,64]  73856      relu_2_1           \n",
      "                                    [] [None,16,16,64]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "11  bn_2_2 (BatchNormalization)     [] [None,16,16,64]  256        conv2d_2_2         \n",
      "                                    [] [None,16,16,64]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "12  relu_2_2 (Activation)           [] [None,16,16,64]  0          bn_2_2             \n",
      "                                    [] [None,16,16,64]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "13  avg_pool2d_2 (AveragePooling2D  [] [None,8,8,64]    0          relu_2_2           \n",
      "                                    [] [None,8,8,64]                                  \n",
      "--------------------------------------------------------------------------------------\n",
      "14  conv2d_3_1 (Conv2D)             [] [None,8,8,128]   147712     avg_pool2d_2       \n",
      "                                    [] [None,8,8,128]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "15  bn_3_1 (BatchNormalization)     [] [None,8,8,128]   512        conv2d_3_1         \n",
      "                                    [] [None,8,8,128]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "16  relu_3_1 (Activation)           [] [None,8,8,128]   0          bn_3_1             \n",
      "                                    [] [None,8,8,128]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "17  conv2d_3_2 (Conv2D)             [] [None,8,8,128]   295168     relu_3_1           \n",
      "                                    [] [None,8,8,128]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "18  bn_3_2 (BatchNormalization)     [] [None,8,8,128]   512        conv2d_3_2         \n",
      "                                    [] [None,8,8,128]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "19  relu_3_2 (Activation)           [] [None,8,8,128]   0          bn_3_2             \n",
      "                                    [] [None,8,8,128]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "20  global_avg_pool2d (GlobalAvera  [] [None,128]       0          relu_3_2           \n",
      "                                    [] [None,128]                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "21  fc1 (Dense)                     [] [None,128]       33024      global_avg_pool2d  \n",
      "                                    [] [None,128]                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "22  bn_fc1 (BatchNormalization)     [] [None,128]       512        fc1                \n",
      "                                    [] [None,128]                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "23  relu_fc1 (Activation)           [] [None,128]       0          bn_fc1             \n",
      "                                    [] [None,128]                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "24  output (Dense)                  [None,10]           2580       relu_fc1           \n",
      "                                    [None,10]                                         \n",
      "--------------------------------------------------------------------------------------\n",
      "Total parameters: 611924\n",
      "50000\n",
      "Epoch 1/50\n",
      "100/100 - 7s - loss_1: 1.7599 - loss_2: 1.8274 - acc_ensemble: 0.4680 - acc_1: 0.4460 - acc_2: 0.4240 - val_loss_1: 1.5566 - val_loss_2: 1.6150 - val_acc_ensemble: 0.4454 - val_acc_1: 0.4250 - val_acc_2: 0.3941\n",
      "Epoch 2/50\n",
      "100/100 - 6s - loss_1: 1.4683 - loss_2: 1.4986 - acc_ensemble: 0.5260 - acc_1: 0.4600 - acc_2: 0.5100 - val_loss_1: 1.4218 - val_loss_2: 1.3870 - val_acc_ensemble: 0.5172 - val_acc_1: 0.4740 - val_acc_2: 0.4814\n",
      "Epoch 3/50\n",
      "100/100 - 6s - loss_1: 1.3128 - loss_2: 1.3696 - acc_ensemble: 0.6080 - acc_1: 0.5720 - acc_2: 0.5600 - val_loss_1: 1.2345 - val_loss_2: 1.2633 - val_acc_ensemble: 0.5775 - val_acc_1: 0.5502 - val_acc_2: 0.5323\n",
      "Epoch 4/50\n",
      "100/100 - 6s - loss_1: 1.1665 - loss_2: 1.2466 - acc_ensemble: 0.6220 - acc_1: 0.5960 - acc_2: 0.5700 - val_loss_1: 1.1238 - val_loss_2: 1.1964 - val_acc_ensemble: 0.6159 - val_acc_1: 0.5968 - val_acc_2: 0.5637\n",
      "Epoch 5/50\n",
      "100/100 - 6s - loss_1: 1.0682 - loss_2: 1.1345 - acc_ensemble: 0.6580 - acc_1: 0.6080 - acc_2: 0.6340 - val_loss_1: 1.0831 - val_loss_2: 1.0877 - val_acc_ensemble: 0.6447 - val_acc_1: 0.6083 - val_acc_2: 0.6100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50\n",
      "100/100 - 6s - loss_1: 1.0187 - loss_2: 1.0483 - acc_ensemble: 0.6860 - acc_1: 0.6480 - acc_2: 0.6260 - val_loss_1: 1.0042 - val_loss_2: 1.0691 - val_acc_ensemble: 0.6635 - val_acc_1: 0.6415 - val_acc_2: 0.6114\n",
      "Epoch 7/50\n",
      "100/100 - 6s - loss_1: 0.9338 - loss_2: 1.0146 - acc_ensemble: 0.7080 - acc_1: 0.6720 - acc_2: 0.6260 - val_loss_1: 0.9760 - val_loss_2: 1.0035 - val_acc_ensemble: 0.6820 - val_acc_1: 0.6518 - val_acc_2: 0.6415\n",
      "Epoch 8/50\n",
      "100/100 - 6s - loss_1: 0.8906 - loss_2: 0.9329 - acc_ensemble: 0.7240 - acc_1: 0.6780 - acc_2: 0.6860 - val_loss_1: 0.9294 - val_loss_2: 0.9784 - val_acc_ensemble: 0.6927 - val_acc_1: 0.6694 - val_acc_2: 0.6499\n",
      "Epoch 9/50\n",
      "100/100 - 6s - loss_1: 0.8287 - loss_2: 0.9051 - acc_ensemble: 0.7280 - acc_1: 0.6840 - acc_2: 0.6880 - val_loss_1: 0.9237 - val_loss_2: 0.9347 - val_acc_ensemble: 0.6965 - val_acc_1: 0.6686 - val_acc_2: 0.6650\n",
      "Epoch 10/50\n",
      "100/100 - 6s - loss_1: 0.8275 - loss_2: 0.8615 - acc_ensemble: 0.7420 - acc_1: 0.7300 - acc_2: 0.6780 - val_loss_1: 0.8536 - val_loss_2: 0.8998 - val_acc_ensemble: 0.7165 - val_acc_1: 0.6941 - val_acc_2: 0.6771\n",
      "Epoch 11/50\n",
      "100/100 - 6s - loss_1: 0.7864 - loss_2: 0.7942 - acc_ensemble: 0.7860 - acc_1: 0.7260 - acc_2: 0.7340 - val_loss_1: 0.8590 - val_loss_2: 0.8764 - val_acc_ensemble: 0.7248 - val_acc_1: 0.6916 - val_acc_2: 0.6831\n",
      "Epoch 12/50\n",
      "100/100 - 6s - loss_1: 0.7362 - loss_2: 0.7735 - acc_ensemble: 0.7720 - acc_1: 0.7560 - acc_2: 0.7200 - val_loss_1: 0.8052 - val_loss_2: 0.8528 - val_acc_ensemble: 0.7298 - val_acc_1: 0.7128 - val_acc_2: 0.6963\n",
      "Epoch 13/50\n",
      "100/100 - 6s - loss_1: 0.7094 - loss_2: 0.7338 - acc_ensemble: 0.7780 - acc_1: 0.7520 - acc_2: 0.7520 - val_loss_1: 0.8143 - val_loss_2: 0.8132 - val_acc_ensemble: 0.7413 - val_acc_1: 0.7148 - val_acc_2: 0.7065\n",
      "Epoch 14/50\n",
      "100/100 - 6s - loss_1: 0.6656 - loss_2: 0.6860 - acc_ensemble: 0.8200 - acc_1: 0.7560 - acc_2: 0.7740 - val_loss_1: 0.7711 - val_loss_2: 0.8154 - val_acc_ensemble: 0.7488 - val_acc_1: 0.7230 - val_acc_2: 0.7076\n",
      "Epoch 15/50\n",
      "100/100 - 6s - loss_1: 0.6321 - loss_2: 0.6746 - acc_ensemble: 0.8260 - acc_1: 0.7700 - acc_2: 0.7620 - val_loss_1: 0.7871 - val_loss_2: 0.7663 - val_acc_ensemble: 0.7598 - val_acc_1: 0.7275 - val_acc_2: 0.7234\n",
      "Epoch 16/50\n",
      "100/100 - 6s - loss_1: 0.5967 - loss_2: 0.5990 - acc_ensemble: 0.8120 - acc_1: 0.7680 - acc_2: 0.7860 - val_loss_1: 0.7534 - val_loss_2: 0.7419 - val_acc_ensemble: 0.7711 - val_acc_1: 0.7322 - val_acc_2: 0.7430\n",
      "Epoch 17/50\n",
      "100/100 - 6s - loss_1: 0.5802 - loss_2: 0.6041 - acc_ensemble: 0.8340 - acc_1: 0.7760 - acc_2: 0.8060 - val_loss_1: 0.7728 - val_loss_2: 0.7240 - val_acc_ensemble: 0.7715 - val_acc_1: 0.7338 - val_acc_2: 0.7441\n",
      "Epoch 18/50\n",
      "100/100 - 6s - loss_1: 0.5715 - loss_2: 0.5870 - acc_ensemble: 0.8320 - acc_1: 0.7920 - acc_2: 0.7860 - val_loss_1: 0.7271 - val_loss_2: 0.7342 - val_acc_ensemble: 0.7807 - val_acc_1: 0.7493 - val_acc_2: 0.7422\n",
      "Epoch 19/50\n",
      "100/100 - 6s - loss_1: 0.5529 - loss_2: 0.5738 - acc_ensemble: 0.8160 - acc_1: 0.7680 - acc_2: 0.7840 - val_loss_1: 0.7315 - val_loss_2: 0.7584 - val_acc_ensemble: 0.7818 - val_acc_1: 0.7469 - val_acc_2: 0.7346\n",
      "Epoch 20/50\n",
      "100/100 - 6s - loss_1: 0.5319 - loss_2: 0.5056 - acc_ensemble: 0.8540 - acc_1: 0.8020 - acc_2: 0.7900 - val_loss_1: 0.7003 - val_loss_2: 0.7674 - val_acc_ensemble: 0.7813 - val_acc_1: 0.7587 - val_acc_2: 0.7355\n",
      "Epoch 21/50\n",
      "100/100 - 6s - loss_1: 0.4790 - loss_2: 0.5083 - acc_ensemble: 0.8440 - acc_1: 0.8020 - acc_2: 0.8340 - val_loss_1: 0.7054 - val_loss_2: 0.6915 - val_acc_ensemble: 0.7906 - val_acc_1: 0.7590 - val_acc_2: 0.7606\n",
      "Epoch 22/50\n",
      "100/100 - 6s - loss_1: 0.4739 - loss_2: 0.4649 - acc_ensemble: 0.8600 - acc_1: 0.8160 - acc_2: 0.8240 - val_loss_1: 0.7084 - val_loss_2: 0.7192 - val_acc_ensemble: 0.7923 - val_acc_1: 0.7606 - val_acc_2: 0.7525\n",
      "Epoch 23/50\n",
      "100/100 - 6s - loss_1: 0.4414 - loss_2: 0.4687 - acc_ensemble: 0.8620 - acc_1: 0.8200 - acc_2: 0.8140 - val_loss_1: 0.6838 - val_loss_2: 0.7161 - val_acc_ensemble: 0.7938 - val_acc_1: 0.7669 - val_acc_2: 0.7538\n",
      "Epoch 24/50\n",
      "100/100 - 6s - loss_1: 0.4227 - loss_2: 0.4262 - acc_ensemble: 0.8520 - acc_1: 0.8020 - acc_2: 0.8080 - val_loss_1: 0.6914 - val_loss_2: 0.7247 - val_acc_ensemble: 0.7936 - val_acc_1: 0.7625 - val_acc_2: 0.7513\n",
      "Epoch 25/50\n",
      "100/100 - 6s - loss_1: 0.3887 - loss_2: 0.4070 - acc_ensemble: 0.8680 - acc_1: 0.8200 - acc_2: 0.8060 - val_loss_1: 0.7037 - val_loss_2: 0.7054 - val_acc_ensemble: 0.7978 - val_acc_1: 0.7673 - val_acc_2: 0.7575\n",
      "Epoch 26/50\n",
      "100/100 - 6s - loss_1: 0.3803 - loss_2: 0.3870 - acc_ensemble: 0.8800 - acc_1: 0.8440 - acc_2: 0.8340 - val_loss_1: 0.6804 - val_loss_2: 0.6881 - val_acc_ensemble: 0.8069 - val_acc_1: 0.7709 - val_acc_2: 0.7694\n",
      "Epoch 27/50\n",
      "100/100 - 6s - loss_1: 0.3445 - loss_2: 0.3972 - acc_ensemble: 0.8640 - acc_1: 0.8380 - acc_2: 0.8480 - val_loss_1: 0.7299 - val_loss_2: 0.6916 - val_acc_ensemble: 0.8012 - val_acc_1: 0.7611 - val_acc_2: 0.7670\n",
      "Epoch 28/50\n",
      "100/100 - 6s - loss_1: 0.3543 - loss_2: 0.3793 - acc_ensemble: 0.8720 - acc_1: 0.8440 - acc_2: 0.8220 - val_loss_1: 0.6695 - val_loss_2: 0.6755 - val_acc_ensemble: 0.8105 - val_acc_1: 0.7758 - val_acc_2: 0.7723\n",
      "Epoch 29/50\n",
      "100/100 - 6s - loss_1: 0.3229 - loss_2: 0.3427 - acc_ensemble: 0.8920 - acc_1: 0.8500 - acc_2: 0.8440 - val_loss_1: 0.6859 - val_loss_2: 0.6832 - val_acc_ensemble: 0.8130 - val_acc_1: 0.7794 - val_acc_2: 0.7762\n",
      "Epoch 30/50\n",
      "100/100 - 6s - loss_1: 0.3115 - loss_2: 0.3267 - acc_ensemble: 0.8740 - acc_1: 0.8620 - acc_2: 0.8280 - val_loss_1: 0.7042 - val_loss_2: 0.6803 - val_acc_ensemble: 0.8117 - val_acc_1: 0.7713 - val_acc_2: 0.7756\n",
      "Epoch 31/50\n",
      "100/100 - 6s - loss_1: 0.2861 - loss_2: 0.3219 - acc_ensemble: 0.8880 - acc_1: 0.8400 - acc_2: 0.8440 - val_loss_1: 0.6847 - val_loss_2: 0.6774 - val_acc_ensemble: 0.8142 - val_acc_1: 0.7809 - val_acc_2: 0.7803\n",
      "Epoch 32/50\n",
      "100/100 - 6s - loss_1: 0.2691 - loss_2: 0.3072 - acc_ensemble: 0.8780 - acc_1: 0.8300 - acc_2: 0.8420 - val_loss_1: 0.7292 - val_loss_2: 0.6776 - val_acc_ensemble: 0.8085 - val_acc_1: 0.7693 - val_acc_2: 0.7812\n",
      "Epoch 33/50\n",
      "100/100 - 6s - loss_1: 0.2868 - loss_2: 0.2583 - acc_ensemble: 0.8860 - acc_1: 0.8420 - acc_2: 0.8500 - val_loss_1: 0.7202 - val_loss_2: 0.6963 - val_acc_ensemble: 0.8115 - val_acc_1: 0.7783 - val_acc_2: 0.7769\n",
      "Epoch 34/50\n",
      "100/100 - 6s - loss_1: 0.2540 - loss_2: 0.2844 - acc_ensemble: 0.8840 - acc_1: 0.8300 - acc_2: 0.8520 - val_loss_1: 0.7207 - val_loss_2: 0.7006 - val_acc_ensemble: 0.8141 - val_acc_1: 0.7771 - val_acc_2: 0.7734\n",
      "Epoch 35/50\n",
      "100/100 - 6s - loss_1: 0.2141 - loss_2: 0.2802 - acc_ensemble: 0.8740 - acc_1: 0.8340 - acc_2: 0.8540 - val_loss_1: 0.7108 - val_loss_2: 0.6899 - val_acc_ensemble: 0.8149 - val_acc_1: 0.7826 - val_acc_2: 0.7781\n",
      "Epoch 36/50\n",
      "100/100 - 6s - loss_1: 0.2455 - loss_2: 0.2423 - acc_ensemble: 0.8840 - acc_1: 0.8360 - acc_2: 0.8360 - val_loss_1: 0.7218 - val_loss_2: 0.7522 - val_acc_ensemble: 0.8161 - val_acc_1: 0.7758 - val_acc_2: 0.7683\n",
      "Epoch 37/50\n",
      "100/100 - 6s - loss_1: 0.2187 - loss_2: 0.2492 - acc_ensemble: 0.9000 - acc_1: 0.8640 - acc_2: 0.8560 - val_loss_1: 0.6831 - val_loss_2: 0.7036 - val_acc_ensemble: 0.8270 - val_acc_1: 0.7923 - val_acc_2: 0.7827\n",
      "Epoch 38/50\n",
      "100/100 - 6s - loss_1: 0.2033 - loss_2: 0.1965 - acc_ensemble: 0.9120 - acc_1: 0.8660 - acc_2: 0.8700 - val_loss_1: 0.6845 - val_loss_2: 0.7158 - val_acc_ensemble: 0.8247 - val_acc_1: 0.7931 - val_acc_2: 0.7831\n",
      "Epoch 39/50\n",
      "100/100 - 6s - loss_1: 0.2078 - loss_2: 0.2049 - acc_ensemble: 0.9000 - acc_1: 0.8460 - acc_2: 0.8780 - val_loss_1: 0.7096 - val_loss_2: 0.7212 - val_acc_ensemble: 0.8224 - val_acc_1: 0.7875 - val_acc_2: 0.7811\n",
      "Epoch 40/50\n",
      "100/100 - 6s - loss_1: 0.1751 - loss_2: 0.1824 - acc_ensemble: 0.9080 - acc_1: 0.8600 - acc_2: 0.8720 - val_loss_1: 0.7444 - val_loss_2: 0.7189 - val_acc_ensemble: 0.8232 - val_acc_1: 0.7795 - val_acc_2: 0.7825\n",
      "Epoch 41/50\n",
      "100/100 - 6s - loss_1: 0.1636 - loss_2: 0.1805 - acc_ensemble: 0.9120 - acc_1: 0.8660 - acc_2: 0.8680 - val_loss_1: 0.7041 - val_loss_2: 0.7339 - val_acc_ensemble: 0.8242 - val_acc_1: 0.7986 - val_acc_2: 0.7834\n",
      "Epoch 42/50\n",
      "100/100 - 6s - loss_1: 0.1386 - loss_2: 0.1736 - acc_ensemble: 0.9120 - acc_1: 0.8740 - acc_2: 0.8620 - val_loss_1: 0.7449 - val_loss_2: 0.7728 - val_acc_ensemble: 0.8235 - val_acc_1: 0.7847 - val_acc_2: 0.7745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50\n",
      "100/100 - 6s - loss_1: 0.1722 - loss_2: 0.1751 - acc_ensemble: 0.8980 - acc_1: 0.8620 - acc_2: 0.8820 - val_loss_1: 0.7447 - val_loss_2: 0.7365 - val_acc_ensemble: 0.8231 - val_acc_1: 0.7881 - val_acc_2: 0.7795\n",
      "Epoch 44/50\n",
      "100/100 - 6s - loss_1: 0.1761 - loss_2: 0.1590 - acc_ensemble: 0.8960 - acc_1: 0.8540 - acc_2: 0.8720 - val_loss_1: 0.8122 - val_loss_2: 0.7965 - val_acc_ensemble: 0.8170 - val_acc_1: 0.7754 - val_acc_2: 0.7702\n",
      "Epoch 45/50\n",
      "100/100 - 6s - loss_1: 0.1561 - loss_2: 0.1748 - acc_ensemble: 0.9220 - acc_1: 0.8640 - acc_2: 0.8920 - val_loss_1: 0.7945 - val_loss_2: 0.7665 - val_acc_ensemble: 0.8230 - val_acc_1: 0.7771 - val_acc_2: 0.7791\n",
      "Epoch 46/50\n",
      "100/100 - 6s - loss_1: 0.1323 - loss_2: 0.1334 - acc_ensemble: 0.9080 - acc_1: 0.8740 - acc_2: 0.8800 - val_loss_1: 0.7392 - val_loss_2: 0.7820 - val_acc_ensemble: 0.8249 - val_acc_1: 0.7945 - val_acc_2: 0.7806\n",
      "Epoch 47/50\n",
      "100/100 - 6s - loss_1: 0.1370 - loss_2: 0.1262 - acc_ensemble: 0.9200 - acc_1: 0.8740 - acc_2: 0.8820 - val_loss_1: 0.7884 - val_loss_2: 0.7647 - val_acc_ensemble: 0.8214 - val_acc_1: 0.7866 - val_acc_2: 0.7884\n",
      "Epoch 48/50\n",
      "100/100 - 6s - loss_1: 0.1194 - loss_2: 0.1463 - acc_ensemble: 0.9120 - acc_1: 0.8580 - acc_2: 0.8620 - val_loss_1: 0.7615 - val_loss_2: 0.7642 - val_acc_ensemble: 0.8258 - val_acc_1: 0.7888 - val_acc_2: 0.7851\n",
      "Epoch 49/50\n",
      "100/100 - 6s - loss_1: 0.1143 - loss_2: 0.1214 - acc_ensemble: 0.9240 - acc_1: 0.8640 - acc_2: 0.8880 - val_loss_1: 0.8228 - val_loss_2: 0.7952 - val_acc_ensemble: 0.8204 - val_acc_1: 0.7777 - val_acc_2: 0.7820\n",
      "Epoch 50/50\n",
      "100/100 - 6s - loss_1: 0.1232 - loss_2: 0.1017 - acc_ensemble: 0.9040 - acc_1: 0.8680 - acc_2: 0.8760 - val_loss_1: 0.7935 - val_loss_2: 0.7784 - val_acc_ensemble: 0.8241 - val_acc_1: 0.7880 - val_acc_2: 0.7885\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B2/S0.00/model_3\n",
      "i   Layer name                      Output shape        Num param  Inbound            \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                    \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                    \n",
      "--------------------------------------------------------------------------------------\n",
      "0   conv2d_1_1 (Conv2D)             [] [None,32,32,32]  1792       input              \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "1   bn_1_1 (BatchNormalization)     [] [None,32,32,32]  128        conv2d_1_1         \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "2   relu_1_1 (Activation)           [] [None,32,32,32]  0          bn_1_1             \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "3   conv2d_1_2 (Conv2D)             [] [None,32,32,32]  18496      relu_1_1           \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "4   bn_1_2 (BatchNormalization)     [] [None,32,32,32]  128        conv2d_1_2         \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "5   relu_1_2 (Activation)           [] [None,32,32,32]  0          bn_1_2             \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "6   avg_pool2d_1 (AveragePooling2D  [] [None,16,16,32]  0          relu_1_2           \n",
      "                                    [] [None,16,16,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "7   conv2d_2_1 (Conv2D)             [] [None,16,16,64]  36992      avg_pool2d_1       \n",
      "                                    [] [None,16,16,64]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "8   bn_2_1 (BatchNormalization)     [] [None,16,16,64]  256        conv2d_2_1         \n",
      "                                    [] [None,16,16,64]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "9   relu_2_1 (Activation)           [] [None,16,16,64]  0          bn_2_1             \n",
      "                                    [] [None,16,16,64]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "10  conv2d_2_2 (Conv2D)             [] [None,16,16,64]  73856      relu_2_1           \n",
      "                                    [] [None,16,16,64]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "11  bn_2_2 (BatchNormalization)     [] [None,16,16,64]  256        conv2d_2_2         \n",
      "                                    [] [None,16,16,64]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "12  relu_2_2 (Activation)           [] [None,16,16,64]  0          bn_2_2             \n",
      "                                    [] [None,16,16,64]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "13  avg_pool2d_2 (AveragePooling2D  [] [None,8,8,64]    0          relu_2_2           \n",
      "                                    [] [None,8,8,64]                                  \n",
      "--------------------------------------------------------------------------------------\n",
      "14  conv2d_3_1 (Conv2D)             [] [None,8,8,128]   147712     avg_pool2d_2       \n",
      "                                    [] [None,8,8,128]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "15  bn_3_1 (BatchNormalization)     [] [None,8,8,128]   512        conv2d_3_1         \n",
      "                                    [] [None,8,8,128]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "16  relu_3_1 (Activation)           [] [None,8,8,128]   0          bn_3_1             \n",
      "                                    [] [None,8,8,128]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "17  conv2d_3_2 (Conv2D)             [] [None,8,8,128]   295168     relu_3_1           \n",
      "                                    [] [None,8,8,128]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "18  bn_3_2 (BatchNormalization)     [] [None,8,8,128]   512        conv2d_3_2         \n",
      "                                    [] [None,8,8,128]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "19  relu_3_2 (Activation)           [] [None,8,8,128]   0          bn_3_2             \n",
      "                                    [] [None,8,8,128]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "20  global_avg_pool2d (GlobalAvera  [] [None,128]       0          relu_3_2           \n",
      "                                    [] [None,128]                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "21  fc1 (Dense)                     [] [None,128]       33024      global_avg_pool2d  \n",
      "                                    [] [None,128]                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "22  bn_fc1 (BatchNormalization)     [] [None,128]       512        fc1                \n",
      "                                    [] [None,128]                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "23  relu_fc1 (Activation)           [] [None,128]       0          bn_fc1             \n",
      "                                    [] [None,128]                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "24  output (Dense)                  [None,10]           2580       relu_fc1           \n",
      "                                    [None,10]                                         \n",
      "--------------------------------------------------------------------------------------\n",
      "Total parameters: 611924\n",
      "50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 - 7s - loss_1: 1.7969 - loss_2: 1.7664 - acc_ensemble: 0.4820 - acc_1: 0.4560 - acc_2: 0.4380 - val_loss_1: 1.5243 - val_loss_2: 1.5437 - val_acc_ensemble: 0.4648 - val_acc_1: 0.4336 - val_acc_2: 0.4332\n",
      "Epoch 2/50\n",
      "100/100 - 6s - loss_1: 1.4949 - loss_2: 1.4910 - acc_ensemble: 0.5480 - acc_1: 0.5100 - acc_2: 0.4960 - val_loss_1: 1.3940 - val_loss_2: 1.4310 - val_acc_ensemble: 0.5126 - val_acc_1: 0.4882 - val_acc_2: 0.4709\n",
      "Epoch 3/50\n",
      "100/100 - 6s - loss_1: 1.3891 - loss_2: 1.3181 - acc_ensemble: 0.5780 - acc_1: 0.5440 - acc_2: 0.5680 - val_loss_1: 1.2926 - val_loss_2: 1.2419 - val_acc_ensemble: 0.5778 - val_acc_1: 0.5240 - val_acc_2: 0.5475\n",
      "Epoch 4/50\n",
      "100/100 - 6s - loss_1: 1.2524 - loss_2: 1.2072 - acc_ensemble: 0.6160 - acc_1: 0.5760 - acc_2: 0.5880 - val_loss_1: 1.2337 - val_loss_2: 1.1562 - val_acc_ensemble: 0.5976 - val_acc_1: 0.5465 - val_acc_2: 0.5861\n",
      "Epoch 5/50\n",
      "100/100 - 6s - loss_1: 1.1603 - loss_2: 1.1159 - acc_ensemble: 0.6600 - acc_1: 0.6140 - acc_2: 0.6200 - val_loss_1: 1.1249 - val_loss_2: 1.0763 - val_acc_ensemble: 0.6348 - val_acc_1: 0.5963 - val_acc_2: 0.6131\n",
      "Epoch 6/50\n",
      "100/100 - 6s - loss_1: 1.0969 - loss_2: 1.0262 - acc_ensemble: 0.6820 - acc_1: 0.6100 - acc_2: 0.6620 - val_loss_1: 1.0641 - val_loss_2: 1.0063 - val_acc_ensemble: 0.6560 - val_acc_1: 0.6171 - val_acc_2: 0.6422\n",
      "Epoch 7/50\n",
      "100/100 - 6s - loss_1: 0.9959 - loss_2: 0.9332 - acc_ensemble: 0.6820 - acc_1: 0.6620 - acc_2: 0.6460 - val_loss_1: 1.0057 - val_loss_2: 1.0050 - val_acc_ensemble: 0.6749 - val_acc_1: 0.6442 - val_acc_2: 0.6420\n",
      "Epoch 8/50\n",
      "100/100 - 6s - loss_1: 0.9577 - loss_2: 0.9001 - acc_ensemble: 0.7240 - acc_1: 0.6820 - acc_2: 0.6660 - val_loss_1: 0.9594 - val_loss_2: 0.9300 - val_acc_ensemble: 0.6886 - val_acc_1: 0.6504 - val_acc_2: 0.6650\n",
      "Epoch 9/50\n",
      "100/100 - 6s - loss_1: 0.8764 - loss_2: 0.8668 - acc_ensemble: 0.7320 - acc_1: 0.6920 - acc_2: 0.6940 - val_loss_1: 0.8983 - val_loss_2: 0.9158 - val_acc_ensemble: 0.7068 - val_acc_1: 0.6798 - val_acc_2: 0.6719\n",
      "Epoch 10/50\n",
      "100/100 - 6s - loss_1: 0.8606 - loss_2: 0.8163 - acc_ensemble: 0.7600 - acc_1: 0.7060 - acc_2: 0.6920 - val_loss_1: 0.8875 - val_loss_2: 0.8843 - val_acc_ensemble: 0.7129 - val_acc_1: 0.6820 - val_acc_2: 0.6832\n",
      "Epoch 11/50\n",
      "100/100 - 6s - loss_1: 0.7906 - loss_2: 0.7703 - acc_ensemble: 0.7560 - acc_1: 0.7060 - acc_2: 0.6980 - val_loss_1: 0.8555 - val_loss_2: 0.8282 - val_acc_ensemble: 0.7360 - val_acc_1: 0.6942 - val_acc_2: 0.7041\n",
      "Epoch 12/50\n",
      "100/100 - 6s - loss_1: 0.7416 - loss_2: 0.7085 - acc_ensemble: 0.7660 - acc_1: 0.7220 - acc_2: 0.7280 - val_loss_1: 0.8356 - val_loss_2: 0.8278 - val_acc_ensemble: 0.7348 - val_acc_1: 0.7062 - val_acc_2: 0.7056\n",
      "Epoch 13/50\n",
      "100/100 - 6s - loss_1: 0.7137 - loss_2: 0.7159 - acc_ensemble: 0.8000 - acc_1: 0.7720 - acc_2: 0.7260 - val_loss_1: 0.7911 - val_loss_2: 0.8071 - val_acc_ensemble: 0.7482 - val_acc_1: 0.7221 - val_acc_2: 0.7177\n",
      "Epoch 14/50\n",
      "100/100 - 6s - loss_1: 0.6759 - loss_2: 0.6759 - acc_ensemble: 0.7780 - acc_1: 0.7620 - acc_2: 0.7240 - val_loss_1: 0.7893 - val_loss_2: 0.8164 - val_acc_ensemble: 0.7494 - val_acc_1: 0.7257 - val_acc_2: 0.7111\n",
      "Epoch 15/50\n",
      "100/100 - 6s - loss_1: 0.6584 - loss_2: 0.6503 - acc_ensemble: 0.7800 - acc_1: 0.7880 - acc_2: 0.7240 - val_loss_1: 0.7527 - val_loss_2: 0.7770 - val_acc_ensemble: 0.7663 - val_acc_1: 0.7390 - val_acc_2: 0.7256\n",
      "Epoch 16/50\n",
      "100/100 - 6s - loss_1: 0.6268 - loss_2: 0.5944 - acc_ensemble: 0.8240 - acc_1: 0.7880 - acc_2: 0.7720 - val_loss_1: 0.7438 - val_loss_2: 0.7369 - val_acc_ensemble: 0.7712 - val_acc_1: 0.7386 - val_acc_2: 0.7464\n",
      "Epoch 17/50\n",
      "100/100 - 6s - loss_1: 0.6036 - loss_2: 0.5705 - acc_ensemble: 0.8140 - acc_1: 0.7820 - acc_2: 0.7740 - val_loss_1: 0.7473 - val_loss_2: 0.7469 - val_acc_ensemble: 0.7730 - val_acc_1: 0.7395 - val_acc_2: 0.7402\n",
      "Epoch 18/50\n",
      "100/100 - 6s - loss_1: 0.5469 - loss_2: 0.5521 - acc_ensemble: 0.7940 - acc_1: 0.7700 - acc_2: 0.7660 - val_loss_1: 0.7186 - val_loss_2: 0.7436 - val_acc_ensemble: 0.7795 - val_acc_1: 0.7503 - val_acc_2: 0.7426\n",
      "Epoch 19/50\n",
      "100/100 - 6s - loss_1: 0.5623 - loss_2: 0.5206 - acc_ensemble: 0.8200 - acc_1: 0.8100 - acc_2: 0.7740 - val_loss_1: 0.6980 - val_loss_2: 0.7599 - val_acc_ensemble: 0.7811 - val_acc_1: 0.7587 - val_acc_2: 0.7414\n",
      "Epoch 20/50\n",
      "100/100 - 6s - loss_1: 0.4985 - loss_2: 0.5211 - acc_ensemble: 0.8260 - acc_1: 0.8000 - acc_2: 0.7840 - val_loss_1: 0.6869 - val_loss_2: 0.7057 - val_acc_ensemble: 0.7919 - val_acc_1: 0.7637 - val_acc_2: 0.7541\n",
      "Epoch 21/50\n",
      "100/100 - 6s - loss_1: 0.4838 - loss_2: 0.5020 - acc_ensemble: 0.8460 - acc_1: 0.7880 - acc_2: 0.7680 - val_loss_1: 0.7322 - val_loss_2: 0.7411 - val_acc_ensemble: 0.7804 - val_acc_1: 0.7485 - val_acc_2: 0.7517\n",
      "Epoch 22/50\n",
      "100/100 - 6s - loss_1: 0.4660 - loss_2: 0.4772 - acc_ensemble: 0.8380 - acc_1: 0.8000 - acc_2: 0.7860 - val_loss_1: 0.6914 - val_loss_2: 0.6996 - val_acc_ensemble: 0.7980 - val_acc_1: 0.7611 - val_acc_2: 0.7610\n",
      "Epoch 23/50\n",
      "100/100 - 6s - loss_1: 0.4527 - loss_2: 0.4657 - acc_ensemble: 0.8520 - acc_1: 0.8040 - acc_2: 0.8140 - val_loss_1: 0.7079 - val_loss_2: 0.6831 - val_acc_ensemble: 0.7934 - val_acc_1: 0.7554 - val_acc_2: 0.7612\n",
      "Epoch 24/50\n",
      "100/100 - 6s - loss_1: 0.4078 - loss_2: 0.4330 - acc_ensemble: 0.8640 - acc_1: 0.8220 - acc_2: 0.8000 - val_loss_1: 0.6857 - val_loss_2: 0.7038 - val_acc_ensemble: 0.7958 - val_acc_1: 0.7688 - val_acc_2: 0.7611\n",
      "Epoch 25/50\n",
      "100/100 - 6s - loss_1: 0.3941 - loss_2: 0.4035 - acc_ensemble: 0.8560 - acc_1: 0.8100 - acc_2: 0.8080 - val_loss_1: 0.6957 - val_loss_2: 0.6992 - val_acc_ensemble: 0.8031 - val_acc_1: 0.7684 - val_acc_2: 0.7626\n",
      "Epoch 26/50\n",
      "100/100 - 6s - loss_1: 0.3869 - loss_2: 0.3887 - acc_ensemble: 0.8640 - acc_1: 0.8360 - acc_2: 0.8120 - val_loss_1: 0.6541 - val_loss_2: 0.6936 - val_acc_ensemble: 0.8095 - val_acc_1: 0.7808 - val_acc_2: 0.7658\n",
      "Epoch 27/50\n",
      "100/100 - 6s - loss_1: 0.3591 - loss_2: 0.3336 - acc_ensemble: 0.8660 - acc_1: 0.8160 - acc_2: 0.8260 - val_loss_1: 0.6952 - val_loss_2: 0.6949 - val_acc_ensemble: 0.8068 - val_acc_1: 0.7677 - val_acc_2: 0.7700\n",
      "Epoch 28/50\n",
      "100/100 - 6s - loss_1: 0.3850 - loss_2: 0.3516 - acc_ensemble: 0.8460 - acc_1: 0.8140 - acc_2: 0.8060 - val_loss_1: 0.6616 - val_loss_2: 0.7234 - val_acc_ensemble: 0.8095 - val_acc_1: 0.7811 - val_acc_2: 0.7563\n",
      "Epoch 29/50\n",
      "100/100 - 6s - loss_1: 0.3336 - loss_2: 0.3575 - acc_ensemble: 0.8860 - acc_1: 0.8360 - acc_2: 0.8240 - val_loss_1: 0.6867 - val_loss_2: 0.6746 - val_acc_ensemble: 0.8131 - val_acc_1: 0.7730 - val_acc_2: 0.7802\n",
      "Epoch 30/50\n",
      "100/100 - 6s - loss_1: 0.3466 - loss_2: 0.3064 - acc_ensemble: 0.8900 - acc_1: 0.8320 - acc_2: 0.8520 - val_loss_1: 0.6712 - val_loss_2: 0.6919 - val_acc_ensemble: 0.8146 - val_acc_1: 0.7840 - val_acc_2: 0.7721\n",
      "Epoch 31/50\n",
      "100/100 - 6s - loss_1: 0.2823 - loss_2: 0.3220 - acc_ensemble: 0.8860 - acc_1: 0.8440 - acc_2: 0.8500 - val_loss_1: 0.6752 - val_loss_2: 0.6958 - val_acc_ensemble: 0.8189 - val_acc_1: 0.7865 - val_acc_2: 0.7702\n",
      "Epoch 32/50\n",
      "100/100 - 6s - loss_1: 0.2958 - loss_2: 0.3058 - acc_ensemble: 0.8740 - acc_1: 0.8460 - acc_2: 0.8360 - val_loss_1: 0.6573 - val_loss_2: 0.6851 - val_acc_ensemble: 0.8169 - val_acc_1: 0.7795 - val_acc_2: 0.7788\n",
      "Epoch 33/50\n",
      "100/100 - 6s - loss_1: 0.2464 - loss_2: 0.2614 - acc_ensemble: 0.8780 - acc_1: 0.8400 - acc_2: 0.8420 - val_loss_1: 0.6610 - val_loss_2: 0.6887 - val_acc_ensemble: 0.8184 - val_acc_1: 0.7896 - val_acc_2: 0.7775\n",
      "Epoch 34/50\n",
      "100/100 - 6s - loss_1: 0.2866 - loss_2: 0.2293 - acc_ensemble: 0.8920 - acc_1: 0.8500 - acc_2: 0.8720 - val_loss_1: 0.7194 - val_loss_2: 0.6715 - val_acc_ensemble: 0.8170 - val_acc_1: 0.7688 - val_acc_2: 0.7852\n",
      "Epoch 35/50\n",
      "100/100 - 6s - loss_1: 0.2831 - loss_2: 0.2478 - acc_ensemble: 0.8880 - acc_1: 0.8440 - acc_2: 0.8640 - val_loss_1: 0.7191 - val_loss_2: 0.6758 - val_acc_ensemble: 0.8184 - val_acc_1: 0.7770 - val_acc_2: 0.7862\n",
      "Epoch 36/50\n",
      "100/100 - 6s - loss_1: 0.2257 - loss_2: 0.2270 - acc_ensemble: 0.8780 - acc_1: 0.8540 - acc_2: 0.8500 - val_loss_1: 0.6957 - val_loss_2: 0.7335 - val_acc_ensemble: 0.8194 - val_acc_1: 0.7871 - val_acc_2: 0.7775\n",
      "Epoch 37/50\n",
      "100/100 - 6s - loss_1: 0.2281 - loss_2: 0.2103 - acc_ensemble: 0.8900 - acc_1: 0.8540 - acc_2: 0.8500 - val_loss_1: 0.7028 - val_loss_2: 0.6897 - val_acc_ensemble: 0.8229 - val_acc_1: 0.7826 - val_acc_2: 0.7894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50\n",
      "100/100 - 6s - loss_1: 0.1876 - loss_2: 0.2176 - acc_ensemble: 0.9020 - acc_1: 0.8540 - acc_2: 0.8640 - val_loss_1: 0.7007 - val_loss_2: 0.6854 - val_acc_ensemble: 0.8282 - val_acc_1: 0.7894 - val_acc_2: 0.7875\n",
      "Epoch 39/50\n",
      "100/100 - 6s - loss_1: 0.1890 - loss_2: 0.1918 - acc_ensemble: 0.8940 - acc_1: 0.8380 - acc_2: 0.8580 - val_loss_1: 0.7311 - val_loss_2: 0.7221 - val_acc_ensemble: 0.8220 - val_acc_1: 0.7829 - val_acc_2: 0.7856\n",
      "Epoch 40/50\n",
      "100/100 - 6s - loss_1: 0.1992 - loss_2: 0.1904 - acc_ensemble: 0.9120 - acc_1: 0.8700 - acc_2: 0.8760 - val_loss_1: 0.7152 - val_loss_2: 0.7083 - val_acc_ensemble: 0.8236 - val_acc_1: 0.7869 - val_acc_2: 0.7861\n",
      "Epoch 41/50\n",
      "100/100 - 6s - loss_1: 0.1702 - loss_2: 0.1666 - acc_ensemble: 0.9140 - acc_1: 0.8680 - acc_2: 0.8780 - val_loss_1: 0.7231 - val_loss_2: 0.7103 - val_acc_ensemble: 0.8281 - val_acc_1: 0.7917 - val_acc_2: 0.7946\n",
      "Epoch 42/50\n",
      "100/100 - 6s - loss_1: 0.1459 - loss_2: 0.1525 - acc_ensemble: 0.9000 - acc_1: 0.8600 - acc_2: 0.8640 - val_loss_1: 0.7206 - val_loss_2: 0.7455 - val_acc_ensemble: 0.8254 - val_acc_1: 0.7930 - val_acc_2: 0.7845\n",
      "Epoch 43/50\n",
      "100/100 - 6s - loss_1: 0.1537 - loss_2: 0.1486 - acc_ensemble: 0.9080 - acc_1: 0.8720 - acc_2: 0.8900 - val_loss_1: 0.7266 - val_loss_2: 0.7379 - val_acc_ensemble: 0.8284 - val_acc_1: 0.7928 - val_acc_2: 0.7892\n",
      "Epoch 44/50\n",
      "100/100 - 6s - loss_1: 0.1563 - loss_2: 0.1593 - acc_ensemble: 0.8900 - acc_1: 0.8500 - acc_2: 0.8700 - val_loss_1: 0.7586 - val_loss_2: 0.7944 - val_acc_ensemble: 0.8222 - val_acc_1: 0.7847 - val_acc_2: 0.7767\n",
      "Epoch 45/50\n",
      "100/100 - 6s - loss_1: 0.1463 - loss_2: 0.1608 - acc_ensemble: 0.9120 - acc_1: 0.8480 - acc_2: 0.8720 - val_loss_1: 0.7918 - val_loss_2: 0.7545 - val_acc_ensemble: 0.8218 - val_acc_1: 0.7820 - val_acc_2: 0.7871\n",
      "Epoch 46/50\n",
      "100/100 - 6s - loss_1: 0.1503 - loss_2: 0.1252 - acc_ensemble: 0.9100 - acc_1: 0.8700 - acc_2: 0.8560 - val_loss_1: 0.7320 - val_loss_2: 0.8031 - val_acc_ensemble: 0.8216 - val_acc_1: 0.7956 - val_acc_2: 0.7818\n",
      "Epoch 47/50\n",
      "100/100 - 6s - loss_1: 0.1337 - loss_2: 0.1317 - acc_ensemble: 0.9100 - acc_1: 0.8500 - acc_2: 0.8700 - val_loss_1: 0.7923 - val_loss_2: 0.8016 - val_acc_ensemble: 0.8206 - val_acc_1: 0.7883 - val_acc_2: 0.7797\n",
      "Epoch 48/50\n",
      "100/100 - 6s - loss_1: 0.1298 - loss_2: 0.1210 - acc_ensemble: 0.9080 - acc_1: 0.8640 - acc_2: 0.8720 - val_loss_1: 0.8125 - val_loss_2: 0.7677 - val_acc_ensemble: 0.8229 - val_acc_1: 0.7823 - val_acc_2: 0.7923\n",
      "Epoch 49/50\n",
      "100/100 - 6s - loss_1: 0.1577 - loss_2: 0.1080 - acc_ensemble: 0.9120 - acc_1: 0.8480 - acc_2: 0.8640 - val_loss_1: 0.7900 - val_loss_2: 0.7977 - val_acc_ensemble: 0.8283 - val_acc_1: 0.7823 - val_acc_2: 0.7900\n",
      "Epoch 50/50\n",
      "100/100 - 6s - loss_1: 0.1258 - loss_2: 0.1535 - acc_ensemble: 0.9040 - acc_1: 0.8700 - acc_2: 0.8540 - val_loss_1: 0.7673 - val_loss_2: 0.8378 - val_acc_ensemble: 0.8243 - val_acc_1: 0.7941 - val_acc_2: 0.7765\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B2/S0.00/model_4\n",
      "i   Layer name                      Output shape        Num param  Inbound            \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                    \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                    \n",
      "--------------------------------------------------------------------------------------\n",
      "0   conv2d_1_1 (Conv2D)             [] [None,32,32,32]  1792       input              \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "1   bn_1_1 (BatchNormalization)     [] [None,32,32,32]  128        conv2d_1_1         \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "2   relu_1_1 (Activation)           [] [None,32,32,32]  0          bn_1_1             \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "3   conv2d_1_2 (Conv2D)             [] [None,32,32,32]  18496      relu_1_1           \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "4   bn_1_2 (BatchNormalization)     [] [None,32,32,32]  128        conv2d_1_2         \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "5   relu_1_2 (Activation)           [] [None,32,32,32]  0          bn_1_2             \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "6   avg_pool2d_1 (AveragePooling2D  [] [None,16,16,32]  0          relu_1_2           \n",
      "                                    [] [None,16,16,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "7   conv2d_2_1 (Conv2D)             [] [None,16,16,64]  36992      avg_pool2d_1       \n",
      "                                    [] [None,16,16,64]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "8   bn_2_1 (BatchNormalization)     [] [None,16,16,64]  256        conv2d_2_1         \n",
      "                                    [] [None,16,16,64]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "9   relu_2_1 (Activation)           [] [None,16,16,64]  0          bn_2_1             \n",
      "                                    [] [None,16,16,64]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "10  conv2d_2_2 (Conv2D)             [] [None,16,16,64]  73856      relu_2_1           \n",
      "                                    [] [None,16,16,64]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "11  bn_2_2 (BatchNormalization)     [] [None,16,16,64]  256        conv2d_2_2         \n",
      "                                    [] [None,16,16,64]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "12  relu_2_2 (Activation)           [] [None,16,16,64]  0          bn_2_2             \n",
      "                                    [] [None,16,16,64]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "13  avg_pool2d_2 (AveragePooling2D  [] [None,8,8,64]    0          relu_2_2           \n",
      "                                    [] [None,8,8,64]                                  \n",
      "--------------------------------------------------------------------------------------\n",
      "14  conv2d_3_1 (Conv2D)             [] [None,8,8,128]   147712     avg_pool2d_2       \n",
      "                                    [] [None,8,8,128]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "15  bn_3_1 (BatchNormalization)     [] [None,8,8,128]   512        conv2d_3_1         \n",
      "                                    [] [None,8,8,128]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "16  relu_3_1 (Activation)           [] [None,8,8,128]   0          bn_3_1             \n",
      "                                    [] [None,8,8,128]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "17  conv2d_3_2 (Conv2D)             [] [None,8,8,128]   295168     relu_3_1           \n",
      "                                    [] [None,8,8,128]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "18  bn_3_2 (BatchNormalization)     [] [None,8,8,128]   512        conv2d_3_2         \n",
      "                                    [] [None,8,8,128]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "19  relu_3_2 (Activation)           [] [None,8,8,128]   0          bn_3_2             \n",
      "                                    [] [None,8,8,128]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "20  global_avg_pool2d (GlobalAvera  [] [None,128]       0          relu_3_2           \n",
      "                                    [] [None,128]                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "21  fc1 (Dense)                     [] [None,128]       33024      global_avg_pool2d  \n",
      "                                    [] [None,128]                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "22  bn_fc1 (BatchNormalization)     [] [None,128]       512        fc1                \n",
      "                                    [] [None,128]                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "23  relu_fc1 (Activation)           [] [None,128]       0          bn_fc1             \n",
      "                                    [] [None,128]                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "24  output (Dense)                  [None,10]           2580       relu_fc1           \n",
      "                                    [None,10]                                         \n",
      "--------------------------------------------------------------------------------------\n",
      "Total parameters: 611924\n",
      "50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 - 7s - loss_1: 1.8151 - loss_2: 1.8203 - acc_ensemble: 0.4420 - acc_1: 0.4100 - acc_2: 0.4120 - val_loss_1: 1.6065 - val_loss_2: 1.5750 - val_acc_ensemble: 0.4331 - val_acc_1: 0.4101 - val_acc_2: 0.4116\n",
      "Epoch 2/50\n",
      "100/100 - 6s - loss_1: 1.5239 - loss_2: 1.5125 - acc_ensemble: 0.5000 - acc_1: 0.4960 - acc_2: 0.4740 - val_loss_1: 1.4445 - val_loss_2: 1.4423 - val_acc_ensemble: 0.5015 - val_acc_1: 0.4680 - val_acc_2: 0.4674\n",
      "Epoch 3/50\n",
      "100/100 - 6s - loss_1: 1.3559 - loss_2: 1.3797 - acc_ensemble: 0.5680 - acc_1: 0.5520 - acc_2: 0.5000 - val_loss_1: 1.2785 - val_loss_2: 1.3450 - val_acc_ensemble: 0.5649 - val_acc_1: 0.5294 - val_acc_2: 0.5077\n",
      "Epoch 4/50\n",
      "100/100 - 6s - loss_1: 1.2089 - loss_2: 1.2717 - acc_ensemble: 0.6360 - acc_1: 0.5960 - acc_2: 0.5760 - val_loss_1: 1.1634 - val_loss_2: 1.2121 - val_acc_ensemble: 0.6055 - val_acc_1: 0.5806 - val_acc_2: 0.5573\n",
      "Epoch 5/50\n",
      "100/100 - 6s - loss_1: 1.1294 - loss_2: 1.1519 - acc_ensemble: 0.6680 - acc_1: 0.6180 - acc_2: 0.6240 - val_loss_1: 1.0682 - val_loss_2: 1.1446 - val_acc_ensemble: 0.6328 - val_acc_1: 0.6157 - val_acc_2: 0.5836\n",
      "Epoch 6/50\n",
      "100/100 - 6s - loss_1: 1.0434 - loss_2: 1.0861 - acc_ensemble: 0.6780 - acc_1: 0.6160 - acc_2: 0.6420 - val_loss_1: 1.0242 - val_loss_2: 1.0668 - val_acc_ensemble: 0.6561 - val_acc_1: 0.6332 - val_acc_2: 0.6155\n",
      "Epoch 7/50\n",
      "100/100 - 6s - loss_1: 1.0018 - loss_2: 1.0207 - acc_ensemble: 0.6960 - acc_1: 0.6620 - acc_2: 0.6520 - val_loss_1: 0.9723 - val_loss_2: 1.0327 - val_acc_ensemble: 0.6699 - val_acc_1: 0.6517 - val_acc_2: 0.6260\n",
      "Epoch 8/50\n",
      "100/100 - 6s - loss_1: 0.9251 - loss_2: 0.9661 - acc_ensemble: 0.7080 - acc_1: 0.6860 - acc_2: 0.6780 - val_loss_1: 0.9171 - val_loss_2: 0.9698 - val_acc_ensemble: 0.6912 - val_acc_1: 0.6747 - val_acc_2: 0.6565\n",
      "Epoch 9/50\n",
      "100/100 - 6s - loss_1: 0.8653 - loss_2: 0.8783 - acc_ensemble: 0.7480 - acc_1: 0.6920 - acc_2: 0.7040 - val_loss_1: 0.9160 - val_loss_2: 0.9353 - val_acc_ensemble: 0.7040 - val_acc_1: 0.6735 - val_acc_2: 0.6692\n",
      "Epoch 10/50\n",
      "100/100 - 6s - loss_1: 0.8458 - loss_2: 0.8426 - acc_ensemble: 0.7560 - acc_1: 0.7180 - acc_2: 0.6940 - val_loss_1: 0.8614 - val_loss_2: 0.9301 - val_acc_ensemble: 0.7131 - val_acc_1: 0.6935 - val_acc_2: 0.6647\n",
      "Epoch 11/50\n",
      "100/100 - 6s - loss_1: 0.7880 - loss_2: 0.8313 - acc_ensemble: 0.7460 - acc_1: 0.7340 - acc_2: 0.7240 - val_loss_1: 0.8480 - val_loss_2: 0.8683 - val_acc_ensemble: 0.7234 - val_acc_1: 0.6966 - val_acc_2: 0.6895\n",
      "Epoch 12/50\n",
      "100/100 - 6s - loss_1: 0.7403 - loss_2: 0.7851 - acc_ensemble: 0.7820 - acc_1: 0.7200 - acc_2: 0.7480 - val_loss_1: 0.8689 - val_loss_2: 0.8762 - val_acc_ensemble: 0.7240 - val_acc_1: 0.6944 - val_acc_2: 0.6898\n",
      "Epoch 13/50\n",
      "100/100 - 6s - loss_1: 0.7056 - loss_2: 0.7390 - acc_ensemble: 0.7780 - acc_1: 0.7340 - acc_2: 0.7380 - val_loss_1: 0.8358 - val_loss_2: 0.8713 - val_acc_ensemble: 0.7352 - val_acc_1: 0.7084 - val_acc_2: 0.6959\n",
      "Epoch 14/50\n",
      "100/100 - 6s - loss_1: 0.6615 - loss_2: 0.7331 - acc_ensemble: 0.8040 - acc_1: 0.7560 - acc_2: 0.7680 - val_loss_1: 0.7766 - val_loss_2: 0.7848 - val_acc_ensemble: 0.7555 - val_acc_1: 0.7281 - val_acc_2: 0.7187\n",
      "Epoch 15/50\n",
      "100/100 - 6s - loss_1: 0.6219 - loss_2: 0.6689 - acc_ensemble: 0.8020 - acc_1: 0.7840 - acc_2: 0.7700 - val_loss_1: 0.7383 - val_loss_2: 0.7814 - val_acc_ensemble: 0.7676 - val_acc_1: 0.7459 - val_acc_2: 0.7213\n",
      "Epoch 16/50\n",
      "100/100 - 6s - loss_1: 0.6043 - loss_2: 0.6528 - acc_ensemble: 0.8160 - acc_1: 0.7960 - acc_2: 0.7820 - val_loss_1: 0.7308 - val_loss_2: 0.7669 - val_acc_ensemble: 0.7684 - val_acc_1: 0.7481 - val_acc_2: 0.7299\n",
      "Epoch 17/50\n",
      "100/100 - 6s - loss_1: 0.5716 - loss_2: 0.6056 - acc_ensemble: 0.8360 - acc_1: 0.7880 - acc_2: 0.7940 - val_loss_1: 0.7132 - val_loss_2: 0.7521 - val_acc_ensemble: 0.7788 - val_acc_1: 0.7558 - val_acc_2: 0.7379\n",
      "Epoch 18/50\n",
      "100/100 - 6s - loss_1: 0.5481 - loss_2: 0.5771 - acc_ensemble: 0.8200 - acc_1: 0.7780 - acc_2: 0.7740 - val_loss_1: 0.7124 - val_loss_2: 0.7357 - val_acc_ensemble: 0.7799 - val_acc_1: 0.7572 - val_acc_2: 0.7456\n",
      "Epoch 19/50\n",
      "100/100 - 6s - loss_1: 0.5348 - loss_2: 0.5238 - acc_ensemble: 0.8540 - acc_1: 0.7960 - acc_2: 0.7980 - val_loss_1: 0.7171 - val_loss_2: 0.7321 - val_acc_ensemble: 0.7884 - val_acc_1: 0.7540 - val_acc_2: 0.7489\n",
      "Epoch 20/50\n",
      "100/100 - 6s - loss_1: 0.4770 - loss_2: 0.5478 - acc_ensemble: 0.8580 - acc_1: 0.8040 - acc_2: 0.7960 - val_loss_1: 0.6950 - val_loss_2: 0.7280 - val_acc_ensemble: 0.7843 - val_acc_1: 0.7618 - val_acc_2: 0.7479\n",
      "Epoch 21/50\n",
      "100/100 - 6s - loss_1: 0.5026 - loss_2: 0.5142 - acc_ensemble: 0.8440 - acc_1: 0.7860 - acc_2: 0.8260 - val_loss_1: 0.6830 - val_loss_2: 0.7281 - val_acc_ensemble: 0.7918 - val_acc_1: 0.7676 - val_acc_2: 0.7503\n",
      "Epoch 22/50\n",
      "100/100 - 6s - loss_1: 0.4707 - loss_2: 0.5142 - acc_ensemble: 0.8520 - acc_1: 0.8060 - acc_2: 0.8140 - val_loss_1: 0.6995 - val_loss_2: 0.7344 - val_acc_ensemble: 0.7894 - val_acc_1: 0.7642 - val_acc_2: 0.7465\n",
      "Epoch 23/50\n",
      "100/100 - 6s - loss_1: 0.4435 - loss_2: 0.4803 - acc_ensemble: 0.8520 - acc_1: 0.7900 - acc_2: 0.8260 - val_loss_1: 0.6795 - val_loss_2: 0.6983 - val_acc_ensemble: 0.7961 - val_acc_1: 0.7739 - val_acc_2: 0.7551\n",
      "Epoch 24/50\n",
      "100/100 - 6s - loss_1: 0.4221 - loss_2: 0.4283 - acc_ensemble: 0.8520 - acc_1: 0.8000 - acc_2: 0.8280 - val_loss_1: 0.6894 - val_loss_2: 0.7036 - val_acc_ensemble: 0.7973 - val_acc_1: 0.7725 - val_acc_2: 0.7614\n",
      "Epoch 25/50\n",
      "100/100 - 6s - loss_1: 0.4024 - loss_2: 0.4369 - acc_ensemble: 0.8680 - acc_1: 0.8160 - acc_2: 0.8240 - val_loss_1: 0.7036 - val_loss_2: 0.7211 - val_acc_ensemble: 0.8006 - val_acc_1: 0.7704 - val_acc_2: 0.7568\n",
      "Epoch 26/50\n",
      "100/100 - 6s - loss_1: 0.3858 - loss_2: 0.3862 - acc_ensemble: 0.8820 - acc_1: 0.8000 - acc_2: 0.8480 - val_loss_1: 0.7174 - val_loss_2: 0.6731 - val_acc_ensemble: 0.8088 - val_acc_1: 0.7640 - val_acc_2: 0.7771\n",
      "Epoch 27/50\n",
      "100/100 - 6s - loss_1: 0.3737 - loss_2: 0.3548 - acc_ensemble: 0.8860 - acc_1: 0.8420 - acc_2: 0.8480 - val_loss_1: 0.6704 - val_loss_2: 0.6944 - val_acc_ensemble: 0.8142 - val_acc_1: 0.7814 - val_acc_2: 0.7675\n",
      "Epoch 28/50\n",
      "100/100 - 6s - loss_1: 0.3263 - loss_2: 0.3747 - acc_ensemble: 0.8800 - acc_1: 0.8400 - acc_2: 0.8380 - val_loss_1: 0.6570 - val_loss_2: 0.7158 - val_acc_ensemble: 0.8075 - val_acc_1: 0.7868 - val_acc_2: 0.7647\n",
      "Epoch 29/50\n",
      "100/100 - 6s - loss_1: 0.3273 - loss_2: 0.3533 - acc_ensemble: 0.8540 - acc_1: 0.8360 - acc_2: 0.8340 - val_loss_1: 0.6678 - val_loss_2: 0.7001 - val_acc_ensemble: 0.8137 - val_acc_1: 0.7831 - val_acc_2: 0.7694\n",
      "Epoch 30/50\n",
      "100/100 - 6s - loss_1: 0.3419 - loss_2: 0.3377 - acc_ensemble: 0.8760 - acc_1: 0.8200 - acc_2: 0.8580 - val_loss_1: 0.6936 - val_loss_2: 0.7118 - val_acc_ensemble: 0.8065 - val_acc_1: 0.7761 - val_acc_2: 0.7662\n",
      "Epoch 31/50\n",
      "100/100 - 6s - loss_1: 0.2986 - loss_2: 0.3455 - acc_ensemble: 0.8860 - acc_1: 0.8400 - acc_2: 0.8540 - val_loss_1: 0.6753 - val_loss_2: 0.7039 - val_acc_ensemble: 0.8169 - val_acc_1: 0.7828 - val_acc_2: 0.7721\n",
      "Epoch 32/50\n",
      "100/100 - 6s - loss_1: 0.2795 - loss_2: 0.2918 - acc_ensemble: 0.8940 - acc_1: 0.8400 - acc_2: 0.8540 - val_loss_1: 0.7144 - val_loss_2: 0.6960 - val_acc_ensemble: 0.8119 - val_acc_1: 0.7729 - val_acc_2: 0.7765\n",
      "Epoch 33/50\n",
      "100/100 - 6s - loss_1: 0.2871 - loss_2: 0.2702 - acc_ensemble: 0.8940 - acc_1: 0.8260 - acc_2: 0.8300 - val_loss_1: 0.7371 - val_loss_2: 0.6917 - val_acc_ensemble: 0.8176 - val_acc_1: 0.7684 - val_acc_2: 0.7785\n",
      "Epoch 34/50\n",
      "100/100 - 6s - loss_1: 0.2840 - loss_2: 0.2735 - acc_ensemble: 0.9000 - acc_1: 0.8540 - acc_2: 0.8700 - val_loss_1: 0.6881 - val_loss_2: 0.6794 - val_acc_ensemble: 0.8166 - val_acc_1: 0.7813 - val_acc_2: 0.7878\n",
      "Epoch 35/50\n",
      "100/100 - 6s - loss_1: 0.2317 - loss_2: 0.2405 - acc_ensemble: 0.8960 - acc_1: 0.8420 - acc_2: 0.8640 - val_loss_1: 0.7032 - val_loss_2: 0.6918 - val_acc_ensemble: 0.8219 - val_acc_1: 0.7802 - val_acc_2: 0.7860\n",
      "Epoch 36/50\n",
      "100/100 - 6s - loss_1: 0.2138 - loss_2: 0.2219 - acc_ensemble: 0.9060 - acc_1: 0.8580 - acc_2: 0.8560 - val_loss_1: 0.6901 - val_loss_2: 0.7050 - val_acc_ensemble: 0.8247 - val_acc_1: 0.7903 - val_acc_2: 0.7823\n",
      "Epoch 37/50\n",
      "100/100 - 6s - loss_1: 0.2135 - loss_2: 0.1848 - acc_ensemble: 0.8960 - acc_1: 0.8500 - acc_2: 0.8640 - val_loss_1: 0.7016 - val_loss_2: 0.7271 - val_acc_ensemble: 0.8231 - val_acc_1: 0.7842 - val_acc_2: 0.7782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50\n",
      "100/100 - 6s - loss_1: 0.2159 - loss_2: 0.2200 - acc_ensemble: 0.8840 - acc_1: 0.8540 - acc_2: 0.8500 - val_loss_1: 0.7251 - val_loss_2: 0.7691 - val_acc_ensemble: 0.8150 - val_acc_1: 0.7828 - val_acc_2: 0.7754\n",
      "Epoch 39/50\n",
      "100/100 - 6s - loss_1: 0.1943 - loss_2: 0.2326 - acc_ensemble: 0.8940 - acc_1: 0.8300 - acc_2: 0.8560 - val_loss_1: 0.7484 - val_loss_2: 0.7167 - val_acc_ensemble: 0.8204 - val_acc_1: 0.7720 - val_acc_2: 0.7832\n",
      "Epoch 40/50\n",
      "100/100 - 6s - loss_1: 0.1890 - loss_2: 0.1848 - acc_ensemble: 0.8900 - acc_1: 0.8340 - acc_2: 0.8660 - val_loss_1: 0.7496 - val_loss_2: 0.7426 - val_acc_ensemble: 0.8252 - val_acc_1: 0.7853 - val_acc_2: 0.7846\n",
      "Epoch 41/50\n",
      "100/100 - 6s - loss_1: 0.1748 - loss_2: 0.1947 - acc_ensemble: 0.9040 - acc_1: 0.8700 - acc_2: 0.8720 - val_loss_1: 0.7389 - val_loss_2: 0.7481 - val_acc_ensemble: 0.8208 - val_acc_1: 0.7851 - val_acc_2: 0.7819\n",
      "Epoch 42/50\n",
      "100/100 - 6s - loss_1: 0.1659 - loss_2: 0.1731 - acc_ensemble: 0.9180 - acc_1: 0.8580 - acc_2: 0.8620 - val_loss_1: 0.7385 - val_loss_2: 0.7820 - val_acc_ensemble: 0.8229 - val_acc_1: 0.7906 - val_acc_2: 0.7733\n",
      "Epoch 43/50\n",
      "100/100 - 6s - loss_1: 0.1442 - loss_2: 0.1787 - acc_ensemble: 0.8920 - acc_1: 0.8580 - acc_2: 0.8620 - val_loss_1: 0.7515 - val_loss_2: 0.7358 - val_acc_ensemble: 0.8268 - val_acc_1: 0.7908 - val_acc_2: 0.7833\n",
      "Epoch 44/50\n",
      "100/100 - 6s - loss_1: 0.1777 - loss_2: 0.1393 - acc_ensemble: 0.9000 - acc_1: 0.8480 - acc_2: 0.8740 - val_loss_1: 0.7813 - val_loss_2: 0.7554 - val_acc_ensemble: 0.8233 - val_acc_1: 0.7801 - val_acc_2: 0.7868\n",
      "Epoch 45/50\n",
      "100/100 - 6s - loss_1: 0.1634 - loss_2: 0.1824 - acc_ensemble: 0.9040 - acc_1: 0.8500 - acc_2: 0.8560 - val_loss_1: 0.7837 - val_loss_2: 0.7609 - val_acc_ensemble: 0.8204 - val_acc_1: 0.7825 - val_acc_2: 0.7822\n",
      "Epoch 46/50\n",
      "100/100 - 6s - loss_1: 0.1884 - loss_2: 0.1331 - acc_ensemble: 0.9120 - acc_1: 0.8680 - acc_2: 0.8780 - val_loss_1: 0.7855 - val_loss_2: 0.7413 - val_acc_ensemble: 0.8318 - val_acc_1: 0.7786 - val_acc_2: 0.7887\n",
      "Epoch 47/50\n",
      "100/100 - 6s - loss_1: 0.1243 - loss_2: 0.1029 - acc_ensemble: 0.9140 - acc_1: 0.8780 - acc_2: 0.8680 - val_loss_1: 0.7424 - val_loss_2: 0.7381 - val_acc_ensemble: 0.8343 - val_acc_1: 0.7957 - val_acc_2: 0.7976\n",
      "Epoch 48/50\n",
      "100/100 - 6s - loss_1: 0.0884 - loss_2: 0.1176 - acc_ensemble: 0.8960 - acc_1: 0.8600 - acc_2: 0.8740 - val_loss_1: 0.7720 - val_loss_2: 0.7960 - val_acc_ensemble: 0.8268 - val_acc_1: 0.7917 - val_acc_2: 0.7897\n",
      "Epoch 49/50\n",
      "100/100 - 6s - loss_1: 0.1024 - loss_2: 0.1138 - acc_ensemble: 0.9140 - acc_1: 0.8800 - acc_2: 0.8660 - val_loss_1: 0.7487 - val_loss_2: 0.7931 - val_acc_ensemble: 0.8311 - val_acc_1: 0.7948 - val_acc_2: 0.7894\n",
      "Epoch 50/50\n",
      "100/100 - 6s - loss_1: 0.1165 - loss_2: 0.0938 - acc_ensemble: 0.9140 - acc_1: 0.8460 - acc_2: 0.8820 - val_loss_1: 0.8024 - val_loss_2: 0.8297 - val_acc_ensemble: 0.8225 - val_acc_1: 0.7877 - val_acc_2: 0.7872\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B2/S0.25/model_1\n",
      "i   Layer name                      Output shape                     Num param  Inbound            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "0   conv2d_1_1 (Conv2D)             [None,32,32,8] [None,32,32,24]   1568       input              \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "1   bn_1_1 (BatchNormalization)     [None,32,32,8] [None,32,32,24]   112        conv2d_1_1         \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "2   relu_1_1 (Activation)           [None,32,32,8] [None,32,32,24]   0          bn_1_1             \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "3   conv2d_1_2 (Conv2D)             [None,32,32,8] [None,32,32,24]   17976      relu_1_1           \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "4   bn_1_2 (BatchNormalization)     [None,32,32,8] [None,32,32,24]   112        conv2d_1_2         \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "5   relu_1_2 (Activation)           [None,32,32,8] [None,32,32,24]   0          bn_1_2             \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "6   avg_pool2d_1 (AveragePooling2D  [None,16,16,8] [None,16,16,24]   0          relu_1_2           \n",
      "                                    [None,16,16,8] [None,16,16,24]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "7   conv2d_2_1 (Conv2D)             [None,16,16,16] [None,16,16,48]  35952      avg_pool2d_1       \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "8   bn_2_1 (BatchNormalization)     [None,16,16,16] [None,16,16,48]  224        conv2d_2_1         \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "9   relu_2_1 (Activation)           [None,16,16,16] [None,16,16,48]  0          bn_2_1             \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "10  conv2d_2_2 (Conv2D)             [None,16,16,16] [None,16,16,48]  71664      relu_2_1           \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "11  bn_2_2 (BatchNormalization)     [None,16,16,16] [None,16,16,48]  224        conv2d_2_2         \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "12  relu_2_2 (Activation)           [None,16,16,16] [None,16,16,48]  0          bn_2_2             \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "13  avg_pool2d_2 (AveragePooling2D  [None,8,8,16] [None,8,8,48]      0          relu_2_2           \n",
      "                                    [None,8,8,16] [None,8,8,48]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "14  conv2d_3_1 (Conv2D)             [None,8,8,32] [None,8,8,96]      143328     avg_pool2d_2       \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "15  bn_3_1 (BatchNormalization)     [None,8,8,32] [None,8,8,96]      448        conv2d_3_1         \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "16  relu_3_1 (Activation)           [None,8,8,32] [None,8,8,96]      0          bn_3_1             \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "17  conv2d_3_2 (Conv2D)             [None,8,8,32] [None,8,8,96]      286176     relu_3_1           \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "18  bn_3_2 (BatchNormalization)     [None,8,8,32] [None,8,8,96]      448        conv2d_3_2         \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "19  relu_3_2 (Activation)           [None,8,8,32] [None,8,8,96]      0          bn_3_2             \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "20  global_avg_pool2d (GlobalAvera  [None,32] [None,96]              0          relu_3_2           \n",
      "                                    [None,32] [None,96]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "21  fc1 (Dense)                     [None,32] [None,96]              32224      global_avg_pool2d  \n",
      "                                    [None,32] [None,96]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "22  bn_fc1 (BatchNormalization)     [None,32] [None,96]              448        fc1                \n",
      "                                    [None,32] [None,96]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "23  relu_fc1 (Activation)           [None,32] [None,96]              0          bn_fc1             \n",
      "                                    [None,32] [None,96]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "24  output (Dense)                  [None,10]                        2534       relu_fc1           \n",
      "                                    [None,10]                                                      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "Total parameters: 593438\n",
      "50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 - 17s - loss_1: 1.7849 - loss_2: 1.7734 - acc_ensemble: 0.4600 - acc_1: 0.4460 - acc_2: 0.4440 - val_loss_1: 1.5329 - val_loss_2: 1.5272 - val_acc_ensemble: 0.4589 - val_acc_1: 0.4331 - val_acc_2: 0.4291\n",
      "Epoch 2/50\n",
      "100/100 - 9s - loss_1: 1.4674 - loss_2: 1.4367 - acc_ensemble: 0.5380 - acc_1: 0.5200 - acc_2: 0.5040 - val_loss_1: 1.3516 - val_loss_2: 1.3606 - val_acc_ensemble: 0.5315 - val_acc_1: 0.5092 - val_acc_2: 0.5018\n",
      "Epoch 3/50\n",
      "100/100 - 9s - loss_1: 1.3053 - loss_2: 1.3036 - acc_ensemble: 0.5960 - acc_1: 0.5640 - acc_2: 0.5520 - val_loss_1: 1.2559 - val_loss_2: 1.2167 - val_acc_ensemble: 0.5873 - val_acc_1: 0.5464 - val_acc_2: 0.5684\n",
      "Epoch 4/50\n",
      "100/100 - 9s - loss_1: 1.1681 - loss_2: 1.1862 - acc_ensemble: 0.6380 - acc_1: 0.5960 - acc_2: 0.6000 - val_loss_1: 1.1642 - val_loss_2: 1.1745 - val_acc_ensemble: 0.6095 - val_acc_1: 0.5764 - val_acc_2: 0.5719\n",
      "Epoch 5/50\n",
      "100/100 - 9s - loss_1: 1.1023 - loss_2: 1.0581 - acc_ensemble: 0.6500 - acc_1: 0.5820 - acc_2: 0.6420 - val_loss_1: 1.1348 - val_loss_2: 1.0726 - val_acc_ensemble: 0.6415 - val_acc_1: 0.5908 - val_acc_2: 0.6174\n",
      "Epoch 6/50\n",
      "100/100 - 9s - loss_1: 1.0211 - loss_2: 0.9917 - acc_ensemble: 0.6740 - acc_1: 0.6480 - acc_2: 0.6640 - val_loss_1: 1.0099 - val_loss_2: 1.0168 - val_acc_ensemble: 0.6707 - val_acc_1: 0.6390 - val_acc_2: 0.6392\n",
      "Epoch 7/50\n",
      "100/100 - 9s - loss_1: 0.9424 - loss_2: 0.9475 - acc_ensemble: 0.7160 - acc_1: 0.6640 - acc_2: 0.7040 - val_loss_1: 0.9784 - val_loss_2: 0.9609 - val_acc_ensemble: 0.6876 - val_acc_1: 0.6531 - val_acc_2: 0.6548\n",
      "Epoch 8/50\n",
      "100/100 - 9s - loss_1: 0.8739 - loss_2: 0.8619 - acc_ensemble: 0.7300 - acc_1: 0.6740 - acc_2: 0.6920 - val_loss_1: 0.9500 - val_loss_2: 0.9209 - val_acc_ensemble: 0.6991 - val_acc_1: 0.6605 - val_acc_2: 0.6766\n",
      "Epoch 9/50\n",
      "100/100 - 9s - loss_1: 0.8173 - loss_2: 0.7861 - acc_ensemble: 0.7360 - acc_1: 0.6740 - acc_2: 0.7320 - val_loss_1: 0.9433 - val_loss_2: 0.8664 - val_acc_ensemble: 0.7168 - val_acc_1: 0.6699 - val_acc_2: 0.6972\n",
      "Epoch 10/50\n",
      "100/100 - 9s - loss_1: 0.8120 - loss_2: 0.7401 - acc_ensemble: 0.7840 - acc_1: 0.7240 - acc_2: 0.7480 - val_loss_1: 0.8831 - val_loss_2: 0.8861 - val_acc_ensemble: 0.7195 - val_acc_1: 0.6873 - val_acc_2: 0.6914\n",
      "Epoch 11/50\n",
      "100/100 - 9s - loss_1: 0.7435 - loss_2: 0.7357 - acc_ensemble: 0.7640 - acc_1: 0.7040 - acc_2: 0.7240 - val_loss_1: 0.8732 - val_loss_2: 0.8421 - val_acc_ensemble: 0.7333 - val_acc_1: 0.6858 - val_acc_2: 0.7032\n",
      "Epoch 12/50\n",
      "100/100 - 9s - loss_1: 0.7086 - loss_2: 0.6808 - acc_ensemble: 0.7900 - acc_1: 0.7020 - acc_2: 0.7560 - val_loss_1: 0.8526 - val_loss_2: 0.7990 - val_acc_ensemble: 0.7425 - val_acc_1: 0.6997 - val_acc_2: 0.7204\n",
      "Epoch 13/50\n",
      "100/100 - 9s - loss_1: 0.6738 - loss_2: 0.6726 - acc_ensemble: 0.7880 - acc_1: 0.7420 - acc_2: 0.7620 - val_loss_1: 0.8541 - val_loss_2: 0.8115 - val_acc_ensemble: 0.7505 - val_acc_1: 0.6982 - val_acc_2: 0.7198\n",
      "Epoch 14/50\n",
      "100/100 - 9s - loss_1: 0.6290 - loss_2: 0.6138 - acc_ensemble: 0.8180 - acc_1: 0.7420 - acc_2: 0.7880 - val_loss_1: 0.8297 - val_loss_2: 0.8073 - val_acc_ensemble: 0.7525 - val_acc_1: 0.7082 - val_acc_2: 0.7190\n",
      "Epoch 15/50\n",
      "100/100 - 9s - loss_1: 0.6065 - loss_2: 0.5844 - acc_ensemble: 0.8260 - acc_1: 0.7620 - acc_2: 0.7960 - val_loss_1: 0.7876 - val_loss_2: 0.7730 - val_acc_ensemble: 0.7670 - val_acc_1: 0.7239 - val_acc_2: 0.7314\n",
      "Epoch 16/50\n",
      "100/100 - 9s - loss_1: 0.5794 - loss_2: 0.5644 - acc_ensemble: 0.8260 - acc_1: 0.7960 - acc_2: 0.7880 - val_loss_1: 0.7727 - val_loss_2: 0.7826 - val_acc_ensemble: 0.7655 - val_acc_1: 0.7271 - val_acc_2: 0.7298\n",
      "Epoch 17/50\n",
      "100/100 - 9s - loss_1: 0.5366 - loss_2: 0.5226 - acc_ensemble: 0.8460 - acc_1: 0.7700 - acc_2: 0.8180 - val_loss_1: 0.8025 - val_loss_2: 0.7667 - val_acc_ensemble: 0.7650 - val_acc_1: 0.7274 - val_acc_2: 0.7352\n",
      "Epoch 18/50\n",
      "100/100 - 9s - loss_1: 0.4900 - loss_2: 0.5012 - acc_ensemble: 0.8420 - acc_1: 0.8000 - acc_2: 0.8280 - val_loss_1: 0.7777 - val_loss_2: 0.7293 - val_acc_ensemble: 0.7728 - val_acc_1: 0.7341 - val_acc_2: 0.7467\n",
      "Epoch 19/50\n",
      "100/100 - 9s - loss_1: 0.4795 - loss_2: 0.4766 - acc_ensemble: 0.8580 - acc_1: 0.7820 - acc_2: 0.8020 - val_loss_1: 0.7609 - val_loss_2: 0.7850 - val_acc_ensemble: 0.7699 - val_acc_1: 0.7383 - val_acc_2: 0.7339\n",
      "Epoch 20/50\n",
      "100/100 - 9s - loss_1: 0.4502 - loss_2: 0.4306 - acc_ensemble: 0.8700 - acc_1: 0.8000 - acc_2: 0.8140 - val_loss_1: 0.8008 - val_loss_2: 0.7744 - val_acc_ensemble: 0.7771 - val_acc_1: 0.7321 - val_acc_2: 0.7404\n",
      "Epoch 21/50\n",
      "100/100 - 9s - loss_1: 0.4274 - loss_2: 0.4054 - acc_ensemble: 0.8640 - acc_1: 0.8000 - acc_2: 0.8360 - val_loss_1: 0.7787 - val_loss_2: 0.7782 - val_acc_ensemble: 0.7790 - val_acc_1: 0.7417 - val_acc_2: 0.7385\n",
      "Epoch 22/50\n",
      "100/100 - 9s - loss_1: 0.4299 - loss_2: 0.3891 - acc_ensemble: 0.8460 - acc_1: 0.7980 - acc_2: 0.8360 - val_loss_1: 0.7821 - val_loss_2: 0.7364 - val_acc_ensemble: 0.7808 - val_acc_1: 0.7366 - val_acc_2: 0.7541\n",
      "Epoch 23/50\n",
      "100/100 - 9s - loss_1: 0.3905 - loss_2: 0.3556 - acc_ensemble: 0.8700 - acc_1: 0.8020 - acc_2: 0.8320 - val_loss_1: 0.7889 - val_loss_2: 0.7477 - val_acc_ensemble: 0.7871 - val_acc_1: 0.7415 - val_acc_2: 0.7522\n",
      "Epoch 24/50\n",
      "100/100 - 9s - loss_1: 0.3495 - loss_2: 0.3532 - acc_ensemble: 0.8860 - acc_1: 0.8100 - acc_2: 0.8540 - val_loss_1: 0.7751 - val_loss_2: 0.7667 - val_acc_ensemble: 0.7870 - val_acc_1: 0.7473 - val_acc_2: 0.7515\n",
      "Epoch 25/50\n",
      "100/100 - 9s - loss_1: 0.3193 - loss_2: 0.3094 - acc_ensemble: 0.8880 - acc_1: 0.8100 - acc_2: 0.8540 - val_loss_1: 0.7724 - val_loss_2: 0.7425 - val_acc_ensemble: 0.7902 - val_acc_1: 0.7546 - val_acc_2: 0.7566\n",
      "Epoch 26/50\n",
      "100/100 - 9s - loss_1: 0.3050 - loss_2: 0.3004 - acc_ensemble: 0.8880 - acc_1: 0.8140 - acc_2: 0.8480 - val_loss_1: 0.7732 - val_loss_2: 0.7836 - val_acc_ensemble: 0.7968 - val_acc_1: 0.7528 - val_acc_2: 0.7499\n",
      "Epoch 27/50\n",
      "100/100 - 9s - loss_1: 0.3087 - loss_2: 0.3105 - acc_ensemble: 0.8860 - acc_1: 0.8140 - acc_2: 0.8500 - val_loss_1: 0.7705 - val_loss_2: 0.7457 - val_acc_ensemble: 0.7943 - val_acc_1: 0.7491 - val_acc_2: 0.7608\n",
      "Epoch 28/50\n",
      "100/100 - 9s - loss_1: 0.2577 - loss_2: 0.2539 - acc_ensemble: 0.9060 - acc_1: 0.8560 - acc_2: 0.8480 - val_loss_1: 0.8171 - val_loss_2: 0.7811 - val_acc_ensemble: 0.7944 - val_acc_1: 0.7471 - val_acc_2: 0.7556\n",
      "Epoch 29/50\n",
      "100/100 - 9s - loss_1: 0.2418 - loss_2: 0.2985 - acc_ensemble: 0.8920 - acc_1: 0.8400 - acc_2: 0.8700 - val_loss_1: 0.8126 - val_loss_2: 0.7839 - val_acc_ensemble: 0.7935 - val_acc_1: 0.7481 - val_acc_2: 0.7555\n",
      "Epoch 30/50\n",
      "100/100 - 9s - loss_1: 0.2645 - loss_2: 0.2386 - acc_ensemble: 0.8840 - acc_1: 0.8260 - acc_2: 0.8300 - val_loss_1: 0.8050 - val_loss_2: 0.7942 - val_acc_ensemble: 0.7965 - val_acc_1: 0.7539 - val_acc_2: 0.7554\n",
      "Epoch 31/50\n",
      "100/100 - 9s - loss_1: 0.2262 - loss_2: 0.2339 - acc_ensemble: 0.8800 - acc_1: 0.8380 - acc_2: 0.8540 - val_loss_1: 0.8353 - val_loss_2: 0.7767 - val_acc_ensemble: 0.8006 - val_acc_1: 0.7506 - val_acc_2: 0.7619\n",
      "Epoch 32/50\n",
      "100/100 - 9s - loss_1: 0.2007 - loss_2: 0.1945 - acc_ensemble: 0.8880 - acc_1: 0.8260 - acc_2: 0.8580 - val_loss_1: 0.8378 - val_loss_2: 0.8057 - val_acc_ensemble: 0.7956 - val_acc_1: 0.7483 - val_acc_2: 0.7557\n",
      "Epoch 33/50\n",
      "100/100 - 9s - loss_1: 0.1734 - loss_2: 0.1983 - acc_ensemble: 0.8980 - acc_1: 0.8360 - acc_2: 0.8600 - val_loss_1: 0.8675 - val_loss_2: 0.7969 - val_acc_ensemble: 0.7950 - val_acc_1: 0.7429 - val_acc_2: 0.7597\n",
      "Epoch 34/50\n",
      "100/100 - 9s - loss_1: 0.1835 - loss_2: 0.1993 - acc_ensemble: 0.8920 - acc_1: 0.8200 - acc_2: 0.8540 - val_loss_1: 0.8761 - val_loss_2: 0.7993 - val_acc_ensemble: 0.7950 - val_acc_1: 0.7433 - val_acc_2: 0.7624\n",
      "Epoch 35/50\n",
      "100/100 - 9s - loss_1: 0.1654 - loss_2: 0.1740 - acc_ensemble: 0.9060 - acc_1: 0.8420 - acc_2: 0.8480 - val_loss_1: 0.8626 - val_loss_2: 0.8496 - val_acc_ensemble: 0.7899 - val_acc_1: 0.7516 - val_acc_2: 0.7525\n",
      "Epoch 36/50\n",
      "100/100 - 9s - loss_1: 0.1545 - loss_2: 0.1938 - acc_ensemble: 0.9000 - acc_1: 0.8400 - acc_2: 0.8760 - val_loss_1: 0.8799 - val_loss_2: 0.8145 - val_acc_ensemble: 0.7996 - val_acc_1: 0.7550 - val_acc_2: 0.7601\n",
      "Epoch 37/50\n",
      "100/100 - 9s - loss_1: 0.1465 - loss_2: 0.1467 - acc_ensemble: 0.9060 - acc_1: 0.8260 - acc_2: 0.8780 - val_loss_1: 0.8985 - val_loss_2: 0.8383 - val_acc_ensemble: 0.8019 - val_acc_1: 0.7478 - val_acc_2: 0.7621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50\n",
      "100/100 - 9s - loss_1: 0.1221 - loss_2: 0.1379 - acc_ensemble: 0.9000 - acc_1: 0.8320 - acc_2: 0.8660 - val_loss_1: 0.8914 - val_loss_2: 0.8389 - val_acc_ensemble: 0.8022 - val_acc_1: 0.7568 - val_acc_2: 0.7679\n",
      "Epoch 39/50\n",
      "100/100 - 9s - loss_1: 0.1384 - loss_2: 0.1328 - acc_ensemble: 0.9180 - acc_1: 0.8480 - acc_2: 0.8700 - val_loss_1: 0.9120 - val_loss_2: 0.8379 - val_acc_ensemble: 0.8018 - val_acc_1: 0.7548 - val_acc_2: 0.7686\n",
      "Epoch 40/50\n",
      "100/100 - 9s - loss_1: 0.1148 - loss_2: 0.1014 - acc_ensemble: 0.9180 - acc_1: 0.8500 - acc_2: 0.8680 - val_loss_1: 0.9196 - val_loss_2: 0.8617 - val_acc_ensemble: 0.8026 - val_acc_1: 0.7537 - val_acc_2: 0.7677\n",
      "Epoch 41/50\n",
      "100/100 - 9s - loss_1: 0.1366 - loss_2: 0.0786 - acc_ensemble: 0.9020 - acc_1: 0.8480 - acc_2: 0.8660 - val_loss_1: 0.9231 - val_loss_2: 0.8980 - val_acc_ensemble: 0.8006 - val_acc_1: 0.7514 - val_acc_2: 0.7635\n",
      "Epoch 42/50\n",
      "100/100 - 9s - loss_1: 0.1203 - loss_2: 0.0874 - acc_ensemble: 0.9040 - acc_1: 0.8420 - acc_2: 0.8580 - val_loss_1: 0.9816 - val_loss_2: 0.9432 - val_acc_ensemble: 0.7961 - val_acc_1: 0.7428 - val_acc_2: 0.7599\n",
      "Epoch 43/50\n",
      "100/100 - 9s - loss_1: 0.1314 - loss_2: 0.1163 - acc_ensemble: 0.9160 - acc_1: 0.8460 - acc_2: 0.8560 - val_loss_1: 0.9645 - val_loss_2: 0.9244 - val_acc_ensemble: 0.8028 - val_acc_1: 0.7519 - val_acc_2: 0.7578\n",
      "Epoch 44/50\n",
      "100/100 - 9s - loss_1: 0.1101 - loss_2: 0.1150 - acc_ensemble: 0.9200 - acc_1: 0.8540 - acc_2: 0.8620 - val_loss_1: 0.9328 - val_loss_2: 0.9456 - val_acc_ensemble: 0.8057 - val_acc_1: 0.7528 - val_acc_2: 0.7610\n",
      "Epoch 45/50\n",
      "100/100 - 9s - loss_1: 0.1207 - loss_2: 0.1144 - acc_ensemble: 0.9180 - acc_1: 0.8660 - acc_2: 0.8280 - val_loss_1: 0.9581 - val_loss_2: 1.0022 - val_acc_ensemble: 0.8000 - val_acc_1: 0.7529 - val_acc_2: 0.7478\n",
      "Epoch 46/50\n",
      "100/100 - 9s - loss_1: 0.1004 - loss_2: 0.1173 - acc_ensemble: 0.9220 - acc_1: 0.8680 - acc_2: 0.8560 - val_loss_1: 0.9353 - val_loss_2: 0.9469 - val_acc_ensemble: 0.8052 - val_acc_1: 0.7522 - val_acc_2: 0.7605\n",
      "Epoch 47/50\n",
      "100/100 - 9s - loss_1: 0.0847 - loss_2: 0.1062 - acc_ensemble: 0.9300 - acc_1: 0.8680 - acc_2: 0.8660 - val_loss_1: 0.9255 - val_loss_2: 0.9442 - val_acc_ensemble: 0.8064 - val_acc_1: 0.7657 - val_acc_2: 0.7638\n",
      "Epoch 48/50\n",
      "100/100 - 9s - loss_1: 0.0632 - loss_2: 0.0952 - acc_ensemble: 0.9240 - acc_1: 0.8560 - acc_2: 0.8640 - val_loss_1: 0.9725 - val_loss_2: 0.9497 - val_acc_ensemble: 0.8061 - val_acc_1: 0.7589 - val_acc_2: 0.7642\n",
      "Epoch 49/50\n",
      "100/100 - 9s - loss_1: 0.0693 - loss_2: 0.0731 - acc_ensemble: 0.9020 - acc_1: 0.8540 - acc_2: 0.8580 - val_loss_1: 0.9861 - val_loss_2: 0.9704 - val_acc_ensemble: 0.8037 - val_acc_1: 0.7592 - val_acc_2: 0.7645\n",
      "Epoch 50/50\n",
      "100/100 - 9s - loss_1: 0.0645 - loss_2: 0.0731 - acc_ensemble: 0.9320 - acc_1: 0.8480 - acc_2: 0.8860 - val_loss_1: 0.9909 - val_loss_2: 1.0674 - val_acc_ensemble: 0.7974 - val_acc_1: 0.7563 - val_acc_2: 0.7451\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B2/S0.25/model_2\n",
      "i   Layer name                      Output shape                     Num param  Inbound            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "0   conv2d_1_1 (Conv2D)             [None,32,32,8] [None,32,32,24]   1568       input              \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "1   bn_1_1 (BatchNormalization)     [None,32,32,8] [None,32,32,24]   112        conv2d_1_1         \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "2   relu_1_1 (Activation)           [None,32,32,8] [None,32,32,24]   0          bn_1_1             \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "3   conv2d_1_2 (Conv2D)             [None,32,32,8] [None,32,32,24]   17976      relu_1_1           \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "4   bn_1_2 (BatchNormalization)     [None,32,32,8] [None,32,32,24]   112        conv2d_1_2         \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "5   relu_1_2 (Activation)           [None,32,32,8] [None,32,32,24]   0          bn_1_2             \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "6   avg_pool2d_1 (AveragePooling2D  [None,16,16,8] [None,16,16,24]   0          relu_1_2           \n",
      "                                    [None,16,16,8] [None,16,16,24]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "7   conv2d_2_1 (Conv2D)             [None,16,16,16] [None,16,16,48]  35952      avg_pool2d_1       \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "8   bn_2_1 (BatchNormalization)     [None,16,16,16] [None,16,16,48]  224        conv2d_2_1         \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "9   relu_2_1 (Activation)           [None,16,16,16] [None,16,16,48]  0          bn_2_1             \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "10  conv2d_2_2 (Conv2D)             [None,16,16,16] [None,16,16,48]  71664      relu_2_1           \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "11  bn_2_2 (BatchNormalization)     [None,16,16,16] [None,16,16,48]  224        conv2d_2_2         \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "12  relu_2_2 (Activation)           [None,16,16,16] [None,16,16,48]  0          bn_2_2             \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "13  avg_pool2d_2 (AveragePooling2D  [None,8,8,16] [None,8,8,48]      0          relu_2_2           \n",
      "                                    [None,8,8,16] [None,8,8,48]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "14  conv2d_3_1 (Conv2D)             [None,8,8,32] [None,8,8,96]      143328     avg_pool2d_2       \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "15  bn_3_1 (BatchNormalization)     [None,8,8,32] [None,8,8,96]      448        conv2d_3_1         \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "16  relu_3_1 (Activation)           [None,8,8,32] [None,8,8,96]      0          bn_3_1             \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "17  conv2d_3_2 (Conv2D)             [None,8,8,32] [None,8,8,96]      286176     relu_3_1           \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "18  bn_3_2 (BatchNormalization)     [None,8,8,32] [None,8,8,96]      448        conv2d_3_2         \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "19  relu_3_2 (Activation)           [None,8,8,32] [None,8,8,96]      0          bn_3_2             \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "20  global_avg_pool2d (GlobalAvera  [None,32] [None,96]              0          relu_3_2           \n",
      "                                    [None,32] [None,96]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "21  fc1 (Dense)                     [None,32] [None,96]              32224      global_avg_pool2d  \n",
      "                                    [None,32] [None,96]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "22  bn_fc1 (BatchNormalization)     [None,32] [None,96]              448        fc1                \n",
      "                                    [None,32] [None,96]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "23  relu_fc1 (Activation)           [None,32] [None,96]              0          bn_fc1             \n",
      "                                    [None,32] [None,96]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "24  output (Dense)                  [None,10]                        2534       relu_fc1           \n",
      "                                    [None,10]                                                      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "Total parameters: 593438\n",
      "50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 - 13s - loss_1: 1.7883 - loss_2: 1.7662 - acc_ensemble: 0.4520 - acc_1: 0.4160 - acc_2: 0.4180 - val_loss_1: 1.5416 - val_loss_2: 1.5466 - val_acc_ensemble: 0.4564 - val_acc_1: 0.4227 - val_acc_2: 0.4240\n",
      "Epoch 2/50\n",
      "100/100 - 9s - loss_1: 1.4838 - loss_2: 1.4601 - acc_ensemble: 0.5340 - acc_1: 0.5040 - acc_2: 0.5300 - val_loss_1: 1.3546 - val_loss_2: 1.3906 - val_acc_ensemble: 0.5257 - val_acc_1: 0.4894 - val_acc_2: 0.4863\n",
      "Epoch 3/50\n",
      "100/100 - 9s - loss_1: 1.3070 - loss_2: 1.2982 - acc_ensemble: 0.6100 - acc_1: 0.5920 - acc_2: 0.5640 - val_loss_1: 1.2581 - val_loss_2: 1.2101 - val_acc_ensemble: 0.5904 - val_acc_1: 0.5400 - val_acc_2: 0.5590\n",
      "Epoch 4/50\n",
      "100/100 - 9s - loss_1: 1.1963 - loss_2: 1.1435 - acc_ensemble: 0.6420 - acc_1: 0.5740 - acc_2: 0.6240 - val_loss_1: 1.1713 - val_loss_2: 1.1320 - val_acc_ensemble: 0.6192 - val_acc_1: 0.5805 - val_acc_2: 0.5888\n",
      "Epoch 5/50\n",
      "100/100 - 9s - loss_1: 1.1014 - loss_2: 1.0839 - acc_ensemble: 0.6840 - acc_1: 0.6120 - acc_2: 0.6840 - val_loss_1: 1.0824 - val_loss_2: 1.0693 - val_acc_ensemble: 0.6493 - val_acc_1: 0.6116 - val_acc_2: 0.6140\n",
      "Epoch 6/50\n",
      "100/100 - 9s - loss_1: 0.9910 - loss_2: 0.9917 - acc_ensemble: 0.6920 - acc_1: 0.6540 - acc_2: 0.6480 - val_loss_1: 1.0408 - val_loss_2: 1.0211 - val_acc_ensemble: 0.6696 - val_acc_1: 0.6295 - val_acc_2: 0.6337\n",
      "Epoch 7/50\n",
      "100/100 - 9s - loss_1: 0.9647 - loss_2: 0.9339 - acc_ensemble: 0.7000 - acc_1: 0.6100 - acc_2: 0.7100 - val_loss_1: 1.0133 - val_loss_2: 0.9846 - val_acc_ensemble: 0.6795 - val_acc_1: 0.6370 - val_acc_2: 0.6506\n",
      "Epoch 8/50\n",
      "100/100 - 9s - loss_1: 0.8743 - loss_2: 0.8917 - acc_ensemble: 0.7220 - acc_1: 0.6700 - acc_2: 0.6900 - val_loss_1: 0.9650 - val_loss_2: 0.9660 - val_acc_ensemble: 0.6906 - val_acc_1: 0.6601 - val_acc_2: 0.6584\n",
      "Epoch 9/50\n",
      "100/100 - 9s - loss_1: 0.8617 - loss_2: 0.8438 - acc_ensemble: 0.7460 - acc_1: 0.7060 - acc_2: 0.6960 - val_loss_1: 0.9197 - val_loss_2: 0.9226 - val_acc_ensemble: 0.7046 - val_acc_1: 0.6730 - val_acc_2: 0.6741\n",
      "Epoch 10/50\n",
      "100/100 - 9s - loss_1: 0.7914 - loss_2: 0.8026 - acc_ensemble: 0.7560 - acc_1: 0.7340 - acc_2: 0.7240 - val_loss_1: 0.9038 - val_loss_2: 0.9342 - val_acc_ensemble: 0.7104 - val_acc_1: 0.6859 - val_acc_2: 0.6682\n",
      "Epoch 11/50\n",
      "100/100 - 9s - loss_1: 0.7585 - loss_2: 0.7498 - acc_ensemble: 0.7760 - acc_1: 0.7300 - acc_2: 0.7400 - val_loss_1: 0.8734 - val_loss_2: 0.8830 - val_acc_ensemble: 0.7196 - val_acc_1: 0.6927 - val_acc_2: 0.6913\n",
      "Epoch 12/50\n",
      "100/100 - 9s - loss_1: 0.7370 - loss_2: 0.7411 - acc_ensemble: 0.7800 - acc_1: 0.7220 - acc_2: 0.7320 - val_loss_1: 0.8752 - val_loss_2: 0.8472 - val_acc_ensemble: 0.7345 - val_acc_1: 0.6955 - val_acc_2: 0.6985\n",
      "Epoch 13/50\n",
      "100/100 - 9s - loss_1: 0.6455 - loss_2: 0.6685 - acc_ensemble: 0.8000 - acc_1: 0.7420 - acc_2: 0.7580 - val_loss_1: 0.8361 - val_loss_2: 0.8333 - val_acc_ensemble: 0.7432 - val_acc_1: 0.7097 - val_acc_2: 0.7057\n",
      "Epoch 14/50\n",
      "100/100 - 9s - loss_1: 0.6125 - loss_2: 0.6272 - acc_ensemble: 0.8240 - acc_1: 0.7680 - acc_2: 0.7780 - val_loss_1: 0.8151 - val_loss_2: 0.8225 - val_acc_ensemble: 0.7480 - val_acc_1: 0.7195 - val_acc_2: 0.7125\n",
      "Epoch 15/50\n",
      "100/100 - 9s - loss_1: 0.5827 - loss_2: 0.5971 - acc_ensemble: 0.8080 - acc_1: 0.7580 - acc_2: 0.7480 - val_loss_1: 0.8321 - val_loss_2: 0.8225 - val_acc_ensemble: 0.7506 - val_acc_1: 0.7115 - val_acc_2: 0.7197\n",
      "Epoch 16/50\n",
      "100/100 - 9s - loss_1: 0.5727 - loss_2: 0.5540 - acc_ensemble: 0.8400 - acc_1: 0.7800 - acc_2: 0.7900 - val_loss_1: 0.8227 - val_loss_2: 0.8063 - val_acc_ensemble: 0.7582 - val_acc_1: 0.7159 - val_acc_2: 0.7225\n",
      "Epoch 17/50\n",
      "100/100 - 9s - loss_1: 0.5568 - loss_2: 0.5260 - acc_ensemble: 0.8320 - acc_1: 0.7980 - acc_2: 0.8000 - val_loss_1: 0.7998 - val_loss_2: 0.7990 - val_acc_ensemble: 0.7612 - val_acc_1: 0.7272 - val_acc_2: 0.7270\n",
      "Epoch 18/50\n",
      "100/100 - 9s - loss_1: 0.5132 - loss_2: 0.5101 - acc_ensemble: 0.8340 - acc_1: 0.7860 - acc_2: 0.8000 - val_loss_1: 0.7929 - val_loss_2: 0.7891 - val_acc_ensemble: 0.7679 - val_acc_1: 0.7318 - val_acc_2: 0.7305\n",
      "Epoch 19/50\n",
      "100/100 - 9s - loss_1: 0.4810 - loss_2: 0.4782 - acc_ensemble: 0.8420 - acc_1: 0.7920 - acc_2: 0.8160 - val_loss_1: 0.7869 - val_loss_2: 0.7817 - val_acc_ensemble: 0.7676 - val_acc_1: 0.7314 - val_acc_2: 0.7352\n",
      "Epoch 20/50\n",
      "100/100 - 9s - loss_1: 0.4390 - loss_2: 0.4640 - acc_ensemble: 0.8440 - acc_1: 0.7960 - acc_2: 0.8160 - val_loss_1: 0.7939 - val_loss_2: 0.7633 - val_acc_ensemble: 0.7721 - val_acc_1: 0.7315 - val_acc_2: 0.7394\n",
      "Epoch 21/50\n",
      "100/100 - 9s - loss_1: 0.4176 - loss_2: 0.4647 - acc_ensemble: 0.8460 - acc_1: 0.8120 - acc_2: 0.8020 - val_loss_1: 0.7831 - val_loss_2: 0.7842 - val_acc_ensemble: 0.7754 - val_acc_1: 0.7380 - val_acc_2: 0.7363\n",
      "Epoch 22/50\n",
      "100/100 - 9s - loss_1: 0.3801 - loss_2: 0.4011 - acc_ensemble: 0.8600 - acc_1: 0.8020 - acc_2: 0.8220 - val_loss_1: 0.7857 - val_loss_2: 0.7901 - val_acc_ensemble: 0.7748 - val_acc_1: 0.7427 - val_acc_2: 0.7401\n",
      "Epoch 23/50\n",
      "100/100 - 9s - loss_1: 0.4026 - loss_2: 0.4192 - acc_ensemble: 0.8740 - acc_1: 0.8200 - acc_2: 0.8360 - val_loss_1: 0.7801 - val_loss_2: 0.7961 - val_acc_ensemble: 0.7795 - val_acc_1: 0.7469 - val_acc_2: 0.7380\n",
      "Epoch 24/50\n",
      "100/100 - 9s - loss_1: 0.3728 - loss_2: 0.3488 - acc_ensemble: 0.8680 - acc_1: 0.8040 - acc_2: 0.8300 - val_loss_1: 0.8016 - val_loss_2: 0.7682 - val_acc_ensemble: 0.7825 - val_acc_1: 0.7392 - val_acc_2: 0.7481\n",
      "Epoch 25/50\n",
      "100/100 - 9s - loss_1: 0.3177 - loss_2: 0.3270 - acc_ensemble: 0.8760 - acc_1: 0.8360 - acc_2: 0.8040 - val_loss_1: 0.7786 - val_loss_2: 0.7807 - val_acc_ensemble: 0.7884 - val_acc_1: 0.7509 - val_acc_2: 0.7511\n",
      "Epoch 26/50\n",
      "100/100 - 9s - loss_1: 0.3179 - loss_2: 0.2970 - acc_ensemble: 0.8740 - acc_1: 0.8260 - acc_2: 0.8380 - val_loss_1: 0.7767 - val_loss_2: 0.8544 - val_acc_ensemble: 0.7861 - val_acc_1: 0.7482 - val_acc_2: 0.7381\n",
      "Epoch 27/50\n",
      "100/100 - 9s - loss_1: 0.3055 - loss_2: 0.3039 - acc_ensemble: 0.8720 - acc_1: 0.8320 - acc_2: 0.8560 - val_loss_1: 0.7947 - val_loss_2: 0.7951 - val_acc_ensemble: 0.7901 - val_acc_1: 0.7470 - val_acc_2: 0.7523\n",
      "Epoch 28/50\n",
      "100/100 - 9s - loss_1: 0.2741 - loss_2: 0.2848 - acc_ensemble: 0.8820 - acc_1: 0.8220 - acc_2: 0.8540 - val_loss_1: 0.8266 - val_loss_2: 0.8078 - val_acc_ensemble: 0.7868 - val_acc_1: 0.7462 - val_acc_2: 0.7454\n",
      "Epoch 29/50\n",
      "100/100 - 9s - loss_1: 0.2293 - loss_2: 0.2775 - acc_ensemble: 0.8780 - acc_1: 0.8160 - acc_2: 0.8500 - val_loss_1: 0.8373 - val_loss_2: 0.8060 - val_acc_ensemble: 0.7912 - val_acc_1: 0.7502 - val_acc_2: 0.7516\n",
      "Epoch 30/50\n",
      "100/100 - 9s - loss_1: 0.2201 - loss_2: 0.2247 - acc_ensemble: 0.9100 - acc_1: 0.8260 - acc_2: 0.8500 - val_loss_1: 0.8890 - val_loss_2: 0.8045 - val_acc_ensemble: 0.7866 - val_acc_1: 0.7355 - val_acc_2: 0.7568\n",
      "Epoch 31/50\n",
      "100/100 - 9s - loss_1: 0.2179 - loss_2: 0.2262 - acc_ensemble: 0.8920 - acc_1: 0.8380 - acc_2: 0.8560 - val_loss_1: 0.8258 - val_loss_2: 0.8000 - val_acc_ensemble: 0.7933 - val_acc_1: 0.7538 - val_acc_2: 0.7602\n",
      "Epoch 32/50\n",
      "100/100 - 9s - loss_1: 0.2037 - loss_2: 0.2184 - acc_ensemble: 0.8900 - acc_1: 0.8280 - acc_2: 0.8340 - val_loss_1: 0.8571 - val_loss_2: 0.8289 - val_acc_ensemble: 0.7932 - val_acc_1: 0.7494 - val_acc_2: 0.7536\n",
      "Epoch 33/50\n",
      "100/100 - 9s - loss_1: 0.2070 - loss_2: 0.1800 - acc_ensemble: 0.8900 - acc_1: 0.8260 - acc_2: 0.8660 - val_loss_1: 0.8474 - val_loss_2: 0.8254 - val_acc_ensemble: 0.7943 - val_acc_1: 0.7538 - val_acc_2: 0.7573\n",
      "Epoch 34/50\n",
      "100/100 - 9s - loss_1: 0.1675 - loss_2: 0.1929 - acc_ensemble: 0.8920 - acc_1: 0.8280 - acc_2: 0.8460 - val_loss_1: 0.8732 - val_loss_2: 0.8714 - val_acc_ensemble: 0.7926 - val_acc_1: 0.7503 - val_acc_2: 0.7465\n",
      "Epoch 35/50\n",
      "100/100 - 9s - loss_1: 0.2007 - loss_2: 0.1665 - acc_ensemble: 0.8840 - acc_1: 0.8360 - acc_2: 0.8700 - val_loss_1: 0.8647 - val_loss_2: 0.8599 - val_acc_ensemble: 0.7949 - val_acc_1: 0.7549 - val_acc_2: 0.7565\n",
      "Epoch 36/50\n",
      "100/100 - 9s - loss_1: 0.1815 - loss_2: 0.1537 - acc_ensemble: 0.9020 - acc_1: 0.8580 - acc_2: 0.8500 - val_loss_1: 0.8997 - val_loss_2: 0.8874 - val_acc_ensemble: 0.7970 - val_acc_1: 0.7476 - val_acc_2: 0.7513\n",
      "Epoch 37/50\n",
      "100/100 - 9s - loss_1: 0.1574 - loss_2: 0.1554 - acc_ensemble: 0.9040 - acc_1: 0.8420 - acc_2: 0.8580 - val_loss_1: 0.8857 - val_loss_2: 0.8710 - val_acc_ensemble: 0.7991 - val_acc_1: 0.7565 - val_acc_2: 0.7531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50\n",
      "100/100 - 9s - loss_1: 0.1397 - loss_2: 0.1461 - acc_ensemble: 0.9060 - acc_1: 0.8740 - acc_2: 0.8680 - val_loss_1: 0.8688 - val_loss_2: 0.9127 - val_acc_ensemble: 0.8006 - val_acc_1: 0.7601 - val_acc_2: 0.7567\n",
      "Epoch 39/50\n",
      "100/100 - 9s - loss_1: 0.1547 - loss_2: 0.1442 - acc_ensemble: 0.8940 - acc_1: 0.8640 - acc_2: 0.8600 - val_loss_1: 0.9116 - val_loss_2: 0.9124 - val_acc_ensemble: 0.7934 - val_acc_1: 0.7563 - val_acc_2: 0.7548\n",
      "Epoch 40/50\n",
      "100/100 - 9s - loss_1: 0.1167 - loss_2: 0.1382 - acc_ensemble: 0.9180 - acc_1: 0.8280 - acc_2: 0.8600 - val_loss_1: 0.9219 - val_loss_2: 0.9399 - val_acc_ensemble: 0.7964 - val_acc_1: 0.7573 - val_acc_2: 0.7506\n",
      "Epoch 41/50\n",
      "100/100 - 9s - loss_1: 0.1115 - loss_2: 0.1375 - acc_ensemble: 0.9200 - acc_1: 0.8680 - acc_2: 0.8560 - val_loss_1: 0.9083 - val_loss_2: 0.9467 - val_acc_ensemble: 0.7977 - val_acc_1: 0.7623 - val_acc_2: 0.7442\n",
      "Epoch 42/50\n",
      "100/100 - 9s - loss_1: 0.0972 - loss_2: 0.1255 - acc_ensemble: 0.9180 - acc_1: 0.8540 - acc_2: 0.8600 - val_loss_1: 0.9359 - val_loss_2: 0.9416 - val_acc_ensemble: 0.8022 - val_acc_1: 0.7551 - val_acc_2: 0.7528\n",
      "Epoch 43/50\n",
      "100/100 - 9s - loss_1: 0.1095 - loss_2: 0.1155 - acc_ensemble: 0.9140 - acc_1: 0.8300 - acc_2: 0.8760 - val_loss_1: 0.9573 - val_loss_2: 0.9953 - val_acc_ensemble: 0.7943 - val_acc_1: 0.7588 - val_acc_2: 0.7475\n",
      "Epoch 44/50\n",
      "100/100 - 9s - loss_1: 0.1196 - loss_2: 0.0881 - acc_ensemble: 0.9200 - acc_1: 0.8460 - acc_2: 0.8820 - val_loss_1: 1.0117 - val_loss_2: 0.9708 - val_acc_ensemble: 0.7989 - val_acc_1: 0.7509 - val_acc_2: 0.7521\n",
      "Epoch 45/50\n",
      "100/100 - 9s - loss_1: 0.1200 - loss_2: 0.1014 - acc_ensemble: 0.9060 - acc_1: 0.8280 - acc_2: 0.8880 - val_loss_1: 0.9902 - val_loss_2: 1.0238 - val_acc_ensemble: 0.7983 - val_acc_1: 0.7490 - val_acc_2: 0.7471\n",
      "Epoch 46/50\n",
      "100/100 - 9s - loss_1: 0.1217 - loss_2: 0.1015 - acc_ensemble: 0.9180 - acc_1: 0.8600 - acc_2: 0.8520 - val_loss_1: 0.9509 - val_loss_2: 1.0059 - val_acc_ensemble: 0.7940 - val_acc_1: 0.7595 - val_acc_2: 0.7439\n",
      "Epoch 47/50\n",
      "100/100 - 9s - loss_1: 0.1021 - loss_2: 0.0790 - acc_ensemble: 0.9220 - acc_1: 0.8580 - acc_2: 0.8840 - val_loss_1: 0.9496 - val_loss_2: 0.9523 - val_acc_ensemble: 0.8027 - val_acc_1: 0.7610 - val_acc_2: 0.7685\n",
      "Epoch 48/50\n",
      "100/100 - 9s - loss_1: 0.0990 - loss_2: 0.0957 - acc_ensemble: 0.9060 - acc_1: 0.8540 - acc_2: 0.8660 - val_loss_1: 1.0017 - val_loss_2: 1.0235 - val_acc_ensemble: 0.8018 - val_acc_1: 0.7565 - val_acc_2: 0.7541\n",
      "Epoch 49/50\n",
      "100/100 - 9s - loss_1: 0.0805 - loss_2: 0.0774 - acc_ensemble: 0.9180 - acc_1: 0.8600 - acc_2: 0.8820 - val_loss_1: 1.0445 - val_loss_2: 1.0101 - val_acc_ensemble: 0.7991 - val_acc_1: 0.7487 - val_acc_2: 0.7599\n",
      "Epoch 50/50\n",
      "100/100 - 9s - loss_1: 0.0824 - loss_2: 0.0791 - acc_ensemble: 0.9180 - acc_1: 0.8580 - acc_2: 0.8800 - val_loss_1: 0.9624 - val_loss_2: 1.0374 - val_acc_ensemble: 0.8042 - val_acc_1: 0.7623 - val_acc_2: 0.7548\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B2/S0.25/model_3\n",
      "i   Layer name                      Output shape                     Num param  Inbound            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "0   conv2d_1_1 (Conv2D)             [None,32,32,8] [None,32,32,24]   1568       input              \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "1   bn_1_1 (BatchNormalization)     [None,32,32,8] [None,32,32,24]   112        conv2d_1_1         \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "2   relu_1_1 (Activation)           [None,32,32,8] [None,32,32,24]   0          bn_1_1             \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "3   conv2d_1_2 (Conv2D)             [None,32,32,8] [None,32,32,24]   17976      relu_1_1           \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "4   bn_1_2 (BatchNormalization)     [None,32,32,8] [None,32,32,24]   112        conv2d_1_2         \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "5   relu_1_2 (Activation)           [None,32,32,8] [None,32,32,24]   0          bn_1_2             \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "6   avg_pool2d_1 (AveragePooling2D  [None,16,16,8] [None,16,16,24]   0          relu_1_2           \n",
      "                                    [None,16,16,8] [None,16,16,24]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "7   conv2d_2_1 (Conv2D)             [None,16,16,16] [None,16,16,48]  35952      avg_pool2d_1       \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "8   bn_2_1 (BatchNormalization)     [None,16,16,16] [None,16,16,48]  224        conv2d_2_1         \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "9   relu_2_1 (Activation)           [None,16,16,16] [None,16,16,48]  0          bn_2_1             \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "10  conv2d_2_2 (Conv2D)             [None,16,16,16] [None,16,16,48]  71664      relu_2_1           \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "11  bn_2_2 (BatchNormalization)     [None,16,16,16] [None,16,16,48]  224        conv2d_2_2         \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "12  relu_2_2 (Activation)           [None,16,16,16] [None,16,16,48]  0          bn_2_2             \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "13  avg_pool2d_2 (AveragePooling2D  [None,8,8,16] [None,8,8,48]      0          relu_2_2           \n",
      "                                    [None,8,8,16] [None,8,8,48]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "14  conv2d_3_1 (Conv2D)             [None,8,8,32] [None,8,8,96]      143328     avg_pool2d_2       \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "15  bn_3_1 (BatchNormalization)     [None,8,8,32] [None,8,8,96]      448        conv2d_3_1         \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "16  relu_3_1 (Activation)           [None,8,8,32] [None,8,8,96]      0          bn_3_1             \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "17  conv2d_3_2 (Conv2D)             [None,8,8,32] [None,8,8,96]      286176     relu_3_1           \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "18  bn_3_2 (BatchNormalization)     [None,8,8,32] [None,8,8,96]      448        conv2d_3_2         \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "19  relu_3_2 (Activation)           [None,8,8,32] [None,8,8,96]      0          bn_3_2             \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "20  global_avg_pool2d (GlobalAvera  [None,32] [None,96]              0          relu_3_2           \n",
      "                                    [None,32] [None,96]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "21  fc1 (Dense)                     [None,32] [None,96]              32224      global_avg_pool2d  \n",
      "                                    [None,32] [None,96]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "22  bn_fc1 (BatchNormalization)     [None,32] [None,96]              448        fc1                \n",
      "                                    [None,32] [None,96]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "23  relu_fc1 (Activation)           [None,32] [None,96]              0          bn_fc1             \n",
      "                                    [None,32] [None,96]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "24  output (Dense)                  [None,10]                        2534       relu_fc1           \n",
      "                                    [None,10]                                                      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "Total parameters: 593438\n",
      "50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 - 13s - loss_1: 1.7689 - loss_2: 1.7475 - acc_ensemble: 0.4880 - acc_1: 0.4480 - acc_2: 0.4720 - val_loss_1: 1.5158 - val_loss_2: 1.5117 - val_acc_ensemble: 0.4693 - val_acc_1: 0.4482 - val_acc_2: 0.4396\n",
      "Epoch 2/50\n",
      "100/100 - 9s - loss_1: 1.4648 - loss_2: 1.4611 - acc_ensemble: 0.5620 - acc_1: 0.5100 - acc_2: 0.5520 - val_loss_1: 1.3652 - val_loss_2: 1.3493 - val_acc_ensemble: 0.5376 - val_acc_1: 0.5012 - val_acc_2: 0.5072\n",
      "Epoch 3/50\n",
      "100/100 - 9s - loss_1: 1.2993 - loss_2: 1.3029 - acc_ensemble: 0.6100 - acc_1: 0.5860 - acc_2: 0.5800 - val_loss_1: 1.2622 - val_loss_2: 1.2706 - val_acc_ensemble: 0.5719 - val_acc_1: 0.5366 - val_acc_2: 0.5367\n",
      "Epoch 4/50\n",
      "100/100 - 9s - loss_1: 1.1706 - loss_2: 1.1731 - acc_ensemble: 0.6660 - acc_1: 0.6520 - acc_2: 0.6420 - val_loss_1: 1.1227 - val_loss_2: 1.1656 - val_acc_ensemble: 0.6177 - val_acc_1: 0.5952 - val_acc_2: 0.5824\n",
      "Epoch 5/50\n",
      "100/100 - 9s - loss_1: 1.0529 - loss_2: 1.0919 - acc_ensemble: 0.6660 - acc_1: 0.6400 - acc_2: 0.6080 - val_loss_1: 1.0482 - val_loss_2: 1.0685 - val_acc_ensemble: 0.6567 - val_acc_1: 0.6325 - val_acc_2: 0.6169\n",
      "Epoch 6/50\n",
      "100/100 - 9s - loss_1: 1.0185 - loss_2: 1.0233 - acc_ensemble: 0.7260 - acc_1: 0.6880 - acc_2: 0.6820 - val_loss_1: 0.9966 - val_loss_2: 1.0398 - val_acc_ensemble: 0.6681 - val_acc_1: 0.6431 - val_acc_2: 0.6304\n",
      "Epoch 7/50\n",
      "100/100 - 9s - loss_1: 0.9216 - loss_2: 0.9214 - acc_ensemble: 0.7380 - acc_1: 0.6840 - acc_2: 0.7020 - val_loss_1: 0.9990 - val_loss_2: 0.9697 - val_acc_ensemble: 0.6855 - val_acc_1: 0.6474 - val_acc_2: 0.6581\n",
      "Epoch 8/50\n",
      "100/100 - 9s - loss_1: 0.8730 - loss_2: 0.9190 - acc_ensemble: 0.7480 - acc_1: 0.7180 - acc_2: 0.7060 - val_loss_1: 0.9575 - val_loss_2: 0.9316 - val_acc_ensemble: 0.6984 - val_acc_1: 0.6647 - val_acc_2: 0.6672\n",
      "Epoch 9/50\n",
      "100/100 - 9s - loss_1: 0.8239 - loss_2: 0.8773 - acc_ensemble: 0.7620 - acc_1: 0.7440 - acc_2: 0.6960 - val_loss_1: 0.9084 - val_loss_2: 0.9226 - val_acc_ensemble: 0.7099 - val_acc_1: 0.6792 - val_acc_2: 0.6695\n",
      "Epoch 10/50\n",
      "100/100 - 9s - loss_1: 0.7556 - loss_2: 0.8098 - acc_ensemble: 0.7580 - acc_1: 0.7380 - acc_2: 0.7160 - val_loss_1: 0.8650 - val_loss_2: 0.8993 - val_acc_ensemble: 0.7202 - val_acc_1: 0.6915 - val_acc_2: 0.6825\n",
      "Epoch 11/50\n",
      "100/100 - 9s - loss_1: 0.7210 - loss_2: 0.7453 - acc_ensemble: 0.7720 - acc_1: 0.7300 - acc_2: 0.7340 - val_loss_1: 0.8638 - val_loss_2: 0.8862 - val_acc_ensemble: 0.7189 - val_acc_1: 0.6955 - val_acc_2: 0.6865\n",
      "Epoch 12/50\n",
      "100/100 - 9s - loss_1: 0.7048 - loss_2: 0.6922 - acc_ensemble: 0.7980 - acc_1: 0.7380 - acc_2: 0.7720 - val_loss_1: 0.8599 - val_loss_2: 0.8453 - val_acc_ensemble: 0.7395 - val_acc_1: 0.6979 - val_acc_2: 0.7078\n",
      "Epoch 13/50\n",
      "100/100 - 9s - loss_1: 0.6548 - loss_2: 0.6609 - acc_ensemble: 0.7980 - acc_1: 0.7860 - acc_2: 0.7460 - val_loss_1: 0.8161 - val_loss_2: 0.8220 - val_acc_ensemble: 0.7492 - val_acc_1: 0.7175 - val_acc_2: 0.7124\n",
      "Epoch 14/50\n",
      "100/100 - 9s - loss_1: 0.6586 - loss_2: 0.6211 - acc_ensemble: 0.7800 - acc_1: 0.7580 - acc_2: 0.7440 - val_loss_1: 0.8257 - val_loss_2: 0.8248 - val_acc_ensemble: 0.7443 - val_acc_1: 0.7110 - val_acc_2: 0.7125\n",
      "Epoch 15/50\n",
      "100/100 - 9s - loss_1: 0.5607 - loss_2: 0.6233 - acc_ensemble: 0.8080 - acc_1: 0.7780 - acc_2: 0.7580 - val_loss_1: 0.8082 - val_loss_2: 0.7901 - val_acc_ensemble: 0.7537 - val_acc_1: 0.7185 - val_acc_2: 0.7270\n",
      "Epoch 16/50\n",
      "100/100 - 9s - loss_1: 0.5532 - loss_2: 0.5723 - acc_ensemble: 0.8160 - acc_1: 0.7860 - acc_2: 0.7680 - val_loss_1: 0.8144 - val_loss_2: 0.7893 - val_acc_ensemble: 0.7609 - val_acc_1: 0.7187 - val_acc_2: 0.7269\n",
      "Epoch 17/50\n",
      "100/100 - 9s - loss_1: 0.5415 - loss_2: 0.5200 - acc_ensemble: 0.8120 - acc_1: 0.8040 - acc_2: 0.7740 - val_loss_1: 0.7653 - val_loss_2: 0.7732 - val_acc_ensemble: 0.7688 - val_acc_1: 0.7339 - val_acc_2: 0.7357\n",
      "Epoch 18/50\n",
      "100/100 - 9s - loss_1: 0.4939 - loss_2: 0.5152 - acc_ensemble: 0.8240 - acc_1: 0.8040 - acc_2: 0.7880 - val_loss_1: 0.7855 - val_loss_2: 0.7899 - val_acc_ensemble: 0.7654 - val_acc_1: 0.7312 - val_acc_2: 0.7317\n",
      "Epoch 19/50\n",
      "100/100 - 9s - loss_1: 0.4639 - loss_2: 0.4473 - acc_ensemble: 0.8140 - acc_1: 0.7940 - acc_2: 0.7760 - val_loss_1: 0.7874 - val_loss_2: 0.7799 - val_acc_ensemble: 0.7719 - val_acc_1: 0.7315 - val_acc_2: 0.7373\n",
      "Epoch 20/50\n",
      "100/100 - 9s - loss_1: 0.4475 - loss_2: 0.4624 - acc_ensemble: 0.8380 - acc_1: 0.8060 - acc_2: 0.7780 - val_loss_1: 0.7578 - val_loss_2: 0.7640 - val_acc_ensemble: 0.7762 - val_acc_1: 0.7444 - val_acc_2: 0.7415\n",
      "Epoch 21/50\n",
      "100/100 - 9s - loss_1: 0.3875 - loss_2: 0.4242 - acc_ensemble: 0.8480 - acc_1: 0.8220 - acc_2: 0.7800 - val_loss_1: 0.7573 - val_loss_2: 0.7664 - val_acc_ensemble: 0.7832 - val_acc_1: 0.7444 - val_acc_2: 0.7441\n",
      "Epoch 22/50\n",
      "100/100 - 9s - loss_1: 0.3673 - loss_2: 0.4122 - acc_ensemble: 0.8180 - acc_1: 0.8040 - acc_2: 0.7920 - val_loss_1: 0.7714 - val_loss_2: 0.7636 - val_acc_ensemble: 0.7798 - val_acc_1: 0.7459 - val_acc_2: 0.7435\n",
      "Epoch 23/50\n",
      "100/100 - 9s - loss_1: 0.3520 - loss_2: 0.3515 - acc_ensemble: 0.8480 - acc_1: 0.8120 - acc_2: 0.7860 - val_loss_1: 0.8201 - val_loss_2: 0.7931 - val_acc_ensemble: 0.7822 - val_acc_1: 0.7372 - val_acc_2: 0.7443\n",
      "Epoch 24/50\n",
      "100/100 - 9s - loss_1: 0.3520 - loss_2: 0.3342 - acc_ensemble: 0.8660 - acc_1: 0.8180 - acc_2: 0.7940 - val_loss_1: 0.7833 - val_loss_2: 0.7931 - val_acc_ensemble: 0.7844 - val_acc_1: 0.7503 - val_acc_2: 0.7404\n",
      "Epoch 25/50\n",
      "100/100 - 9s - loss_1: 0.2818 - loss_2: 0.3276 - acc_ensemble: 0.8620 - acc_1: 0.8420 - acc_2: 0.8000 - val_loss_1: 0.7967 - val_loss_2: 0.8000 - val_acc_ensemble: 0.7848 - val_acc_1: 0.7458 - val_acc_2: 0.7470\n",
      "Epoch 26/50\n",
      "100/100 - 9s - loss_1: 0.3251 - loss_2: 0.3078 - acc_ensemble: 0.8580 - acc_1: 0.8180 - acc_2: 0.8080 - val_loss_1: 0.8066 - val_loss_2: 0.8127 - val_acc_ensemble: 0.7813 - val_acc_1: 0.7386 - val_acc_2: 0.7461\n",
      "Epoch 27/50\n",
      "100/100 - 9s - loss_1: 0.2961 - loss_2: 0.3200 - acc_ensemble: 0.8460 - acc_1: 0.8380 - acc_2: 0.7980 - val_loss_1: 0.7785 - val_loss_2: 0.8466 - val_acc_ensemble: 0.7860 - val_acc_1: 0.7524 - val_acc_2: 0.7380\n",
      "Epoch 28/50\n",
      "100/100 - 9s - loss_1: 0.2764 - loss_2: 0.2611 - acc_ensemble: 0.8660 - acc_1: 0.8120 - acc_2: 0.8160 - val_loss_1: 0.8360 - val_loss_2: 0.8211 - val_acc_ensemble: 0.7870 - val_acc_1: 0.7385 - val_acc_2: 0.7427\n",
      "Epoch 29/50\n",
      "100/100 - 9s - loss_1: 0.2583 - loss_2: 0.2413 - acc_ensemble: 0.8600 - acc_1: 0.8420 - acc_2: 0.8240 - val_loss_1: 0.8071 - val_loss_2: 0.8039 - val_acc_ensemble: 0.7968 - val_acc_1: 0.7540 - val_acc_2: 0.7549\n",
      "Epoch 30/50\n",
      "100/100 - 9s - loss_1: 0.1970 - loss_2: 0.2396 - acc_ensemble: 0.8700 - acc_1: 0.8380 - acc_2: 0.8200 - val_loss_1: 0.8140 - val_loss_2: 0.7976 - val_acc_ensemble: 0.7923 - val_acc_1: 0.7582 - val_acc_2: 0.7583\n",
      "Epoch 31/50\n",
      "100/100 - 9s - loss_1: 0.1922 - loss_2: 0.2062 - acc_ensemble: 0.8560 - acc_1: 0.8500 - acc_2: 0.8080 - val_loss_1: 0.8245 - val_loss_2: 0.8482 - val_acc_ensemble: 0.7911 - val_acc_1: 0.7535 - val_acc_2: 0.7444\n",
      "Epoch 32/50\n",
      "100/100 - 9s - loss_1: 0.1879 - loss_2: 0.2067 - acc_ensemble: 0.8820 - acc_1: 0.8440 - acc_2: 0.8140 - val_loss_1: 0.8443 - val_loss_2: 0.8566 - val_acc_ensemble: 0.7904 - val_acc_1: 0.7511 - val_acc_2: 0.7455\n",
      "Epoch 33/50\n",
      "100/100 - 9s - loss_1: 0.1627 - loss_2: 0.2262 - acc_ensemble: 0.8740 - acc_1: 0.8280 - acc_2: 0.8200 - val_loss_1: 0.8625 - val_loss_2: 0.8478 - val_acc_ensemble: 0.7941 - val_acc_1: 0.7509 - val_acc_2: 0.7523\n",
      "Epoch 34/50\n",
      "100/100 - 9s - loss_1: 0.1557 - loss_2: 0.1906 - acc_ensemble: 0.8680 - acc_1: 0.8700 - acc_2: 0.8080 - val_loss_1: 0.8415 - val_loss_2: 0.8860 - val_acc_ensemble: 0.7921 - val_acc_1: 0.7535 - val_acc_2: 0.7455\n",
      "Epoch 35/50\n",
      "100/100 - 9s - loss_1: 0.2045 - loss_2: 0.1706 - acc_ensemble: 0.8840 - acc_1: 0.8380 - acc_2: 0.8200 - val_loss_1: 0.9114 - val_loss_2: 0.8882 - val_acc_ensemble: 0.7866 - val_acc_1: 0.7407 - val_acc_2: 0.7471\n",
      "Epoch 36/50\n",
      "100/100 - 9s - loss_1: 0.1594 - loss_2: 0.1715 - acc_ensemble: 0.8780 - acc_1: 0.8540 - acc_2: 0.8180 - val_loss_1: 0.8610 - val_loss_2: 0.8829 - val_acc_ensemble: 0.7977 - val_acc_1: 0.7572 - val_acc_2: 0.7517\n",
      "Epoch 37/50\n",
      "100/100 - 9s - loss_1: 0.1215 - loss_2: 0.1472 - acc_ensemble: 0.8800 - acc_1: 0.8380 - acc_2: 0.8400 - val_loss_1: 0.8843 - val_loss_2: 0.8784 - val_acc_ensemble: 0.7924 - val_acc_1: 0.7531 - val_acc_2: 0.7585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50\n",
      "100/100 - 9s - loss_1: 0.1324 - loss_2: 0.1252 - acc_ensemble: 0.9020 - acc_1: 0.8560 - acc_2: 0.8360 - val_loss_1: 0.9198 - val_loss_2: 0.9053 - val_acc_ensemble: 0.7921 - val_acc_1: 0.7422 - val_acc_2: 0.7541\n",
      "Epoch 39/50\n",
      "100/100 - 9s - loss_1: 0.1302 - loss_2: 0.1156 - acc_ensemble: 0.8920 - acc_1: 0.8380 - acc_2: 0.8320 - val_loss_1: 0.9969 - val_loss_2: 0.8777 - val_acc_ensemble: 0.7936 - val_acc_1: 0.7378 - val_acc_2: 0.7643\n",
      "Epoch 40/50\n",
      "100/100 - 9s - loss_1: 0.1108 - loss_2: 0.1004 - acc_ensemble: 0.8800 - acc_1: 0.8640 - acc_2: 0.8220 - val_loss_1: 0.8878 - val_loss_2: 0.9388 - val_acc_ensemble: 0.7987 - val_acc_1: 0.7594 - val_acc_2: 0.7536\n",
      "Epoch 41/50\n",
      "100/100 - 9s - loss_1: 0.0973 - loss_2: 0.1257 - acc_ensemble: 0.8840 - acc_1: 0.8560 - acc_2: 0.8300 - val_loss_1: 0.9312 - val_loss_2: 0.9967 - val_acc_ensemble: 0.7924 - val_acc_1: 0.7584 - val_acc_2: 0.7414\n",
      "Epoch 42/50\n",
      "100/100 - 9s - loss_1: 0.0927 - loss_2: 0.1700 - acc_ensemble: 0.8860 - acc_1: 0.8480 - acc_2: 0.8440 - val_loss_1: 0.9786 - val_loss_2: 0.9570 - val_acc_ensemble: 0.7940 - val_acc_1: 0.7516 - val_acc_2: 0.7569\n",
      "Epoch 43/50\n",
      "100/100 - 9s - loss_1: 0.1076 - loss_2: 0.1267 - acc_ensemble: 0.8840 - acc_1: 0.8560 - acc_2: 0.8240 - val_loss_1: 0.9902 - val_loss_2: 0.9814 - val_acc_ensemble: 0.7932 - val_acc_1: 0.7544 - val_acc_2: 0.7440\n",
      "Epoch 44/50\n",
      "100/100 - 9s - loss_1: 0.1100 - loss_2: 0.1264 - acc_ensemble: 0.8800 - acc_1: 0.8480 - acc_2: 0.8200 - val_loss_1: 0.9859 - val_loss_2: 0.9687 - val_acc_ensemble: 0.7933 - val_acc_1: 0.7481 - val_acc_2: 0.7501\n",
      "Epoch 45/50\n",
      "100/100 - 9s - loss_1: 0.1064 - loss_2: 0.1134 - acc_ensemble: 0.8940 - acc_1: 0.8520 - acc_2: 0.8280 - val_loss_1: 1.0018 - val_loss_2: 0.9407 - val_acc_ensemble: 0.7953 - val_acc_1: 0.7503 - val_acc_2: 0.7563\n",
      "Epoch 46/50\n",
      "100/100 - 9s - loss_1: 0.1040 - loss_2: 0.0959 - acc_ensemble: 0.8960 - acc_1: 0.8660 - acc_2: 0.8200 - val_loss_1: 0.9532 - val_loss_2: 0.9569 - val_acc_ensemble: 0.8022 - val_acc_1: 0.7658 - val_acc_2: 0.7587\n",
      "Epoch 47/50\n",
      "100/100 - 9s - loss_1: 0.0917 - loss_2: 0.0950 - acc_ensemble: 0.9000 - acc_1: 0.8520 - acc_2: 0.8360 - val_loss_1: 1.0033 - val_loss_2: 0.9963 - val_acc_ensemble: 0.7975 - val_acc_1: 0.7522 - val_acc_2: 0.7505\n",
      "Epoch 48/50\n",
      "100/100 - 9s - loss_1: 0.0636 - loss_2: 0.0789 - acc_ensemble: 0.8920 - acc_1: 0.8680 - acc_2: 0.8360 - val_loss_1: 0.9929 - val_loss_2: 0.9996 - val_acc_ensemble: 0.7996 - val_acc_1: 0.7575 - val_acc_2: 0.7607\n",
      "Epoch 49/50\n",
      "100/100 - 9s - loss_1: 0.0560 - loss_2: 0.0804 - acc_ensemble: 0.8980 - acc_1: 0.8780 - acc_2: 0.8360 - val_loss_1: 0.9913 - val_loss_2: 0.9831 - val_acc_ensemble: 0.8035 - val_acc_1: 0.7651 - val_acc_2: 0.7644\n",
      "Epoch 50/50\n",
      "100/100 - 9s - loss_1: 0.0801 - loss_2: 0.0650 - acc_ensemble: 0.8880 - acc_1: 0.8720 - acc_2: 0.8480 - val_loss_1: 1.0422 - val_loss_2: 0.9823 - val_acc_ensemble: 0.7991 - val_acc_1: 0.7548 - val_acc_2: 0.7613\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B2/S0.25/model_4\n",
      "i   Layer name                      Output shape                     Num param  Inbound            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "0   conv2d_1_1 (Conv2D)             [None,32,32,8] [None,32,32,24]   1568       input              \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "1   bn_1_1 (BatchNormalization)     [None,32,32,8] [None,32,32,24]   112        conv2d_1_1         \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "2   relu_1_1 (Activation)           [None,32,32,8] [None,32,32,24]   0          bn_1_1             \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "3   conv2d_1_2 (Conv2D)             [None,32,32,8] [None,32,32,24]   17976      relu_1_1           \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "4   bn_1_2 (BatchNormalization)     [None,32,32,8] [None,32,32,24]   112        conv2d_1_2         \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "5   relu_1_2 (Activation)           [None,32,32,8] [None,32,32,24]   0          bn_1_2             \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "6   avg_pool2d_1 (AveragePooling2D  [None,16,16,8] [None,16,16,24]   0          relu_1_2           \n",
      "                                    [None,16,16,8] [None,16,16,24]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "7   conv2d_2_1 (Conv2D)             [None,16,16,16] [None,16,16,48]  35952      avg_pool2d_1       \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "8   bn_2_1 (BatchNormalization)     [None,16,16,16] [None,16,16,48]  224        conv2d_2_1         \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "9   relu_2_1 (Activation)           [None,16,16,16] [None,16,16,48]  0          bn_2_1             \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "10  conv2d_2_2 (Conv2D)             [None,16,16,16] [None,16,16,48]  71664      relu_2_1           \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "11  bn_2_2 (BatchNormalization)     [None,16,16,16] [None,16,16,48]  224        conv2d_2_2         \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "12  relu_2_2 (Activation)           [None,16,16,16] [None,16,16,48]  0          bn_2_2             \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "13  avg_pool2d_2 (AveragePooling2D  [None,8,8,16] [None,8,8,48]      0          relu_2_2           \n",
      "                                    [None,8,8,16] [None,8,8,48]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "14  conv2d_3_1 (Conv2D)             [None,8,8,32] [None,8,8,96]      143328     avg_pool2d_2       \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "15  bn_3_1 (BatchNormalization)     [None,8,8,32] [None,8,8,96]      448        conv2d_3_1         \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "16  relu_3_1 (Activation)           [None,8,8,32] [None,8,8,96]      0          bn_3_1             \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "17  conv2d_3_2 (Conv2D)             [None,8,8,32] [None,8,8,96]      286176     relu_3_1           \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "18  bn_3_2 (BatchNormalization)     [None,8,8,32] [None,8,8,96]      448        conv2d_3_2         \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "19  relu_3_2 (Activation)           [None,8,8,32] [None,8,8,96]      0          bn_3_2             \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "20  global_avg_pool2d (GlobalAvera  [None,32] [None,96]              0          relu_3_2           \n",
      "                                    [None,32] [None,96]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "21  fc1 (Dense)                     [None,32] [None,96]              32224      global_avg_pool2d  \n",
      "                                    [None,32] [None,96]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "22  bn_fc1 (BatchNormalization)     [None,32] [None,96]              448        fc1                \n",
      "                                    [None,32] [None,96]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "23  relu_fc1 (Activation)           [None,32] [None,96]              0          bn_fc1             \n",
      "                                    [None,32] [None,96]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "24  output (Dense)                  [None,10]                        2534       relu_fc1           \n",
      "                                    [None,10]                                                      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "Total parameters: 593438\n",
      "50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 - 13s - loss_1: 1.7954 - loss_2: 1.7626 - acc_ensemble: 0.4580 - acc_1: 0.4220 - acc_2: 0.4180 - val_loss_1: 1.5738 - val_loss_2: 1.5592 - val_acc_ensemble: 0.4509 - val_acc_1: 0.4106 - val_acc_2: 0.4221\n",
      "Epoch 2/50\n",
      "100/100 - 9s - loss_1: 1.4659 - loss_2: 1.4482 - acc_ensemble: 0.5460 - acc_1: 0.4780 - acc_2: 0.5240 - val_loss_1: 1.3903 - val_loss_2: 1.3255 - val_acc_ensemble: 0.5391 - val_acc_1: 0.4947 - val_acc_2: 0.5180\n",
      "Epoch 3/50\n",
      "100/100 - 9s - loss_1: 1.3341 - loss_2: 1.2790 - acc_ensemble: 0.5880 - acc_1: 0.5440 - acc_2: 0.5800 - val_loss_1: 1.2717 - val_loss_2: 1.2119 - val_acc_ensemble: 0.5787 - val_acc_1: 0.5340 - val_acc_2: 0.5605\n",
      "Epoch 4/50\n",
      "100/100 - 9s - loss_1: 1.2024 - loss_2: 1.1705 - acc_ensemble: 0.6160 - acc_1: 0.6020 - acc_2: 0.6040 - val_loss_1: 1.1574 - val_loss_2: 1.1140 - val_acc_ensemble: 0.6147 - val_acc_1: 0.5747 - val_acc_2: 0.6011\n",
      "Epoch 5/50\n",
      "100/100 - 9s - loss_1: 1.0989 - loss_2: 1.0748 - acc_ensemble: 0.6880 - acc_1: 0.6400 - acc_2: 0.6320 - val_loss_1: 1.0830 - val_loss_2: 1.0773 - val_acc_ensemble: 0.6510 - val_acc_1: 0.6061 - val_acc_2: 0.6154\n",
      "Epoch 6/50\n",
      "100/100 - 9s - loss_1: 1.0226 - loss_2: 1.0283 - acc_ensemble: 0.6740 - acc_1: 0.6300 - acc_2: 0.6520 - val_loss_1: 1.0732 - val_loss_2: 1.0212 - val_acc_ensemble: 0.6654 - val_acc_1: 0.6220 - val_acc_2: 0.6373\n",
      "Epoch 7/50\n",
      "100/100 - 9s - loss_1: 0.9458 - loss_2: 0.9086 - acc_ensemble: 0.7140 - acc_1: 0.6620 - acc_2: 0.7080 - val_loss_1: 1.0053 - val_loss_2: 0.9541 - val_acc_ensemble: 0.6796 - val_acc_1: 0.6376 - val_acc_2: 0.6635\n",
      "Epoch 8/50\n",
      "100/100 - 9s - loss_1: 0.9186 - loss_2: 0.8707 - acc_ensemble: 0.7280 - acc_1: 0.6900 - acc_2: 0.6880 - val_loss_1: 0.9659 - val_loss_2: 0.9645 - val_acc_ensemble: 0.6969 - val_acc_1: 0.6549 - val_acc_2: 0.6578\n",
      "Epoch 9/50\n",
      "100/100 - 9s - loss_1: 0.8612 - loss_2: 0.8255 - acc_ensemble: 0.7580 - acc_1: 0.7260 - acc_2: 0.7420 - val_loss_1: 0.8959 - val_loss_2: 0.8965 - val_acc_ensemble: 0.7093 - val_acc_1: 0.6828 - val_acc_2: 0.6809\n",
      "Epoch 10/50\n",
      "100/100 - 9s - loss_1: 0.8311 - loss_2: 0.8054 - acc_ensemble: 0.7740 - acc_1: 0.7280 - acc_2: 0.7380 - val_loss_1: 0.8702 - val_loss_2: 0.8561 - val_acc_ensemble: 0.7256 - val_acc_1: 0.6879 - val_acc_2: 0.6999\n",
      "Epoch 11/50\n",
      "100/100 - 9s - loss_1: 0.7269 - loss_2: 0.7372 - acc_ensemble: 0.7800 - acc_1: 0.7380 - acc_2: 0.7540 - val_loss_1: 0.8762 - val_loss_2: 0.8629 - val_acc_ensemble: 0.7287 - val_acc_1: 0.6907 - val_acc_2: 0.6980\n",
      "Epoch 12/50\n",
      "100/100 - 9s - loss_1: 0.7425 - loss_2: 0.6917 - acc_ensemble: 0.7860 - acc_1: 0.7840 - acc_2: 0.7180 - val_loss_1: 0.8566 - val_loss_2: 0.8234 - val_acc_ensemble: 0.7353 - val_acc_1: 0.6980 - val_acc_2: 0.7114\n",
      "Epoch 13/50\n",
      "100/100 - 9s - loss_1: 0.7009 - loss_2: 0.6758 - acc_ensemble: 0.8140 - acc_1: 0.7800 - acc_2: 0.7400 - val_loss_1: 0.8097 - val_loss_2: 0.8517 - val_acc_ensemble: 0.7450 - val_acc_1: 0.7142 - val_acc_2: 0.7029\n",
      "Epoch 14/50\n",
      "100/100 - 9s - loss_1: 0.6513 - loss_2: 0.6188 - acc_ensemble: 0.8100 - acc_1: 0.7640 - acc_2: 0.7800 - val_loss_1: 0.8175 - val_loss_2: 0.8031 - val_acc_ensemble: 0.7492 - val_acc_1: 0.7059 - val_acc_2: 0.7195\n",
      "Epoch 15/50\n",
      "100/100 - 9s - loss_1: 0.6301 - loss_2: 0.5571 - acc_ensemble: 0.8100 - acc_1: 0.7640 - acc_2: 0.7680 - val_loss_1: 0.8165 - val_loss_2: 0.8010 - val_acc_ensemble: 0.7531 - val_acc_1: 0.7183 - val_acc_2: 0.7250\n",
      "Epoch 16/50\n",
      "100/100 - 9s - loss_1: 0.6059 - loss_2: 0.5504 - acc_ensemble: 0.8440 - acc_1: 0.7860 - acc_2: 0.7860 - val_loss_1: 0.7921 - val_loss_2: 0.8009 - val_acc_ensemble: 0.7611 - val_acc_1: 0.7189 - val_acc_2: 0.7280\n",
      "Epoch 17/50\n",
      "100/100 - 9s - loss_1: 0.5611 - loss_2: 0.5099 - acc_ensemble: 0.8300 - acc_1: 0.7920 - acc_2: 0.8080 - val_loss_1: 0.7956 - val_loss_2: 0.7942 - val_acc_ensemble: 0.7634 - val_acc_1: 0.7239 - val_acc_2: 0.7324\n",
      "Epoch 18/50\n",
      "100/100 - 9s - loss_1: 0.5251 - loss_2: 0.4909 - acc_ensemble: 0.8200 - acc_1: 0.7700 - acc_2: 0.7680 - val_loss_1: 0.8095 - val_loss_2: 0.8270 - val_acc_ensemble: 0.7619 - val_acc_1: 0.7213 - val_acc_2: 0.7201\n",
      "Epoch 19/50\n",
      "100/100 - 9s - loss_1: 0.4966 - loss_2: 0.4447 - acc_ensemble: 0.8480 - acc_1: 0.7900 - acc_2: 0.8200 - val_loss_1: 0.7651 - val_loss_2: 0.7572 - val_acc_ensemble: 0.7773 - val_acc_1: 0.7367 - val_acc_2: 0.7440\n",
      "Epoch 20/50\n",
      "100/100 - 9s - loss_1: 0.4704 - loss_2: 0.4616 - acc_ensemble: 0.8580 - acc_1: 0.8060 - acc_2: 0.7940 - val_loss_1: 0.7790 - val_loss_2: 0.7797 - val_acc_ensemble: 0.7732 - val_acc_1: 0.7317 - val_acc_2: 0.7354\n",
      "Epoch 21/50\n",
      "100/100 - 9s - loss_1: 0.4693 - loss_2: 0.4234 - acc_ensemble: 0.8400 - acc_1: 0.8080 - acc_2: 0.8160 - val_loss_1: 0.7632 - val_loss_2: 0.7608 - val_acc_ensemble: 0.7777 - val_acc_1: 0.7337 - val_acc_2: 0.7468\n",
      "Epoch 22/50\n",
      "100/100 - 9s - loss_1: 0.3863 - loss_2: 0.3900 - acc_ensemble: 0.8500 - acc_1: 0.8020 - acc_2: 0.7980 - val_loss_1: 0.7594 - val_loss_2: 0.8073 - val_acc_ensemble: 0.7740 - val_acc_1: 0.7376 - val_acc_2: 0.7355\n",
      "Epoch 23/50\n",
      "100/100 - 9s - loss_1: 0.3796 - loss_2: 0.3403 - acc_ensemble: 0.8620 - acc_1: 0.8140 - acc_2: 0.8160 - val_loss_1: 0.7980 - val_loss_2: 0.8225 - val_acc_ensemble: 0.7811 - val_acc_1: 0.7322 - val_acc_2: 0.7367\n",
      "Epoch 24/50\n",
      "100/100 - 9s - loss_1: 0.3778 - loss_2: 0.3499 - acc_ensemble: 0.8780 - acc_1: 0.8300 - acc_2: 0.8180 - val_loss_1: 0.8118 - val_loss_2: 0.8151 - val_acc_ensemble: 0.7814 - val_acc_1: 0.7305 - val_acc_2: 0.7390\n",
      "Epoch 25/50\n",
      "100/100 - 9s - loss_1: 0.3669 - loss_2: 0.3039 - acc_ensemble: 0.8640 - acc_1: 0.8280 - acc_2: 0.8340 - val_loss_1: 0.7957 - val_loss_2: 0.8020 - val_acc_ensemble: 0.7850 - val_acc_1: 0.7404 - val_acc_2: 0.7440\n",
      "Epoch 26/50\n",
      "100/100 - 9s - loss_1: 0.2942 - loss_2: 0.3154 - acc_ensemble: 0.8540 - acc_1: 0.8200 - acc_2: 0.8260 - val_loss_1: 0.8109 - val_loss_2: 0.8117 - val_acc_ensemble: 0.7836 - val_acc_1: 0.7378 - val_acc_2: 0.7429\n",
      "Epoch 27/50\n",
      "100/100 - 9s - loss_1: 0.3256 - loss_2: 0.3044 - acc_ensemble: 0.8640 - acc_1: 0.8200 - acc_2: 0.8200 - val_loss_1: 0.7960 - val_loss_2: 0.8206 - val_acc_ensemble: 0.7848 - val_acc_1: 0.7447 - val_acc_2: 0.7459\n",
      "Epoch 28/50\n",
      "100/100 - 9s - loss_1: 0.2891 - loss_2: 0.2991 - acc_ensemble: 0.8700 - acc_1: 0.8200 - acc_2: 0.8300 - val_loss_1: 0.8144 - val_loss_2: 0.8302 - val_acc_ensemble: 0.7837 - val_acc_1: 0.7420 - val_acc_2: 0.7432\n",
      "Epoch 29/50\n",
      "100/100 - 9s - loss_1: 0.2732 - loss_2: 0.2354 - acc_ensemble: 0.8680 - acc_1: 0.8260 - acc_2: 0.8500 - val_loss_1: 0.8157 - val_loss_2: 0.7921 - val_acc_ensemble: 0.7897 - val_acc_1: 0.7455 - val_acc_2: 0.7579\n",
      "Epoch 30/50\n",
      "100/100 - 9s - loss_1: 0.2539 - loss_2: 0.2303 - acc_ensemble: 0.8680 - acc_1: 0.8380 - acc_2: 0.8360 - val_loss_1: 0.7787 - val_loss_2: 0.8230 - val_acc_ensemble: 0.7949 - val_acc_1: 0.7553 - val_acc_2: 0.7524\n",
      "Epoch 31/50\n",
      "100/100 - 9s - loss_1: 0.2330 - loss_2: 0.2017 - acc_ensemble: 0.8720 - acc_1: 0.8160 - acc_2: 0.8560 - val_loss_1: 0.8487 - val_loss_2: 0.8314 - val_acc_ensemble: 0.7894 - val_acc_1: 0.7420 - val_acc_2: 0.7571\n",
      "Epoch 32/50\n",
      "100/100 - 9s - loss_1: 0.2260 - loss_2: 0.1703 - acc_ensemble: 0.8800 - acc_1: 0.8220 - acc_2: 0.8640 - val_loss_1: 0.8179 - val_loss_2: 0.8522 - val_acc_ensemble: 0.7900 - val_acc_1: 0.7518 - val_acc_2: 0.7539\n",
      "Epoch 33/50\n",
      "100/100 - 9s - loss_1: 0.2058 - loss_2: 0.1894 - acc_ensemble: 0.8780 - acc_1: 0.8280 - acc_2: 0.8380 - val_loss_1: 0.8475 - val_loss_2: 0.8672 - val_acc_ensemble: 0.7904 - val_acc_1: 0.7443 - val_acc_2: 0.7539\n",
      "Epoch 34/50\n",
      "100/100 - 9s - loss_1: 0.1984 - loss_2: 0.1815 - acc_ensemble: 0.8800 - acc_1: 0.8380 - acc_2: 0.8240 - val_loss_1: 0.8577 - val_loss_2: 0.8875 - val_acc_ensemble: 0.7931 - val_acc_1: 0.7454 - val_acc_2: 0.7560\n",
      "Epoch 35/50\n",
      "100/100 - 9s - loss_1: 0.2149 - loss_2: 0.1976 - acc_ensemble: 0.8740 - acc_1: 0.8360 - acc_2: 0.8400 - val_loss_1: 0.8441 - val_loss_2: 0.9020 - val_acc_ensemble: 0.7879 - val_acc_1: 0.7492 - val_acc_2: 0.7422\n",
      "Epoch 36/50\n",
      "100/100 - 9s - loss_1: 0.1614 - loss_2: 0.1265 - acc_ensemble: 0.8880 - acc_1: 0.8460 - acc_2: 0.8580 - val_loss_1: 0.8331 - val_loss_2: 0.8585 - val_acc_ensemble: 0.8042 - val_acc_1: 0.7575 - val_acc_2: 0.7679\n",
      "Epoch 37/50\n",
      "100/100 - 9s - loss_1: 0.1648 - loss_2: 0.1452 - acc_ensemble: 0.8940 - acc_1: 0.8580 - acc_2: 0.8420 - val_loss_1: 0.8903 - val_loss_2: 0.9226 - val_acc_ensemble: 0.7917 - val_acc_1: 0.7470 - val_acc_2: 0.7484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50\n",
      "100/100 - 9s - loss_1: 0.1389 - loss_2: 0.1396 - acc_ensemble: 0.8840 - acc_1: 0.8640 - acc_2: 0.8340 - val_loss_1: 0.8416 - val_loss_2: 0.9103 - val_acc_ensemble: 0.7980 - val_acc_1: 0.7590 - val_acc_2: 0.7528\n",
      "Epoch 39/50\n",
      "100/100 - 9s - loss_1: 0.1140 - loss_2: 0.1351 - acc_ensemble: 0.9000 - acc_1: 0.8360 - acc_2: 0.8520 - val_loss_1: 0.8910 - val_loss_2: 0.9097 - val_acc_ensemble: 0.7974 - val_acc_1: 0.7543 - val_acc_2: 0.7576\n",
      "Epoch 40/50\n",
      "100/100 - 9s - loss_1: 0.1403 - loss_2: 0.1427 - acc_ensemble: 0.8960 - acc_1: 0.8280 - acc_2: 0.8460 - val_loss_1: 0.9547 - val_loss_2: 0.9535 - val_acc_ensemble: 0.7919 - val_acc_1: 0.7389 - val_acc_2: 0.7465\n",
      "Epoch 41/50\n",
      "100/100 - 9s - loss_1: 0.1438 - loss_2: 0.1373 - acc_ensemble: 0.8960 - acc_1: 0.8320 - acc_2: 0.8420 - val_loss_1: 0.9241 - val_loss_2: 0.9600 - val_acc_ensemble: 0.7956 - val_acc_1: 0.7431 - val_acc_2: 0.7484\n",
      "Epoch 42/50\n",
      "100/100 - 9s - loss_1: 0.1368 - loss_2: 0.1256 - acc_ensemble: 0.8940 - acc_1: 0.8400 - acc_2: 0.8560 - val_loss_1: 0.9183 - val_loss_2: 0.9686 - val_acc_ensemble: 0.7963 - val_acc_1: 0.7486 - val_acc_2: 0.7552\n",
      "Epoch 43/50\n",
      "100/100 - 9s - loss_1: 0.1138 - loss_2: 0.1363 - acc_ensemble: 0.9100 - acc_1: 0.8500 - acc_2: 0.8500 - val_loss_1: 0.9200 - val_loss_2: 0.9783 - val_acc_ensemble: 0.7917 - val_acc_1: 0.7527 - val_acc_2: 0.7476\n",
      "Epoch 44/50\n",
      "100/100 - 9s - loss_1: 0.1227 - loss_2: 0.1268 - acc_ensemble: 0.9020 - acc_1: 0.8400 - acc_2: 0.8680 - val_loss_1: 0.9503 - val_loss_2: 0.9657 - val_acc_ensemble: 0.7985 - val_acc_1: 0.7504 - val_acc_2: 0.7494\n",
      "Epoch 45/50\n",
      "100/100 - 9s - loss_1: 0.1311 - loss_2: 0.0926 - acc_ensemble: 0.9100 - acc_1: 0.8360 - acc_2: 0.8580 - val_loss_1: 0.9627 - val_loss_2: 0.9651 - val_acc_ensemble: 0.7954 - val_acc_1: 0.7445 - val_acc_2: 0.7545\n",
      "Epoch 46/50\n",
      "100/100 - 9s - loss_1: 0.1229 - loss_2: 0.0780 - acc_ensemble: 0.8980 - acc_1: 0.8600 - acc_2: 0.8540 - val_loss_1: 0.9183 - val_loss_2: 1.0136 - val_acc_ensemble: 0.7997 - val_acc_1: 0.7563 - val_acc_2: 0.7568\n",
      "Epoch 47/50\n",
      "100/100 - 9s - loss_1: 0.1042 - loss_2: 0.0969 - acc_ensemble: 0.9040 - acc_1: 0.8560 - acc_2: 0.8580 - val_loss_1: 0.9215 - val_loss_2: 1.0107 - val_acc_ensemble: 0.7982 - val_acc_1: 0.7572 - val_acc_2: 0.7537\n",
      "Epoch 48/50\n",
      "100/100 - 9s - loss_1: 0.0954 - loss_2: 0.0642 - acc_ensemble: 0.9220 - acc_1: 0.8640 - acc_2: 0.8560 - val_loss_1: 0.9350 - val_loss_2: 0.9635 - val_acc_ensemble: 0.8059 - val_acc_1: 0.7604 - val_acc_2: 0.7631\n",
      "Epoch 49/50\n",
      "100/100 - 9s - loss_1: 0.1138 - loss_2: 0.0625 - acc_ensemble: 0.8900 - acc_1: 0.8420 - acc_2: 0.8540 - val_loss_1: 1.0406 - val_loss_2: 1.0566 - val_acc_ensemble: 0.7981 - val_acc_1: 0.7451 - val_acc_2: 0.7483\n",
      "Epoch 50/50\n",
      "100/100 - 9s - loss_1: 0.1069 - loss_2: 0.0785 - acc_ensemble: 0.9000 - acc_1: 0.8660 - acc_2: 0.8720 - val_loss_1: 0.9579 - val_loss_2: 0.9950 - val_acc_ensemble: 0.8029 - val_acc_1: 0.7542 - val_acc_2: 0.7646\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B2/S0.50/model_1\n",
      "i   Layer name                      Output shape                     Num param  Inbound            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "0   conv2d_1_1 (Conv2D)             [None,32,32,16] [None,32,32,16]  1344       input              \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "1   bn_1_1 (BatchNormalization)     [None,32,32,16] [None,32,32,16]  96         conv2d_1_1         \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "2   relu_1_1 (Activation)           [None,32,32,16] [None,32,32,16]  0          bn_1_1             \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "3   conv2d_1_2 (Conv2D)             [None,32,32,16] [None,32,32,16]  16240      relu_1_1           \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "4   bn_1_2 (BatchNormalization)     [None,32,32,16] [None,32,32,16]  96         conv2d_1_2         \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "5   relu_1_2 (Activation)           [None,32,32,16] [None,32,32,16]  0          bn_1_2             \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "6   avg_pool2d_1 (AveragePooling2D  [None,16,16,16] [None,16,16,16]  0          relu_1_2           \n",
      "                                    [None,16,16,16] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "7   conv2d_2_1 (Conv2D)             [None,16,16,32] [None,16,16,32]  32480      avg_pool2d_1       \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "8   bn_2_1 (BatchNormalization)     [None,16,16,32] [None,16,16,32]  192        conv2d_2_1         \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "9   relu_2_1 (Activation)           [None,16,16,32] [None,16,16,32]  0          bn_2_1             \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "10  conv2d_2_2 (Conv2D)             [None,16,16,32] [None,16,16,32]  64736      relu_2_1           \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "11  bn_2_2 (BatchNormalization)     [None,16,16,32] [None,16,16,32]  192        conv2d_2_2         \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "12  relu_2_2 (Activation)           [None,16,16,32] [None,16,16,32]  0          bn_2_2             \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "13  avg_pool2d_2 (AveragePooling2D  [None,8,8,32] [None,8,8,32]      0          relu_2_2           \n",
      "                                    [None,8,8,32] [None,8,8,32]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "14  conv2d_3_1 (Conv2D)             [None,8,8,64] [None,8,8,64]      129472     avg_pool2d_2       \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "15  bn_3_1 (BatchNormalization)     [None,8,8,64] [None,8,8,64]      384        conv2d_3_1         \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "16  relu_3_1 (Activation)           [None,8,8,64] [None,8,8,64]      0          bn_3_1             \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "17  conv2d_3_2 (Conv2D)             [None,8,8,64] [None,8,8,64]      258496     relu_3_1           \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "18  bn_3_2 (BatchNormalization)     [None,8,8,64] [None,8,8,64]      384        conv2d_3_2         \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "19  relu_3_2 (Activation)           [None,8,8,64] [None,8,8,64]      0          bn_3_2             \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "20  global_avg_pool2d (GlobalAvera  [None,64] [None,64]              0          relu_3_2           \n",
      "                                    [None,64] [None,64]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "21  fc1 (Dense)                     [None,64] [None,64]              29120      global_avg_pool2d  \n",
      "                                    [None,64] [None,64]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "22  bn_fc1 (BatchNormalization)     [None,64] [None,64]              384        fc1                \n",
      "                                    [None,64] [None,64]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "23  relu_fc1 (Activation)           [None,64] [None,64]              0          bn_fc1             \n",
      "                                    [None,64] [None,64]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "24  output (Dense)                  [None,10]                        2275       relu_fc1           \n",
      "                                    [None,10]                                                      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "Total parameters: 535891\n",
      "50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 - 14s - loss_1: 1.7629 - loss_2: 1.7847 - acc_ensemble: 0.4780 - acc_1: 0.4380 - acc_2: 0.4120 - val_loss_1: 1.5318 - val_loss_2: 1.5721 - val_acc_ensemble: 0.4662 - val_acc_1: 0.4396 - val_acc_2: 0.4134\n",
      "Epoch 2/50\n",
      "100/100 - 9s - loss_1: 1.4617 - loss_2: 1.4482 - acc_ensemble: 0.5700 - acc_1: 0.5580 - acc_2: 0.5380 - val_loss_1: 1.3371 - val_loss_2: 1.3476 - val_acc_ensemble: 0.5468 - val_acc_1: 0.5115 - val_acc_2: 0.5128\n",
      "Epoch 3/50\n",
      "100/100 - 9s - loss_1: 1.3077 - loss_2: 1.2937 - acc_ensemble: 0.6140 - acc_1: 0.5840 - acc_2: 0.5780 - val_loss_1: 1.2210 - val_loss_2: 1.2357 - val_acc_ensemble: 0.5838 - val_acc_1: 0.5522 - val_acc_2: 0.5542\n",
      "Epoch 4/50\n",
      "100/100 - 9s - loss_1: 1.1809 - loss_2: 1.1922 - acc_ensemble: 0.6220 - acc_1: 0.5980 - acc_2: 0.6000 - val_loss_1: 1.1635 - val_loss_2: 1.1571 - val_acc_ensemble: 0.6080 - val_acc_1: 0.5761 - val_acc_2: 0.5815\n",
      "Epoch 5/50\n",
      "100/100 - 9s - loss_1: 1.1080 - loss_2: 1.1035 - acc_ensemble: 0.6660 - acc_1: 0.6140 - acc_2: 0.6200 - val_loss_1: 1.1008 - val_loss_2: 1.0705 - val_acc_ensemble: 0.6443 - val_acc_1: 0.6017 - val_acc_2: 0.6222\n",
      "Epoch 6/50\n",
      "100/100 - 9s - loss_1: 1.0395 - loss_2: 1.0038 - acc_ensemble: 0.6740 - acc_1: 0.6140 - acc_2: 0.6580 - val_loss_1: 1.0597 - val_loss_2: 0.9775 - val_acc_ensemble: 0.6690 - val_acc_1: 0.6191 - val_acc_2: 0.6537\n",
      "Epoch 7/50\n",
      "100/100 - 9s - loss_1: 0.9524 - loss_2: 0.9313 - acc_ensemble: 0.7040 - acc_1: 0.6740 - acc_2: 0.6940 - val_loss_1: 0.9813 - val_loss_2: 0.9654 - val_acc_ensemble: 0.6814 - val_acc_1: 0.6467 - val_acc_2: 0.6554\n",
      "Epoch 8/50\n",
      "100/100 - 9s - loss_1: 0.8724 - loss_2: 0.8964 - acc_ensemble: 0.7120 - acc_1: 0.6420 - acc_2: 0.6940 - val_loss_1: 0.9677 - val_loss_2: 0.9754 - val_acc_ensemble: 0.6886 - val_acc_1: 0.6620 - val_acc_2: 0.6531\n",
      "Epoch 9/50\n",
      "100/100 - 9s - loss_1: 0.8601 - loss_2: 0.8313 - acc_ensemble: 0.7420 - acc_1: 0.6940 - acc_2: 0.7280 - val_loss_1: 0.9528 - val_loss_2: 0.8924 - val_acc_ensemble: 0.7032 - val_acc_1: 0.6624 - val_acc_2: 0.6905\n",
      "Epoch 10/50\n",
      "100/100 - 9s - loss_1: 0.8130 - loss_2: 0.7914 - acc_ensemble: 0.7600 - acc_1: 0.6980 - acc_2: 0.7360 - val_loss_1: 0.9156 - val_loss_2: 0.8842 - val_acc_ensemble: 0.7083 - val_acc_1: 0.6746 - val_acc_2: 0.6870\n",
      "Epoch 11/50\n",
      "100/100 - 9s - loss_1: 0.7511 - loss_2: 0.7423 - acc_ensemble: 0.7840 - acc_1: 0.7260 - acc_2: 0.7440 - val_loss_1: 0.9053 - val_loss_2: 0.8522 - val_acc_ensemble: 0.7236 - val_acc_1: 0.6808 - val_acc_2: 0.6965\n",
      "Epoch 12/50\n",
      "100/100 - 9s - loss_1: 0.7173 - loss_2: 0.6969 - acc_ensemble: 0.7760 - acc_1: 0.7120 - acc_2: 0.7560 - val_loss_1: 0.8910 - val_loss_2: 0.8466 - val_acc_ensemble: 0.7313 - val_acc_1: 0.6876 - val_acc_2: 0.7049\n",
      "Epoch 13/50\n",
      "100/100 - 9s - loss_1: 0.7070 - loss_2: 0.6850 - acc_ensemble: 0.7700 - acc_1: 0.7120 - acc_2: 0.7320 - val_loss_1: 0.8645 - val_loss_2: 0.8346 - val_acc_ensemble: 0.7348 - val_acc_1: 0.6991 - val_acc_2: 0.7048\n",
      "Epoch 14/50\n",
      "100/100 - 9s - loss_1: 0.6340 - loss_2: 0.6384 - acc_ensemble: 0.8140 - acc_1: 0.7600 - acc_2: 0.7480 - val_loss_1: 0.8441 - val_loss_2: 0.7992 - val_acc_ensemble: 0.7480 - val_acc_1: 0.7075 - val_acc_2: 0.7201\n",
      "Epoch 15/50\n",
      "100/100 - 9s - loss_1: 0.6064 - loss_2: 0.5717 - acc_ensemble: 0.8080 - acc_1: 0.7620 - acc_2: 0.7640 - val_loss_1: 0.8268 - val_loss_2: 0.7992 - val_acc_ensemble: 0.7530 - val_acc_1: 0.7178 - val_acc_2: 0.7279\n",
      "Epoch 16/50\n",
      "100/100 - 9s - loss_1: 0.5400 - loss_2: 0.5753 - acc_ensemble: 0.7960 - acc_1: 0.7700 - acc_2: 0.7620 - val_loss_1: 0.8172 - val_loss_2: 0.8080 - val_acc_ensemble: 0.7538 - val_acc_1: 0.7223 - val_acc_2: 0.7181\n",
      "Epoch 17/50\n",
      "100/100 - 9s - loss_1: 0.5674 - loss_2: 0.5519 - acc_ensemble: 0.8140 - acc_1: 0.7780 - acc_2: 0.7700 - val_loss_1: 0.8234 - val_loss_2: 0.7829 - val_acc_ensemble: 0.7601 - val_acc_1: 0.7143 - val_acc_2: 0.7287\n",
      "Epoch 18/50\n",
      "100/100 - 9s - loss_1: 0.5082 - loss_2: 0.4988 - acc_ensemble: 0.8360 - acc_1: 0.7800 - acc_2: 0.7940 - val_loss_1: 0.7893 - val_loss_2: 0.7554 - val_acc_ensemble: 0.7663 - val_acc_1: 0.7323 - val_acc_2: 0.7400\n",
      "Epoch 19/50\n",
      "100/100 - 9s - loss_1: 0.4804 - loss_2: 0.4792 - acc_ensemble: 0.8460 - acc_1: 0.8000 - acc_2: 0.8180 - val_loss_1: 0.8038 - val_loss_2: 0.7684 - val_acc_ensemble: 0.7672 - val_acc_1: 0.7272 - val_acc_2: 0.7374\n",
      "Epoch 20/50\n",
      "100/100 - 9s - loss_1: 0.4608 - loss_2: 0.4601 - acc_ensemble: 0.8160 - acc_1: 0.7660 - acc_2: 0.7720 - val_loss_1: 0.8219 - val_loss_2: 0.7876 - val_acc_ensemble: 0.7687 - val_acc_1: 0.7280 - val_acc_2: 0.7335\n",
      "Epoch 21/50\n",
      "100/100 - 9s - loss_1: 0.4699 - loss_2: 0.4201 - acc_ensemble: 0.8500 - acc_1: 0.8080 - acc_2: 0.8200 - val_loss_1: 0.7923 - val_loss_2: 0.7383 - val_acc_ensemble: 0.7741 - val_acc_1: 0.7329 - val_acc_2: 0.7556\n",
      "Epoch 22/50\n",
      "100/100 - 9s - loss_1: 0.4058 - loss_2: 0.3769 - acc_ensemble: 0.8440 - acc_1: 0.7820 - acc_2: 0.7940 - val_loss_1: 0.8145 - val_loss_2: 0.7856 - val_acc_ensemble: 0.7708 - val_acc_1: 0.7282 - val_acc_2: 0.7442\n",
      "Epoch 23/50\n",
      "100/100 - 9s - loss_1: 0.3712 - loss_2: 0.3669 - acc_ensemble: 0.8540 - acc_1: 0.7980 - acc_2: 0.8120 - val_loss_1: 0.8118 - val_loss_2: 0.7630 - val_acc_ensemble: 0.7784 - val_acc_1: 0.7351 - val_acc_2: 0.7505\n",
      "Epoch 24/50\n",
      "100/100 - 9s - loss_1: 0.3833 - loss_2: 0.3349 - acc_ensemble: 0.8480 - acc_1: 0.7920 - acc_2: 0.8060 - val_loss_1: 0.8363 - val_loss_2: 0.8054 - val_acc_ensemble: 0.7713 - val_acc_1: 0.7318 - val_acc_2: 0.7418\n",
      "Epoch 25/50\n",
      "100/100 - 9s - loss_1: 0.3696 - loss_2: 0.3421 - acc_ensemble: 0.8420 - acc_1: 0.7980 - acc_2: 0.8020 - val_loss_1: 0.8399 - val_loss_2: 0.8063 - val_acc_ensemble: 0.7758 - val_acc_1: 0.7259 - val_acc_2: 0.7439\n",
      "Epoch 26/50\n",
      "100/100 - 9s - loss_1: 0.3393 - loss_2: 0.2812 - acc_ensemble: 0.8600 - acc_1: 0.8220 - acc_2: 0.8320 - val_loss_1: 0.8256 - val_loss_2: 0.7930 - val_acc_ensemble: 0.7802 - val_acc_1: 0.7377 - val_acc_2: 0.7485\n",
      "Epoch 27/50\n",
      "100/100 - 9s - loss_1: 0.2846 - loss_2: 0.2790 - acc_ensemble: 0.8500 - acc_1: 0.8260 - acc_2: 0.8120 - val_loss_1: 0.8235 - val_loss_2: 0.7915 - val_acc_ensemble: 0.7811 - val_acc_1: 0.7380 - val_acc_2: 0.7523\n",
      "Epoch 28/50\n",
      "100/100 - 9s - loss_1: 0.2907 - loss_2: 0.2809 - acc_ensemble: 0.8740 - acc_1: 0.8500 - acc_2: 0.8080 - val_loss_1: 0.8041 - val_loss_2: 0.8303 - val_acc_ensemble: 0.7868 - val_acc_1: 0.7500 - val_acc_2: 0.7434\n",
      "Epoch 29/50\n",
      "100/100 - 9s - loss_1: 0.2450 - loss_2: 0.2674 - acc_ensemble: 0.8680 - acc_1: 0.8360 - acc_2: 0.8260 - val_loss_1: 0.8659 - val_loss_2: 0.8362 - val_acc_ensemble: 0.7772 - val_acc_1: 0.7422 - val_acc_2: 0.7413\n",
      "Epoch 30/50\n",
      "100/100 - 9s - loss_1: 0.2566 - loss_2: 0.2387 - acc_ensemble: 0.8840 - acc_1: 0.8300 - acc_2: 0.8360 - val_loss_1: 0.8657 - val_loss_2: 0.8239 - val_acc_ensemble: 0.7827 - val_acc_1: 0.7358 - val_acc_2: 0.7538\n",
      "Epoch 31/50\n",
      "100/100 - 9s - loss_1: 0.2215 - loss_2: 0.2344 - acc_ensemble: 0.8820 - acc_1: 0.8340 - acc_2: 0.8460 - val_loss_1: 0.8840 - val_loss_2: 0.8348 - val_acc_ensemble: 0.7863 - val_acc_1: 0.7348 - val_acc_2: 0.7477\n",
      "Epoch 32/50\n",
      "100/100 - 9s - loss_1: 0.2243 - loss_2: 0.2037 - acc_ensemble: 0.8820 - acc_1: 0.8180 - acc_2: 0.8420 - val_loss_1: 0.8768 - val_loss_2: 0.8600 - val_acc_ensemble: 0.7813 - val_acc_1: 0.7401 - val_acc_2: 0.7479\n",
      "Epoch 33/50\n",
      "100/100 - 9s - loss_1: 0.1930 - loss_2: 0.1933 - acc_ensemble: 0.9020 - acc_1: 0.8460 - acc_2: 0.8440 - val_loss_1: 0.8877 - val_loss_2: 0.8483 - val_acc_ensemble: 0.7865 - val_acc_1: 0.7447 - val_acc_2: 0.7495\n",
      "Epoch 34/50\n",
      "100/100 - 9s - loss_1: 0.1668 - loss_2: 0.1555 - acc_ensemble: 0.8940 - acc_1: 0.8440 - acc_2: 0.8400 - val_loss_1: 0.9382 - val_loss_2: 0.8369 - val_acc_ensemble: 0.7891 - val_acc_1: 0.7331 - val_acc_2: 0.7574\n",
      "Epoch 35/50\n",
      "100/100 - 9s - loss_1: 0.1646 - loss_2: 0.1474 - acc_ensemble: 0.8820 - acc_1: 0.8320 - acc_2: 0.8260 - val_loss_1: 0.9229 - val_loss_2: 0.8448 - val_acc_ensemble: 0.7896 - val_acc_1: 0.7403 - val_acc_2: 0.7638\n",
      "Epoch 36/50\n",
      "100/100 - 9s - loss_1: 0.1682 - loss_2: 0.1170 - acc_ensemble: 0.9000 - acc_1: 0.8320 - acc_2: 0.8580 - val_loss_1: 0.9535 - val_loss_2: 0.8785 - val_acc_ensemble: 0.7887 - val_acc_1: 0.7445 - val_acc_2: 0.7578\n",
      "Epoch 37/50\n",
      "100/100 - 9s - loss_1: 0.1931 - loss_2: 0.1305 - acc_ensemble: 0.8900 - acc_1: 0.8460 - acc_2: 0.8340 - val_loss_1: 0.9052 - val_loss_2: 0.9352 - val_acc_ensemble: 0.7898 - val_acc_1: 0.7501 - val_acc_2: 0.7482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50\n",
      "100/100 - 9s - loss_1: 0.1487 - loss_2: 0.1686 - acc_ensemble: 0.8880 - acc_1: 0.8480 - acc_2: 0.8060 - val_loss_1: 0.9529 - val_loss_2: 0.9883 - val_acc_ensemble: 0.7782 - val_acc_1: 0.7398 - val_acc_2: 0.7372\n",
      "Epoch 39/50\n",
      "100/100 - 9s - loss_1: 0.1247 - loss_2: 0.1518 - acc_ensemble: 0.8860 - acc_1: 0.8420 - acc_2: 0.8340 - val_loss_1: 0.9412 - val_loss_2: 0.9054 - val_acc_ensemble: 0.7892 - val_acc_1: 0.7446 - val_acc_2: 0.7629\n",
      "Epoch 40/50\n",
      "100/100 - 9s - loss_1: 0.1339 - loss_2: 0.1304 - acc_ensemble: 0.8940 - acc_1: 0.8680 - acc_2: 0.8460 - val_loss_1: 0.9707 - val_loss_2: 0.9124 - val_acc_ensemble: 0.7921 - val_acc_1: 0.7486 - val_acc_2: 0.7582\n",
      "Epoch 41/50\n",
      "100/100 - 9s - loss_1: 0.0993 - loss_2: 0.1246 - acc_ensemble: 0.8920 - acc_1: 0.8660 - acc_2: 0.8340 - val_loss_1: 0.9845 - val_loss_2: 0.9406 - val_acc_ensemble: 0.7929 - val_acc_1: 0.7446 - val_acc_2: 0.7581\n",
      "Epoch 42/50\n",
      "100/100 - 9s - loss_1: 0.0946 - loss_2: 0.1097 - acc_ensemble: 0.9020 - acc_1: 0.8560 - acc_2: 0.8460 - val_loss_1: 0.9771 - val_loss_2: 0.9531 - val_acc_ensemble: 0.7924 - val_acc_1: 0.7524 - val_acc_2: 0.7528\n",
      "Epoch 43/50\n",
      "100/100 - 9s - loss_1: 0.1284 - loss_2: 0.0882 - acc_ensemble: 0.9180 - acc_1: 0.8540 - acc_2: 0.8260 - val_loss_1: 0.9796 - val_loss_2: 0.9743 - val_acc_ensemble: 0.7877 - val_acc_1: 0.7457 - val_acc_2: 0.7504\n",
      "Epoch 44/50\n",
      "100/100 - 9s - loss_1: 0.1182 - loss_2: 0.1037 - acc_ensemble: 0.8820 - acc_1: 0.8680 - acc_2: 0.8440 - val_loss_1: 0.9953 - val_loss_2: 0.9691 - val_acc_ensemble: 0.7905 - val_acc_1: 0.7456 - val_acc_2: 0.7500\n",
      "Epoch 45/50\n",
      "100/100 - 9s - loss_1: 0.1097 - loss_2: 0.0892 - acc_ensemble: 0.8880 - acc_1: 0.8460 - acc_2: 0.8620 - val_loss_1: 1.0544 - val_loss_2: 0.9468 - val_acc_ensemble: 0.7907 - val_acc_1: 0.7404 - val_acc_2: 0.7638\n",
      "Epoch 46/50\n",
      "100/100 - 9s - loss_1: 0.1201 - loss_2: 0.1066 - acc_ensemble: 0.8940 - acc_1: 0.8500 - acc_2: 0.8420 - val_loss_1: 1.0707 - val_loss_2: 1.0194 - val_acc_ensemble: 0.7867 - val_acc_1: 0.7343 - val_acc_2: 0.7487\n",
      "Epoch 47/50\n",
      "100/100 - 9s - loss_1: 0.1207 - loss_2: 0.1183 - acc_ensemble: 0.9080 - acc_1: 0.8640 - acc_2: 0.8620 - val_loss_1: 1.0298 - val_loss_2: 0.9890 - val_acc_ensemble: 0.7875 - val_acc_1: 0.7436 - val_acc_2: 0.7538\n",
      "Epoch 48/50\n",
      "100/100 - 9s - loss_1: 0.0905 - loss_2: 0.0812 - acc_ensemble: 0.9040 - acc_1: 0.8480 - acc_2: 0.8380 - val_loss_1: 1.0498 - val_loss_2: 0.9962 - val_acc_ensemble: 0.7888 - val_acc_1: 0.7454 - val_acc_2: 0.7496\n",
      "Epoch 49/50\n",
      "100/100 - 9s - loss_1: 0.0888 - loss_2: 0.0840 - acc_ensemble: 0.8920 - acc_1: 0.8540 - acc_2: 0.8360 - val_loss_1: 1.0527 - val_loss_2: 1.0275 - val_acc_ensemble: 0.7897 - val_acc_1: 0.7484 - val_acc_2: 0.7489\n",
      "Epoch 50/50\n",
      "100/100 - 9s - loss_1: 0.1054 - loss_2: 0.0823 - acc_ensemble: 0.9000 - acc_1: 0.8540 - acc_2: 0.8420 - val_loss_1: 1.0231 - val_loss_2: 1.0309 - val_acc_ensemble: 0.7955 - val_acc_1: 0.7518 - val_acc_2: 0.7533\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B2/S0.50/model_2\n",
      "i   Layer name                      Output shape                     Num param  Inbound            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "0   conv2d_1_1 (Conv2D)             [None,32,32,16] [None,32,32,16]  1344       input              \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "1   bn_1_1 (BatchNormalization)     [None,32,32,16] [None,32,32,16]  96         conv2d_1_1         \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "2   relu_1_1 (Activation)           [None,32,32,16] [None,32,32,16]  0          bn_1_1             \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "3   conv2d_1_2 (Conv2D)             [None,32,32,16] [None,32,32,16]  16240      relu_1_1           \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "4   bn_1_2 (BatchNormalization)     [None,32,32,16] [None,32,32,16]  96         conv2d_1_2         \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "5   relu_1_2 (Activation)           [None,32,32,16] [None,32,32,16]  0          bn_1_2             \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "6   avg_pool2d_1 (AveragePooling2D  [None,16,16,16] [None,16,16,16]  0          relu_1_2           \n",
      "                                    [None,16,16,16] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "7   conv2d_2_1 (Conv2D)             [None,16,16,32] [None,16,16,32]  32480      avg_pool2d_1       \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "8   bn_2_1 (BatchNormalization)     [None,16,16,32] [None,16,16,32]  192        conv2d_2_1         \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "9   relu_2_1 (Activation)           [None,16,16,32] [None,16,16,32]  0          bn_2_1             \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "10  conv2d_2_2 (Conv2D)             [None,16,16,32] [None,16,16,32]  64736      relu_2_1           \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "11  bn_2_2 (BatchNormalization)     [None,16,16,32] [None,16,16,32]  192        conv2d_2_2         \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "12  relu_2_2 (Activation)           [None,16,16,32] [None,16,16,32]  0          bn_2_2             \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "13  avg_pool2d_2 (AveragePooling2D  [None,8,8,32] [None,8,8,32]      0          relu_2_2           \n",
      "                                    [None,8,8,32] [None,8,8,32]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "14  conv2d_3_1 (Conv2D)             [None,8,8,64] [None,8,8,64]      129472     avg_pool2d_2       \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "15  bn_3_1 (BatchNormalization)     [None,8,8,64] [None,8,8,64]      384        conv2d_3_1         \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "16  relu_3_1 (Activation)           [None,8,8,64] [None,8,8,64]      0          bn_3_1             \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "17  conv2d_3_2 (Conv2D)             [None,8,8,64] [None,8,8,64]      258496     relu_3_1           \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "18  bn_3_2 (BatchNormalization)     [None,8,8,64] [None,8,8,64]      384        conv2d_3_2         \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "19  relu_3_2 (Activation)           [None,8,8,64] [None,8,8,64]      0          bn_3_2             \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "20  global_avg_pool2d (GlobalAvera  [None,64] [None,64]              0          relu_3_2           \n",
      "                                    [None,64] [None,64]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "21  fc1 (Dense)                     [None,64] [None,64]              29120      global_avg_pool2d  \n",
      "                                    [None,64] [None,64]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "22  bn_fc1 (BatchNormalization)     [None,64] [None,64]              384        fc1                \n",
      "                                    [None,64] [None,64]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "23  relu_fc1 (Activation)           [None,64] [None,64]              0          bn_fc1             \n",
      "                                    [None,64] [None,64]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "24  output (Dense)                  [None,10]                        2275       relu_fc1           \n",
      "                                    [None,10]                                                      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "Total parameters: 535891\n",
      "50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 - 13s - loss_1: 1.7315 - loss_2: 1.7545 - acc_ensemble: 0.4920 - acc_1: 0.4700 - acc_2: 0.4740 - val_loss_1: 1.4983 - val_loss_2: 1.5486 - val_acc_ensemble: 0.4634 - val_acc_1: 0.4426 - val_acc_2: 0.4266\n",
      "Epoch 2/50\n",
      "100/100 - 9s - loss_1: 1.4501 - loss_2: 1.4729 - acc_ensemble: 0.5380 - acc_1: 0.5220 - acc_2: 0.4960 - val_loss_1: 1.3924 - val_loss_2: 1.3894 - val_acc_ensemble: 0.5242 - val_acc_1: 0.4939 - val_acc_2: 0.4942\n",
      "Epoch 3/50\n",
      "100/100 - 9s - loss_1: 1.2914 - loss_2: 1.3064 - acc_ensemble: 0.6320 - acc_1: 0.6080 - acc_2: 0.5840 - val_loss_1: 1.1748 - val_loss_2: 1.2621 - val_acc_ensemble: 0.5910 - val_acc_1: 0.5750 - val_acc_2: 0.5385\n",
      "Epoch 4/50\n",
      "100/100 - 9s - loss_1: 1.1588 - loss_2: 1.1871 - acc_ensemble: 0.6360 - acc_1: 0.6000 - acc_2: 0.6320 - val_loss_1: 1.1645 - val_loss_2: 1.1522 - val_acc_ensemble: 0.6195 - val_acc_1: 0.5824 - val_acc_2: 0.5842\n",
      "Epoch 5/50\n",
      "100/100 - 9s - loss_1: 1.0745 - loss_2: 1.0835 - acc_ensemble: 0.6700 - acc_1: 0.6260 - acc_2: 0.6340 - val_loss_1: 1.0961 - val_loss_2: 1.1235 - val_acc_ensemble: 0.6435 - val_acc_1: 0.6050 - val_acc_2: 0.5951\n",
      "Epoch 6/50\n",
      "100/100 - 9s - loss_1: 1.0097 - loss_2: 1.0419 - acc_ensemble: 0.7040 - acc_1: 0.6560 - acc_2: 0.6620 - val_loss_1: 1.0123 - val_loss_2: 1.0021 - val_acc_ensemble: 0.6659 - val_acc_1: 0.6395 - val_acc_2: 0.6423\n",
      "Epoch 7/50\n",
      "100/100 - 9s - loss_1: 0.9593 - loss_2: 0.9492 - acc_ensemble: 0.7120 - acc_1: 0.6660 - acc_2: 0.7160 - val_loss_1: 0.9895 - val_loss_2: 0.9694 - val_acc_ensemble: 0.6810 - val_acc_1: 0.6484 - val_acc_2: 0.6549\n",
      "Epoch 8/50\n",
      "100/100 - 9s - loss_1: 0.8711 - loss_2: 0.8617 - acc_ensemble: 0.7320 - acc_1: 0.6980 - acc_2: 0.7140 - val_loss_1: 0.9430 - val_loss_2: 0.9477 - val_acc_ensemble: 0.6952 - val_acc_1: 0.6610 - val_acc_2: 0.6645\n",
      "Epoch 9/50\n",
      "100/100 - 9s - loss_1: 0.8092 - loss_2: 0.8672 - acc_ensemble: 0.7340 - acc_1: 0.7000 - acc_2: 0.6900 - val_loss_1: 0.9252 - val_loss_2: 0.9275 - val_acc_ensemble: 0.7037 - val_acc_1: 0.6727 - val_acc_2: 0.6702\n",
      "Epoch 10/50\n",
      "100/100 - 9s - loss_1: 0.7858 - loss_2: 0.8177 - acc_ensemble: 0.7540 - acc_1: 0.7240 - acc_2: 0.7160 - val_loss_1: 0.8836 - val_loss_2: 0.8964 - val_acc_ensemble: 0.7198 - val_acc_1: 0.6890 - val_acc_2: 0.6793\n",
      "Epoch 11/50\n",
      "100/100 - 9s - loss_1: 0.7164 - loss_2: 0.7348 - acc_ensemble: 0.7840 - acc_1: 0.7180 - acc_2: 0.7520 - val_loss_1: 0.8679 - val_loss_2: 0.8599 - val_acc_ensemble: 0.7308 - val_acc_1: 0.6978 - val_acc_2: 0.6965\n",
      "Epoch 12/50\n",
      "100/100 - 9s - loss_1: 0.7146 - loss_2: 0.7222 - acc_ensemble: 0.7820 - acc_1: 0.7440 - acc_2: 0.7240 - val_loss_1: 0.8509 - val_loss_2: 0.8492 - val_acc_ensemble: 0.7350 - val_acc_1: 0.6970 - val_acc_2: 0.6969\n",
      "Epoch 13/50\n",
      "100/100 - 9s - loss_1: 0.6564 - loss_2: 0.6733 - acc_ensemble: 0.7980 - acc_1: 0.7360 - acc_2: 0.7700 - val_loss_1: 0.8387 - val_loss_2: 0.8274 - val_acc_ensemble: 0.7421 - val_acc_1: 0.7077 - val_acc_2: 0.7090\n",
      "Epoch 14/50\n",
      "100/100 - 9s - loss_1: 0.6158 - loss_2: 0.6478 - acc_ensemble: 0.8140 - acc_1: 0.7400 - acc_2: 0.7540 - val_loss_1: 0.8497 - val_loss_2: 0.8600 - val_acc_ensemble: 0.7388 - val_acc_1: 0.7058 - val_acc_2: 0.6968\n",
      "Epoch 15/50\n",
      "100/100 - 9s - loss_1: 0.5883 - loss_2: 0.5993 - acc_ensemble: 0.8120 - acc_1: 0.7880 - acc_2: 0.7640 - val_loss_1: 0.8203 - val_loss_2: 0.7964 - val_acc_ensemble: 0.7502 - val_acc_1: 0.7131 - val_acc_2: 0.7244\n",
      "Epoch 16/50\n",
      "100/100 - 9s - loss_1: 0.5552 - loss_2: 0.5497 - acc_ensemble: 0.8140 - acc_1: 0.7620 - acc_2: 0.7820 - val_loss_1: 0.8268 - val_loss_2: 0.7921 - val_acc_ensemble: 0.7570 - val_acc_1: 0.7139 - val_acc_2: 0.7279\n",
      "Epoch 17/50\n",
      "100/100 - 9s - loss_1: 0.5382 - loss_2: 0.5142 - acc_ensemble: 0.8160 - acc_1: 0.7640 - acc_2: 0.7720 - val_loss_1: 0.7995 - val_loss_2: 0.8004 - val_acc_ensemble: 0.7620 - val_acc_1: 0.7249 - val_acc_2: 0.7225\n",
      "Epoch 18/50\n",
      "100/100 - 9s - loss_1: 0.4954 - loss_2: 0.5281 - acc_ensemble: 0.8220 - acc_1: 0.7720 - acc_2: 0.7680 - val_loss_1: 0.8188 - val_loss_2: 0.8098 - val_acc_ensemble: 0.7616 - val_acc_1: 0.7230 - val_acc_2: 0.7242\n",
      "Epoch 19/50\n",
      "100/100 - 9s - loss_1: 0.4966 - loss_2: 0.4895 - acc_ensemble: 0.8400 - acc_1: 0.7860 - acc_2: 0.8060 - val_loss_1: 0.7861 - val_loss_2: 0.7687 - val_acc_ensemble: 0.7694 - val_acc_1: 0.7326 - val_acc_2: 0.7401\n",
      "Epoch 20/50\n",
      "100/100 - 9s - loss_1: 0.4405 - loss_2: 0.4589 - acc_ensemble: 0.8360 - acc_1: 0.7700 - acc_2: 0.8160 - val_loss_1: 0.8059 - val_loss_2: 0.7990 - val_acc_ensemble: 0.7675 - val_acc_1: 0.7323 - val_acc_2: 0.7284\n",
      "Epoch 21/50\n",
      "100/100 - 9s - loss_1: 0.4412 - loss_2: 0.4767 - acc_ensemble: 0.8520 - acc_1: 0.8140 - acc_2: 0.7940 - val_loss_1: 0.7916 - val_loss_2: 0.7863 - val_acc_ensemble: 0.7777 - val_acc_1: 0.7340 - val_acc_2: 0.7336\n",
      "Epoch 22/50\n",
      "100/100 - 9s - loss_1: 0.4239 - loss_2: 0.3685 - acc_ensemble: 0.8460 - acc_1: 0.8160 - acc_2: 0.8060 - val_loss_1: 0.7900 - val_loss_2: 0.8002 - val_acc_ensemble: 0.7801 - val_acc_1: 0.7388 - val_acc_2: 0.7376\n",
      "Epoch 23/50\n",
      "100/100 - 9s - loss_1: 0.3837 - loss_2: 0.3699 - acc_ensemble: 0.8540 - acc_1: 0.8100 - acc_2: 0.8040 - val_loss_1: 0.7983 - val_loss_2: 0.8173 - val_acc_ensemble: 0.7713 - val_acc_1: 0.7395 - val_acc_2: 0.7322\n",
      "Epoch 24/50\n",
      "100/100 - 9s - loss_1: 0.3797 - loss_2: 0.3699 - acc_ensemble: 0.8440 - acc_1: 0.8280 - acc_2: 0.8100 - val_loss_1: 0.8165 - val_loss_2: 0.8181 - val_acc_ensemble: 0.7752 - val_acc_1: 0.7363 - val_acc_2: 0.7345\n",
      "Epoch 25/50\n",
      "100/100 - 9s - loss_1: 0.3373 - loss_2: 0.3322 - acc_ensemble: 0.8640 - acc_1: 0.8260 - acc_2: 0.8240 - val_loss_1: 0.8302 - val_loss_2: 0.8208 - val_acc_ensemble: 0.7778 - val_acc_1: 0.7410 - val_acc_2: 0.7408\n",
      "Epoch 26/50\n",
      "100/100 - 9s - loss_1: 0.3075 - loss_2: 0.2974 - acc_ensemble: 0.8560 - acc_1: 0.8260 - acc_2: 0.8060 - val_loss_1: 0.8321 - val_loss_2: 0.8137 - val_acc_ensemble: 0.7780 - val_acc_1: 0.7359 - val_acc_2: 0.7430\n",
      "Epoch 27/50\n",
      "100/100 - 9s - loss_1: 0.2899 - loss_2: 0.2988 - acc_ensemble: 0.8520 - acc_1: 0.8260 - acc_2: 0.8220 - val_loss_1: 0.8231 - val_loss_2: 0.8277 - val_acc_ensemble: 0.7829 - val_acc_1: 0.7393 - val_acc_2: 0.7380\n",
      "Epoch 28/50\n",
      "100/100 - 9s - loss_1: 0.2839 - loss_2: 0.2451 - acc_ensemble: 0.8680 - acc_1: 0.8460 - acc_2: 0.8280 - val_loss_1: 0.8257 - val_loss_2: 0.8296 - val_acc_ensemble: 0.7844 - val_acc_1: 0.7446 - val_acc_2: 0.7409\n",
      "Epoch 29/50\n",
      "100/100 - 9s - loss_1: 0.2660 - loss_2: 0.2743 - acc_ensemble: 0.8840 - acc_1: 0.8560 - acc_2: 0.8340 - val_loss_1: 0.8543 - val_loss_2: 0.8352 - val_acc_ensemble: 0.7830 - val_acc_1: 0.7381 - val_acc_2: 0.7432\n",
      "Epoch 30/50\n",
      "100/100 - 9s - loss_1: 0.2648 - loss_2: 0.2802 - acc_ensemble: 0.8760 - acc_1: 0.8260 - acc_2: 0.8260 - val_loss_1: 0.8465 - val_loss_2: 0.9028 - val_acc_ensemble: 0.7794 - val_acc_1: 0.7379 - val_acc_2: 0.7232\n",
      "Epoch 31/50\n",
      "100/100 - 9s - loss_1: 0.2337 - loss_2: 0.2446 - acc_ensemble: 0.8680 - acc_1: 0.8400 - acc_2: 0.8220 - val_loss_1: 0.8614 - val_loss_2: 0.8888 - val_acc_ensemble: 0.7824 - val_acc_1: 0.7423 - val_acc_2: 0.7330\n",
      "Epoch 32/50\n",
      "100/100 - 9s - loss_1: 0.2258 - loss_2: 0.2019 - acc_ensemble: 0.8780 - acc_1: 0.8460 - acc_2: 0.8100 - val_loss_1: 0.8546 - val_loss_2: 0.9079 - val_acc_ensemble: 0.7820 - val_acc_1: 0.7441 - val_acc_2: 0.7349\n",
      "Epoch 33/50\n",
      "100/100 - 9s - loss_1: 0.1943 - loss_2: 0.2051 - acc_ensemble: 0.8820 - acc_1: 0.8460 - acc_2: 0.8300 - val_loss_1: 0.8878 - val_loss_2: 0.9120 - val_acc_ensemble: 0.7792 - val_acc_1: 0.7419 - val_acc_2: 0.7310\n",
      "Epoch 34/50\n",
      "100/100 - 9s - loss_1: 0.1794 - loss_2: 0.1829 - acc_ensemble: 0.8940 - acc_1: 0.8540 - acc_2: 0.8500 - val_loss_1: 0.9127 - val_loss_2: 0.9051 - val_acc_ensemble: 0.7894 - val_acc_1: 0.7378 - val_acc_2: 0.7400\n",
      "Epoch 35/50\n",
      "100/100 - 9s - loss_1: 0.1679 - loss_2: 0.1751 - acc_ensemble: 0.8960 - acc_1: 0.8460 - acc_2: 0.8400 - val_loss_1: 0.8959 - val_loss_2: 0.8985 - val_acc_ensemble: 0.7888 - val_acc_1: 0.7448 - val_acc_2: 0.7438\n",
      "Epoch 36/50\n",
      "100/100 - 9s - loss_1: 0.1832 - loss_2: 0.1384 - acc_ensemble: 0.8800 - acc_1: 0.8380 - acc_2: 0.8400 - val_loss_1: 0.9259 - val_loss_2: 0.9535 - val_acc_ensemble: 0.7814 - val_acc_1: 0.7445 - val_acc_2: 0.7347\n",
      "Epoch 37/50\n",
      "100/100 - 9s - loss_1: 0.1328 - loss_2: 0.1312 - acc_ensemble: 0.9040 - acc_1: 0.8620 - acc_2: 0.8480 - val_loss_1: 0.9177 - val_loss_2: 0.9675 - val_acc_ensemble: 0.7878 - val_acc_1: 0.7485 - val_acc_2: 0.7390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50\n",
      "100/100 - 9s - loss_1: 0.1417 - loss_2: 0.1403 - acc_ensemble: 0.8800 - acc_1: 0.8300 - acc_2: 0.8380 - val_loss_1: 0.9672 - val_loss_2: 0.9656 - val_acc_ensemble: 0.7795 - val_acc_1: 0.7367 - val_acc_2: 0.7358\n",
      "Epoch 39/50\n",
      "100/100 - 9s - loss_1: 0.1385 - loss_2: 0.1504 - acc_ensemble: 0.8960 - acc_1: 0.8760 - acc_2: 0.8560 - val_loss_1: 0.9658 - val_loss_2: 0.9405 - val_acc_ensemble: 0.7860 - val_acc_1: 0.7396 - val_acc_2: 0.7464\n",
      "Epoch 40/50\n",
      "100/100 - 9s - loss_1: 0.1416 - loss_2: 0.1415 - acc_ensemble: 0.9020 - acc_1: 0.8720 - acc_2: 0.8400 - val_loss_1: 0.9562 - val_loss_2: 0.9943 - val_acc_ensemble: 0.7908 - val_acc_1: 0.7467 - val_acc_2: 0.7300\n",
      "Epoch 41/50\n",
      "100/100 - 9s - loss_1: 0.1006 - loss_2: 0.1359 - acc_ensemble: 0.9040 - acc_1: 0.8720 - acc_2: 0.8500 - val_loss_1: 0.9619 - val_loss_2: 0.9621 - val_acc_ensemble: 0.7862 - val_acc_1: 0.7510 - val_acc_2: 0.7405\n",
      "Epoch 42/50\n",
      "100/100 - 9s - loss_1: 0.0975 - loss_2: 0.1490 - acc_ensemble: 0.9100 - acc_1: 0.8520 - acc_2: 0.8160 - val_loss_1: 1.0075 - val_loss_2: 1.0361 - val_acc_ensemble: 0.7820 - val_acc_1: 0.7386 - val_acc_2: 0.7296\n",
      "Epoch 43/50\n",
      "100/100 - 9s - loss_1: 0.1016 - loss_2: 0.1751 - acc_ensemble: 0.8920 - acc_1: 0.8540 - acc_2: 0.8180 - val_loss_1: 1.0238 - val_loss_2: 1.0409 - val_acc_ensemble: 0.7860 - val_acc_1: 0.7419 - val_acc_2: 0.7315\n",
      "Epoch 44/50\n",
      "100/100 - 9s - loss_1: 0.1412 - loss_2: 0.1070 - acc_ensemble: 0.9000 - acc_1: 0.8560 - acc_2: 0.8660 - val_loss_1: 1.0080 - val_loss_2: 0.9672 - val_acc_ensemble: 0.7922 - val_acc_1: 0.7381 - val_acc_2: 0.7508\n",
      "Epoch 45/50\n",
      "100/100 - 9s - loss_1: 0.1040 - loss_2: 0.1001 - acc_ensemble: 0.8980 - acc_1: 0.8800 - acc_2: 0.8580 - val_loss_1: 1.0280 - val_loss_2: 0.9691 - val_acc_ensemble: 0.7888 - val_acc_1: 0.7465 - val_acc_2: 0.7521\n",
      "Epoch 46/50\n",
      "100/100 - 9s - loss_1: 0.0859 - loss_2: 0.0880 - acc_ensemble: 0.9000 - acc_1: 0.8800 - acc_2: 0.8680 - val_loss_1: 1.0185 - val_loss_2: 0.9992 - val_acc_ensemble: 0.7926 - val_acc_1: 0.7544 - val_acc_2: 0.7474\n",
      "Epoch 47/50\n",
      "100/100 - 9s - loss_1: 0.1027 - loss_2: 0.0723 - acc_ensemble: 0.8980 - acc_1: 0.8520 - acc_2: 0.8560 - val_loss_1: 1.0527 - val_loss_2: 1.0168 - val_acc_ensemble: 0.7915 - val_acc_1: 0.7460 - val_acc_2: 0.7486\n",
      "Epoch 48/50\n",
      "100/100 - 9s - loss_1: 0.0854 - loss_2: 0.0595 - acc_ensemble: 0.9020 - acc_1: 0.8500 - acc_2: 0.8460 - val_loss_1: 1.0076 - val_loss_2: 1.0164 - val_acc_ensemble: 0.7950 - val_acc_1: 0.7494 - val_acc_2: 0.7522\n",
      "Epoch 49/50\n",
      "100/100 - 9s - loss_1: 0.0777 - loss_2: 0.0634 - acc_ensemble: 0.9080 - acc_1: 0.8660 - acc_2: 0.8580 - val_loss_1: 1.0712 - val_loss_2: 1.0573 - val_acc_ensemble: 0.7922 - val_acc_1: 0.7447 - val_acc_2: 0.7478\n",
      "Epoch 50/50\n",
      "100/100 - 9s - loss_1: 0.0966 - loss_2: 0.0884 - acc_ensemble: 0.9040 - acc_1: 0.8540 - acc_2: 0.8600 - val_loss_1: 1.0664 - val_loss_2: 1.0798 - val_acc_ensemble: 0.7882 - val_acc_1: 0.7436 - val_acc_2: 0.7424\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B2/S0.50/model_3\n",
      "i   Layer name                      Output shape                     Num param  Inbound            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "0   conv2d_1_1 (Conv2D)             [None,32,32,16] [None,32,32,16]  1344       input              \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "1   bn_1_1 (BatchNormalization)     [None,32,32,16] [None,32,32,16]  96         conv2d_1_1         \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "2   relu_1_1 (Activation)           [None,32,32,16] [None,32,32,16]  0          bn_1_1             \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "3   conv2d_1_2 (Conv2D)             [None,32,32,16] [None,32,32,16]  16240      relu_1_1           \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "4   bn_1_2 (BatchNormalization)     [None,32,32,16] [None,32,32,16]  96         conv2d_1_2         \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "5   relu_1_2 (Activation)           [None,32,32,16] [None,32,32,16]  0          bn_1_2             \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "6   avg_pool2d_1 (AveragePooling2D  [None,16,16,16] [None,16,16,16]  0          relu_1_2           \n",
      "                                    [None,16,16,16] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "7   conv2d_2_1 (Conv2D)             [None,16,16,32] [None,16,16,32]  32480      avg_pool2d_1       \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "8   bn_2_1 (BatchNormalization)     [None,16,16,32] [None,16,16,32]  192        conv2d_2_1         \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "9   relu_2_1 (Activation)           [None,16,16,32] [None,16,16,32]  0          bn_2_1             \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "10  conv2d_2_2 (Conv2D)             [None,16,16,32] [None,16,16,32]  64736      relu_2_1           \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "11  bn_2_2 (BatchNormalization)     [None,16,16,32] [None,16,16,32]  192        conv2d_2_2         \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "12  relu_2_2 (Activation)           [None,16,16,32] [None,16,16,32]  0          bn_2_2             \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "13  avg_pool2d_2 (AveragePooling2D  [None,8,8,32] [None,8,8,32]      0          relu_2_2           \n",
      "                                    [None,8,8,32] [None,8,8,32]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "14  conv2d_3_1 (Conv2D)             [None,8,8,64] [None,8,8,64]      129472     avg_pool2d_2       \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "15  bn_3_1 (BatchNormalization)     [None,8,8,64] [None,8,8,64]      384        conv2d_3_1         \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "16  relu_3_1 (Activation)           [None,8,8,64] [None,8,8,64]      0          bn_3_1             \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "17  conv2d_3_2 (Conv2D)             [None,8,8,64] [None,8,8,64]      258496     relu_3_1           \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "18  bn_3_2 (BatchNormalization)     [None,8,8,64] [None,8,8,64]      384        conv2d_3_2         \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "19  relu_3_2 (Activation)           [None,8,8,64] [None,8,8,64]      0          bn_3_2             \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "20  global_avg_pool2d (GlobalAvera  [None,64] [None,64]              0          relu_3_2           \n",
      "                                    [None,64] [None,64]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "21  fc1 (Dense)                     [None,64] [None,64]              29120      global_avg_pool2d  \n",
      "                                    [None,64] [None,64]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "22  bn_fc1 (BatchNormalization)     [None,64] [None,64]              384        fc1                \n",
      "                                    [None,64] [None,64]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "23  relu_fc1 (Activation)           [None,64] [None,64]              0          bn_fc1             \n",
      "                                    [None,64] [None,64]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "24  output (Dense)                  [None,10]                        2275       relu_fc1           \n",
      "                                    [None,10]                                                      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "Total parameters: 535891\n",
      "50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 - 13s - loss_1: 1.7819 - loss_2: 1.7472 - acc_ensemble: 0.4980 - acc_1: 0.4660 - acc_2: 0.4760 - val_loss_1: 1.5210 - val_loss_2: 1.4906 - val_acc_ensemble: 0.4718 - val_acc_1: 0.4347 - val_acc_2: 0.4522\n",
      "Epoch 2/50\n",
      "100/100 - 9s - loss_1: 1.4501 - loss_2: 1.4319 - acc_ensemble: 0.5600 - acc_1: 0.5480 - acc_2: 0.5220 - val_loss_1: 1.3166 - val_loss_2: 1.3740 - val_acc_ensemble: 0.5350 - val_acc_1: 0.5171 - val_acc_2: 0.4911\n",
      "Epoch 3/50\n",
      "100/100 - 9s - loss_1: 1.2827 - loss_2: 1.2886 - acc_ensemble: 0.6140 - acc_1: 0.5860 - acc_2: 0.5680 - val_loss_1: 1.2173 - val_loss_2: 1.2266 - val_acc_ensemble: 0.5799 - val_acc_1: 0.5543 - val_acc_2: 0.5522\n",
      "Epoch 4/50\n",
      "100/100 - 9s - loss_1: 1.1920 - loss_2: 1.1878 - acc_ensemble: 0.6220 - acc_1: 0.6060 - acc_2: 0.6120 - val_loss_1: 1.1487 - val_loss_2: 1.1457 - val_acc_ensemble: 0.6213 - val_acc_1: 0.5901 - val_acc_2: 0.5872\n",
      "Epoch 5/50\n",
      "100/100 - 9s - loss_1: 1.0895 - loss_2: 1.0931 - acc_ensemble: 0.6760 - acc_1: 0.6340 - acc_2: 0.6280 - val_loss_1: 1.0887 - val_loss_2: 1.0762 - val_acc_ensemble: 0.6480 - val_acc_1: 0.6082 - val_acc_2: 0.6130\n",
      "Epoch 6/50\n",
      "100/100 - 9s - loss_1: 0.9640 - loss_2: 1.0336 - acc_ensemble: 0.6960 - acc_1: 0.6680 - acc_2: 0.6540 - val_loss_1: 1.0479 - val_loss_2: 1.0005 - val_acc_ensemble: 0.6597 - val_acc_1: 0.6239 - val_acc_2: 0.6439\n",
      "Epoch 7/50\n",
      "100/100 - 9s - loss_1: 0.9548 - loss_2: 0.9408 - acc_ensemble: 0.6980 - acc_1: 0.6640 - acc_2: 0.6620 - val_loss_1: 0.9959 - val_loss_2: 0.9689 - val_acc_ensemble: 0.6771 - val_acc_1: 0.6439 - val_acc_2: 0.6531\n",
      "Epoch 8/50\n",
      "100/100 - 9s - loss_1: 0.8719 - loss_2: 0.9054 - acc_ensemble: 0.7260 - acc_1: 0.6900 - acc_2: 0.6860 - val_loss_1: 0.9653 - val_loss_2: 0.9752 - val_acc_ensemble: 0.6944 - val_acc_1: 0.6591 - val_acc_2: 0.6540\n",
      "Epoch 9/50\n",
      "100/100 - 9s - loss_1: 0.8400 - loss_2: 0.8390 - acc_ensemble: 0.7380 - acc_1: 0.7060 - acc_2: 0.7100 - val_loss_1: 0.9226 - val_loss_2: 0.9022 - val_acc_ensemble: 0.7073 - val_acc_1: 0.6729 - val_acc_2: 0.6837\n",
      "Epoch 10/50\n",
      "100/100 - 9s - loss_1: 0.7828 - loss_2: 0.7878 - acc_ensemble: 0.7480 - acc_1: 0.7420 - acc_2: 0.7100 - val_loss_1: 0.8821 - val_loss_2: 0.9214 - val_acc_ensemble: 0.7143 - val_acc_1: 0.6903 - val_acc_2: 0.6717\n",
      "Epoch 11/50\n",
      "100/100 - 9s - loss_1: 0.7438 - loss_2: 0.7495 - acc_ensemble: 0.8000 - acc_1: 0.7420 - acc_2: 0.7420 - val_loss_1: 0.8615 - val_loss_2: 0.8601 - val_acc_ensemble: 0.7291 - val_acc_1: 0.6940 - val_acc_2: 0.6960\n",
      "Epoch 12/50\n",
      "100/100 - 9s - loss_1: 0.7019 - loss_2: 0.7066 - acc_ensemble: 0.7980 - acc_1: 0.7520 - acc_2: 0.7560 - val_loss_1: 0.8916 - val_loss_2: 0.8428 - val_acc_ensemble: 0.7306 - val_acc_1: 0.6895 - val_acc_2: 0.7033\n",
      "Epoch 13/50\n",
      "100/100 - 9s - loss_1: 0.6870 - loss_2: 0.6858 - acc_ensemble: 0.7780 - acc_1: 0.7760 - acc_2: 0.7040 - val_loss_1: 0.8462 - val_loss_2: 0.8800 - val_acc_ensemble: 0.7271 - val_acc_1: 0.6988 - val_acc_2: 0.6883\n",
      "Epoch 14/50\n",
      "100/100 - 9s - loss_1: 0.6020 - loss_2: 0.6633 - acc_ensemble: 0.7980 - acc_1: 0.7880 - acc_2: 0.7440 - val_loss_1: 0.8056 - val_loss_2: 0.8412 - val_acc_ensemble: 0.7477 - val_acc_1: 0.7181 - val_acc_2: 0.7049\n",
      "Epoch 15/50\n",
      "100/100 - 9s - loss_1: 0.5878 - loss_2: 0.5928 - acc_ensemble: 0.8200 - acc_1: 0.7700 - acc_2: 0.7760 - val_loss_1: 0.8314 - val_loss_2: 0.8145 - val_acc_ensemble: 0.7513 - val_acc_1: 0.7087 - val_acc_2: 0.7151\n",
      "Epoch 16/50\n",
      "100/100 - 9s - loss_1: 0.5348 - loss_2: 0.5499 - acc_ensemble: 0.8480 - acc_1: 0.8000 - acc_2: 0.7720 - val_loss_1: 0.8013 - val_loss_2: 0.8280 - val_acc_ensemble: 0.7518 - val_acc_1: 0.7267 - val_acc_2: 0.7133\n",
      "Epoch 17/50\n",
      "100/100 - 9s - loss_1: 0.5304 - loss_2: 0.5631 - acc_ensemble: 0.8380 - acc_1: 0.7840 - acc_2: 0.7820 - val_loss_1: 0.8007 - val_loss_2: 0.7990 - val_acc_ensemble: 0.7615 - val_acc_1: 0.7231 - val_acc_2: 0.7225\n",
      "Epoch 18/50\n",
      "100/100 - 9s - loss_1: 0.4964 - loss_2: 0.5510 - acc_ensemble: 0.8360 - acc_1: 0.7980 - acc_2: 0.7720 - val_loss_1: 0.8244 - val_loss_2: 0.8199 - val_acc_ensemble: 0.7588 - val_acc_1: 0.7226 - val_acc_2: 0.7150\n",
      "Epoch 19/50\n",
      "100/100 - 9s - loss_1: 0.4612 - loss_2: 0.4878 - acc_ensemble: 0.8480 - acc_1: 0.7860 - acc_2: 0.7940 - val_loss_1: 0.7683 - val_loss_2: 0.7981 - val_acc_ensemble: 0.7702 - val_acc_1: 0.7411 - val_acc_2: 0.7334\n",
      "Epoch 20/50\n",
      "100/100 - 9s - loss_1: 0.4448 - loss_2: 0.4353 - acc_ensemble: 0.8520 - acc_1: 0.8120 - acc_2: 0.7800 - val_loss_1: 0.8083 - val_loss_2: 0.8037 - val_acc_ensemble: 0.7713 - val_acc_1: 0.7295 - val_acc_2: 0.7299\n",
      "Epoch 21/50\n",
      "100/100 - 9s - loss_1: 0.4020 - loss_2: 0.4258 - acc_ensemble: 0.8400 - acc_1: 0.7760 - acc_2: 0.8020 - val_loss_1: 0.7945 - val_loss_2: 0.8149 - val_acc_ensemble: 0.7664 - val_acc_1: 0.7411 - val_acc_2: 0.7245\n",
      "Epoch 22/50\n",
      "100/100 - 9s - loss_1: 0.3671 - loss_2: 0.4129 - acc_ensemble: 0.8340 - acc_1: 0.8000 - acc_2: 0.7740 - val_loss_1: 0.8319 - val_loss_2: 0.8265 - val_acc_ensemble: 0.7695 - val_acc_1: 0.7305 - val_acc_2: 0.7257\n",
      "Epoch 23/50\n",
      "100/100 - 9s - loss_1: 0.3229 - loss_2: 0.3713 - acc_ensemble: 0.8620 - acc_1: 0.8020 - acc_2: 0.8120 - val_loss_1: 0.7942 - val_loss_2: 0.7891 - val_acc_ensemble: 0.7802 - val_acc_1: 0.7411 - val_acc_2: 0.7415\n",
      "Epoch 24/50\n",
      "100/100 - 9s - loss_1: 0.3380 - loss_2: 0.3465 - acc_ensemble: 0.8440 - acc_1: 0.7980 - acc_2: 0.8160 - val_loss_1: 0.8587 - val_loss_2: 0.7926 - val_acc_ensemble: 0.7753 - val_acc_1: 0.7334 - val_acc_2: 0.7393\n",
      "Epoch 25/50\n",
      "100/100 - 9s - loss_1: 0.3471 - loss_2: 0.3126 - acc_ensemble: 0.8660 - acc_1: 0.8140 - acc_2: 0.8280 - val_loss_1: 0.8198 - val_loss_2: 0.7997 - val_acc_ensemble: 0.7775 - val_acc_1: 0.7396 - val_acc_2: 0.7434\n",
      "Epoch 26/50\n",
      "100/100 - 9s - loss_1: 0.3349 - loss_2: 0.3078 - acc_ensemble: 0.8740 - acc_1: 0.8140 - acc_2: 0.8300 - val_loss_1: 0.8312 - val_loss_2: 0.8116 - val_acc_ensemble: 0.7821 - val_acc_1: 0.7383 - val_acc_2: 0.7413\n",
      "Epoch 27/50\n",
      "100/100 - 9s - loss_1: 0.2929 - loss_2: 0.3237 - acc_ensemble: 0.8680 - acc_1: 0.8180 - acc_2: 0.8340 - val_loss_1: 0.8438 - val_loss_2: 0.8306 - val_acc_ensemble: 0.7814 - val_acc_1: 0.7402 - val_acc_2: 0.7379\n",
      "Epoch 28/50\n",
      "100/100 - 9s - loss_1: 0.2270 - loss_2: 0.2773 - acc_ensemble: 0.8860 - acc_1: 0.8240 - acc_2: 0.8480 - val_loss_1: 0.8640 - val_loss_2: 0.8349 - val_acc_ensemble: 0.7822 - val_acc_1: 0.7328 - val_acc_2: 0.7377\n",
      "Epoch 29/50\n",
      "100/100 - 9s - loss_1: 0.2271 - loss_2: 0.2570 - acc_ensemble: 0.8920 - acc_1: 0.8380 - acc_2: 0.8540 - val_loss_1: 0.8309 - val_loss_2: 0.8163 - val_acc_ensemble: 0.7875 - val_acc_1: 0.7508 - val_acc_2: 0.7418\n",
      "Epoch 30/50\n",
      "100/100 - 9s - loss_1: 0.2044 - loss_2: 0.2776 - acc_ensemble: 0.8740 - acc_1: 0.8180 - acc_2: 0.8280 - val_loss_1: 0.8995 - val_loss_2: 0.8396 - val_acc_ensemble: 0.7874 - val_acc_1: 0.7402 - val_acc_2: 0.7440\n",
      "Epoch 31/50\n",
      "100/100 - 9s - loss_1: 0.2307 - loss_2: 0.2494 - acc_ensemble: 0.8860 - acc_1: 0.8320 - acc_2: 0.8340 - val_loss_1: 0.8954 - val_loss_2: 0.8274 - val_acc_ensemble: 0.7878 - val_acc_1: 0.7381 - val_acc_2: 0.7461\n",
      "Epoch 32/50\n",
      "100/100 - 9s - loss_1: 0.2120 - loss_2: 0.2124 - acc_ensemble: 0.8800 - acc_1: 0.8180 - acc_2: 0.8260 - val_loss_1: 0.9040 - val_loss_2: 0.8797 - val_acc_ensemble: 0.7852 - val_acc_1: 0.7352 - val_acc_2: 0.7405\n",
      "Epoch 33/50\n",
      "100/100 - 9s - loss_1: 0.1825 - loss_2: 0.1740 - acc_ensemble: 0.8780 - acc_1: 0.8180 - acc_2: 0.8560 - val_loss_1: 0.8975 - val_loss_2: 0.8302 - val_acc_ensemble: 0.7915 - val_acc_1: 0.7438 - val_acc_2: 0.7536\n",
      "Epoch 34/50\n",
      "100/100 - 9s - loss_1: 0.1790 - loss_2: 0.1796 - acc_ensemble: 0.8760 - acc_1: 0.8280 - acc_2: 0.8440 - val_loss_1: 0.9451 - val_loss_2: 0.8788 - val_acc_ensemble: 0.7850 - val_acc_1: 0.7331 - val_acc_2: 0.7465\n",
      "Epoch 35/50\n",
      "100/100 - 9s - loss_1: 0.1376 - loss_2: 0.1624 - acc_ensemble: 0.8740 - acc_1: 0.8160 - acc_2: 0.8480 - val_loss_1: 0.9362 - val_loss_2: 0.8735 - val_acc_ensemble: 0.7853 - val_acc_1: 0.7467 - val_acc_2: 0.7510\n",
      "Epoch 36/50\n",
      "100/100 - 9s - loss_1: 0.1587 - loss_2: 0.1493 - acc_ensemble: 0.8740 - acc_1: 0.8200 - acc_2: 0.8660 - val_loss_1: 0.9766 - val_loss_2: 0.9208 - val_acc_ensemble: 0.7864 - val_acc_1: 0.7362 - val_acc_2: 0.7428\n",
      "Epoch 37/50\n",
      "100/100 - 9s - loss_1: 0.1504 - loss_2: 0.1504 - acc_ensemble: 0.8680 - acc_1: 0.8300 - acc_2: 0.8300 - val_loss_1: 0.9675 - val_loss_2: 0.9449 - val_acc_ensemble: 0.7826 - val_acc_1: 0.7422 - val_acc_2: 0.7338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50\n",
      "100/100 - 9s - loss_1: 0.1333 - loss_2: 0.1549 - acc_ensemble: 0.8820 - acc_1: 0.8100 - acc_2: 0.8500 - val_loss_1: 0.9639 - val_loss_2: 0.9593 - val_acc_ensemble: 0.7884 - val_acc_1: 0.7485 - val_acc_2: 0.7400\n",
      "Epoch 39/50\n",
      "100/100 - 9s - loss_1: 0.1509 - loss_2: 0.1398 - acc_ensemble: 0.8880 - acc_1: 0.8240 - acc_2: 0.8780 - val_loss_1: 0.9781 - val_loss_2: 0.9593 - val_acc_ensemble: 0.7844 - val_acc_1: 0.7432 - val_acc_2: 0.7442\n",
      "Epoch 40/50\n",
      "100/100 - 9s - loss_1: 0.1333 - loss_2: 0.1284 - acc_ensemble: 0.8960 - acc_1: 0.8520 - acc_2: 0.8680 - val_loss_1: 0.9650 - val_loss_2: 0.9462 - val_acc_ensemble: 0.7907 - val_acc_1: 0.7478 - val_acc_2: 0.7457\n",
      "Epoch 41/50\n",
      "100/100 - 9s - loss_1: 0.0992 - loss_2: 0.1470 - acc_ensemble: 0.9000 - acc_1: 0.8520 - acc_2: 0.8640 - val_loss_1: 1.0197 - val_loss_2: 0.9786 - val_acc_ensemble: 0.7885 - val_acc_1: 0.7395 - val_acc_2: 0.7407\n",
      "Epoch 42/50\n",
      "100/100 - 9s - loss_1: 0.1102 - loss_2: 0.1306 - acc_ensemble: 0.8920 - acc_1: 0.8460 - acc_2: 0.8420 - val_loss_1: 1.0327 - val_loss_2: 0.9819 - val_acc_ensemble: 0.7901 - val_acc_1: 0.7394 - val_acc_2: 0.7421\n",
      "Epoch 43/50\n",
      "100/100 - 9s - loss_1: 0.1165 - loss_2: 0.1098 - acc_ensemble: 0.8920 - acc_1: 0.8560 - acc_2: 0.8880 - val_loss_1: 0.9735 - val_loss_2: 0.9616 - val_acc_ensemble: 0.7921 - val_acc_1: 0.7515 - val_acc_2: 0.7491\n",
      "Epoch 44/50\n",
      "100/100 - 9s - loss_1: 0.0817 - loss_2: 0.1042 - acc_ensemble: 0.9180 - acc_1: 0.8360 - acc_2: 0.8740 - val_loss_1: 1.0001 - val_loss_2: 0.9561 - val_acc_ensemble: 0.7973 - val_acc_1: 0.7541 - val_acc_2: 0.7580\n",
      "Epoch 45/50\n",
      "100/100 - 9s - loss_1: 0.0686 - loss_2: 0.0763 - acc_ensemble: 0.9080 - acc_1: 0.8260 - acc_2: 0.8840 - val_loss_1: 1.0327 - val_loss_2: 0.9869 - val_acc_ensemble: 0.7940 - val_acc_1: 0.7513 - val_acc_2: 0.7528\n",
      "Epoch 46/50\n",
      "100/100 - 9s - loss_1: 0.0832 - loss_2: 0.0916 - acc_ensemble: 0.8960 - acc_1: 0.8320 - acc_2: 0.8560 - val_loss_1: 1.0403 - val_loss_2: 1.0151 - val_acc_ensemble: 0.7888 - val_acc_1: 0.7463 - val_acc_2: 0.7449\n",
      "Epoch 47/50\n",
      "100/100 - 9s - loss_1: 0.0802 - loss_2: 0.0956 - acc_ensemble: 0.9080 - acc_1: 0.8400 - acc_2: 0.8600 - val_loss_1: 1.0604 - val_loss_2: 0.9837 - val_acc_ensemble: 0.7915 - val_acc_1: 0.7489 - val_acc_2: 0.7538\n",
      "Epoch 48/50\n",
      "100/100 - 9s - loss_1: 0.1007 - loss_2: 0.0628 - acc_ensemble: 0.9000 - acc_1: 0.8440 - acc_2: 0.8620 - val_loss_1: 1.1286 - val_loss_2: 0.9984 - val_acc_ensemble: 0.7940 - val_acc_1: 0.7357 - val_acc_2: 0.7574\n",
      "Epoch 49/50\n",
      "100/100 - 9s - loss_1: 0.1010 - loss_2: 0.0840 - acc_ensemble: 0.9060 - acc_1: 0.8360 - acc_2: 0.8620 - val_loss_1: 1.1046 - val_loss_2: 1.0402 - val_acc_ensemble: 0.7963 - val_acc_1: 0.7449 - val_acc_2: 0.7492\n",
      "Epoch 50/50\n",
      "100/100 - 9s - loss_1: 0.0999 - loss_2: 0.0827 - acc_ensemble: 0.9200 - acc_1: 0.8560 - acc_2: 0.8680 - val_loss_1: 1.0814 - val_loss_2: 1.0520 - val_acc_ensemble: 0.7903 - val_acc_1: 0.7502 - val_acc_2: 0.7478\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B2/S0.50/model_4\n",
      "i   Layer name                      Output shape                     Num param  Inbound            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "0   conv2d_1_1 (Conv2D)             [None,32,32,16] [None,32,32,16]  1344       input              \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "1   bn_1_1 (BatchNormalization)     [None,32,32,16] [None,32,32,16]  96         conv2d_1_1         \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "2   relu_1_1 (Activation)           [None,32,32,16] [None,32,32,16]  0          bn_1_1             \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "3   conv2d_1_2 (Conv2D)             [None,32,32,16] [None,32,32,16]  16240      relu_1_1           \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "4   bn_1_2 (BatchNormalization)     [None,32,32,16] [None,32,32,16]  96         conv2d_1_2         \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "5   relu_1_2 (Activation)           [None,32,32,16] [None,32,32,16]  0          bn_1_2             \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "6   avg_pool2d_1 (AveragePooling2D  [None,16,16,16] [None,16,16,16]  0          relu_1_2           \n",
      "                                    [None,16,16,16] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "7   conv2d_2_1 (Conv2D)             [None,16,16,32] [None,16,16,32]  32480      avg_pool2d_1       \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "8   bn_2_1 (BatchNormalization)     [None,16,16,32] [None,16,16,32]  192        conv2d_2_1         \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "9   relu_2_1 (Activation)           [None,16,16,32] [None,16,16,32]  0          bn_2_1             \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "10  conv2d_2_2 (Conv2D)             [None,16,16,32] [None,16,16,32]  64736      relu_2_1           \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "11  bn_2_2 (BatchNormalization)     [None,16,16,32] [None,16,16,32]  192        conv2d_2_2         \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "12  relu_2_2 (Activation)           [None,16,16,32] [None,16,16,32]  0          bn_2_2             \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "13  avg_pool2d_2 (AveragePooling2D  [None,8,8,32] [None,8,8,32]      0          relu_2_2           \n",
      "                                    [None,8,8,32] [None,8,8,32]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "14  conv2d_3_1 (Conv2D)             [None,8,8,64] [None,8,8,64]      129472     avg_pool2d_2       \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "15  bn_3_1 (BatchNormalization)     [None,8,8,64] [None,8,8,64]      384        conv2d_3_1         \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "16  relu_3_1 (Activation)           [None,8,8,64] [None,8,8,64]      0          bn_3_1             \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "17  conv2d_3_2 (Conv2D)             [None,8,8,64] [None,8,8,64]      258496     relu_3_1           \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "18  bn_3_2 (BatchNormalization)     [None,8,8,64] [None,8,8,64]      384        conv2d_3_2         \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "19  relu_3_2 (Activation)           [None,8,8,64] [None,8,8,64]      0          bn_3_2             \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "20  global_avg_pool2d (GlobalAvera  [None,64] [None,64]              0          relu_3_2           \n",
      "                                    [None,64] [None,64]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "21  fc1 (Dense)                     [None,64] [None,64]              29120      global_avg_pool2d  \n",
      "                                    [None,64] [None,64]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "22  bn_fc1 (BatchNormalization)     [None,64] [None,64]              384        fc1                \n",
      "                                    [None,64] [None,64]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "23  relu_fc1 (Activation)           [None,64] [None,64]              0          bn_fc1             \n",
      "                                    [None,64] [None,64]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "24  output (Dense)                  [None,10]                        2275       relu_fc1           \n",
      "                                    [None,10]                                                      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "Total parameters: 535891\n",
      "50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 - 13s - loss_1: 1.8206 - loss_2: 1.7889 - acc_ensemble: 0.4660 - acc_1: 0.4460 - acc_2: 0.4300 - val_loss_1: 1.5445 - val_loss_2: 1.5056 - val_acc_ensemble: 0.4685 - val_acc_1: 0.4305 - val_acc_2: 0.4491\n",
      "Epoch 2/50\n",
      "100/100 - 9s - loss_1: 1.4411 - loss_2: 1.4398 - acc_ensemble: 0.5860 - acc_1: 0.5380 - acc_2: 0.5340 - val_loss_1: 1.3985 - val_loss_2: 1.3193 - val_acc_ensemble: 0.5350 - val_acc_1: 0.4922 - val_acc_2: 0.5194\n",
      "Epoch 3/50\n",
      "100/100 - 9s - loss_1: 1.3250 - loss_2: 1.3053 - acc_ensemble: 0.6120 - acc_1: 0.5800 - acc_2: 0.5660 - val_loss_1: 1.2577 - val_loss_2: 1.2202 - val_acc_ensemble: 0.5819 - val_acc_1: 0.5495 - val_acc_2: 0.5536\n",
      "Epoch 4/50\n",
      "100/100 - 9s - loss_1: 1.2167 - loss_2: 1.1851 - acc_ensemble: 0.6220 - acc_1: 0.5720 - acc_2: 0.5980 - val_loss_1: 1.1820 - val_loss_2: 1.1804 - val_acc_ensemble: 0.6179 - val_acc_1: 0.5776 - val_acc_2: 0.5765\n",
      "Epoch 5/50\n",
      "100/100 - 9s - loss_1: 1.1322 - loss_2: 1.1049 - acc_ensemble: 0.6660 - acc_1: 0.6220 - acc_2: 0.6380 - val_loss_1: 1.1132 - val_loss_2: 1.0944 - val_acc_ensemble: 0.6327 - val_acc_1: 0.5996 - val_acc_2: 0.6004\n",
      "Epoch 6/50\n",
      "100/100 - 9s - loss_1: 1.0507 - loss_2: 1.0156 - acc_ensemble: 0.6740 - acc_1: 0.6480 - acc_2: 0.6660 - val_loss_1: 1.0616 - val_loss_2: 1.0563 - val_acc_ensemble: 0.6501 - val_acc_1: 0.6244 - val_acc_2: 0.6208\n",
      "Epoch 7/50\n",
      "100/100 - 9s - loss_1: 0.9669 - loss_2: 0.9548 - acc_ensemble: 0.6880 - acc_1: 0.6540 - acc_2: 0.6480 - val_loss_1: 1.0211 - val_loss_2: 1.0149 - val_acc_ensemble: 0.6662 - val_acc_1: 0.6402 - val_acc_2: 0.6363\n",
      "Epoch 8/50\n",
      "100/100 - 9s - loss_1: 0.9275 - loss_2: 0.9069 - acc_ensemble: 0.7080 - acc_1: 0.6680 - acc_2: 0.6560 - val_loss_1: 0.9768 - val_loss_2: 0.9630 - val_acc_ensemble: 0.6892 - val_acc_1: 0.6530 - val_acc_2: 0.6556\n",
      "Epoch 9/50\n",
      "100/100 - 9s - loss_1: 0.8824 - loss_2: 0.8571 - acc_ensemble: 0.7360 - acc_1: 0.7040 - acc_2: 0.6800 - val_loss_1: 0.9418 - val_loss_2: 0.9128 - val_acc_ensemble: 0.7036 - val_acc_1: 0.6679 - val_acc_2: 0.6721\n",
      "Epoch 10/50\n",
      "100/100 - 9s - loss_1: 0.8366 - loss_2: 0.8058 - acc_ensemble: 0.7440 - acc_1: 0.7160 - acc_2: 0.7100 - val_loss_1: 0.9364 - val_loss_2: 0.9235 - val_acc_ensemble: 0.7001 - val_acc_1: 0.6645 - val_acc_2: 0.6727\n",
      "Epoch 11/50\n",
      "100/100 - 9s - loss_1: 0.7690 - loss_2: 0.7582 - acc_ensemble: 0.7400 - acc_1: 0.7180 - acc_2: 0.7100 - val_loss_1: 0.9103 - val_loss_2: 0.8993 - val_acc_ensemble: 0.7120 - val_acc_1: 0.6799 - val_acc_2: 0.6828\n",
      "Epoch 12/50\n",
      "100/100 - 9s - loss_1: 0.7446 - loss_2: 0.7420 - acc_ensemble: 0.7680 - acc_1: 0.7400 - acc_2: 0.6880 - val_loss_1: 0.9095 - val_loss_2: 0.8893 - val_acc_ensemble: 0.7205 - val_acc_1: 0.6816 - val_acc_2: 0.6853\n",
      "Epoch 13/50\n",
      "100/100 - 9s - loss_1: 0.6856 - loss_2: 0.7040 - acc_ensemble: 0.7780 - acc_1: 0.7640 - acc_2: 0.7140 - val_loss_1: 0.9006 - val_loss_2: 0.8748 - val_acc_ensemble: 0.7261 - val_acc_1: 0.6839 - val_acc_2: 0.6912\n",
      "Epoch 14/50\n",
      "100/100 - 9s - loss_1: 0.6671 - loss_2: 0.6690 - acc_ensemble: 0.7940 - acc_1: 0.7260 - acc_2: 0.7520 - val_loss_1: 0.8845 - val_loss_2: 0.8277 - val_acc_ensemble: 0.7324 - val_acc_1: 0.6908 - val_acc_2: 0.7048\n",
      "Epoch 15/50\n",
      "100/100 - 9s - loss_1: 0.6555 - loss_2: 0.6523 - acc_ensemble: 0.7760 - acc_1: 0.7540 - acc_2: 0.7200 - val_loss_1: 0.8558 - val_loss_2: 0.8393 - val_acc_ensemble: 0.7414 - val_acc_1: 0.7022 - val_acc_2: 0.7016\n",
      "Epoch 16/50\n",
      "100/100 - 9s - loss_1: 0.6151 - loss_2: 0.5744 - acc_ensemble: 0.8180 - acc_1: 0.7700 - acc_2: 0.7760 - val_loss_1: 0.8791 - val_loss_2: 0.8377 - val_acc_ensemble: 0.7404 - val_acc_1: 0.6984 - val_acc_2: 0.7131\n",
      "Epoch 17/50\n",
      "100/100 - 9s - loss_1: 0.5462 - loss_2: 0.5415 - acc_ensemble: 0.8240 - acc_1: 0.7820 - acc_2: 0.7680 - val_loss_1: 0.8722 - val_loss_2: 0.8077 - val_acc_ensemble: 0.7477 - val_acc_1: 0.7027 - val_acc_2: 0.7171\n",
      "Epoch 18/50\n",
      "100/100 - 9s - loss_1: 0.5521 - loss_2: 0.5419 - acc_ensemble: 0.8240 - acc_1: 0.7980 - acc_2: 0.7740 - val_loss_1: 0.8228 - val_loss_2: 0.7887 - val_acc_ensemble: 0.7589 - val_acc_1: 0.7254 - val_acc_2: 0.7247\n",
      "Epoch 19/50\n",
      "100/100 - 9s - loss_1: 0.5150 - loss_2: 0.5150 - acc_ensemble: 0.8160 - acc_1: 0.7920 - acc_2: 0.7740 - val_loss_1: 0.8548 - val_loss_2: 0.7943 - val_acc_ensemble: 0.7600 - val_acc_1: 0.7145 - val_acc_2: 0.7248\n",
      "Epoch 20/50\n",
      "100/100 - 9s - loss_1: 0.4872 - loss_2: 0.4658 - acc_ensemble: 0.8340 - acc_1: 0.7980 - acc_2: 0.7960 - val_loss_1: 0.8422 - val_loss_2: 0.7747 - val_acc_ensemble: 0.7657 - val_acc_1: 0.7153 - val_acc_2: 0.7329\n",
      "Epoch 21/50\n",
      "100/100 - 9s - loss_1: 0.4519 - loss_2: 0.4424 - acc_ensemble: 0.8420 - acc_1: 0.8100 - acc_2: 0.8100 - val_loss_1: 0.8369 - val_loss_2: 0.8172 - val_acc_ensemble: 0.7629 - val_acc_1: 0.7234 - val_acc_2: 0.7286\n",
      "Epoch 22/50\n",
      "100/100 - 9s - loss_1: 0.4515 - loss_2: 0.4689 - acc_ensemble: 0.8520 - acc_1: 0.7940 - acc_2: 0.8040 - val_loss_1: 0.8317 - val_loss_2: 0.7753 - val_acc_ensemble: 0.7682 - val_acc_1: 0.7210 - val_acc_2: 0.7404\n",
      "Epoch 23/50\n",
      "100/100 - 9s - loss_1: 0.4131 - loss_2: 0.3972 - acc_ensemble: 0.8500 - acc_1: 0.8120 - acc_2: 0.8200 - val_loss_1: 0.8253 - val_loss_2: 0.7844 - val_acc_ensemble: 0.7698 - val_acc_1: 0.7323 - val_acc_2: 0.7415\n",
      "Epoch 24/50\n",
      "100/100 - 9s - loss_1: 0.4255 - loss_2: 0.3646 - acc_ensemble: 0.8660 - acc_1: 0.8040 - acc_2: 0.8080 - val_loss_1: 0.8249 - val_loss_2: 0.8230 - val_acc_ensemble: 0.7710 - val_acc_1: 0.7306 - val_acc_2: 0.7338\n",
      "Epoch 25/50\n",
      "100/100 - 9s - loss_1: 0.3705 - loss_2: 0.3686 - acc_ensemble: 0.8600 - acc_1: 0.8080 - acc_2: 0.8100 - val_loss_1: 0.8454 - val_loss_2: 0.7868 - val_acc_ensemble: 0.7764 - val_acc_1: 0.7294 - val_acc_2: 0.7447\n",
      "Epoch 26/50\n",
      "100/100 - 9s - loss_1: 0.3591 - loss_2: 0.3091 - acc_ensemble: 0.8640 - acc_1: 0.8180 - acc_2: 0.8160 - val_loss_1: 0.8326 - val_loss_2: 0.8223 - val_acc_ensemble: 0.7746 - val_acc_1: 0.7272 - val_acc_2: 0.7397\n",
      "Epoch 27/50\n",
      "100/100 - 9s - loss_1: 0.2908 - loss_2: 0.3097 - acc_ensemble: 0.8740 - acc_1: 0.8320 - acc_2: 0.8220 - val_loss_1: 0.8190 - val_loss_2: 0.7816 - val_acc_ensemble: 0.7834 - val_acc_1: 0.7438 - val_acc_2: 0.7519\n",
      "Epoch 28/50\n",
      "100/100 - 9s - loss_1: 0.2846 - loss_2: 0.2670 - acc_ensemble: 0.8640 - acc_1: 0.8160 - acc_2: 0.8360 - val_loss_1: 0.8527 - val_loss_2: 0.8015 - val_acc_ensemble: 0.7831 - val_acc_1: 0.7403 - val_acc_2: 0.7521\n",
      "Epoch 29/50\n",
      "100/100 - 9s - loss_1: 0.2773 - loss_2: 0.3026 - acc_ensemble: 0.8740 - acc_1: 0.8340 - acc_2: 0.8340 - val_loss_1: 0.8504 - val_loss_2: 0.8199 - val_acc_ensemble: 0.7811 - val_acc_1: 0.7405 - val_acc_2: 0.7438\n",
      "Epoch 30/50\n",
      "100/100 - 9s - loss_1: 0.2593 - loss_2: 0.2423 - acc_ensemble: 0.8740 - acc_1: 0.8280 - acc_2: 0.8300 - val_loss_1: 0.8656 - val_loss_2: 0.8085 - val_acc_ensemble: 0.7824 - val_acc_1: 0.7330 - val_acc_2: 0.7532\n",
      "Epoch 31/50\n",
      "100/100 - 9s - loss_1: 0.2344 - loss_2: 0.2280 - acc_ensemble: 0.8720 - acc_1: 0.8140 - acc_2: 0.8420 - val_loss_1: 0.8620 - val_loss_2: 0.8454 - val_acc_ensemble: 0.7864 - val_acc_1: 0.7365 - val_acc_2: 0.7497\n",
      "Epoch 32/50\n",
      "100/100 - 9s - loss_1: 0.2070 - loss_2: 0.2044 - acc_ensemble: 0.8740 - acc_1: 0.8120 - acc_2: 0.8400 - val_loss_1: 0.8882 - val_loss_2: 0.8481 - val_acc_ensemble: 0.7875 - val_acc_1: 0.7366 - val_acc_2: 0.7476\n",
      "Epoch 33/50\n",
      "100/100 - 9s - loss_1: 0.2135 - loss_2: 0.2155 - acc_ensemble: 0.8820 - acc_1: 0.8220 - acc_2: 0.8220 - val_loss_1: 0.9075 - val_loss_2: 0.8767 - val_acc_ensemble: 0.7878 - val_acc_1: 0.7338 - val_acc_2: 0.7415\n",
      "Epoch 34/50\n",
      "100/100 - 9s - loss_1: 0.1885 - loss_2: 0.2203 - acc_ensemble: 0.8680 - acc_1: 0.8340 - acc_2: 0.8360 - val_loss_1: 0.9130 - val_loss_2: 0.8665 - val_acc_ensemble: 0.7839 - val_acc_1: 0.7402 - val_acc_2: 0.7557\n",
      "Epoch 35/50\n",
      "100/100 - 9s - loss_1: 0.1858 - loss_2: 0.1908 - acc_ensemble: 0.8940 - acc_1: 0.8320 - acc_2: 0.8600 - val_loss_1: 0.9178 - val_loss_2: 0.8562 - val_acc_ensemble: 0.7846 - val_acc_1: 0.7408 - val_acc_2: 0.7542\n",
      "Epoch 36/50\n",
      "100/100 - 9s - loss_1: 0.1689 - loss_2: 0.1875 - acc_ensemble: 0.8920 - acc_1: 0.8360 - acc_2: 0.8560 - val_loss_1: 0.9238 - val_loss_2: 0.8819 - val_acc_ensemble: 0.7874 - val_acc_1: 0.7439 - val_acc_2: 0.7541\n",
      "Epoch 37/50\n",
      "100/100 - 9s - loss_1: 0.1606 - loss_2: 0.1354 - acc_ensemble: 0.9060 - acc_1: 0.8280 - acc_2: 0.8560 - val_loss_1: 0.9473 - val_loss_2: 0.8977 - val_acc_ensemble: 0.7872 - val_acc_1: 0.7381 - val_acc_2: 0.7532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50\n",
      "100/100 - 9s - loss_1: 0.1683 - loss_2: 0.1283 - acc_ensemble: 0.8920 - acc_1: 0.8320 - acc_2: 0.8560 - val_loss_1: 0.9438 - val_loss_2: 0.8974 - val_acc_ensemble: 0.7874 - val_acc_1: 0.7424 - val_acc_2: 0.7597\n",
      "Epoch 39/50\n",
      "100/100 - 9s - loss_1: 0.1494 - loss_2: 0.1433 - acc_ensemble: 0.8980 - acc_1: 0.8420 - acc_2: 0.8440 - val_loss_1: 0.9470 - val_loss_2: 0.9500 - val_acc_ensemble: 0.7885 - val_acc_1: 0.7468 - val_acc_2: 0.7446\n",
      "Epoch 40/50\n",
      "100/100 - 9s - loss_1: 0.1407 - loss_2: 0.1252 - acc_ensemble: 0.8940 - acc_1: 0.8340 - acc_2: 0.8440 - val_loss_1: 0.9613 - val_loss_2: 0.9183 - val_acc_ensemble: 0.7894 - val_acc_1: 0.7377 - val_acc_2: 0.7537\n",
      "Epoch 41/50\n",
      "100/100 - 9s - loss_1: 0.1086 - loss_2: 0.1227 - acc_ensemble: 0.9040 - acc_1: 0.8220 - acc_2: 0.8380 - val_loss_1: 1.0247 - val_loss_2: 0.9262 - val_acc_ensemble: 0.7915 - val_acc_1: 0.7324 - val_acc_2: 0.7574\n",
      "Epoch 42/50\n",
      "100/100 - 9s - loss_1: 0.1225 - loss_2: 0.1200 - acc_ensemble: 0.8920 - acc_1: 0.8220 - acc_2: 0.8460 - val_loss_1: 0.9957 - val_loss_2: 1.0233 - val_acc_ensemble: 0.7867 - val_acc_1: 0.7418 - val_acc_2: 0.7398\n",
      "Epoch 43/50\n",
      "100/100 - 9s - loss_1: 0.1139 - loss_2: 0.1228 - acc_ensemble: 0.9000 - acc_1: 0.8400 - acc_2: 0.8560 - val_loss_1: 1.0148 - val_loss_2: 0.9864 - val_acc_ensemble: 0.7829 - val_acc_1: 0.7378 - val_acc_2: 0.7402\n",
      "Epoch 44/50\n",
      "100/100 - 9s - loss_1: 0.1267 - loss_2: 0.1437 - acc_ensemble: 0.8920 - acc_1: 0.8400 - acc_2: 0.8600 - val_loss_1: 1.0559 - val_loss_2: 0.9701 - val_acc_ensemble: 0.7827 - val_acc_1: 0.7374 - val_acc_2: 0.7491\n",
      "Epoch 45/50\n",
      "100/100 - 9s - loss_1: 0.1237 - loss_2: 0.0946 - acc_ensemble: 0.8880 - acc_1: 0.8460 - acc_2: 0.8540 - val_loss_1: 1.0123 - val_loss_2: 0.9816 - val_acc_ensemble: 0.7893 - val_acc_1: 0.7433 - val_acc_2: 0.7528\n",
      "Epoch 46/50\n",
      "100/100 - 9s - loss_1: 0.0913 - loss_2: 0.0979 - acc_ensemble: 0.8900 - acc_1: 0.8360 - acc_2: 0.8520 - val_loss_1: 1.0262 - val_loss_2: 1.0035 - val_acc_ensemble: 0.7955 - val_acc_1: 0.7457 - val_acc_2: 0.7499\n",
      "Epoch 47/50\n",
      "100/100 - 9s - loss_1: 0.0758 - loss_2: 0.0971 - acc_ensemble: 0.8880 - acc_1: 0.8220 - acc_2: 0.8700 - val_loss_1: 1.0783 - val_loss_2: 0.9873 - val_acc_ensemble: 0.7931 - val_acc_1: 0.7358 - val_acc_2: 0.7538\n",
      "Epoch 48/50\n",
      "100/100 - 9s - loss_1: 0.0615 - loss_2: 0.0718 - acc_ensemble: 0.8920 - acc_1: 0.8260 - acc_2: 0.8600 - val_loss_1: 1.0690 - val_loss_2: 1.0110 - val_acc_ensemble: 0.7975 - val_acc_1: 0.7451 - val_acc_2: 0.7570\n",
      "Epoch 49/50\n",
      "100/100 - 9s - loss_1: 0.0766 - loss_2: 0.0655 - acc_ensemble: 0.8980 - acc_1: 0.8460 - acc_2: 0.8580 - val_loss_1: 1.0764 - val_loss_2: 1.0327 - val_acc_ensemble: 0.7893 - val_acc_1: 0.7426 - val_acc_2: 0.7513\n",
      "Epoch 50/50\n",
      "100/100 - 9s - loss_1: 0.0952 - loss_2: 0.0762 - acc_ensemble: 0.8980 - acc_1: 0.8360 - acc_2: 0.8300 - val_loss_1: 1.0903 - val_loss_2: 1.0793 - val_acc_ensemble: 0.7910 - val_acc_1: 0.7434 - val_acc_2: 0.7426\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B2/S0.75/model_1\n",
      "i   Layer name                      Output shape                     Num param  Inbound            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "0   conv2d_1_1 (Conv2D)             [None,32,32,24] [None,32,32,8]   1120       input              \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "1   bn_1_1 (BatchNormalization)     [None,32,32,24] [None,32,32,8]   80         conv2d_1_1         \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "2   relu_1_1 (Activation)           [None,32,32,24] [None,32,32,8]   0          bn_1_1             \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "3   conv2d_1_2 (Conv2D)             [None,32,32,24] [None,32,32,8]   13352      relu_1_1           \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "4   bn_1_2 (BatchNormalization)     [None,32,32,24] [None,32,32,8]   80         conv2d_1_2         \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "5   relu_1_2 (Activation)           [None,32,32,24] [None,32,32,8]   0          bn_1_2             \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "6   avg_pool2d_1 (AveragePooling2D  [None,16,16,24] [None,16,16,8]   0          relu_1_2           \n",
      "                                    [None,16,16,24] [None,16,16,8]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "7   conv2d_2_1 (Conv2D)             [None,16,16,48] [None,16,16,16]  26704      avg_pool2d_1       \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "8   bn_2_1 (BatchNormalization)     [None,16,16,48] [None,16,16,16]  160        conv2d_2_1         \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "9   relu_2_1 (Activation)           [None,16,16,48] [None,16,16,16]  0          bn_2_1             \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "10  conv2d_2_2 (Conv2D)             [None,16,16,48] [None,16,16,16]  53200      relu_2_1           \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "11  bn_2_2 (BatchNormalization)     [None,16,16,48] [None,16,16,16]  160        conv2d_2_2         \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "12  relu_2_2 (Activation)           [None,16,16,48] [None,16,16,16]  0          bn_2_2             \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "13  avg_pool2d_2 (AveragePooling2D  [None,8,8,48] [None,8,8,16]      0          relu_2_2           \n",
      "                                    [None,8,8,48] [None,8,8,16]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "14  conv2d_3_1 (Conv2D)             [None,8,8,96] [None,8,8,32]      106400     avg_pool2d_2       \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "15  bn_3_1 (BatchNormalization)     [None,8,8,96] [None,8,8,32]      320        conv2d_3_1         \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "16  relu_3_1 (Activation)           [None,8,8,96] [None,8,8,32]      0          bn_3_1             \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "17  conv2d_3_2 (Conv2D)             [None,8,8,96] [None,8,8,32]      212384     relu_3_1           \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "18  bn_3_2 (BatchNormalization)     [None,8,8,96] [None,8,8,32]      320        conv2d_3_2         \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "19  relu_3_2 (Activation)           [None,8,8,96] [None,8,8,32]      0          bn_3_2             \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "20  global_avg_pool2d (GlobalAvera  [None,96] [None,32]              0          relu_3_2           \n",
      "                                    [None,96] [None,32]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "21  fc1 (Dense)                     [None,96] [None,32]              23968      global_avg_pool2d  \n",
      "                                    [None,96] [None,32]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "22  bn_fc1 (BatchNormalization)     [None,96] [None,32]              320        fc1                \n",
      "                                    [None,96] [None,32]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "23  relu_fc1 (Activation)           [None,96] [None,32]              0          bn_fc1             \n",
      "                                    [None,96] [None,32]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "24  output (Dense)                  [None,10]                        1921       relu_fc1           \n",
      "                                    [None,10]                                                      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "Total parameters: 440489\n",
      "50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 - 13s - loss_1: 1.7478 - loss_2: 1.7910 - acc_ensemble: 0.4680 - acc_1: 0.4740 - acc_2: 0.4100 - val_loss_1: 1.4942 - val_loss_2: 1.5450 - val_acc_ensemble: 0.4643 - val_acc_1: 0.4455 - val_acc_2: 0.4298\n",
      "Epoch 2/50\n",
      "100/100 - 9s - loss_1: 1.4130 - loss_2: 1.4322 - acc_ensemble: 0.5540 - acc_1: 0.5220 - acc_2: 0.4860 - val_loss_1: 1.3343 - val_loss_2: 1.3776 - val_acc_ensemble: 0.5299 - val_acc_1: 0.5152 - val_acc_2: 0.4988\n",
      "Epoch 3/50\n",
      "100/100 - 9s - loss_1: 1.2347 - loss_2: 1.2651 - acc_ensemble: 0.6180 - acc_1: 0.5740 - acc_2: 0.5620 - val_loss_1: 1.2052 - val_loss_2: 1.1964 - val_acc_ensemble: 0.5898 - val_acc_1: 0.5646 - val_acc_2: 0.5653\n",
      "Epoch 4/50\n",
      "100/100 - 9s - loss_1: 1.1575 - loss_2: 1.1440 - acc_ensemble: 0.6160 - acc_1: 0.6060 - acc_2: 0.5920 - val_loss_1: 1.1064 - val_loss_2: 1.1274 - val_acc_ensemble: 0.6213 - val_acc_1: 0.6019 - val_acc_2: 0.5906\n",
      "Epoch 5/50\n",
      "100/100 - 9s - loss_1: 1.0513 - loss_2: 1.0658 - acc_ensemble: 0.6680 - acc_1: 0.6340 - acc_2: 0.6420 - val_loss_1: 1.0559 - val_loss_2: 1.0297 - val_acc_ensemble: 0.6471 - val_acc_1: 0.6209 - val_acc_2: 0.6324\n",
      "Epoch 6/50\n",
      "100/100 - 9s - loss_1: 0.9598 - loss_2: 0.9654 - acc_ensemble: 0.7020 - acc_1: 0.6840 - acc_2: 0.6680 - val_loss_1: 0.9695 - val_loss_2: 0.9766 - val_acc_ensemble: 0.6744 - val_acc_1: 0.6510 - val_acc_2: 0.6539\n",
      "Epoch 7/50\n",
      "100/100 - 9s - loss_1: 0.8973 - loss_2: 0.9071 - acc_ensemble: 0.7180 - acc_1: 0.7180 - acc_2: 0.6760 - val_loss_1: 0.9652 - val_loss_2: 0.9560 - val_acc_ensemble: 0.6812 - val_acc_1: 0.6556 - val_acc_2: 0.6600\n",
      "Epoch 8/50\n",
      "100/100 - 9s - loss_1: 0.8354 - loss_2: 0.8356 - acc_ensemble: 0.7320 - acc_1: 0.7220 - acc_2: 0.6920 - val_loss_1: 0.9238 - val_loss_2: 0.9066 - val_acc_ensemble: 0.6960 - val_acc_1: 0.6667 - val_acc_2: 0.6821\n",
      "Epoch 9/50\n",
      "100/100 - 9s - loss_1: 0.8132 - loss_2: 0.8162 - acc_ensemble: 0.7600 - acc_1: 0.7400 - acc_2: 0.6960 - val_loss_1: 0.8719 - val_loss_2: 0.8664 - val_acc_ensemble: 0.7088 - val_acc_1: 0.6904 - val_acc_2: 0.6912\n",
      "Epoch 10/50\n",
      "100/100 - 9s - loss_1: 0.7572 - loss_2: 0.7508 - acc_ensemble: 0.7660 - acc_1: 0.7520 - acc_2: 0.7420 - val_loss_1: 0.8469 - val_loss_2: 0.8576 - val_acc_ensemble: 0.7202 - val_acc_1: 0.7029 - val_acc_2: 0.6988\n",
      "Epoch 11/50\n",
      "100/100 - 9s - loss_1: 0.7263 - loss_2: 0.7089 - acc_ensemble: 0.7680 - acc_1: 0.7740 - acc_2: 0.7480 - val_loss_1: 0.8229 - val_loss_2: 0.8339 - val_acc_ensemble: 0.7323 - val_acc_1: 0.7141 - val_acc_2: 0.7042\n",
      "Epoch 12/50\n",
      "100/100 - 9s - loss_1: 0.6464 - loss_2: 0.6721 - acc_ensemble: 0.7820 - acc_1: 0.7480 - acc_2: 0.7480 - val_loss_1: 0.8105 - val_loss_2: 0.8105 - val_acc_ensemble: 0.7364 - val_acc_1: 0.7206 - val_acc_2: 0.7132\n",
      "Epoch 13/50\n",
      "100/100 - 9s - loss_1: 0.6418 - loss_2: 0.6341 - acc_ensemble: 0.7700 - acc_1: 0.7480 - acc_2: 0.7540 - val_loss_1: 0.7731 - val_loss_2: 0.7905 - val_acc_ensemble: 0.7493 - val_acc_1: 0.7331 - val_acc_2: 0.7240\n",
      "Epoch 14/50\n",
      "100/100 - 9s - loss_1: 0.5796 - loss_2: 0.5906 - acc_ensemble: 0.8060 - acc_1: 0.7900 - acc_2: 0.7740 - val_loss_1: 0.7785 - val_loss_2: 0.7756 - val_acc_ensemble: 0.7497 - val_acc_1: 0.7348 - val_acc_2: 0.7282\n",
      "Epoch 15/50\n",
      "100/100 - 9s - loss_1: 0.5635 - loss_2: 0.5552 - acc_ensemble: 0.8040 - acc_1: 0.7840 - acc_2: 0.7620 - val_loss_1: 0.7902 - val_loss_2: 0.7914 - val_acc_ensemble: 0.7471 - val_acc_1: 0.7269 - val_acc_2: 0.7229\n",
      "Epoch 16/50\n",
      "100/100 - 9s - loss_1: 0.5374 - loss_2: 0.5359 - acc_ensemble: 0.8460 - acc_1: 0.8260 - acc_2: 0.7860 - val_loss_1: 0.7499 - val_loss_2: 0.7503 - val_acc_ensemble: 0.7696 - val_acc_1: 0.7434 - val_acc_2: 0.7465\n",
      "Epoch 17/50\n",
      "100/100 - 9s - loss_1: 0.4844 - loss_2: 0.4940 - acc_ensemble: 0.8300 - acc_1: 0.8040 - acc_2: 0.7800 - val_loss_1: 0.7695 - val_loss_2: 0.7406 - val_acc_ensemble: 0.7680 - val_acc_1: 0.7398 - val_acc_2: 0.7452\n",
      "Epoch 18/50\n",
      "100/100 - 9s - loss_1: 0.4772 - loss_2: 0.4420 - acc_ensemble: 0.8400 - acc_1: 0.8280 - acc_2: 0.8020 - val_loss_1: 0.7597 - val_loss_2: 0.7732 - val_acc_ensemble: 0.7688 - val_acc_1: 0.7451 - val_acc_2: 0.7416\n",
      "Epoch 19/50\n",
      "100/100 - 9s - loss_1: 0.4519 - loss_2: 0.4315 - acc_ensemble: 0.8260 - acc_1: 0.8100 - acc_2: 0.7900 - val_loss_1: 0.7520 - val_loss_2: 0.7610 - val_acc_ensemble: 0.7653 - val_acc_1: 0.7485 - val_acc_2: 0.7428\n",
      "Epoch 20/50\n",
      "100/100 - 9s - loss_1: 0.4008 - loss_2: 0.3951 - acc_ensemble: 0.8320 - acc_1: 0.8200 - acc_2: 0.8020 - val_loss_1: 0.7566 - val_loss_2: 0.7632 - val_acc_ensemble: 0.7760 - val_acc_1: 0.7531 - val_acc_2: 0.7484\n",
      "Epoch 21/50\n",
      "100/100 - 9s - loss_1: 0.3819 - loss_2: 0.4002 - acc_ensemble: 0.8540 - acc_1: 0.8300 - acc_2: 0.8420 - val_loss_1: 0.7528 - val_loss_2: 0.7513 - val_acc_ensemble: 0.7749 - val_acc_1: 0.7552 - val_acc_2: 0.7524\n",
      "Epoch 22/50\n",
      "100/100 - 9s - loss_1: 0.3667 - loss_2: 0.3722 - acc_ensemble: 0.8480 - acc_1: 0.8280 - acc_2: 0.8260 - val_loss_1: 0.7502 - val_loss_2: 0.7569 - val_acc_ensemble: 0.7768 - val_acc_1: 0.7560 - val_acc_2: 0.7509\n",
      "Epoch 23/50\n",
      "100/100 - 9s - loss_1: 0.3342 - loss_2: 0.3284 - acc_ensemble: 0.8480 - acc_1: 0.8200 - acc_2: 0.8180 - val_loss_1: 0.7778 - val_loss_2: 0.7925 - val_acc_ensemble: 0.7713 - val_acc_1: 0.7497 - val_acc_2: 0.7428\n",
      "Epoch 24/50\n",
      "100/100 - 9s - loss_1: 0.3039 - loss_2: 0.3266 - acc_ensemble: 0.8460 - acc_1: 0.8500 - acc_2: 0.8080 - val_loss_1: 0.7703 - val_loss_2: 0.7391 - val_acc_ensemble: 0.7833 - val_acc_1: 0.7543 - val_acc_2: 0.7615\n",
      "Epoch 25/50\n",
      "100/100 - 9s - loss_1: 0.2920 - loss_2: 0.2706 - acc_ensemble: 0.8640 - acc_1: 0.8400 - acc_2: 0.8240 - val_loss_1: 0.7854 - val_loss_2: 0.7549 - val_acc_ensemble: 0.7808 - val_acc_1: 0.7484 - val_acc_2: 0.7558\n",
      "Epoch 26/50\n",
      "100/100 - 9s - loss_1: 0.2736 - loss_2: 0.3043 - acc_ensemble: 0.8700 - acc_1: 0.8460 - acc_2: 0.8160 - val_loss_1: 0.8048 - val_loss_2: 0.7639 - val_acc_ensemble: 0.7796 - val_acc_1: 0.7517 - val_acc_2: 0.7568\n",
      "Epoch 27/50\n",
      "100/100 - 9s - loss_1: 0.2454 - loss_2: 0.2822 - acc_ensemble: 0.8800 - acc_1: 0.8540 - acc_2: 0.8320 - val_loss_1: 0.7857 - val_loss_2: 0.7892 - val_acc_ensemble: 0.7821 - val_acc_1: 0.7561 - val_acc_2: 0.7507\n",
      "Epoch 28/50\n",
      "100/100 - 9s - loss_1: 0.2155 - loss_2: 0.2168 - acc_ensemble: 0.8980 - acc_1: 0.8780 - acc_2: 0.8600 - val_loss_1: 0.7991 - val_loss_2: 0.7603 - val_acc_ensemble: 0.7915 - val_acc_1: 0.7603 - val_acc_2: 0.7606\n",
      "Epoch 29/50\n",
      "100/100 - 9s - loss_1: 0.2364 - loss_2: 0.2234 - acc_ensemble: 0.8960 - acc_1: 0.8700 - acc_2: 0.8520 - val_loss_1: 0.8261 - val_loss_2: 0.7986 - val_acc_ensemble: 0.7830 - val_acc_1: 0.7569 - val_acc_2: 0.7568\n",
      "Epoch 30/50\n",
      "100/100 - 9s - loss_1: 0.1777 - loss_2: 0.2115 - acc_ensemble: 0.8840 - acc_1: 0.8660 - acc_2: 0.8580 - val_loss_1: 0.8356 - val_loss_2: 0.7947 - val_acc_ensemble: 0.7898 - val_acc_1: 0.7567 - val_acc_2: 0.7651\n",
      "Epoch 31/50\n",
      "100/100 - 9s - loss_1: 0.1931 - loss_2: 0.1855 - acc_ensemble: 0.9040 - acc_1: 0.8620 - acc_2: 0.8640 - val_loss_1: 0.8624 - val_loss_2: 0.8318 - val_acc_ensemble: 0.7819 - val_acc_1: 0.7524 - val_acc_2: 0.7556\n",
      "Epoch 32/50\n",
      "100/100 - 9s - loss_1: 0.1621 - loss_2: 0.2024 - acc_ensemble: 0.8920 - acc_1: 0.8740 - acc_2: 0.8520 - val_loss_1: 0.8492 - val_loss_2: 0.8436 - val_acc_ensemble: 0.7849 - val_acc_1: 0.7617 - val_acc_2: 0.7576\n",
      "Epoch 33/50\n",
      "100/100 - 9s - loss_1: 0.1427 - loss_2: 0.1484 - acc_ensemble: 0.8920 - acc_1: 0.8740 - acc_2: 0.8600 - val_loss_1: 0.8556 - val_loss_2: 0.8656 - val_acc_ensemble: 0.7859 - val_acc_1: 0.7592 - val_acc_2: 0.7576\n",
      "Epoch 34/50\n",
      "100/100 - 9s - loss_1: 0.1528 - loss_2: 0.1702 - acc_ensemble: 0.8960 - acc_1: 0.8740 - acc_2: 0.8460 - val_loss_1: 0.8748 - val_loss_2: 0.8577 - val_acc_ensemble: 0.7829 - val_acc_1: 0.7607 - val_acc_2: 0.7527\n",
      "Epoch 35/50\n",
      "100/100 - 9s - loss_1: 0.1465 - loss_2: 0.1538 - acc_ensemble: 0.8860 - acc_1: 0.8760 - acc_2: 0.8500 - val_loss_1: 0.8680 - val_loss_2: 0.8589 - val_acc_ensemble: 0.7890 - val_acc_1: 0.7595 - val_acc_2: 0.7608\n",
      "Epoch 36/50\n",
      "100/100 - 9s - loss_1: 0.1455 - loss_2: 0.1368 - acc_ensemble: 0.8960 - acc_1: 0.8900 - acc_2: 0.8500 - val_loss_1: 0.8928 - val_loss_2: 0.8742 - val_acc_ensemble: 0.7899 - val_acc_1: 0.7599 - val_acc_2: 0.7584\n",
      "Epoch 37/50\n",
      "100/100 - 9s - loss_1: 0.1424 - loss_2: 0.1579 - acc_ensemble: 0.9040 - acc_1: 0.8880 - acc_2: 0.8820 - val_loss_1: 0.8789 - val_loss_2: 0.8527 - val_acc_ensemble: 0.7907 - val_acc_1: 0.7589 - val_acc_2: 0.7642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50\n",
      "100/100 - 9s - loss_1: 0.1207 - loss_2: 0.0962 - acc_ensemble: 0.9040 - acc_1: 0.8820 - acc_2: 0.8860 - val_loss_1: 0.8828 - val_loss_2: 0.8737 - val_acc_ensemble: 0.7930 - val_acc_1: 0.7637 - val_acc_2: 0.7656\n",
      "Epoch 39/50\n",
      "100/100 - 9s - loss_1: 0.0897 - loss_2: 0.1401 - acc_ensemble: 0.9000 - acc_1: 0.8720 - acc_2: 0.8780 - val_loss_1: 0.9165 - val_loss_2: 0.9151 - val_acc_ensemble: 0.7910 - val_acc_1: 0.7670 - val_acc_2: 0.7608\n",
      "Epoch 40/50\n",
      "100/100 - 9s - loss_1: 0.1172 - loss_2: 0.1164 - acc_ensemble: 0.8980 - acc_1: 0.8640 - acc_2: 0.8580 - val_loss_1: 0.9266 - val_loss_2: 0.9276 - val_acc_ensemble: 0.7913 - val_acc_1: 0.7612 - val_acc_2: 0.7623\n",
      "Epoch 41/50\n",
      "100/100 - 9s - loss_1: 0.0835 - loss_2: 0.0931 - acc_ensemble: 0.9060 - acc_1: 0.8720 - acc_2: 0.8820 - val_loss_1: 0.9056 - val_loss_2: 0.8841 - val_acc_ensemble: 0.7966 - val_acc_1: 0.7694 - val_acc_2: 0.7717\n",
      "Epoch 42/50\n",
      "100/100 - 9s - loss_1: 0.1129 - loss_2: 0.1065 - acc_ensemble: 0.9080 - acc_1: 0.8680 - acc_2: 0.8760 - val_loss_1: 0.9479 - val_loss_2: 0.9219 - val_acc_ensemble: 0.7935 - val_acc_1: 0.7590 - val_acc_2: 0.7644\n",
      "Epoch 43/50\n",
      "100/100 - 9s - loss_1: 0.1012 - loss_2: 0.1164 - acc_ensemble: 0.9100 - acc_1: 0.8820 - acc_2: 0.8660 - val_loss_1: 0.9290 - val_loss_2: 0.9626 - val_acc_ensemble: 0.7911 - val_acc_1: 0.7669 - val_acc_2: 0.7582\n",
      "Epoch 44/50\n",
      "100/100 - 9s - loss_1: 0.0884 - loss_2: 0.1193 - acc_ensemble: 0.9220 - acc_1: 0.8900 - acc_2: 0.8680 - val_loss_1: 0.9767 - val_loss_2: 0.9061 - val_acc_ensemble: 0.7910 - val_acc_1: 0.7567 - val_acc_2: 0.7669\n",
      "Epoch 45/50\n",
      "100/100 - 9s - loss_1: 0.1077 - loss_2: 0.0863 - acc_ensemble: 0.9020 - acc_1: 0.8740 - acc_2: 0.8600 - val_loss_1: 1.0021 - val_loss_2: 0.9389 - val_acc_ensemble: 0.7959 - val_acc_1: 0.7555 - val_acc_2: 0.7676\n",
      "Epoch 46/50\n",
      "100/100 - 9s - loss_1: 0.1169 - loss_2: 0.1102 - acc_ensemble: 0.9020 - acc_1: 0.8800 - acc_2: 0.8580 - val_loss_1: 1.0276 - val_loss_2: 0.9557 - val_acc_ensemble: 0.7823 - val_acc_1: 0.7500 - val_acc_2: 0.7575\n",
      "Epoch 47/50\n",
      "100/100 - 9s - loss_1: 0.1060 - loss_2: 0.0747 - acc_ensemble: 0.9220 - acc_1: 0.8920 - acc_2: 0.8980 - val_loss_1: 0.9540 - val_loss_2: 0.9593 - val_acc_ensemble: 0.7943 - val_acc_1: 0.7686 - val_acc_2: 0.7687\n",
      "Epoch 48/50\n",
      "100/100 - 9s - loss_1: 0.1003 - loss_2: 0.0703 - acc_ensemble: 0.9140 - acc_1: 0.8800 - acc_2: 0.8860 - val_loss_1: 1.0357 - val_loss_2: 0.9907 - val_acc_ensemble: 0.7850 - val_acc_1: 0.7496 - val_acc_2: 0.7612\n",
      "Epoch 49/50\n",
      "100/100 - 9s - loss_1: 0.0853 - loss_2: 0.0731 - acc_ensemble: 0.9260 - acc_1: 0.8940 - acc_2: 0.8920 - val_loss_1: 0.9741 - val_loss_2: 0.9934 - val_acc_ensemble: 0.7894 - val_acc_1: 0.7702 - val_acc_2: 0.7663\n",
      "Epoch 50/50\n",
      "100/100 - 9s - loss_1: 0.0645 - loss_2: 0.0719 - acc_ensemble: 0.9360 - acc_1: 0.9100 - acc_2: 0.8900 - val_loss_1: 0.9921 - val_loss_2: 1.0087 - val_acc_ensemble: 0.7925 - val_acc_1: 0.7691 - val_acc_2: 0.7625\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B2/S0.75/model_2\n",
      "i   Layer name                      Output shape                     Num param  Inbound            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "0   conv2d_1_1 (Conv2D)             [None,32,32,24] [None,32,32,8]   1120       input              \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "1   bn_1_1 (BatchNormalization)     [None,32,32,24] [None,32,32,8]   80         conv2d_1_1         \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "2   relu_1_1 (Activation)           [None,32,32,24] [None,32,32,8]   0          bn_1_1             \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "3   conv2d_1_2 (Conv2D)             [None,32,32,24] [None,32,32,8]   13352      relu_1_1           \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "4   bn_1_2 (BatchNormalization)     [None,32,32,24] [None,32,32,8]   80         conv2d_1_2         \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "5   relu_1_2 (Activation)           [None,32,32,24] [None,32,32,8]   0          bn_1_2             \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "6   avg_pool2d_1 (AveragePooling2D  [None,16,16,24] [None,16,16,8]   0          relu_1_2           \n",
      "                                    [None,16,16,24] [None,16,16,8]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "7   conv2d_2_1 (Conv2D)             [None,16,16,48] [None,16,16,16]  26704      avg_pool2d_1       \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "8   bn_2_1 (BatchNormalization)     [None,16,16,48] [None,16,16,16]  160        conv2d_2_1         \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "9   relu_2_1 (Activation)           [None,16,16,48] [None,16,16,16]  0          bn_2_1             \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "10  conv2d_2_2 (Conv2D)             [None,16,16,48] [None,16,16,16]  53200      relu_2_1           \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "11  bn_2_2 (BatchNormalization)     [None,16,16,48] [None,16,16,16]  160        conv2d_2_2         \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "12  relu_2_2 (Activation)           [None,16,16,48] [None,16,16,16]  0          bn_2_2             \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "13  avg_pool2d_2 (AveragePooling2D  [None,8,8,48] [None,8,8,16]      0          relu_2_2           \n",
      "                                    [None,8,8,48] [None,8,8,16]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "14  conv2d_3_1 (Conv2D)             [None,8,8,96] [None,8,8,32]      106400     avg_pool2d_2       \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "15  bn_3_1 (BatchNormalization)     [None,8,8,96] [None,8,8,32]      320        conv2d_3_1         \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "16  relu_3_1 (Activation)           [None,8,8,96] [None,8,8,32]      0          bn_3_1             \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "17  conv2d_3_2 (Conv2D)             [None,8,8,96] [None,8,8,32]      212384     relu_3_1           \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "18  bn_3_2 (BatchNormalization)     [None,8,8,96] [None,8,8,32]      320        conv2d_3_2         \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "19  relu_3_2 (Activation)           [None,8,8,96] [None,8,8,32]      0          bn_3_2             \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "20  global_avg_pool2d (GlobalAvera  [None,96] [None,32]              0          relu_3_2           \n",
      "                                    [None,96] [None,32]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "21  fc1 (Dense)                     [None,96] [None,32]              23968      global_avg_pool2d  \n",
      "                                    [None,96] [None,32]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "22  bn_fc1 (BatchNormalization)     [None,96] [None,32]              320        fc1                \n",
      "                                    [None,96] [None,32]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "23  relu_fc1 (Activation)           [None,96] [None,32]              0          bn_fc1             \n",
      "                                    [None,96] [None,32]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "24  output (Dense)                  [None,10]                        1921       relu_fc1           \n",
      "                                    [None,10]                                                      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "Total parameters: 440489\n",
      "50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 - 13s - loss_1: 1.7904 - loss_2: 1.7672 - acc_ensemble: 0.4860 - acc_1: 0.4600 - acc_2: 0.4600 - val_loss_1: 1.5130 - val_loss_2: 1.4965 - val_acc_ensemble: 0.4726 - val_acc_1: 0.4413 - val_acc_2: 0.4577\n",
      "Epoch 2/50\n",
      "100/100 - 9s - loss_1: 1.4605 - loss_2: 1.4191 - acc_ensemble: 0.5480 - acc_1: 0.5260 - acc_2: 0.4840 - val_loss_1: 1.3612 - val_loss_2: 1.3748 - val_acc_ensemble: 0.5256 - val_acc_1: 0.5060 - val_acc_2: 0.4973\n",
      "Epoch 3/50\n",
      "100/100 - 9s - loss_1: 1.3118 - loss_2: 1.2747 - acc_ensemble: 0.5960 - acc_1: 0.5700 - acc_2: 0.5620 - val_loss_1: 1.2482 - val_loss_2: 1.2180 - val_acc_ensemble: 0.5716 - val_acc_1: 0.5467 - val_acc_2: 0.5539\n",
      "Epoch 4/50\n",
      "100/100 - 9s - loss_1: 1.2054 - loss_2: 1.1751 - acc_ensemble: 0.6080 - acc_1: 0.5620 - acc_2: 0.5960 - val_loss_1: 1.1776 - val_loss_2: 1.1187 - val_acc_ensemble: 0.6032 - val_acc_1: 0.5653 - val_acc_2: 0.5914\n",
      "Epoch 5/50\n",
      "100/100 - 9s - loss_1: 1.0965 - loss_2: 1.0916 - acc_ensemble: 0.6580 - acc_1: 0.6540 - acc_2: 0.6240 - val_loss_1: 1.0702 - val_loss_2: 1.1045 - val_acc_ensemble: 0.6307 - val_acc_1: 0.6095 - val_acc_2: 0.6017\n",
      "Epoch 6/50\n",
      "100/100 - 9s - loss_1: 1.0155 - loss_2: 0.9992 - acc_ensemble: 0.6740 - acc_1: 0.6360 - acc_2: 0.6840 - val_loss_1: 1.0330 - val_loss_2: 0.9934 - val_acc_ensemble: 0.6646 - val_acc_1: 0.6289 - val_acc_2: 0.6473\n",
      "Epoch 7/50\n",
      "100/100 - 9s - loss_1: 0.9759 - loss_2: 0.9125 - acc_ensemble: 0.6980 - acc_1: 0.6600 - acc_2: 0.6640 - val_loss_1: 0.9809 - val_loss_2: 0.9805 - val_acc_ensemble: 0.6746 - val_acc_1: 0.6501 - val_acc_2: 0.6502\n",
      "Epoch 8/50\n",
      "100/100 - 9s - loss_1: 0.9073 - loss_2: 0.8683 - acc_ensemble: 0.7260 - acc_1: 0.6780 - acc_2: 0.6980 - val_loss_1: 0.9584 - val_loss_2: 0.9449 - val_acc_ensemble: 0.6841 - val_acc_1: 0.6598 - val_acc_2: 0.6654\n",
      "Epoch 9/50\n",
      "100/100 - 9s - loss_1: 0.8352 - loss_2: 0.8020 - acc_ensemble: 0.7320 - acc_1: 0.7080 - acc_2: 0.7060 - val_loss_1: 0.9374 - val_loss_2: 0.8943 - val_acc_ensemble: 0.6955 - val_acc_1: 0.6669 - val_acc_2: 0.6836\n",
      "Epoch 10/50\n",
      "100/100 - 9s - loss_1: 0.7994 - loss_2: 0.7785 - acc_ensemble: 0.7300 - acc_1: 0.7080 - acc_2: 0.7140 - val_loss_1: 0.9091 - val_loss_2: 0.8736 - val_acc_ensemble: 0.7043 - val_acc_1: 0.6779 - val_acc_2: 0.6901\n",
      "Epoch 11/50\n",
      "100/100 - 9s - loss_1: 0.7550 - loss_2: 0.7247 - acc_ensemble: 0.7840 - acc_1: 0.7480 - acc_2: 0.7460 - val_loss_1: 0.8656 - val_loss_2: 0.8691 - val_acc_ensemble: 0.7150 - val_acc_1: 0.6935 - val_acc_2: 0.6970\n",
      "Epoch 12/50\n",
      "100/100 - 9s - loss_1: 0.7330 - loss_2: 0.7151 - acc_ensemble: 0.7800 - acc_1: 0.7260 - acc_2: 0.7560 - val_loss_1: 0.8350 - val_loss_2: 0.8494 - val_acc_ensemble: 0.7256 - val_acc_1: 0.7030 - val_acc_2: 0.7023\n",
      "Epoch 13/50\n",
      "100/100 - 9s - loss_1: 0.6678 - loss_2: 0.6317 - acc_ensemble: 0.7720 - acc_1: 0.7600 - acc_2: 0.7620 - val_loss_1: 0.8296 - val_loss_2: 0.8327 - val_acc_ensemble: 0.7258 - val_acc_1: 0.7123 - val_acc_2: 0.7081\n",
      "Epoch 14/50\n",
      "100/100 - 9s - loss_1: 0.6368 - loss_2: 0.5917 - acc_ensemble: 0.7720 - acc_1: 0.7520 - acc_2: 0.7540 - val_loss_1: 0.8256 - val_loss_2: 0.8081 - val_acc_ensemble: 0.7369 - val_acc_1: 0.7123 - val_acc_2: 0.7184\n",
      "Epoch 15/50\n",
      "100/100 - 9s - loss_1: 0.6279 - loss_2: 0.5897 - acc_ensemble: 0.8200 - acc_1: 0.7680 - acc_2: 0.7820 - val_loss_1: 0.7964 - val_loss_2: 0.8025 - val_acc_ensemble: 0.7448 - val_acc_1: 0.7265 - val_acc_2: 0.7207\n",
      "Epoch 16/50\n",
      "100/100 - 9s - loss_1: 0.5696 - loss_2: 0.5261 - acc_ensemble: 0.8020 - acc_1: 0.7620 - acc_2: 0.7780 - val_loss_1: 0.8012 - val_loss_2: 0.7952 - val_acc_ensemble: 0.7451 - val_acc_1: 0.7197 - val_acc_2: 0.7222\n",
      "Epoch 17/50\n",
      "100/100 - 9s - loss_1: 0.5513 - loss_2: 0.5294 - acc_ensemble: 0.8020 - acc_1: 0.7660 - acc_2: 0.7740 - val_loss_1: 0.7902 - val_loss_2: 0.7753 - val_acc_ensemble: 0.7538 - val_acc_1: 0.7294 - val_acc_2: 0.7301\n",
      "Epoch 18/50\n",
      "100/100 - 9s - loss_1: 0.5272 - loss_2: 0.4905 - acc_ensemble: 0.8280 - acc_1: 0.8080 - acc_2: 0.8040 - val_loss_1: 0.7515 - val_loss_2: 0.7537 - val_acc_ensemble: 0.7670 - val_acc_1: 0.7424 - val_acc_2: 0.7427\n",
      "Epoch 19/50\n",
      "100/100 - 9s - loss_1: 0.4972 - loss_2: 0.4630 - acc_ensemble: 0.8180 - acc_1: 0.7960 - acc_2: 0.7900 - val_loss_1: 0.7629 - val_loss_2: 0.7729 - val_acc_ensemble: 0.7612 - val_acc_1: 0.7394 - val_acc_2: 0.7364\n",
      "Epoch 20/50\n",
      "100/100 - 9s - loss_1: 0.4728 - loss_2: 0.4379 - acc_ensemble: 0.8180 - acc_1: 0.7880 - acc_2: 0.7900 - val_loss_1: 0.7579 - val_loss_2: 0.7551 - val_acc_ensemble: 0.7726 - val_acc_1: 0.7393 - val_acc_2: 0.7454\n",
      "Epoch 21/50\n",
      "100/100 - 9s - loss_1: 0.4335 - loss_2: 0.4268 - acc_ensemble: 0.8300 - acc_1: 0.8240 - acc_2: 0.8020 - val_loss_1: 0.7573 - val_loss_2: 0.7514 - val_acc_ensemble: 0.7688 - val_acc_1: 0.7461 - val_acc_2: 0.7470\n",
      "Epoch 22/50\n",
      "100/100 - 9s - loss_1: 0.3899 - loss_2: 0.3980 - acc_ensemble: 0.8120 - acc_1: 0.8060 - acc_2: 0.7720 - val_loss_1: 0.7517 - val_loss_2: 0.7942 - val_acc_ensemble: 0.7717 - val_acc_1: 0.7540 - val_acc_2: 0.7389\n",
      "Epoch 23/50\n",
      "100/100 - 9s - loss_1: 0.3636 - loss_2: 0.3614 - acc_ensemble: 0.8280 - acc_1: 0.7920 - acc_2: 0.7960 - val_loss_1: 0.7923 - val_loss_2: 0.7696 - val_acc_ensemble: 0.7695 - val_acc_1: 0.7437 - val_acc_2: 0.7453\n",
      "Epoch 24/50\n",
      "100/100 - 9s - loss_1: 0.3645 - loss_2: 0.3543 - acc_ensemble: 0.8240 - acc_1: 0.8020 - acc_2: 0.8120 - val_loss_1: 0.7792 - val_loss_2: 0.7734 - val_acc_ensemble: 0.7774 - val_acc_1: 0.7483 - val_acc_2: 0.7468\n",
      "Epoch 25/50\n",
      "100/100 - 9s - loss_1: 0.3500 - loss_2: 0.3122 - acc_ensemble: 0.8500 - acc_1: 0.8300 - acc_2: 0.8040 - val_loss_1: 0.7887 - val_loss_2: 0.7973 - val_acc_ensemble: 0.7737 - val_acc_1: 0.7484 - val_acc_2: 0.7448\n",
      "Epoch 26/50\n",
      "100/100 - 9s - loss_1: 0.3190 - loss_2: 0.2991 - acc_ensemble: 0.8620 - acc_1: 0.8300 - acc_2: 0.8160 - val_loss_1: 0.7812 - val_loss_2: 0.7669 - val_acc_ensemble: 0.7772 - val_acc_1: 0.7516 - val_acc_2: 0.7523\n",
      "Epoch 27/50\n",
      "100/100 - 9s - loss_1: 0.2826 - loss_2: 0.2879 - acc_ensemble: 0.8420 - acc_1: 0.8280 - acc_2: 0.8080 - val_loss_1: 0.7947 - val_loss_2: 0.7836 - val_acc_ensemble: 0.7840 - val_acc_1: 0.7497 - val_acc_2: 0.7514\n",
      "Epoch 28/50\n",
      "100/100 - 9s - loss_1: 0.2581 - loss_2: 0.2556 - acc_ensemble: 0.8500 - acc_1: 0.8160 - acc_2: 0.8080 - val_loss_1: 0.8113 - val_loss_2: 0.8261 - val_acc_ensemble: 0.7810 - val_acc_1: 0.7510 - val_acc_2: 0.7463\n",
      "Epoch 29/50\n",
      "100/100 - 9s - loss_1: 0.2619 - loss_2: 0.2418 - acc_ensemble: 0.8660 - acc_1: 0.8340 - acc_2: 0.8320 - val_loss_1: 0.8260 - val_loss_2: 0.8244 - val_acc_ensemble: 0.7749 - val_acc_1: 0.7490 - val_acc_2: 0.7485\n",
      "Epoch 30/50\n",
      "100/100 - 9s - loss_1: 0.2362 - loss_2: 0.2010 - acc_ensemble: 0.8560 - acc_1: 0.8100 - acc_2: 0.8280 - val_loss_1: 0.8097 - val_loss_2: 0.8210 - val_acc_ensemble: 0.7807 - val_acc_1: 0.7505 - val_acc_2: 0.7570\n",
      "Epoch 31/50\n",
      "100/100 - 9s - loss_1: 0.2420 - loss_2: 0.2288 - acc_ensemble: 0.8540 - acc_1: 0.8280 - acc_2: 0.8320 - val_loss_1: 0.8484 - val_loss_2: 0.8269 - val_acc_ensemble: 0.7826 - val_acc_1: 0.7522 - val_acc_2: 0.7541\n",
      "Epoch 32/50\n",
      "100/100 - 9s - loss_1: 0.2044 - loss_2: 0.1814 - acc_ensemble: 0.8660 - acc_1: 0.8340 - acc_2: 0.8200 - val_loss_1: 0.8018 - val_loss_2: 0.8474 - val_acc_ensemble: 0.7878 - val_acc_1: 0.7667 - val_acc_2: 0.7526\n",
      "Epoch 33/50\n",
      "100/100 - 9s - loss_1: 0.1795 - loss_2: 0.1744 - acc_ensemble: 0.8700 - acc_1: 0.8300 - acc_2: 0.8440 - val_loss_1: 0.8237 - val_loss_2: 0.8384 - val_acc_ensemble: 0.7848 - val_acc_1: 0.7613 - val_acc_2: 0.7576\n",
      "Epoch 34/50\n",
      "100/100 - 9s - loss_1: 0.1917 - loss_2: 0.2086 - acc_ensemble: 0.8600 - acc_1: 0.8380 - acc_2: 0.8300 - val_loss_1: 0.8644 - val_loss_2: 0.8775 - val_acc_ensemble: 0.7789 - val_acc_1: 0.7568 - val_acc_2: 0.7520\n",
      "Epoch 35/50\n",
      "100/100 - 9s - loss_1: 0.1875 - loss_2: 0.1753 - acc_ensemble: 0.8620 - acc_1: 0.8280 - acc_2: 0.8220 - val_loss_1: 0.8452 - val_loss_2: 0.8515 - val_acc_ensemble: 0.7905 - val_acc_1: 0.7616 - val_acc_2: 0.7617\n",
      "Epoch 36/50\n",
      "100/100 - 9s - loss_1: 0.1659 - loss_2: 0.1454 - acc_ensemble: 0.8620 - acc_1: 0.8280 - acc_2: 0.8320 - val_loss_1: 0.8399 - val_loss_2: 0.8510 - val_acc_ensemble: 0.7902 - val_acc_1: 0.7623 - val_acc_2: 0.7605\n",
      "Epoch 37/50\n",
      "100/100 - 9s - loss_1: 0.1555 - loss_2: 0.1211 - acc_ensemble: 0.8760 - acc_1: 0.8320 - acc_2: 0.8560 - val_loss_1: 0.8546 - val_loss_2: 0.8753 - val_acc_ensemble: 0.7915 - val_acc_1: 0.7626 - val_acc_2: 0.7613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50\n",
      "100/100 - 9s - loss_1: 0.1616 - loss_2: 0.1330 - acc_ensemble: 0.8580 - acc_1: 0.8300 - acc_2: 0.8420 - val_loss_1: 0.8996 - val_loss_2: 0.9216 - val_acc_ensemble: 0.7881 - val_acc_1: 0.7499 - val_acc_2: 0.7504\n",
      "Epoch 39/50\n",
      "100/100 - 9s - loss_1: 0.1518 - loss_2: 0.1478 - acc_ensemble: 0.8780 - acc_1: 0.8500 - acc_2: 0.8360 - val_loss_1: 0.8956 - val_loss_2: 0.8977 - val_acc_ensemble: 0.7874 - val_acc_1: 0.7576 - val_acc_2: 0.7595\n",
      "Epoch 40/50\n",
      "100/100 - 9s - loss_1: 0.1144 - loss_2: 0.1063 - acc_ensemble: 0.8800 - acc_1: 0.8360 - acc_2: 0.8560 - val_loss_1: 0.8829 - val_loss_2: 0.9204 - val_acc_ensemble: 0.7879 - val_acc_1: 0.7654 - val_acc_2: 0.7608\n",
      "Epoch 41/50\n",
      "100/100 - 9s - loss_1: 0.1008 - loss_2: 0.1193 - acc_ensemble: 0.8740 - acc_1: 0.8500 - acc_2: 0.8400 - val_loss_1: 0.9104 - val_loss_2: 0.9741 - val_acc_ensemble: 0.7886 - val_acc_1: 0.7605 - val_acc_2: 0.7540\n",
      "Epoch 42/50\n",
      "100/100 - 9s - loss_1: 0.1135 - loss_2: 0.1151 - acc_ensemble: 0.8640 - acc_1: 0.8340 - acc_2: 0.8200 - val_loss_1: 0.9700 - val_loss_2: 0.9741 - val_acc_ensemble: 0.7823 - val_acc_1: 0.7550 - val_acc_2: 0.7558\n",
      "Epoch 43/50\n",
      "100/100 - 9s - loss_1: 0.1076 - loss_2: 0.1165 - acc_ensemble: 0.8860 - acc_1: 0.8380 - acc_2: 0.8440 - val_loss_1: 0.9793 - val_loss_2: 1.0091 - val_acc_ensemble: 0.7806 - val_acc_1: 0.7498 - val_acc_2: 0.7501\n",
      "Epoch 44/50\n",
      "100/100 - 9s - loss_1: 0.0861 - loss_2: 0.1250 - acc_ensemble: 0.8860 - acc_1: 0.8480 - acc_2: 0.8380 - val_loss_1: 0.9268 - val_loss_2: 0.9573 - val_acc_ensemble: 0.7918 - val_acc_1: 0.7686 - val_acc_2: 0.7645\n",
      "Epoch 45/50\n",
      "100/100 - 9s - loss_1: 0.0903 - loss_2: 0.0916 - acc_ensemble: 0.8800 - acc_1: 0.8340 - acc_2: 0.8200 - val_loss_1: 1.0100 - val_loss_2: 1.0084 - val_acc_ensemble: 0.7867 - val_acc_1: 0.7507 - val_acc_2: 0.7604\n",
      "Epoch 46/50\n",
      "100/100 - 9s - loss_1: 0.1053 - loss_2: 0.1074 - acc_ensemble: 0.8780 - acc_1: 0.8560 - acc_2: 0.8300 - val_loss_1: 0.9903 - val_loss_2: 0.9831 - val_acc_ensemble: 0.7880 - val_acc_1: 0.7612 - val_acc_2: 0.7569\n",
      "Epoch 47/50\n",
      "100/100 - 9s - loss_1: 0.1074 - loss_2: 0.0951 - acc_ensemble: 0.8780 - acc_1: 0.8540 - acc_2: 0.8440 - val_loss_1: 1.0293 - val_loss_2: 1.0020 - val_acc_ensemble: 0.7888 - val_acc_1: 0.7535 - val_acc_2: 0.7587\n",
      "Epoch 48/50\n",
      "100/100 - 9s - loss_1: 0.1012 - loss_2: 0.0873 - acc_ensemble: 0.8660 - acc_1: 0.8460 - acc_2: 0.8440 - val_loss_1: 1.0138 - val_loss_2: 0.9917 - val_acc_ensemble: 0.7887 - val_acc_1: 0.7540 - val_acc_2: 0.7601\n",
      "Epoch 49/50\n",
      "100/100 - 9s - loss_1: 0.0860 - loss_2: 0.1031 - acc_ensemble: 0.8800 - acc_1: 0.8460 - acc_2: 0.8440 - val_loss_1: 0.9932 - val_loss_2: 1.0474 - val_acc_ensemble: 0.7854 - val_acc_1: 0.7621 - val_acc_2: 0.7533\n",
      "Epoch 50/50\n",
      "100/100 - 9s - loss_1: 0.0699 - loss_2: 0.0787 - acc_ensemble: 0.8960 - acc_1: 0.8300 - acc_2: 0.8540 - val_loss_1: 1.0269 - val_loss_2: 1.0305 - val_acc_ensemble: 0.7889 - val_acc_1: 0.7608 - val_acc_2: 0.7583\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B2/S0.75/model_3\n",
      "i   Layer name                      Output shape                     Num param  Inbound            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "0   conv2d_1_1 (Conv2D)             [None,32,32,24] [None,32,32,8]   1120       input              \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "1   bn_1_1 (BatchNormalization)     [None,32,32,24] [None,32,32,8]   80         conv2d_1_1         \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "2   relu_1_1 (Activation)           [None,32,32,24] [None,32,32,8]   0          bn_1_1             \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "3   conv2d_1_2 (Conv2D)             [None,32,32,24] [None,32,32,8]   13352      relu_1_1           \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "4   bn_1_2 (BatchNormalization)     [None,32,32,24] [None,32,32,8]   80         conv2d_1_2         \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "5   relu_1_2 (Activation)           [None,32,32,24] [None,32,32,8]   0          bn_1_2             \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "6   avg_pool2d_1 (AveragePooling2D  [None,16,16,24] [None,16,16,8]   0          relu_1_2           \n",
      "                                    [None,16,16,24] [None,16,16,8]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "7   conv2d_2_1 (Conv2D)             [None,16,16,48] [None,16,16,16]  26704      avg_pool2d_1       \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "8   bn_2_1 (BatchNormalization)     [None,16,16,48] [None,16,16,16]  160        conv2d_2_1         \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "9   relu_2_1 (Activation)           [None,16,16,48] [None,16,16,16]  0          bn_2_1             \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "10  conv2d_2_2 (Conv2D)             [None,16,16,48] [None,16,16,16]  53200      relu_2_1           \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "11  bn_2_2 (BatchNormalization)     [None,16,16,48] [None,16,16,16]  160        conv2d_2_2         \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "12  relu_2_2 (Activation)           [None,16,16,48] [None,16,16,16]  0          bn_2_2             \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "13  avg_pool2d_2 (AveragePooling2D  [None,8,8,48] [None,8,8,16]      0          relu_2_2           \n",
      "                                    [None,8,8,48] [None,8,8,16]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "14  conv2d_3_1 (Conv2D)             [None,8,8,96] [None,8,8,32]      106400     avg_pool2d_2       \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "15  bn_3_1 (BatchNormalization)     [None,8,8,96] [None,8,8,32]      320        conv2d_3_1         \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "16  relu_3_1 (Activation)           [None,8,8,96] [None,8,8,32]      0          bn_3_1             \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "17  conv2d_3_2 (Conv2D)             [None,8,8,96] [None,8,8,32]      212384     relu_3_1           \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "18  bn_3_2 (BatchNormalization)     [None,8,8,96] [None,8,8,32]      320        conv2d_3_2         \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "19  relu_3_2 (Activation)           [None,8,8,96] [None,8,8,32]      0          bn_3_2             \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "20  global_avg_pool2d (GlobalAvera  [None,96] [None,32]              0          relu_3_2           \n",
      "                                    [None,96] [None,32]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "21  fc1 (Dense)                     [None,96] [None,32]              23968      global_avg_pool2d  \n",
      "                                    [None,96] [None,32]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "22  bn_fc1 (BatchNormalization)     [None,96] [None,32]              320        fc1                \n",
      "                                    [None,96] [None,32]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "23  relu_fc1 (Activation)           [None,96] [None,32]              0          bn_fc1             \n",
      "                                    [None,96] [None,32]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "24  output (Dense)                  [None,10]                        1921       relu_fc1           \n",
      "                                    [None,10]                                                      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "Total parameters: 440489\n",
      "50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 - 14s - loss_1: 1.7749 - loss_2: 1.7564 - acc_ensemble: 0.4880 - acc_1: 0.4300 - acc_2: 0.4980 - val_loss_1: 1.5189 - val_loss_2: 1.4860 - val_acc_ensemble: 0.4726 - val_acc_1: 0.4318 - val_acc_2: 0.4526\n",
      "Epoch 2/50\n",
      "100/100 - 9s - loss_1: 1.4546 - loss_2: 1.4281 - acc_ensemble: 0.5700 - acc_1: 0.5740 - acc_2: 0.5360 - val_loss_1: 1.3298 - val_loss_2: 1.3240 - val_acc_ensemble: 0.5342 - val_acc_1: 0.5188 - val_acc_2: 0.5122\n",
      "Epoch 3/50\n",
      "100/100 - 9s - loss_1: 1.2810 - loss_2: 1.2411 - acc_ensemble: 0.6120 - acc_1: 0.5820 - acc_2: 0.5840 - val_loss_1: 1.2160 - val_loss_2: 1.2027 - val_acc_ensemble: 0.5828 - val_acc_1: 0.5625 - val_acc_2: 0.5596\n",
      "Epoch 4/50\n",
      "100/100 - 9s - loss_1: 1.1430 - loss_2: 1.1498 - acc_ensemble: 0.6540 - acc_1: 0.6320 - acc_2: 0.6340 - val_loss_1: 1.1113 - val_loss_2: 1.0880 - val_acc_ensemble: 0.6232 - val_acc_1: 0.6020 - val_acc_2: 0.6052\n",
      "Epoch 5/50\n",
      "100/100 - 9s - loss_1: 1.0743 - loss_2: 0.9982 - acc_ensemble: 0.7160 - acc_1: 0.6780 - acc_2: 0.6940 - val_loss_1: 1.0695 - val_loss_2: 1.0335 - val_acc_ensemble: 0.6450 - val_acc_1: 0.6162 - val_acc_2: 0.6297\n",
      "Epoch 6/50\n",
      "100/100 - 9s - loss_1: 0.9830 - loss_2: 0.9506 - acc_ensemble: 0.6860 - acc_1: 0.6680 - acc_2: 0.6520 - val_loss_1: 1.0070 - val_loss_2: 0.9844 - val_acc_ensemble: 0.6710 - val_acc_1: 0.6412 - val_acc_2: 0.6497\n",
      "Epoch 7/50\n",
      "100/100 - 9s - loss_1: 0.9201 - loss_2: 0.8944 - acc_ensemble: 0.7220 - acc_1: 0.6720 - acc_2: 0.7060 - val_loss_1: 0.9958 - val_loss_2: 0.9372 - val_acc_ensemble: 0.6808 - val_acc_1: 0.6438 - val_acc_2: 0.6685\n",
      "Epoch 8/50\n",
      "100/100 - 9s - loss_1: 0.8726 - loss_2: 0.8294 - acc_ensemble: 0.7440 - acc_1: 0.7000 - acc_2: 0.7000 - val_loss_1: 0.9373 - val_loss_2: 0.9080 - val_acc_ensemble: 0.6930 - val_acc_1: 0.6664 - val_acc_2: 0.6784\n",
      "Epoch 9/50\n",
      "100/100 - 9s - loss_1: 0.7936 - loss_2: 0.7639 - acc_ensemble: 0.7620 - acc_1: 0.6980 - acc_2: 0.7320 - val_loss_1: 0.9242 - val_loss_2: 0.8734 - val_acc_ensemble: 0.7055 - val_acc_1: 0.6755 - val_acc_2: 0.6907\n",
      "Epoch 10/50\n",
      "100/100 - 9s - loss_1: 0.7516 - loss_2: 0.7454 - acc_ensemble: 0.7720 - acc_1: 0.7340 - acc_2: 0.7380 - val_loss_1: 0.8594 - val_loss_2: 0.8514 - val_acc_ensemble: 0.7204 - val_acc_1: 0.6931 - val_acc_2: 0.6963\n",
      "Epoch 11/50\n",
      "100/100 - 9s - loss_1: 0.6801 - loss_2: 0.7203 - acc_ensemble: 0.7680 - acc_1: 0.7300 - acc_2: 0.7580 - val_loss_1: 0.8902 - val_loss_2: 0.8108 - val_acc_ensemble: 0.7246 - val_acc_1: 0.6898 - val_acc_2: 0.7080\n",
      "Epoch 12/50\n",
      "100/100 - 9s - loss_1: 0.7063 - loss_2: 0.6646 - acc_ensemble: 0.7800 - acc_1: 0.7640 - acc_2: 0.7640 - val_loss_1: 0.8437 - val_loss_2: 0.8116 - val_acc_ensemble: 0.7340 - val_acc_1: 0.7040 - val_acc_2: 0.7148\n",
      "Epoch 13/50\n",
      "100/100 - 9s - loss_1: 0.6360 - loss_2: 0.6216 - acc_ensemble: 0.7960 - acc_1: 0.7660 - acc_2: 0.7540 - val_loss_1: 0.8137 - val_loss_2: 0.7744 - val_acc_ensemble: 0.7489 - val_acc_1: 0.7138 - val_acc_2: 0.7296\n",
      "Epoch 14/50\n",
      "100/100 - 9s - loss_1: 0.5954 - loss_2: 0.5798 - acc_ensemble: 0.8020 - acc_1: 0.7800 - acc_2: 0.7760 - val_loss_1: 0.8145 - val_loss_2: 0.7751 - val_acc_ensemble: 0.7480 - val_acc_1: 0.7166 - val_acc_2: 0.7305\n",
      "Epoch 15/50\n",
      "100/100 - 9s - loss_1: 0.5821 - loss_2: 0.5333 - acc_ensemble: 0.8160 - acc_1: 0.8000 - acc_2: 0.7900 - val_loss_1: 0.7856 - val_loss_2: 0.7646 - val_acc_ensemble: 0.7533 - val_acc_1: 0.7261 - val_acc_2: 0.7302\n",
      "Epoch 16/50\n",
      "100/100 - 9s - loss_1: 0.5061 - loss_2: 0.4815 - acc_ensemble: 0.8280 - acc_1: 0.7960 - acc_2: 0.7880 - val_loss_1: 0.8022 - val_loss_2: 0.7946 - val_acc_ensemble: 0.7551 - val_acc_1: 0.7264 - val_acc_2: 0.7329\n",
      "Epoch 17/50\n",
      "100/100 - 9s - loss_1: 0.4986 - loss_2: 0.4841 - acc_ensemble: 0.8280 - acc_1: 0.7960 - acc_2: 0.7820 - val_loss_1: 0.8153 - val_loss_2: 0.7772 - val_acc_ensemble: 0.7613 - val_acc_1: 0.7249 - val_acc_2: 0.7361\n",
      "Epoch 18/50\n",
      "100/100 - 9s - loss_1: 0.4511 - loss_2: 0.4429 - acc_ensemble: 0.8500 - acc_1: 0.7920 - acc_2: 0.8120 - val_loss_1: 0.7823 - val_loss_2: 0.7680 - val_acc_ensemble: 0.7690 - val_acc_1: 0.7331 - val_acc_2: 0.7402\n",
      "Epoch 19/50\n",
      "100/100 - 9s - loss_1: 0.4464 - loss_2: 0.4548 - acc_ensemble: 0.8360 - acc_1: 0.8240 - acc_2: 0.7980 - val_loss_1: 0.7611 - val_loss_2: 0.7583 - val_acc_ensemble: 0.7689 - val_acc_1: 0.7462 - val_acc_2: 0.7457\n",
      "Epoch 20/50\n",
      "100/100 - 9s - loss_1: 0.4306 - loss_2: 0.4009 - acc_ensemble: 0.8540 - acc_1: 0.8220 - acc_2: 0.7960 - val_loss_1: 0.7699 - val_loss_2: 0.7757 - val_acc_ensemble: 0.7698 - val_acc_1: 0.7389 - val_acc_2: 0.7422\n",
      "Epoch 21/50\n",
      "100/100 - 9s - loss_1: 0.3750 - loss_2: 0.3842 - acc_ensemble: 0.8380 - acc_1: 0.8160 - acc_2: 0.8240 - val_loss_1: 0.7629 - val_loss_2: 0.7722 - val_acc_ensemble: 0.7718 - val_acc_1: 0.7486 - val_acc_2: 0.7408\n",
      "Epoch 22/50\n",
      "100/100 - 9s - loss_1: 0.3754 - loss_2: 0.3434 - acc_ensemble: 0.8480 - acc_1: 0.8220 - acc_2: 0.8120 - val_loss_1: 0.7989 - val_loss_2: 0.7609 - val_acc_ensemble: 0.7720 - val_acc_1: 0.7407 - val_acc_2: 0.7493\n",
      "Epoch 23/50\n",
      "100/100 - 9s - loss_1: 0.3305 - loss_2: 0.3218 - acc_ensemble: 0.8720 - acc_1: 0.8340 - acc_2: 0.8220 - val_loss_1: 0.8407 - val_loss_2: 0.7519 - val_acc_ensemble: 0.7741 - val_acc_1: 0.7366 - val_acc_2: 0.7532\n",
      "Epoch 24/50\n",
      "100/100 - 9s - loss_1: 0.3284 - loss_2: 0.2846 - acc_ensemble: 0.8800 - acc_1: 0.8460 - acc_2: 0.8480 - val_loss_1: 0.7816 - val_loss_2: 0.7586 - val_acc_ensemble: 0.7796 - val_acc_1: 0.7515 - val_acc_2: 0.7600\n",
      "Epoch 25/50\n",
      "100/100 - 9s - loss_1: 0.2995 - loss_2: 0.2965 - acc_ensemble: 0.8740 - acc_1: 0.8440 - acc_2: 0.8380 - val_loss_1: 0.8240 - val_loss_2: 0.7864 - val_acc_ensemble: 0.7743 - val_acc_1: 0.7421 - val_acc_2: 0.7500\n",
      "Epoch 26/50\n",
      "100/100 - 9s - loss_1: 0.2720 - loss_2: 0.3053 - acc_ensemble: 0.8640 - acc_1: 0.8380 - acc_2: 0.8300 - val_loss_1: 0.8008 - val_loss_2: 0.7753 - val_acc_ensemble: 0.7805 - val_acc_1: 0.7533 - val_acc_2: 0.7567\n",
      "Epoch 27/50\n",
      "100/100 - 9s - loss_1: 0.2804 - loss_2: 0.2622 - acc_ensemble: 0.8960 - acc_1: 0.8480 - acc_2: 0.8700 - val_loss_1: 0.8021 - val_loss_2: 0.7800 - val_acc_ensemble: 0.7844 - val_acc_1: 0.7544 - val_acc_2: 0.7597\n",
      "Epoch 28/50\n",
      "100/100 - 9s - loss_1: 0.2316 - loss_2: 0.2167 - acc_ensemble: 0.8920 - acc_1: 0.8780 - acc_2: 0.8540 - val_loss_1: 0.8271 - val_loss_2: 0.7903 - val_acc_ensemble: 0.7858 - val_acc_1: 0.7495 - val_acc_2: 0.7610\n",
      "Epoch 29/50\n",
      "100/100 - 9s - loss_1: 0.2320 - loss_2: 0.2260 - acc_ensemble: 0.9020 - acc_1: 0.8620 - acc_2: 0.8660 - val_loss_1: 0.7966 - val_loss_2: 0.7794 - val_acc_ensemble: 0.7917 - val_acc_1: 0.7672 - val_acc_2: 0.7664\n",
      "Epoch 30/50\n",
      "100/100 - 9s - loss_1: 0.2069 - loss_2: 0.1814 - acc_ensemble: 0.8900 - acc_1: 0.8480 - acc_2: 0.8580 - val_loss_1: 0.8474 - val_loss_2: 0.8407 - val_acc_ensemble: 0.7861 - val_acc_1: 0.7558 - val_acc_2: 0.7554\n",
      "Epoch 31/50\n",
      "100/100 - 9s - loss_1: 0.2258 - loss_2: 0.2176 - acc_ensemble: 0.8920 - acc_1: 0.8780 - acc_2: 0.8440 - val_loss_1: 0.8470 - val_loss_2: 0.8143 - val_acc_ensemble: 0.7904 - val_acc_1: 0.7566 - val_acc_2: 0.7616\n",
      "Epoch 32/50\n",
      "100/100 - 9s - loss_1: 0.2130 - loss_2: 0.1708 - acc_ensemble: 0.8760 - acc_1: 0.8600 - acc_2: 0.8420 - val_loss_1: 0.8337 - val_loss_2: 0.8399 - val_acc_ensemble: 0.7861 - val_acc_1: 0.7591 - val_acc_2: 0.7504\n",
      "Epoch 33/50\n",
      "100/100 - 9s - loss_1: 0.1711 - loss_2: 0.1941 - acc_ensemble: 0.8720 - acc_1: 0.8560 - acc_2: 0.8560 - val_loss_1: 0.8788 - val_loss_2: 0.8652 - val_acc_ensemble: 0.7863 - val_acc_1: 0.7526 - val_acc_2: 0.7527\n",
      "Epoch 34/50\n",
      "100/100 - 9s - loss_1: 0.1815 - loss_2: 0.1712 - acc_ensemble: 0.8940 - acc_1: 0.8820 - acc_2: 0.8560 - val_loss_1: 0.8786 - val_loss_2: 0.8735 - val_acc_ensemble: 0.7829 - val_acc_1: 0.7538 - val_acc_2: 0.7550\n",
      "Epoch 35/50\n",
      "100/100 - 9s - loss_1: 0.1690 - loss_2: 0.1321 - acc_ensemble: 0.8840 - acc_1: 0.8560 - acc_2: 0.8500 - val_loss_1: 0.8691 - val_loss_2: 0.8840 - val_acc_ensemble: 0.7858 - val_acc_1: 0.7563 - val_acc_2: 0.7565\n",
      "Epoch 36/50\n",
      "100/100 - 9s - loss_1: 0.1531 - loss_2: 0.1613 - acc_ensemble: 0.8900 - acc_1: 0.8620 - acc_2: 0.8720 - val_loss_1: 0.9038 - val_loss_2: 0.8752 - val_acc_ensemble: 0.7890 - val_acc_1: 0.7632 - val_acc_2: 0.7572\n",
      "Epoch 37/50\n",
      "100/100 - 9s - loss_1: 0.1467 - loss_2: 0.1255 - acc_ensemble: 0.9020 - acc_1: 0.8740 - acc_2: 0.8700 - val_loss_1: 0.8870 - val_loss_2: 0.8985 - val_acc_ensemble: 0.7883 - val_acc_1: 0.7578 - val_acc_2: 0.7560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50\n",
      "100/100 - 9s - loss_1: 0.1330 - loss_2: 0.1148 - acc_ensemble: 0.8940 - acc_1: 0.8660 - acc_2: 0.8440 - val_loss_1: 0.9108 - val_loss_2: 0.8854 - val_acc_ensemble: 0.7920 - val_acc_1: 0.7579 - val_acc_2: 0.7647\n",
      "Epoch 39/50\n",
      "100/100 - 9s - loss_1: 0.1172 - loss_2: 0.1167 - acc_ensemble: 0.9000 - acc_1: 0.8960 - acc_2: 0.8520 - val_loss_1: 0.9157 - val_loss_2: 0.9102 - val_acc_ensemble: 0.7907 - val_acc_1: 0.7613 - val_acc_2: 0.7629\n",
      "Epoch 40/50\n",
      "100/100 - 9s - loss_1: 0.1165 - loss_2: 0.1071 - acc_ensemble: 0.9120 - acc_1: 0.8840 - acc_2: 0.8500 - val_loss_1: 0.9489 - val_loss_2: 0.9563 - val_acc_ensemble: 0.7869 - val_acc_1: 0.7601 - val_acc_2: 0.7592\n",
      "Epoch 41/50\n",
      "100/100 - 9s - loss_1: 0.1153 - loss_2: 0.0859 - acc_ensemble: 0.9060 - acc_1: 0.8800 - acc_2: 0.8600 - val_loss_1: 0.9611 - val_loss_2: 0.9295 - val_acc_ensemble: 0.7910 - val_acc_1: 0.7631 - val_acc_2: 0.7605\n",
      "Epoch 42/50\n",
      "100/100 - 9s - loss_1: 0.1095 - loss_2: 0.0974 - acc_ensemble: 0.9140 - acc_1: 0.8740 - acc_2: 0.8820 - val_loss_1: 0.9820 - val_loss_2: 0.9623 - val_acc_ensemble: 0.7885 - val_acc_1: 0.7550 - val_acc_2: 0.7594\n",
      "Epoch 43/50\n",
      "100/100 - 9s - loss_1: 0.1007 - loss_2: 0.0737 - acc_ensemble: 0.9100 - acc_1: 0.8800 - acc_2: 0.8760 - val_loss_1: 0.9984 - val_loss_2: 0.9419 - val_acc_ensemble: 0.7911 - val_acc_1: 0.7524 - val_acc_2: 0.7667\n",
      "Epoch 44/50\n",
      "100/100 - 9s - loss_1: 0.1038 - loss_2: 0.0744 - acc_ensemble: 0.9200 - acc_1: 0.8820 - acc_2: 0.8800 - val_loss_1: 0.9738 - val_loss_2: 0.9767 - val_acc_ensemble: 0.7937 - val_acc_1: 0.7616 - val_acc_2: 0.7621\n",
      "Epoch 45/50\n",
      "100/100 - 9s - loss_1: 0.0815 - loss_2: 0.0847 - acc_ensemble: 0.9060 - acc_1: 0.8720 - acc_2: 0.8580 - val_loss_1: 0.9768 - val_loss_2: 1.0085 - val_acc_ensemble: 0.7939 - val_acc_1: 0.7665 - val_acc_2: 0.7559\n",
      "Epoch 46/50\n",
      "100/100 - 9s - loss_1: 0.0863 - loss_2: 0.0923 - acc_ensemble: 0.8920 - acc_1: 0.8580 - acc_2: 0.8340 - val_loss_1: 1.0010 - val_loss_2: 1.0548 - val_acc_ensemble: 0.7878 - val_acc_1: 0.7603 - val_acc_2: 0.7526\n",
      "Epoch 47/50\n",
      "100/100 - 9s - loss_1: 0.1045 - loss_2: 0.1136 - acc_ensemble: 0.9140 - acc_1: 0.8740 - acc_2: 0.8620 - val_loss_1: 1.0354 - val_loss_2: 1.0438 - val_acc_ensemble: 0.7887 - val_acc_1: 0.7564 - val_acc_2: 0.7527\n",
      "Epoch 48/50\n",
      "100/100 - 9s - loss_1: 0.1207 - loss_2: 0.1076 - acc_ensemble: 0.9140 - acc_1: 0.8780 - acc_2: 0.8640 - val_loss_1: 1.0362 - val_loss_2: 1.0294 - val_acc_ensemble: 0.7836 - val_acc_1: 0.7535 - val_acc_2: 0.7529\n",
      "Epoch 49/50\n",
      "100/100 - 9s - loss_1: 0.0787 - loss_2: 0.0706 - acc_ensemble: 0.9100 - acc_1: 0.8840 - acc_2: 0.8660 - val_loss_1: 1.0419 - val_loss_2: 1.0336 - val_acc_ensemble: 0.7890 - val_acc_1: 0.7565 - val_acc_2: 0.7607\n",
      "Epoch 50/50\n",
      "100/100 - 9s - loss_1: 0.0986 - loss_2: 0.0873 - acc_ensemble: 0.9100 - acc_1: 0.8940 - acc_2: 0.8780 - val_loss_1: 1.0919 - val_loss_2: 1.0434 - val_acc_ensemble: 0.7879 - val_acc_1: 0.7480 - val_acc_2: 0.7599\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B2/S0.75/model_4\n",
      "i   Layer name                      Output shape                     Num param  Inbound            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "0   conv2d_1_1 (Conv2D)             [None,32,32,24] [None,32,32,8]   1120       input              \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "1   bn_1_1 (BatchNormalization)     [None,32,32,24] [None,32,32,8]   80         conv2d_1_1         \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "2   relu_1_1 (Activation)           [None,32,32,24] [None,32,32,8]   0          bn_1_1             \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "3   conv2d_1_2 (Conv2D)             [None,32,32,24] [None,32,32,8]   13352      relu_1_1           \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "4   bn_1_2 (BatchNormalization)     [None,32,32,24] [None,32,32,8]   80         conv2d_1_2         \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "5   relu_1_2 (Activation)           [None,32,32,24] [None,32,32,8]   0          bn_1_2             \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "6   avg_pool2d_1 (AveragePooling2D  [None,16,16,24] [None,16,16,8]   0          relu_1_2           \n",
      "                                    [None,16,16,24] [None,16,16,8]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "7   conv2d_2_1 (Conv2D)             [None,16,16,48] [None,16,16,16]  26704      avg_pool2d_1       \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "8   bn_2_1 (BatchNormalization)     [None,16,16,48] [None,16,16,16]  160        conv2d_2_1         \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "9   relu_2_1 (Activation)           [None,16,16,48] [None,16,16,16]  0          bn_2_1             \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "10  conv2d_2_2 (Conv2D)             [None,16,16,48] [None,16,16,16]  53200      relu_2_1           \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "11  bn_2_2 (BatchNormalization)     [None,16,16,48] [None,16,16,16]  160        conv2d_2_2         \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "12  relu_2_2 (Activation)           [None,16,16,48] [None,16,16,16]  0          bn_2_2             \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "13  avg_pool2d_2 (AveragePooling2D  [None,8,8,48] [None,8,8,16]      0          relu_2_2           \n",
      "                                    [None,8,8,48] [None,8,8,16]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "14  conv2d_3_1 (Conv2D)             [None,8,8,96] [None,8,8,32]      106400     avg_pool2d_2       \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "15  bn_3_1 (BatchNormalization)     [None,8,8,96] [None,8,8,32]      320        conv2d_3_1         \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "16  relu_3_1 (Activation)           [None,8,8,96] [None,8,8,32]      0          bn_3_1             \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "17  conv2d_3_2 (Conv2D)             [None,8,8,96] [None,8,8,32]      212384     relu_3_1           \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "18  bn_3_2 (BatchNormalization)     [None,8,8,96] [None,8,8,32]      320        conv2d_3_2         \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "19  relu_3_2 (Activation)           [None,8,8,96] [None,8,8,32]      0          bn_3_2             \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "20  global_avg_pool2d (GlobalAvera  [None,96] [None,32]              0          relu_3_2           \n",
      "                                    [None,96] [None,32]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "21  fc1 (Dense)                     [None,96] [None,32]              23968      global_avg_pool2d  \n",
      "                                    [None,96] [None,32]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "22  bn_fc1 (BatchNormalization)     [None,96] [None,32]              320        fc1                \n",
      "                                    [None,96] [None,32]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "23  relu_fc1 (Activation)           [None,96] [None,32]              0          bn_fc1             \n",
      "                                    [None,96] [None,32]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "24  output (Dense)                  [None,10]                        1921       relu_fc1           \n",
      "                                    [None,10]                                                      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "Total parameters: 440489\n",
      "50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 - 13s - loss_1: 1.7997 - loss_2: 1.8001 - acc_ensemble: 0.5120 - acc_1: 0.4340 - acc_2: 0.4720 - val_loss_1: 1.5493 - val_loss_2: 1.5072 - val_acc_ensemble: 0.4647 - val_acc_1: 0.4310 - val_acc_2: 0.4487\n",
      "Epoch 2/50\n",
      "100/100 - 9s - loss_1: 1.4526 - loss_2: 1.4756 - acc_ensemble: 0.5480 - acc_1: 0.5200 - acc_2: 0.5160 - val_loss_1: 1.3908 - val_loss_2: 1.3847 - val_acc_ensemble: 0.5102 - val_acc_1: 0.4869 - val_acc_2: 0.4877\n",
      "Epoch 3/50\n",
      "100/100 - 9s - loss_1: 1.3116 - loss_2: 1.2987 - acc_ensemble: 0.5900 - acc_1: 0.5760 - acc_2: 0.5320 - val_loss_1: 1.2229 - val_loss_2: 1.2319 - val_acc_ensemble: 0.5789 - val_acc_1: 0.5650 - val_acc_2: 0.5528\n",
      "Epoch 4/50\n",
      "100/100 - 9s - loss_1: 1.1762 - loss_2: 1.2245 - acc_ensemble: 0.6200 - acc_1: 0.5900 - acc_2: 0.6080 - val_loss_1: 1.1524 - val_loss_2: 1.1362 - val_acc_ensemble: 0.6099 - val_acc_1: 0.5778 - val_acc_2: 0.5893\n",
      "Epoch 5/50\n",
      "100/100 - 9s - loss_1: 1.0772 - loss_2: 1.0538 - acc_ensemble: 0.6540 - acc_1: 0.6280 - acc_2: 0.6320 - val_loss_1: 1.0710 - val_loss_2: 1.0733 - val_acc_ensemble: 0.6297 - val_acc_1: 0.6026 - val_acc_2: 0.6129\n",
      "Epoch 6/50\n",
      "100/100 - 9s - loss_1: 0.9841 - loss_2: 1.0003 - acc_ensemble: 0.6760 - acc_1: 0.6500 - acc_2: 0.6480 - val_loss_1: 1.0127 - val_loss_2: 0.9853 - val_acc_ensemble: 0.6642 - val_acc_1: 0.6297 - val_acc_2: 0.6439\n",
      "Epoch 7/50\n",
      "100/100 - 9s - loss_1: 0.9228 - loss_2: 0.9305 - acc_ensemble: 0.7020 - acc_1: 0.6560 - acc_2: 0.6840 - val_loss_1: 0.9978 - val_loss_2: 0.9836 - val_acc_ensemble: 0.6715 - val_acc_1: 0.6391 - val_acc_2: 0.6491\n",
      "Epoch 8/50\n",
      "100/100 - 9s - loss_1: 0.8480 - loss_2: 0.8566 - acc_ensemble: 0.7220 - acc_1: 0.6820 - acc_2: 0.7100 - val_loss_1: 0.9358 - val_loss_2: 0.9188 - val_acc_ensemble: 0.6909 - val_acc_1: 0.6645 - val_acc_2: 0.6706\n",
      "Epoch 9/50\n",
      "100/100 - 9s - loss_1: 0.8031 - loss_2: 0.8175 - acc_ensemble: 0.7420 - acc_1: 0.7160 - acc_2: 0.7320 - val_loss_1: 0.8843 - val_loss_2: 0.8903 - val_acc_ensemble: 0.6998 - val_acc_1: 0.6841 - val_acc_2: 0.6807\n",
      "Epoch 10/50\n",
      "100/100 - 9s - loss_1: 0.7821 - loss_2: 0.7731 - acc_ensemble: 0.7580 - acc_1: 0.7260 - acc_2: 0.7220 - val_loss_1: 0.9045 - val_loss_2: 0.8649 - val_acc_ensemble: 0.7097 - val_acc_1: 0.6796 - val_acc_2: 0.6916\n",
      "Epoch 11/50\n",
      "100/100 - 9s - loss_1: 0.7106 - loss_2: 0.7117 - acc_ensemble: 0.7700 - acc_1: 0.7420 - acc_2: 0.7560 - val_loss_1: 0.8392 - val_loss_2: 0.8322 - val_acc_ensemble: 0.7271 - val_acc_1: 0.7051 - val_acc_2: 0.7083\n",
      "Epoch 12/50\n",
      "100/100 - 9s - loss_1: 0.7007 - loss_2: 0.6615 - acc_ensemble: 0.8000 - acc_1: 0.7360 - acc_2: 0.7900 - val_loss_1: 0.8261 - val_loss_2: 0.7998 - val_acc_ensemble: 0.7365 - val_acc_1: 0.7109 - val_acc_2: 0.7229\n",
      "Epoch 13/50\n",
      "100/100 - 9s - loss_1: 0.6131 - loss_2: 0.6525 - acc_ensemble: 0.8100 - acc_1: 0.7480 - acc_2: 0.7940 - val_loss_1: 0.8170 - val_loss_2: 0.7886 - val_acc_ensemble: 0.7451 - val_acc_1: 0.7122 - val_acc_2: 0.7212\n",
      "Epoch 14/50\n",
      "100/100 - 9s - loss_1: 0.5943 - loss_2: 0.6219 - acc_ensemble: 0.8260 - acc_1: 0.7720 - acc_2: 0.8140 - val_loss_1: 0.7950 - val_loss_2: 0.7628 - val_acc_ensemble: 0.7527 - val_acc_1: 0.7237 - val_acc_2: 0.7369\n",
      "Epoch 15/50\n",
      "100/100 - 9s - loss_1: 0.5855 - loss_2: 0.5895 - acc_ensemble: 0.8040 - acc_1: 0.7820 - acc_2: 0.7680 - val_loss_1: 0.8496 - val_loss_2: 0.7851 - val_acc_ensemble: 0.7426 - val_acc_1: 0.7149 - val_acc_2: 0.7261\n",
      "Epoch 16/50\n",
      "100/100 - 9s - loss_1: 0.5399 - loss_2: 0.5152 - acc_ensemble: 0.8080 - acc_1: 0.7900 - acc_2: 0.7760 - val_loss_1: 0.7795 - val_loss_2: 0.7628 - val_acc_ensemble: 0.7579 - val_acc_1: 0.7354 - val_acc_2: 0.7335\n",
      "Epoch 17/50\n",
      "100/100 - 9s - loss_1: 0.5138 - loss_2: 0.5011 - acc_ensemble: 0.8100 - acc_1: 0.7580 - acc_2: 0.7880 - val_loss_1: 0.8069 - val_loss_2: 0.7770 - val_acc_ensemble: 0.7528 - val_acc_1: 0.7238 - val_acc_2: 0.7309\n",
      "Epoch 18/50\n",
      "100/100 - 9s - loss_1: 0.4733 - loss_2: 0.4829 - acc_ensemble: 0.8360 - acc_1: 0.7960 - acc_2: 0.8000 - val_loss_1: 0.7709 - val_loss_2: 0.7626 - val_acc_ensemble: 0.7685 - val_acc_1: 0.7427 - val_acc_2: 0.7406\n",
      "Epoch 19/50\n",
      "100/100 - 9s - loss_1: 0.4668 - loss_2: 0.4303 - acc_ensemble: 0.8260 - acc_1: 0.8080 - acc_2: 0.8160 - val_loss_1: 0.7764 - val_loss_2: 0.7439 - val_acc_ensemble: 0.7677 - val_acc_1: 0.7430 - val_acc_2: 0.7507\n",
      "Epoch 20/50\n",
      "100/100 - 9s - loss_1: 0.4288 - loss_2: 0.4223 - acc_ensemble: 0.8360 - acc_1: 0.8300 - acc_2: 0.8000 - val_loss_1: 0.7820 - val_loss_2: 0.7721 - val_acc_ensemble: 0.7669 - val_acc_1: 0.7385 - val_acc_2: 0.7432\n",
      "Epoch 21/50\n",
      "100/100 - 9s - loss_1: 0.4095 - loss_2: 0.3830 - acc_ensemble: 0.8480 - acc_1: 0.8180 - acc_2: 0.8160 - val_loss_1: 0.7688 - val_loss_2: 0.7633 - val_acc_ensemble: 0.7751 - val_acc_1: 0.7475 - val_acc_2: 0.7502\n",
      "Epoch 22/50\n",
      "100/100 - 9s - loss_1: 0.3862 - loss_2: 0.3732 - acc_ensemble: 0.8540 - acc_1: 0.8100 - acc_2: 0.8380 - val_loss_1: 0.7744 - val_loss_2: 0.7517 - val_acc_ensemble: 0.7761 - val_acc_1: 0.7440 - val_acc_2: 0.7494\n",
      "Epoch 23/50\n",
      "100/100 - 9s - loss_1: 0.3633 - loss_2: 0.3416 - acc_ensemble: 0.8640 - acc_1: 0.8340 - acc_2: 0.8420 - val_loss_1: 0.7753 - val_loss_2: 0.7659 - val_acc_ensemble: 0.7777 - val_acc_1: 0.7516 - val_acc_2: 0.7509\n",
      "Epoch 24/50\n",
      "100/100 - 9s - loss_1: 0.3436 - loss_2: 0.3367 - acc_ensemble: 0.8460 - acc_1: 0.8100 - acc_2: 0.8240 - val_loss_1: 0.8074 - val_loss_2: 0.7560 - val_acc_ensemble: 0.7803 - val_acc_1: 0.7455 - val_acc_2: 0.7515\n",
      "Epoch 25/50\n",
      "100/100 - 9s - loss_1: 0.3273 - loss_2: 0.2974 - acc_ensemble: 0.8760 - acc_1: 0.8280 - acc_2: 0.8480 - val_loss_1: 0.7905 - val_loss_2: 0.7602 - val_acc_ensemble: 0.7801 - val_acc_1: 0.7523 - val_acc_2: 0.7549\n",
      "Epoch 26/50\n",
      "100/100 - 9s - loss_1: 0.2904 - loss_2: 0.2872 - acc_ensemble: 0.8680 - acc_1: 0.8220 - acc_2: 0.8300 - val_loss_1: 0.8102 - val_loss_2: 0.7914 - val_acc_ensemble: 0.7817 - val_acc_1: 0.7512 - val_acc_2: 0.7546\n",
      "Epoch 27/50\n",
      "100/100 - 9s - loss_1: 0.2790 - loss_2: 0.2733 - acc_ensemble: 0.8680 - acc_1: 0.8380 - acc_2: 0.8380 - val_loss_1: 0.7869 - val_loss_2: 0.7718 - val_acc_ensemble: 0.7859 - val_acc_1: 0.7604 - val_acc_2: 0.7543\n",
      "Epoch 28/50\n",
      "100/100 - 9s - loss_1: 0.2817 - loss_2: 0.2569 - acc_ensemble: 0.8720 - acc_1: 0.8420 - acc_2: 0.8480 - val_loss_1: 0.7916 - val_loss_2: 0.8094 - val_acc_ensemble: 0.7861 - val_acc_1: 0.7581 - val_acc_2: 0.7519\n",
      "Epoch 29/50\n",
      "100/100 - 9s - loss_1: 0.2408 - loss_2: 0.2088 - acc_ensemble: 0.8760 - acc_1: 0.8400 - acc_2: 0.8460 - val_loss_1: 0.8210 - val_loss_2: 0.7804 - val_acc_ensemble: 0.7893 - val_acc_1: 0.7544 - val_acc_2: 0.7613\n",
      "Epoch 30/50\n",
      "100/100 - 9s - loss_1: 0.2215 - loss_2: 0.2431 - acc_ensemble: 0.8700 - acc_1: 0.8540 - acc_2: 0.8620 - val_loss_1: 0.8576 - val_loss_2: 0.8192 - val_acc_ensemble: 0.7830 - val_acc_1: 0.7486 - val_acc_2: 0.7546\n",
      "Epoch 31/50\n",
      "100/100 - 9s - loss_1: 0.2120 - loss_2: 0.2058 - acc_ensemble: 0.8860 - acc_1: 0.8820 - acc_2: 0.8600 - val_loss_1: 0.8201 - val_loss_2: 0.7941 - val_acc_ensemble: 0.7907 - val_acc_1: 0.7576 - val_acc_2: 0.7611\n",
      "Epoch 32/50\n",
      "100/100 - 9s - loss_1: 0.1794 - loss_2: 0.1968 - acc_ensemble: 0.8720 - acc_1: 0.8700 - acc_2: 0.8500 - val_loss_1: 0.8502 - val_loss_2: 0.8227 - val_acc_ensemble: 0.7862 - val_acc_1: 0.7587 - val_acc_2: 0.7587\n",
      "Epoch 33/50\n",
      "100/100 - 9s - loss_1: 0.1654 - loss_2: 0.1501 - acc_ensemble: 0.8800 - acc_1: 0.8360 - acc_2: 0.8420 - val_loss_1: 0.8700 - val_loss_2: 0.8425 - val_acc_ensemble: 0.7918 - val_acc_1: 0.7549 - val_acc_2: 0.7570\n",
      "Epoch 34/50\n",
      "100/100 - 9s - loss_1: 0.1649 - loss_2: 0.1694 - acc_ensemble: 0.8720 - acc_1: 0.8660 - acc_2: 0.8520 - val_loss_1: 0.9035 - val_loss_2: 0.8629 - val_acc_ensemble: 0.7848 - val_acc_1: 0.7508 - val_acc_2: 0.7526\n",
      "Epoch 35/50\n",
      "100/100 - 9s - loss_1: 0.1805 - loss_2: 0.1595 - acc_ensemble: 0.8640 - acc_1: 0.8140 - acc_2: 0.8380 - val_loss_1: 0.9231 - val_loss_2: 0.8387 - val_acc_ensemble: 0.7864 - val_acc_1: 0.7469 - val_acc_2: 0.7656\n",
      "Epoch 36/50\n",
      "100/100 - 9s - loss_1: 0.1697 - loss_2: 0.1351 - acc_ensemble: 0.8860 - acc_1: 0.8600 - acc_2: 0.8560 - val_loss_1: 0.8894 - val_loss_2: 0.8645 - val_acc_ensemble: 0.7904 - val_acc_1: 0.7627 - val_acc_2: 0.7612\n",
      "Epoch 37/50\n",
      "100/100 - 9s - loss_1: 0.1306 - loss_2: 0.1511 - acc_ensemble: 0.8920 - acc_1: 0.8600 - acc_2: 0.8580 - val_loss_1: 0.9528 - val_loss_2: 0.8963 - val_acc_ensemble: 0.7829 - val_acc_1: 0.7469 - val_acc_2: 0.7587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50\n",
      "100/100 - 9s - loss_1: 0.1558 - loss_2: 0.1492 - acc_ensemble: 0.8780 - acc_1: 0.8440 - acc_2: 0.8560 - val_loss_1: 0.9216 - val_loss_2: 0.8966 - val_acc_ensemble: 0.7872 - val_acc_1: 0.7579 - val_acc_2: 0.7581\n",
      "Epoch 39/50\n",
      "100/100 - 9s - loss_1: 0.1216 - loss_2: 0.1160 - acc_ensemble: 0.8840 - acc_1: 0.8740 - acc_2: 0.8500 - val_loss_1: 0.8871 - val_loss_2: 0.9052 - val_acc_ensemble: 0.7961 - val_acc_1: 0.7657 - val_acc_2: 0.7616\n",
      "Epoch 40/50\n",
      "100/100 - 9s - loss_1: 0.1035 - loss_2: 0.1094 - acc_ensemble: 0.8980 - acc_1: 0.8460 - acc_2: 0.8540 - val_loss_1: 0.9553 - val_loss_2: 0.9372 - val_acc_ensemble: 0.7862 - val_acc_1: 0.7554 - val_acc_2: 0.7569\n",
      "Epoch 41/50\n",
      "100/100 - 9s - loss_1: 0.1279 - loss_2: 0.0975 - acc_ensemble: 0.8880 - acc_1: 0.8200 - acc_2: 0.8520 - val_loss_1: 0.9813 - val_loss_2: 0.9066 - val_acc_ensemble: 0.7907 - val_acc_1: 0.7494 - val_acc_2: 0.7658\n",
      "Epoch 42/50\n",
      "100/100 - 9s - loss_1: 0.1058 - loss_2: 0.1066 - acc_ensemble: 0.8900 - acc_1: 0.8600 - acc_2: 0.8740 - val_loss_1: 0.9734 - val_loss_2: 0.9061 - val_acc_ensemble: 0.7906 - val_acc_1: 0.7589 - val_acc_2: 0.7647\n",
      "Epoch 43/50\n",
      "100/100 - 9s - loss_1: 0.0865 - loss_2: 0.0777 - acc_ensemble: 0.8980 - acc_1: 0.8460 - acc_2: 0.8620 - val_loss_1: 0.9904 - val_loss_2: 0.9215 - val_acc_ensemble: 0.7976 - val_acc_1: 0.7576 - val_acc_2: 0.7729\n",
      "Epoch 44/50\n",
      "100/100 - 9s - loss_1: 0.1180 - loss_2: 0.0931 - acc_ensemble: 0.8940 - acc_1: 0.8620 - acc_2: 0.8660 - val_loss_1: 1.0474 - val_loss_2: 0.9849 - val_acc_ensemble: 0.7874 - val_acc_1: 0.7458 - val_acc_2: 0.7610\n",
      "Epoch 45/50\n",
      "100/100 - 9s - loss_1: 0.1306 - loss_2: 0.0895 - acc_ensemble: 0.8860 - acc_1: 0.8560 - acc_2: 0.8620 - val_loss_1: 1.0260 - val_loss_2: 0.9566 - val_acc_ensemble: 0.7894 - val_acc_1: 0.7527 - val_acc_2: 0.7622\n",
      "Epoch 46/50\n",
      "100/100 - 9s - loss_1: 0.0872 - loss_2: 0.1001 - acc_ensemble: 0.9060 - acc_1: 0.8760 - acc_2: 0.8680 - val_loss_1: 0.9930 - val_loss_2: 0.9516 - val_acc_ensemble: 0.7952 - val_acc_1: 0.7600 - val_acc_2: 0.7626\n",
      "Epoch 47/50\n",
      "100/100 - 9s - loss_1: 0.0768 - loss_2: 0.0847 - acc_ensemble: 0.9000 - acc_1: 0.8680 - acc_2: 0.8580 - val_loss_1: 1.0232 - val_loss_2: 1.0217 - val_acc_ensemble: 0.7885 - val_acc_1: 0.7525 - val_acc_2: 0.7550\n",
      "Epoch 48/50\n",
      "100/100 - 9s - loss_1: 0.1131 - loss_2: 0.0827 - acc_ensemble: 0.9040 - acc_1: 0.8580 - acc_2: 0.8700 - val_loss_1: 1.0301 - val_loss_2: 0.9973 - val_acc_ensemble: 0.7934 - val_acc_1: 0.7581 - val_acc_2: 0.7613\n",
      "Epoch 49/50\n",
      "100/100 - 9s - loss_1: 0.0859 - loss_2: 0.0913 - acc_ensemble: 0.8920 - acc_1: 0.8600 - acc_2: 0.8600 - val_loss_1: 1.0544 - val_loss_2: 1.0256 - val_acc_ensemble: 0.7874 - val_acc_1: 0.7483 - val_acc_2: 0.7564\n",
      "Epoch 50/50\n",
      "100/100 - 9s - loss_1: 0.0833 - loss_2: 0.0810 - acc_ensemble: 0.8960 - acc_1: 0.8780 - acc_2: 0.8620 - val_loss_1: 1.0128 - val_loss_2: 0.9873 - val_acc_ensemble: 0.7950 - val_acc_1: 0.7606 - val_acc_2: 0.7647\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B2/S1.00/model_1\n",
      "i   Layer name                      Output shape        Num param  Inbound            \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                    \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                    \n",
      "--------------------------------------------------------------------------------------\n",
      "0   conv2d_1_1 (Conv2D)             [None,32,32,32] []  896        input              \n",
      "                                    [None,32,32,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "1   bn_1_1 (BatchNormalization)     [None,32,32,32] []  64         conv2d_1_1         \n",
      "                                    [None,32,32,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "2   relu_1_1 (Activation)           [None,32,32,32] []  0          bn_1_1             \n",
      "                                    [None,32,32,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "3   conv2d_1_2 (Conv2D)             [None,32,32,32] []  9248       relu_1_1           \n",
      "                                    [None,32,32,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "4   bn_1_2 (BatchNormalization)     [None,32,32,32] []  64         conv2d_1_2         \n",
      "                                    [None,32,32,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "5   relu_1_2 (Activation)           [None,32,32,32] []  0          bn_1_2             \n",
      "                                    [None,32,32,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "6   avg_pool2d_1 (AveragePooling2D  [None,16,16,32] []  0          relu_1_2           \n",
      "                                    [None,16,16,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "7   conv2d_2_1 (Conv2D)             [None,16,16,64] []  18496      avg_pool2d_1       \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "8   bn_2_1 (BatchNormalization)     [None,16,16,64] []  128        conv2d_2_1         \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "9   relu_2_1 (Activation)           [None,16,16,64] []  0          bn_2_1             \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "10  conv2d_2_2 (Conv2D)             [None,16,16,64] []  36928      relu_2_1           \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "11  bn_2_2 (BatchNormalization)     [None,16,16,64] []  128        conv2d_2_2         \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "12  relu_2_2 (Activation)           [None,16,16,64] []  0          bn_2_2             \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "13  avg_pool2d_2 (AveragePooling2D  [None,8,8,64] []    0          relu_2_2           \n",
      "                                    [None,8,8,64] []                                  \n",
      "--------------------------------------------------------------------------------------\n",
      "14  conv2d_3_1 (Conv2D)             [None,8,8,128] []   73856      avg_pool2d_2       \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "15  bn_3_1 (BatchNormalization)     [None,8,8,128] []   256        conv2d_3_1         \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "16  relu_3_1 (Activation)           [None,8,8,128] []   0          bn_3_1             \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "17  conv2d_3_2 (Conv2D)             [None,8,8,128] []   147584     relu_3_1           \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "18  bn_3_2 (BatchNormalization)     [None,8,8,128] []   256        conv2d_3_2         \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "19  relu_3_2 (Activation)           [None,8,8,128] []   0          bn_3_2             \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "20  global_avg_pool2d (GlobalAvera  [None,128] []       0          relu_3_2           \n",
      "                                    [None,128] []                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "21  fc1 (Dense)                     [None,128] []       16512      global_avg_pool2d  \n",
      "                                    [None,128] []                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "22  bn_fc1 (BatchNormalization)     [None,128] []       256        fc1                \n",
      "                                    [None,128] []                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "23  relu_fc1 (Activation)           [None,128] []       0          bn_fc1             \n",
      "                                    [None,128] []                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "24  output (Dense)                  [None,10]           1290       relu_fc1           \n",
      "                                    [None,10]                                         \n",
      "--------------------------------------------------------------------------------------\n",
      "Total parameters: 305962\n",
      "50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 - 7s - loss_1: 1.6884 - loss_2: 1.6868 - acc_ensemble: 0.4860 - acc_1: 0.4860 - acc_2: 0.4860 - val_loss_1: 1.4443 - val_loss_2: 1.4443 - val_acc_ensemble: 0.4644 - val_acc_1: 0.4644 - val_acc_2: 0.4644\n",
      "Epoch 2/50\n",
      "100/100 - 6s - loss_1: 1.3633 - loss_2: 1.3563 - acc_ensemble: 0.5620 - acc_1: 0.5620 - acc_2: 0.5620 - val_loss_1: 1.2584 - val_loss_2: 1.2584 - val_acc_ensemble: 0.5504 - val_acc_1: 0.5504 - val_acc_2: 0.5504\n",
      "Epoch 3/50\n",
      "100/100 - 6s - loss_1: 1.2111 - loss_2: 1.2039 - acc_ensemble: 0.6320 - acc_1: 0.6320 - acc_2: 0.6320 - val_loss_1: 1.1651 - val_loss_2: 1.1651 - val_acc_ensemble: 0.5800 - val_acc_1: 0.5800 - val_acc_2: 0.5800\n",
      "Epoch 4/50\n",
      "100/100 - 6s - loss_1: 1.0994 - loss_2: 1.0855 - acc_ensemble: 0.6400 - acc_1: 0.6400 - acc_2: 0.6400 - val_loss_1: 1.0489 - val_loss_2: 1.0489 - val_acc_ensemble: 0.6263 - val_acc_1: 0.6263 - val_acc_2: 0.6263\n",
      "Epoch 5/50\n",
      "100/100 - 6s - loss_1: 1.0208 - loss_2: 0.9891 - acc_ensemble: 0.6840 - acc_1: 0.6840 - acc_2: 0.6840 - val_loss_1: 0.9920 - val_loss_2: 0.9920 - val_acc_ensemble: 0.6469 - val_acc_1: 0.6469 - val_acc_2: 0.6469\n",
      "Epoch 6/50\n",
      "100/100 - 6s - loss_1: 0.9315 - loss_2: 0.9054 - acc_ensemble: 0.7200 - acc_1: 0.7200 - acc_2: 0.7200 - val_loss_1: 0.9468 - val_loss_2: 0.9468 - val_acc_ensemble: 0.6615 - val_acc_1: 0.6615 - val_acc_2: 0.6615\n",
      "Epoch 7/50\n",
      "100/100 - 6s - loss_1: 0.8636 - loss_2: 0.8560 - acc_ensemble: 0.6940 - acc_1: 0.6940 - acc_2: 0.6940 - val_loss_1: 0.9342 - val_loss_2: 0.9342 - val_acc_ensemble: 0.6712 - val_acc_1: 0.6712 - val_acc_2: 0.6712\n",
      "Epoch 8/50\n",
      "100/100 - 6s - loss_1: 0.7936 - loss_2: 0.7857 - acc_ensemble: 0.6960 - acc_1: 0.6960 - acc_2: 0.6960 - val_loss_1: 0.9037 - val_loss_2: 0.9037 - val_acc_ensemble: 0.6840 - val_acc_1: 0.6840 - val_acc_2: 0.6840\n",
      "Epoch 9/50\n",
      "100/100 - 6s - loss_1: 0.7510 - loss_2: 0.7419 - acc_ensemble: 0.7540 - acc_1: 0.7540 - acc_2: 0.7540 - val_loss_1: 0.8857 - val_loss_2: 0.8857 - val_acc_ensemble: 0.6889 - val_acc_1: 0.6889 - val_acc_2: 0.6889\n",
      "Epoch 10/50\n",
      "100/100 - 6s - loss_1: 0.6870 - loss_2: 0.6862 - acc_ensemble: 0.7680 - acc_1: 0.7680 - acc_2: 0.7680 - val_loss_1: 0.8306 - val_loss_2: 0.8306 - val_acc_ensemble: 0.7078 - val_acc_1: 0.7078 - val_acc_2: 0.7078\n",
      "Epoch 11/50\n",
      "100/100 - 6s - loss_1: 0.6335 - loss_2: 0.6447 - acc_ensemble: 0.7860 - acc_1: 0.7860 - acc_2: 0.7860 - val_loss_1: 0.8460 - val_loss_2: 0.8460 - val_acc_ensemble: 0.7062 - val_acc_1: 0.7062 - val_acc_2: 0.7062\n",
      "Epoch 12/50\n",
      "100/100 - 6s - loss_1: 0.5997 - loss_2: 0.6052 - acc_ensemble: 0.8100 - acc_1: 0.8100 - acc_2: 0.8100 - val_loss_1: 0.8005 - val_loss_2: 0.8005 - val_acc_ensemble: 0.7214 - val_acc_1: 0.7214 - val_acc_2: 0.7214\n",
      "Epoch 13/50\n",
      "100/100 - 6s - loss_1: 0.5647 - loss_2: 0.5551 - acc_ensemble: 0.7820 - acc_1: 0.7820 - acc_2: 0.7820 - val_loss_1: 0.8189 - val_loss_2: 0.8189 - val_acc_ensemble: 0.7168 - val_acc_1: 0.7168 - val_acc_2: 0.7168\n",
      "Epoch 14/50\n",
      "100/100 - 6s - loss_1: 0.5000 - loss_2: 0.5419 - acc_ensemble: 0.7940 - acc_1: 0.7940 - acc_2: 0.7940 - val_loss_1: 0.7893 - val_loss_2: 0.7893 - val_acc_ensemble: 0.7307 - val_acc_1: 0.7307 - val_acc_2: 0.7307\n",
      "Epoch 15/50\n",
      "100/100 - 6s - loss_1: 0.5078 - loss_2: 0.4989 - acc_ensemble: 0.8080 - acc_1: 0.8080 - acc_2: 0.8080 - val_loss_1: 0.7842 - val_loss_2: 0.7842 - val_acc_ensemble: 0.7308 - val_acc_1: 0.7308 - val_acc_2: 0.7308\n",
      "Epoch 16/50\n",
      "100/100 - 6s - loss_1: 0.4671 - loss_2: 0.4491 - acc_ensemble: 0.8180 - acc_1: 0.8180 - acc_2: 0.8180 - val_loss_1: 0.7782 - val_loss_2: 0.7782 - val_acc_ensemble: 0.7394 - val_acc_1: 0.7394 - val_acc_2: 0.7394\n",
      "Epoch 17/50\n",
      "100/100 - 6s - loss_1: 0.4399 - loss_2: 0.4406 - acc_ensemble: 0.8240 - acc_1: 0.8240 - acc_2: 0.8240 - val_loss_1: 0.7640 - val_loss_2: 0.7640 - val_acc_ensemble: 0.7421 - val_acc_1: 0.7421 - val_acc_2: 0.7421\n",
      "Epoch 18/50\n",
      "100/100 - 6s - loss_1: 0.3929 - loss_2: 0.4014 - acc_ensemble: 0.8320 - acc_1: 0.8320 - acc_2: 0.8320 - val_loss_1: 0.7877 - val_loss_2: 0.7877 - val_acc_ensemble: 0.7377 - val_acc_1: 0.7377 - val_acc_2: 0.7377\n",
      "Epoch 19/50\n",
      "100/100 - 6s - loss_1: 0.3791 - loss_2: 0.3908 - acc_ensemble: 0.8520 - acc_1: 0.8520 - acc_2: 0.8520 - val_loss_1: 0.7649 - val_loss_2: 0.7649 - val_acc_ensemble: 0.7460 - val_acc_1: 0.7460 - val_acc_2: 0.7460\n",
      "Epoch 20/50\n",
      "100/100 - 6s - loss_1: 0.3731 - loss_2: 0.3746 - acc_ensemble: 0.8660 - acc_1: 0.8660 - acc_2: 0.8660 - val_loss_1: 0.7787 - val_loss_2: 0.7787 - val_acc_ensemble: 0.7446 - val_acc_1: 0.7446 - val_acc_2: 0.7446\n",
      "Epoch 21/50\n",
      "100/100 - 6s - loss_1: 0.3388 - loss_2: 0.3344 - acc_ensemble: 0.8280 - acc_1: 0.8280 - acc_2: 0.8280 - val_loss_1: 0.8009 - val_loss_2: 0.8009 - val_acc_ensemble: 0.7446 - val_acc_1: 0.7446 - val_acc_2: 0.7446\n",
      "Epoch 22/50\n",
      "100/100 - 6s - loss_1: 0.3119 - loss_2: 0.3066 - acc_ensemble: 0.8480 - acc_1: 0.8480 - acc_2: 0.8480 - val_loss_1: 0.7783 - val_loss_2: 0.7783 - val_acc_ensemble: 0.7467 - val_acc_1: 0.7467 - val_acc_2: 0.7467\n",
      "Epoch 23/50\n",
      "100/100 - 6s - loss_1: 0.2785 - loss_2: 0.2892 - acc_ensemble: 0.8580 - acc_1: 0.8580 - acc_2: 0.8580 - val_loss_1: 0.8252 - val_loss_2: 0.8252 - val_acc_ensemble: 0.7461 - val_acc_1: 0.7461 - val_acc_2: 0.7461\n",
      "Epoch 24/50\n",
      "100/100 - 6s - loss_1: 0.2411 - loss_2: 0.2476 - acc_ensemble: 0.8500 - acc_1: 0.8500 - acc_2: 0.8500 - val_loss_1: 0.8057 - val_loss_2: 0.8057 - val_acc_ensemble: 0.7483 - val_acc_1: 0.7483 - val_acc_2: 0.7483\n",
      "Epoch 25/50\n",
      "100/100 - 6s - loss_1: 0.2515 - loss_2: 0.2345 - acc_ensemble: 0.8620 - acc_1: 0.8620 - acc_2: 0.8620 - val_loss_1: 0.8478 - val_loss_2: 0.8478 - val_acc_ensemble: 0.7463 - val_acc_1: 0.7463 - val_acc_2: 0.7463\n",
      "Epoch 26/50\n",
      "100/100 - 6s - loss_1: 0.2271 - loss_2: 0.2613 - acc_ensemble: 0.8700 - acc_1: 0.8700 - acc_2: 0.8700 - val_loss_1: 0.8225 - val_loss_2: 0.8225 - val_acc_ensemble: 0.7495 - val_acc_1: 0.7495 - val_acc_2: 0.7495\n",
      "Epoch 27/50\n",
      "100/100 - 6s - loss_1: 0.2105 - loss_2: 0.2101 - acc_ensemble: 0.8680 - acc_1: 0.8680 - acc_2: 0.8680 - val_loss_1: 0.8301 - val_loss_2: 0.8301 - val_acc_ensemble: 0.7501 - val_acc_1: 0.7501 - val_acc_2: 0.7501\n",
      "Epoch 28/50\n",
      "100/100 - 6s - loss_1: 0.1731 - loss_2: 0.1988 - acc_ensemble: 0.8780 - acc_1: 0.8780 - acc_2: 0.8780 - val_loss_1: 0.8349 - val_loss_2: 0.8349 - val_acc_ensemble: 0.7542 - val_acc_1: 0.7542 - val_acc_2: 0.7542\n",
      "Epoch 29/50\n",
      "100/100 - 6s - loss_1: 0.1807 - loss_2: 0.1789 - acc_ensemble: 0.8620 - acc_1: 0.8620 - acc_2: 0.8620 - val_loss_1: 0.8686 - val_loss_2: 0.8686 - val_acc_ensemble: 0.7487 - val_acc_1: 0.7487 - val_acc_2: 0.7487\n",
      "Epoch 30/50\n",
      "100/100 - 6s - loss_1: 0.1961 - loss_2: 0.1888 - acc_ensemble: 0.8820 - acc_1: 0.8820 - acc_2: 0.8820 - val_loss_1: 0.8576 - val_loss_2: 0.8576 - val_acc_ensemble: 0.7534 - val_acc_1: 0.7534 - val_acc_2: 0.7534\n",
      "Epoch 31/50\n",
      "100/100 - 6s - loss_1: 0.1665 - loss_2: 0.1774 - acc_ensemble: 0.8820 - acc_1: 0.8820 - acc_2: 0.8820 - val_loss_1: 0.8664 - val_loss_2: 0.8664 - val_acc_ensemble: 0.7513 - val_acc_1: 0.7513 - val_acc_2: 0.7513\n",
      "Epoch 32/50\n",
      "100/100 - 6s - loss_1: 0.1556 - loss_2: 0.1581 - acc_ensemble: 0.8740 - acc_1: 0.8740 - acc_2: 0.8740 - val_loss_1: 0.9089 - val_loss_2: 0.9089 - val_acc_ensemble: 0.7485 - val_acc_1: 0.7485 - val_acc_2: 0.7485\n",
      "Epoch 33/50\n",
      "100/100 - 6s - loss_1: 0.1384 - loss_2: 0.1547 - acc_ensemble: 0.8840 - acc_1: 0.8840 - acc_2: 0.8840 - val_loss_1: 0.9379 - val_loss_2: 0.9379 - val_acc_ensemble: 0.7440 - val_acc_1: 0.7440 - val_acc_2: 0.7440\n",
      "Epoch 34/50\n",
      "100/100 - 6s - loss_1: 0.1530 - loss_2: 0.1528 - acc_ensemble: 0.8840 - acc_1: 0.8840 - acc_2: 0.8840 - val_loss_1: 0.8967 - val_loss_2: 0.8967 - val_acc_ensemble: 0.7561 - val_acc_1: 0.7561 - val_acc_2: 0.7561\n",
      "Epoch 35/50\n",
      "100/100 - 6s - loss_1: 0.1255 - loss_2: 0.1450 - acc_ensemble: 0.8840 - acc_1: 0.8840 - acc_2: 0.8840 - val_loss_1: 0.9336 - val_loss_2: 0.9336 - val_acc_ensemble: 0.7478 - val_acc_1: 0.7478 - val_acc_2: 0.7478\n",
      "Epoch 36/50\n",
      "100/100 - 6s - loss_1: 0.1327 - loss_2: 0.1310 - acc_ensemble: 0.8960 - acc_1: 0.8960 - acc_2: 0.8960 - val_loss_1: 0.9260 - val_loss_2: 0.9260 - val_acc_ensemble: 0.7570 - val_acc_1: 0.7570 - val_acc_2: 0.7570\n",
      "Epoch 37/50\n",
      "100/100 - 6s - loss_1: 0.1032 - loss_2: 0.1270 - acc_ensemble: 0.8920 - acc_1: 0.8920 - acc_2: 0.8920 - val_loss_1: 0.9427 - val_loss_2: 0.9427 - val_acc_ensemble: 0.7538 - val_acc_1: 0.7538 - val_acc_2: 0.7538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50\n",
      "100/100 - 6s - loss_1: 0.1158 - loss_2: 0.1123 - acc_ensemble: 0.9040 - acc_1: 0.9040 - acc_2: 0.9040 - val_loss_1: 0.9513 - val_loss_2: 0.9513 - val_acc_ensemble: 0.7539 - val_acc_1: 0.7539 - val_acc_2: 0.7539\n",
      "Epoch 39/50\n",
      "100/100 - 6s - loss_1: 0.0986 - loss_2: 0.0964 - acc_ensemble: 0.8900 - acc_1: 0.8900 - acc_2: 0.8900 - val_loss_1: 0.9570 - val_loss_2: 0.9570 - val_acc_ensemble: 0.7537 - val_acc_1: 0.7537 - val_acc_2: 0.7537\n",
      "Epoch 40/50\n",
      "100/100 - 6s - loss_1: 0.1041 - loss_2: 0.1185 - acc_ensemble: 0.8720 - acc_1: 0.8720 - acc_2: 0.8720 - val_loss_1: 0.9741 - val_loss_2: 0.9741 - val_acc_ensemble: 0.7586 - val_acc_1: 0.7586 - val_acc_2: 0.7586\n",
      "Epoch 41/50\n",
      "100/100 - 6s - loss_1: 0.1019 - loss_2: 0.1082 - acc_ensemble: 0.8820 - acc_1: 0.8820 - acc_2: 0.8820 - val_loss_1: 0.9911 - val_loss_2: 0.9911 - val_acc_ensemble: 0.7522 - val_acc_1: 0.7522 - val_acc_2: 0.7522\n",
      "Epoch 42/50\n",
      "100/100 - 6s - loss_1: 0.1015 - loss_2: 0.0954 - acc_ensemble: 0.8800 - acc_1: 0.8800 - acc_2: 0.8800 - val_loss_1: 1.0133 - val_loss_2: 1.0133 - val_acc_ensemble: 0.7501 - val_acc_1: 0.7501 - val_acc_2: 0.7501\n",
      "Epoch 43/50\n",
      "100/100 - 6s - loss_1: 0.1073 - loss_2: 0.0958 - acc_ensemble: 0.8740 - acc_1: 0.8740 - acc_2: 0.8740 - val_loss_1: 1.0440 - val_loss_2: 1.0440 - val_acc_ensemble: 0.7454 - val_acc_1: 0.7454 - val_acc_2: 0.7454\n",
      "Epoch 44/50\n",
      "100/100 - 6s - loss_1: 0.0910 - loss_2: 0.0978 - acc_ensemble: 0.8860 - acc_1: 0.8860 - acc_2: 0.8860 - val_loss_1: 1.0126 - val_loss_2: 1.0126 - val_acc_ensemble: 0.7537 - val_acc_1: 0.7537 - val_acc_2: 0.7537\n",
      "Epoch 45/50\n",
      "100/100 - 6s - loss_1: 0.1013 - loss_2: 0.0772 - acc_ensemble: 0.8900 - acc_1: 0.8900 - acc_2: 0.8900 - val_loss_1: 1.0185 - val_loss_2: 1.0185 - val_acc_ensemble: 0.7550 - val_acc_1: 0.7550 - val_acc_2: 0.7550\n",
      "Epoch 46/50\n",
      "100/100 - 6s - loss_1: 0.0757 - loss_2: 0.0780 - acc_ensemble: 0.8900 - acc_1: 0.8900 - acc_2: 0.8900 - val_loss_1: 0.9926 - val_loss_2: 0.9926 - val_acc_ensemble: 0.7581 - val_acc_1: 0.7581 - val_acc_2: 0.7581\n",
      "Epoch 47/50\n",
      "100/100 - 6s - loss_1: 0.0650 - loss_2: 0.0702 - acc_ensemble: 0.8860 - acc_1: 0.8860 - acc_2: 0.8860 - val_loss_1: 1.0499 - val_loss_2: 1.0499 - val_acc_ensemble: 0.7598 - val_acc_1: 0.7598 - val_acc_2: 0.7598\n",
      "Epoch 48/50\n",
      "100/100 - 6s - loss_1: 0.0907 - loss_2: 0.0822 - acc_ensemble: 0.8920 - acc_1: 0.8920 - acc_2: 0.8920 - val_loss_1: 1.0373 - val_loss_2: 1.0373 - val_acc_ensemble: 0.7543 - val_acc_1: 0.7543 - val_acc_2: 0.7543\n",
      "Epoch 49/50\n",
      "100/100 - 6s - loss_1: 0.0803 - loss_2: 0.0749 - acc_ensemble: 0.9040 - acc_1: 0.9040 - acc_2: 0.9040 - val_loss_1: 1.0479 - val_loss_2: 1.0479 - val_acc_ensemble: 0.7548 - val_acc_1: 0.7548 - val_acc_2: 0.7548\n",
      "Epoch 50/50\n",
      "100/100 - 6s - loss_1: 0.0690 - loss_2: 0.0624 - acc_ensemble: 0.8820 - acc_1: 0.8820 - acc_2: 0.8820 - val_loss_1: 1.0676 - val_loss_2: 1.0676 - val_acc_ensemble: 0.7557 - val_acc_1: 0.7557 - val_acc_2: 0.7557\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B2/S1.00/model_2\n",
      "i   Layer name                      Output shape        Num param  Inbound            \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                    \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                    \n",
      "--------------------------------------------------------------------------------------\n",
      "0   conv2d_1_1 (Conv2D)             [None,32,32,32] []  896        input              \n",
      "                                    [None,32,32,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "1   bn_1_1 (BatchNormalization)     [None,32,32,32] []  64         conv2d_1_1         \n",
      "                                    [None,32,32,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "2   relu_1_1 (Activation)           [None,32,32,32] []  0          bn_1_1             \n",
      "                                    [None,32,32,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "3   conv2d_1_2 (Conv2D)             [None,32,32,32] []  9248       relu_1_1           \n",
      "                                    [None,32,32,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "4   bn_1_2 (BatchNormalization)     [None,32,32,32] []  64         conv2d_1_2         \n",
      "                                    [None,32,32,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "5   relu_1_2 (Activation)           [None,32,32,32] []  0          bn_1_2             \n",
      "                                    [None,32,32,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "6   avg_pool2d_1 (AveragePooling2D  [None,16,16,32] []  0          relu_1_2           \n",
      "                                    [None,16,16,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "7   conv2d_2_1 (Conv2D)             [None,16,16,64] []  18496      avg_pool2d_1       \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "8   bn_2_1 (BatchNormalization)     [None,16,16,64] []  128        conv2d_2_1         \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "9   relu_2_1 (Activation)           [None,16,16,64] []  0          bn_2_1             \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "10  conv2d_2_2 (Conv2D)             [None,16,16,64] []  36928      relu_2_1           \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "11  bn_2_2 (BatchNormalization)     [None,16,16,64] []  128        conv2d_2_2         \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "12  relu_2_2 (Activation)           [None,16,16,64] []  0          bn_2_2             \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "13  avg_pool2d_2 (AveragePooling2D  [None,8,8,64] []    0          relu_2_2           \n",
      "                                    [None,8,8,64] []                                  \n",
      "--------------------------------------------------------------------------------------\n",
      "14  conv2d_3_1 (Conv2D)             [None,8,8,128] []   73856      avg_pool2d_2       \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "15  bn_3_1 (BatchNormalization)     [None,8,8,128] []   256        conv2d_3_1         \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "16  relu_3_1 (Activation)           [None,8,8,128] []   0          bn_3_1             \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "17  conv2d_3_2 (Conv2D)             [None,8,8,128] []   147584     relu_3_1           \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "18  bn_3_2 (BatchNormalization)     [None,8,8,128] []   256        conv2d_3_2         \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "19  relu_3_2 (Activation)           [None,8,8,128] []   0          bn_3_2             \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "20  global_avg_pool2d (GlobalAvera  [None,128] []       0          relu_3_2           \n",
      "                                    [None,128] []                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "21  fc1 (Dense)                     [None,128] []       16512      global_avg_pool2d  \n",
      "                                    [None,128] []                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "22  bn_fc1 (BatchNormalization)     [None,128] []       256        fc1                \n",
      "                                    [None,128] []                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "23  relu_fc1 (Activation)           [None,128] []       0          bn_fc1             \n",
      "                                    [None,128] []                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "24  output (Dense)                  [None,10]           1290       relu_fc1           \n",
      "                                    [None,10]                                         \n",
      "--------------------------------------------------------------------------------------\n",
      "Total parameters: 305962\n",
      "50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 - 7s - loss_1: 1.6683 - loss_2: 1.6713 - acc_ensemble: 0.5160 - acc_1: 0.5160 - acc_2: 0.5160 - val_loss_1: 1.3826 - val_loss_2: 1.3826 - val_acc_ensemble: 0.4889 - val_acc_1: 0.4889 - val_acc_2: 0.4889\n",
      "Epoch 2/50\n",
      "100/100 - 6s - loss_1: 1.2918 - loss_2: 1.2892 - acc_ensemble: 0.5940 - acc_1: 0.5940 - acc_2: 0.5940 - val_loss_1: 1.2112 - val_loss_2: 1.2112 - val_acc_ensemble: 0.5609 - val_acc_1: 0.5609 - val_acc_2: 0.5609\n",
      "Epoch 3/50\n",
      "100/100 - 6s - loss_1: 1.1078 - loss_2: 1.1244 - acc_ensemble: 0.6400 - acc_1: 0.6400 - acc_2: 0.6400 - val_loss_1: 1.0967 - val_loss_2: 1.0967 - val_acc_ensemble: 0.6052 - val_acc_1: 0.6052 - val_acc_2: 0.6052\n",
      "Epoch 4/50\n",
      "100/100 - 6s - loss_1: 1.0089 - loss_2: 1.0297 - acc_ensemble: 0.6480 - acc_1: 0.6480 - acc_2: 0.6480 - val_loss_1: 1.0183 - val_loss_2: 1.0183 - val_acc_ensemble: 0.6344 - val_acc_1: 0.6344 - val_acc_2: 0.6344\n",
      "Epoch 5/50\n",
      "100/100 - 6s - loss_1: 0.9273 - loss_2: 0.9358 - acc_ensemble: 0.6780 - acc_1: 0.6780 - acc_2: 0.6780 - val_loss_1: 0.9551 - val_loss_2: 0.9551 - val_acc_ensemble: 0.6575 - val_acc_1: 0.6575 - val_acc_2: 0.6575\n",
      "Epoch 6/50\n",
      "100/100 - 6s - loss_1: 0.8553 - loss_2: 0.8389 - acc_ensemble: 0.7300 - acc_1: 0.7300 - acc_2: 0.7300 - val_loss_1: 0.9186 - val_loss_2: 0.9186 - val_acc_ensemble: 0.6752 - val_acc_1: 0.6752 - val_acc_2: 0.6752\n",
      "Epoch 7/50\n",
      "100/100 - 6s - loss_1: 0.7811 - loss_2: 0.7719 - acc_ensemble: 0.7620 - acc_1: 0.7620 - acc_2: 0.7620 - val_loss_1: 0.8687 - val_loss_2: 0.8687 - val_acc_ensemble: 0.6918 - val_acc_1: 0.6918 - val_acc_2: 0.6918\n",
      "Epoch 8/50\n",
      "100/100 - 6s - loss_1: 0.7384 - loss_2: 0.7441 - acc_ensemble: 0.7560 - acc_1: 0.7560 - acc_2: 0.7560 - val_loss_1: 0.8349 - val_loss_2: 0.8349 - val_acc_ensemble: 0.7075 - val_acc_1: 0.7075 - val_acc_2: 0.7075\n",
      "Epoch 9/50\n",
      "100/100 - 6s - loss_1: 0.6833 - loss_2: 0.6845 - acc_ensemble: 0.7820 - acc_1: 0.7820 - acc_2: 0.7820 - val_loss_1: 0.8170 - val_loss_2: 0.8170 - val_acc_ensemble: 0.7103 - val_acc_1: 0.7103 - val_acc_2: 0.7103\n",
      "Epoch 10/50\n",
      "100/100 - 6s - loss_1: 0.6408 - loss_2: 0.6403 - acc_ensemble: 0.7980 - acc_1: 0.7980 - acc_2: 0.7980 - val_loss_1: 0.7853 - val_loss_2: 0.7853 - val_acc_ensemble: 0.7222 - val_acc_1: 0.7222 - val_acc_2: 0.7222\n",
      "Epoch 11/50\n",
      "100/100 - 6s - loss_1: 0.5948 - loss_2: 0.5993 - acc_ensemble: 0.8100 - acc_1: 0.8100 - acc_2: 0.8100 - val_loss_1: 0.7901 - val_loss_2: 0.7901 - val_acc_ensemble: 0.7247 - val_acc_1: 0.7247 - val_acc_2: 0.7247\n",
      "Epoch 12/50\n",
      "100/100 - 6s - loss_1: 0.5571 - loss_2: 0.5702 - acc_ensemble: 0.7980 - acc_1: 0.7980 - acc_2: 0.7980 - val_loss_1: 0.7738 - val_loss_2: 0.7738 - val_acc_ensemble: 0.7349 - val_acc_1: 0.7349 - val_acc_2: 0.7349\n",
      "Epoch 13/50\n",
      "100/100 - 6s - loss_1: 0.5121 - loss_2: 0.5106 - acc_ensemble: 0.8400 - acc_1: 0.8400 - acc_2: 0.8400 - val_loss_1: 0.7650 - val_loss_2: 0.7650 - val_acc_ensemble: 0.7373 - val_acc_1: 0.7373 - val_acc_2: 0.7373\n",
      "Epoch 14/50\n",
      "100/100 - 6s - loss_1: 0.5137 - loss_2: 0.5050 - acc_ensemble: 0.8280 - acc_1: 0.8280 - acc_2: 0.8280 - val_loss_1: 0.7555 - val_loss_2: 0.7555 - val_acc_ensemble: 0.7408 - val_acc_1: 0.7408 - val_acc_2: 0.7408\n",
      "Epoch 15/50\n",
      "100/100 - 6s - loss_1: 0.4453 - loss_2: 0.4771 - acc_ensemble: 0.8500 - acc_1: 0.8500 - acc_2: 0.8500 - val_loss_1: 0.7801 - val_loss_2: 0.7801 - val_acc_ensemble: 0.7381 - val_acc_1: 0.7381 - val_acc_2: 0.7381\n",
      "Epoch 16/50\n",
      "100/100 - 6s - loss_1: 0.4340 - loss_2: 0.4304 - acc_ensemble: 0.8280 - acc_1: 0.8280 - acc_2: 0.8280 - val_loss_1: 0.7645 - val_loss_2: 0.7645 - val_acc_ensemble: 0.7412 - val_acc_1: 0.7412 - val_acc_2: 0.7412\n",
      "Epoch 17/50\n",
      "100/100 - 6s - loss_1: 0.3915 - loss_2: 0.3794 - acc_ensemble: 0.8280 - acc_1: 0.8280 - acc_2: 0.8280 - val_loss_1: 0.7801 - val_loss_2: 0.7801 - val_acc_ensemble: 0.7406 - val_acc_1: 0.7406 - val_acc_2: 0.7406\n",
      "Epoch 18/50\n",
      "100/100 - 6s - loss_1: 0.3600 - loss_2: 0.3702 - acc_ensemble: 0.8460 - acc_1: 0.8460 - acc_2: 0.8460 - val_loss_1: 0.7536 - val_loss_2: 0.7536 - val_acc_ensemble: 0.7494 - val_acc_1: 0.7494 - val_acc_2: 0.7494\n",
      "Epoch 19/50\n",
      "100/100 - 6s - loss_1: 0.3310 - loss_2: 0.3451 - acc_ensemble: 0.8760 - acc_1: 0.8760 - acc_2: 0.8760 - val_loss_1: 0.7707 - val_loss_2: 0.7707 - val_acc_ensemble: 0.7495 - val_acc_1: 0.7495 - val_acc_2: 0.7495\n",
      "Epoch 20/50\n",
      "100/100 - 6s - loss_1: 0.3211 - loss_2: 0.3451 - acc_ensemble: 0.8660 - acc_1: 0.8660 - acc_2: 0.8660 - val_loss_1: 0.7772 - val_loss_2: 0.7772 - val_acc_ensemble: 0.7492 - val_acc_1: 0.7492 - val_acc_2: 0.7492\n",
      "Epoch 21/50\n",
      "100/100 - 6s - loss_1: 0.3156 - loss_2: 0.3281 - acc_ensemble: 0.8720 - acc_1: 0.8720 - acc_2: 0.8720 - val_loss_1: 0.7812 - val_loss_2: 0.7812 - val_acc_ensemble: 0.7475 - val_acc_1: 0.7475 - val_acc_2: 0.7475\n",
      "Epoch 22/50\n",
      "100/100 - 6s - loss_1: 0.2765 - loss_2: 0.2716 - acc_ensemble: 0.8980 - acc_1: 0.8980 - acc_2: 0.8980 - val_loss_1: 0.7430 - val_loss_2: 0.7430 - val_acc_ensemble: 0.7635 - val_acc_1: 0.7635 - val_acc_2: 0.7635\n",
      "Epoch 23/50\n",
      "100/100 - 6s - loss_1: 0.2891 - loss_2: 0.2734 - acc_ensemble: 0.8860 - acc_1: 0.8860 - acc_2: 0.8860 - val_loss_1: 0.7896 - val_loss_2: 0.7896 - val_acc_ensemble: 0.7545 - val_acc_1: 0.7545 - val_acc_2: 0.7545\n",
      "Epoch 24/50\n",
      "100/100 - 6s - loss_1: 0.2852 - loss_2: 0.2721 - acc_ensemble: 0.8920 - acc_1: 0.8920 - acc_2: 0.8920 - val_loss_1: 0.7794 - val_loss_2: 0.7794 - val_acc_ensemble: 0.7593 - val_acc_1: 0.7593 - val_acc_2: 0.7593\n",
      "Epoch 25/50\n",
      "100/100 - 6s - loss_1: 0.2355 - loss_2: 0.2305 - acc_ensemble: 0.8920 - acc_1: 0.8920 - acc_2: 0.8920 - val_loss_1: 0.7896 - val_loss_2: 0.7896 - val_acc_ensemble: 0.7582 - val_acc_1: 0.7582 - val_acc_2: 0.7582\n",
      "Epoch 26/50\n",
      "100/100 - 6s - loss_1: 0.2181 - loss_2: 0.2137 - acc_ensemble: 0.8740 - acc_1: 0.8740 - acc_2: 0.8740 - val_loss_1: 0.8187 - val_loss_2: 0.8187 - val_acc_ensemble: 0.7503 - val_acc_1: 0.7503 - val_acc_2: 0.7503\n",
      "Epoch 27/50\n",
      "100/100 - 6s - loss_1: 0.1946 - loss_2: 0.2098 - acc_ensemble: 0.9000 - acc_1: 0.9000 - acc_2: 0.9000 - val_loss_1: 0.8007 - val_loss_2: 0.8007 - val_acc_ensemble: 0.7647 - val_acc_1: 0.7647 - val_acc_2: 0.7647\n",
      "Epoch 28/50\n",
      "100/100 - 6s - loss_1: 0.1954 - loss_2: 0.1806 - acc_ensemble: 0.8960 - acc_1: 0.8960 - acc_2: 0.8960 - val_loss_1: 0.8043 - val_loss_2: 0.8043 - val_acc_ensemble: 0.7603 - val_acc_1: 0.7603 - val_acc_2: 0.7603\n",
      "Epoch 29/50\n",
      "100/100 - 6s - loss_1: 0.1769 - loss_2: 0.1618 - acc_ensemble: 0.9120 - acc_1: 0.9120 - acc_2: 0.9120 - val_loss_1: 0.8089 - val_loss_2: 0.8089 - val_acc_ensemble: 0.7661 - val_acc_1: 0.7661 - val_acc_2: 0.7661\n",
      "Epoch 30/50\n",
      "100/100 - 6s - loss_1: 0.1638 - loss_2: 0.1840 - acc_ensemble: 0.8840 - acc_1: 0.8840 - acc_2: 0.8840 - val_loss_1: 0.8253 - val_loss_2: 0.8253 - val_acc_ensemble: 0.7654 - val_acc_1: 0.7654 - val_acc_2: 0.7654\n",
      "Epoch 31/50\n",
      "100/100 - 6s - loss_1: 0.1547 - loss_2: 0.1518 - acc_ensemble: 0.8920 - acc_1: 0.8920 - acc_2: 0.8920 - val_loss_1: 0.8240 - val_loss_2: 0.8240 - val_acc_ensemble: 0.7678 - val_acc_1: 0.7678 - val_acc_2: 0.7678\n",
      "Epoch 32/50\n",
      "100/100 - 6s - loss_1: 0.1648 - loss_2: 0.1645 - acc_ensemble: 0.8900 - acc_1: 0.8900 - acc_2: 0.8900 - val_loss_1: 0.8416 - val_loss_2: 0.8416 - val_acc_ensemble: 0.7647 - val_acc_1: 0.7647 - val_acc_2: 0.7647\n",
      "Epoch 33/50\n",
      "100/100 - 6s - loss_1: 0.1501 - loss_2: 0.1383 - acc_ensemble: 0.9060 - acc_1: 0.9060 - acc_2: 0.9060 - val_loss_1: 0.8789 - val_loss_2: 0.8789 - val_acc_ensemble: 0.7593 - val_acc_1: 0.7593 - val_acc_2: 0.7593\n",
      "Epoch 34/50\n",
      "100/100 - 6s - loss_1: 0.1317 - loss_2: 0.1434 - acc_ensemble: 0.9220 - acc_1: 0.9220 - acc_2: 0.9220 - val_loss_1: 0.8561 - val_loss_2: 0.8561 - val_acc_ensemble: 0.7611 - val_acc_1: 0.7611 - val_acc_2: 0.7611\n",
      "Epoch 35/50\n",
      "100/100 - 6s - loss_1: 0.1186 - loss_2: 0.1270 - acc_ensemble: 0.9080 - acc_1: 0.9080 - acc_2: 0.9080 - val_loss_1: 0.9013 - val_loss_2: 0.9013 - val_acc_ensemble: 0.7606 - val_acc_1: 0.7606 - val_acc_2: 0.7606\n",
      "Epoch 36/50\n",
      "100/100 - 6s - loss_1: 0.1160 - loss_2: 0.1282 - acc_ensemble: 0.9060 - acc_1: 0.9060 - acc_2: 0.9060 - val_loss_1: 0.9118 - val_loss_2: 0.9118 - val_acc_ensemble: 0.7539 - val_acc_1: 0.7539 - val_acc_2: 0.7539\n",
      "Epoch 37/50\n",
      "100/100 - 6s - loss_1: 0.1321 - loss_2: 0.1169 - acc_ensemble: 0.9060 - acc_1: 0.9060 - acc_2: 0.9060 - val_loss_1: 0.9172 - val_loss_2: 0.9172 - val_acc_ensemble: 0.7587 - val_acc_1: 0.7587 - val_acc_2: 0.7587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50\n",
      "100/100 - 6s - loss_1: 0.1081 - loss_2: 0.1094 - acc_ensemble: 0.9100 - acc_1: 0.9100 - acc_2: 0.9100 - val_loss_1: 0.8725 - val_loss_2: 0.8725 - val_acc_ensemble: 0.7708 - val_acc_1: 0.7708 - val_acc_2: 0.7708\n",
      "Epoch 39/50\n",
      "100/100 - 6s - loss_1: 0.0898 - loss_2: 0.0939 - acc_ensemble: 0.9100 - acc_1: 0.9100 - acc_2: 0.9100 - val_loss_1: 0.9396 - val_loss_2: 0.9396 - val_acc_ensemble: 0.7568 - val_acc_1: 0.7568 - val_acc_2: 0.7568\n",
      "Epoch 40/50\n",
      "100/100 - 6s - loss_1: 0.0944 - loss_2: 0.0966 - acc_ensemble: 0.9120 - acc_1: 0.9120 - acc_2: 0.9120 - val_loss_1: 0.9149 - val_loss_2: 0.9149 - val_acc_ensemble: 0.7724 - val_acc_1: 0.7724 - val_acc_2: 0.7724\n",
      "Epoch 41/50\n",
      "100/100 - 6s - loss_1: 0.0877 - loss_2: 0.0816 - acc_ensemble: 0.8960 - acc_1: 0.8960 - acc_2: 0.8960 - val_loss_1: 0.9686 - val_loss_2: 0.9686 - val_acc_ensemble: 0.7605 - val_acc_1: 0.7605 - val_acc_2: 0.7605\n",
      "Epoch 42/50\n",
      "100/100 - 6s - loss_1: 0.0940 - loss_2: 0.0974 - acc_ensemble: 0.8940 - acc_1: 0.8940 - acc_2: 0.8940 - val_loss_1: 0.9701 - val_loss_2: 0.9701 - val_acc_ensemble: 0.7618 - val_acc_1: 0.7618 - val_acc_2: 0.7618\n",
      "Epoch 43/50\n",
      "100/100 - 6s - loss_1: 0.1064 - loss_2: 0.0998 - acc_ensemble: 0.9040 - acc_1: 0.9040 - acc_2: 0.9040 - val_loss_1: 0.9538 - val_loss_2: 0.9538 - val_acc_ensemble: 0.7692 - val_acc_1: 0.7692 - val_acc_2: 0.7692\n",
      "Epoch 44/50\n",
      "100/100 - 6s - loss_1: 0.0905 - loss_2: 0.0828 - acc_ensemble: 0.9080 - acc_1: 0.9080 - acc_2: 0.9080 - val_loss_1: 0.9863 - val_loss_2: 0.9863 - val_acc_ensemble: 0.7593 - val_acc_1: 0.7593 - val_acc_2: 0.7593\n",
      "Epoch 45/50\n",
      "100/100 - 6s - loss_1: 0.0715 - loss_2: 0.0800 - acc_ensemble: 0.9100 - acc_1: 0.9100 - acc_2: 0.9100 - val_loss_1: 0.9540 - val_loss_2: 0.9540 - val_acc_ensemble: 0.7700 - val_acc_1: 0.7700 - val_acc_2: 0.7700\n",
      "Epoch 46/50\n",
      "100/100 - 6s - loss_1: 0.0634 - loss_2: 0.0629 - acc_ensemble: 0.9060 - acc_1: 0.9060 - acc_2: 0.9060 - val_loss_1: 0.9669 - val_loss_2: 0.9669 - val_acc_ensemble: 0.7709 - val_acc_1: 0.7709 - val_acc_2: 0.7709\n",
      "Epoch 47/50\n",
      "100/100 - 6s - loss_1: 0.0845 - loss_2: 0.0630 - acc_ensemble: 0.8940 - acc_1: 0.8940 - acc_2: 0.8940 - val_loss_1: 1.0332 - val_loss_2: 1.0332 - val_acc_ensemble: 0.7524 - val_acc_1: 0.7524 - val_acc_2: 0.7524\n",
      "Epoch 48/50\n",
      "100/100 - 6s - loss_1: 0.0774 - loss_2: 0.0680 - acc_ensemble: 0.9000 - acc_1: 0.9000 - acc_2: 0.9000 - val_loss_1: 1.0603 - val_loss_2: 1.0603 - val_acc_ensemble: 0.7563 - val_acc_1: 0.7563 - val_acc_2: 0.7563\n",
      "Epoch 49/50\n",
      "100/100 - 6s - loss_1: 0.0560 - loss_2: 0.0566 - acc_ensemble: 0.9140 - acc_1: 0.9140 - acc_2: 0.9140 - val_loss_1: 0.9903 - val_loss_2: 0.9903 - val_acc_ensemble: 0.7687 - val_acc_1: 0.7687 - val_acc_2: 0.7687\n",
      "Epoch 50/50\n",
      "100/100 - 6s - loss_1: 0.0573 - loss_2: 0.0494 - acc_ensemble: 0.9060 - acc_1: 0.9060 - acc_2: 0.9060 - val_loss_1: 1.0323 - val_loss_2: 1.0323 - val_acc_ensemble: 0.7646 - val_acc_1: 0.7646 - val_acc_2: 0.7646\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B2/S1.00/model_3\n",
      "i   Layer name                      Output shape        Num param  Inbound            \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                    \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                    \n",
      "--------------------------------------------------------------------------------------\n",
      "0   conv2d_1_1 (Conv2D)             [None,32,32,32] []  896        input              \n",
      "                                    [None,32,32,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "1   bn_1_1 (BatchNormalization)     [None,32,32,32] []  64         conv2d_1_1         \n",
      "                                    [None,32,32,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "2   relu_1_1 (Activation)           [None,32,32,32] []  0          bn_1_1             \n",
      "                                    [None,32,32,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "3   conv2d_1_2 (Conv2D)             [None,32,32,32] []  9248       relu_1_1           \n",
      "                                    [None,32,32,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "4   bn_1_2 (BatchNormalization)     [None,32,32,32] []  64         conv2d_1_2         \n",
      "                                    [None,32,32,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "5   relu_1_2 (Activation)           [None,32,32,32] []  0          bn_1_2             \n",
      "                                    [None,32,32,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "6   avg_pool2d_1 (AveragePooling2D  [None,16,16,32] []  0          relu_1_2           \n",
      "                                    [None,16,16,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "7   conv2d_2_1 (Conv2D)             [None,16,16,64] []  18496      avg_pool2d_1       \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "8   bn_2_1 (BatchNormalization)     [None,16,16,64] []  128        conv2d_2_1         \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "9   relu_2_1 (Activation)           [None,16,16,64] []  0          bn_2_1             \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "10  conv2d_2_2 (Conv2D)             [None,16,16,64] []  36928      relu_2_1           \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "11  bn_2_2 (BatchNormalization)     [None,16,16,64] []  128        conv2d_2_2         \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "12  relu_2_2 (Activation)           [None,16,16,64] []  0          bn_2_2             \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "13  avg_pool2d_2 (AveragePooling2D  [None,8,8,64] []    0          relu_2_2           \n",
      "                                    [None,8,8,64] []                                  \n",
      "--------------------------------------------------------------------------------------\n",
      "14  conv2d_3_1 (Conv2D)             [None,8,8,128] []   73856      avg_pool2d_2       \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "15  bn_3_1 (BatchNormalization)     [None,8,8,128] []   256        conv2d_3_1         \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "16  relu_3_1 (Activation)           [None,8,8,128] []   0          bn_3_1             \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "17  conv2d_3_2 (Conv2D)             [None,8,8,128] []   147584     relu_3_1           \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "18  bn_3_2 (BatchNormalization)     [None,8,8,128] []   256        conv2d_3_2         \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "19  relu_3_2 (Activation)           [None,8,8,128] []   0          bn_3_2             \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "20  global_avg_pool2d (GlobalAvera  [None,128] []       0          relu_3_2           \n",
      "                                    [None,128] []                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "21  fc1 (Dense)                     [None,128] []       16512      global_avg_pool2d  \n",
      "                                    [None,128] []                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "22  bn_fc1 (BatchNormalization)     [None,128] []       256        fc1                \n",
      "                                    [None,128] []                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "23  relu_fc1 (Activation)           [None,128] []       0          bn_fc1             \n",
      "                                    [None,128] []                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "24  output (Dense)                  [None,10]           1290       relu_fc1           \n",
      "                                    [None,10]                                         \n",
      "--------------------------------------------------------------------------------------\n",
      "Total parameters: 305962\n",
      "50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 - 7s - loss_1: 1.6989 - loss_2: 1.7035 - acc_ensemble: 0.5040 - acc_1: 0.5040 - acc_2: 0.5040 - val_loss_1: 1.4054 - val_loss_2: 1.4054 - val_acc_ensemble: 0.4853 - val_acc_1: 0.4853 - val_acc_2: 0.4853\n",
      "Epoch 2/50\n",
      "100/100 - 6s - loss_1: 1.3226 - loss_2: 1.3323 - acc_ensemble: 0.5700 - acc_1: 0.5700 - acc_2: 0.5700 - val_loss_1: 1.2690 - val_loss_2: 1.2690 - val_acc_ensemble: 0.5359 - val_acc_1: 0.5359 - val_acc_2: 0.5359\n",
      "Epoch 3/50\n",
      "100/100 - 6s - loss_1: 1.1337 - loss_2: 1.1619 - acc_ensemble: 0.6260 - acc_1: 0.6260 - acc_2: 0.6260 - val_loss_1: 1.1046 - val_loss_2: 1.1046 - val_acc_ensemble: 0.6066 - val_acc_1: 0.6066 - val_acc_2: 0.6066\n",
      "Epoch 4/50\n",
      "100/100 - 6s - loss_1: 1.0415 - loss_2: 1.0797 - acc_ensemble: 0.6380 - acc_1: 0.6380 - acc_2: 0.6380 - val_loss_1: 1.0519 - val_loss_2: 1.0519 - val_acc_ensemble: 0.6227 - val_acc_1: 0.6227 - val_acc_2: 0.6227\n",
      "Epoch 5/50\n",
      "100/100 - 6s - loss_1: 0.9466 - loss_2: 0.9515 - acc_ensemble: 0.6720 - acc_1: 0.6720 - acc_2: 0.6720 - val_loss_1: 1.0085 - val_loss_2: 1.0085 - val_acc_ensemble: 0.6397 - val_acc_1: 0.6397 - val_acc_2: 0.6397\n",
      "Epoch 6/50\n",
      "100/100 - 6s - loss_1: 0.8934 - loss_2: 0.8948 - acc_ensemble: 0.6820 - acc_1: 0.6820 - acc_2: 0.6820 - val_loss_1: 0.9632 - val_loss_2: 0.9632 - val_acc_ensemble: 0.6604 - val_acc_1: 0.6604 - val_acc_2: 0.6604\n",
      "Epoch 7/50\n",
      "100/100 - 6s - loss_1: 0.8082 - loss_2: 0.8097 - acc_ensemble: 0.7240 - acc_1: 0.7240 - acc_2: 0.7240 - val_loss_1: 0.9072 - val_loss_2: 0.9072 - val_acc_ensemble: 0.6792 - val_acc_1: 0.6792 - val_acc_2: 0.6792\n",
      "Epoch 8/50\n",
      "100/100 - 6s - loss_1: 0.7740 - loss_2: 0.7792 - acc_ensemble: 0.7340 - acc_1: 0.7340 - acc_2: 0.7340 - val_loss_1: 0.8811 - val_loss_2: 0.8811 - val_acc_ensemble: 0.6901 - val_acc_1: 0.6901 - val_acc_2: 0.6901\n",
      "Epoch 9/50\n",
      "100/100 - 6s - loss_1: 0.7253 - loss_2: 0.7042 - acc_ensemble: 0.7440 - acc_1: 0.7440 - acc_2: 0.7440 - val_loss_1: 0.8466 - val_loss_2: 0.8466 - val_acc_ensemble: 0.7034 - val_acc_1: 0.7034 - val_acc_2: 0.7034\n",
      "Epoch 10/50\n",
      "100/100 - 6s - loss_1: 0.6573 - loss_2: 0.6672 - acc_ensemble: 0.7460 - acc_1: 0.7460 - acc_2: 0.7460 - val_loss_1: 0.8514 - val_loss_2: 0.8514 - val_acc_ensemble: 0.7035 - val_acc_1: 0.7035 - val_acc_2: 0.7035\n",
      "Epoch 11/50\n",
      "100/100 - 6s - loss_1: 0.6390 - loss_2: 0.6156 - acc_ensemble: 0.7580 - acc_1: 0.7580 - acc_2: 0.7580 - val_loss_1: 0.8132 - val_loss_2: 0.8132 - val_acc_ensemble: 0.7190 - val_acc_1: 0.7190 - val_acc_2: 0.7190\n",
      "Epoch 12/50\n",
      "100/100 - 6s - loss_1: 0.5844 - loss_2: 0.5885 - acc_ensemble: 0.8100 - acc_1: 0.8100 - acc_2: 0.8100 - val_loss_1: 0.7868 - val_loss_2: 0.7868 - val_acc_ensemble: 0.7257 - val_acc_1: 0.7257 - val_acc_2: 0.7257\n",
      "Epoch 13/50\n",
      "100/100 - 6s - loss_1: 0.5567 - loss_2: 0.5401 - acc_ensemble: 0.8140 - acc_1: 0.8140 - acc_2: 0.8140 - val_loss_1: 0.7812 - val_loss_2: 0.7812 - val_acc_ensemble: 0.7294 - val_acc_1: 0.7294 - val_acc_2: 0.7294\n",
      "Epoch 14/50\n",
      "100/100 - 6s - loss_1: 0.5149 - loss_2: 0.5281 - acc_ensemble: 0.8000 - acc_1: 0.8000 - acc_2: 0.8000 - val_loss_1: 0.7734 - val_loss_2: 0.7734 - val_acc_ensemble: 0.7350 - val_acc_1: 0.7350 - val_acc_2: 0.7350\n",
      "Epoch 15/50\n",
      "100/100 - 6s - loss_1: 0.4814 - loss_2: 0.4663 - acc_ensemble: 0.8060 - acc_1: 0.8060 - acc_2: 0.8060 - val_loss_1: 0.7635 - val_loss_2: 0.7635 - val_acc_ensemble: 0.7399 - val_acc_1: 0.7399 - val_acc_2: 0.7399\n",
      "Epoch 16/50\n",
      "100/100 - 6s - loss_1: 0.4494 - loss_2: 0.4368 - acc_ensemble: 0.8200 - acc_1: 0.8200 - acc_2: 0.8200 - val_loss_1: 0.7854 - val_loss_2: 0.7854 - val_acc_ensemble: 0.7374 - val_acc_1: 0.7374 - val_acc_2: 0.7374\n",
      "Epoch 17/50\n",
      "100/100 - 6s - loss_1: 0.4513 - loss_2: 0.4322 - acc_ensemble: 0.8440 - acc_1: 0.8440 - acc_2: 0.8440 - val_loss_1: 0.7698 - val_loss_2: 0.7698 - val_acc_ensemble: 0.7391 - val_acc_1: 0.7391 - val_acc_2: 0.7391\n",
      "Epoch 18/50\n",
      "100/100 - 6s - loss_1: 0.4010 - loss_2: 0.3886 - acc_ensemble: 0.8300 - acc_1: 0.8300 - acc_2: 0.8300 - val_loss_1: 0.7455 - val_loss_2: 0.7455 - val_acc_ensemble: 0.7518 - val_acc_1: 0.7518 - val_acc_2: 0.7518\n",
      "Epoch 19/50\n",
      "100/100 - 6s - loss_1: 0.3710 - loss_2: 0.3675 - acc_ensemble: 0.8580 - acc_1: 0.8580 - acc_2: 0.8580 - val_loss_1: 0.7523 - val_loss_2: 0.7523 - val_acc_ensemble: 0.7553 - val_acc_1: 0.7553 - val_acc_2: 0.7553\n",
      "Epoch 20/50\n",
      "100/100 - 6s - loss_1: 0.3528 - loss_2: 0.3490 - acc_ensemble: 0.8620 - acc_1: 0.8620 - acc_2: 0.8620 - val_loss_1: 0.7725 - val_loss_2: 0.7725 - val_acc_ensemble: 0.7503 - val_acc_1: 0.7503 - val_acc_2: 0.7503\n",
      "Epoch 21/50\n",
      "100/100 - 6s - loss_1: 0.3042 - loss_2: 0.3118 - acc_ensemble: 0.8700 - acc_1: 0.8700 - acc_2: 0.8700 - val_loss_1: 0.7739 - val_loss_2: 0.7739 - val_acc_ensemble: 0.7519 - val_acc_1: 0.7519 - val_acc_2: 0.7519\n",
      "Epoch 22/50\n",
      "100/100 - 6s - loss_1: 0.3298 - loss_2: 0.3420 - acc_ensemble: 0.8320 - acc_1: 0.8320 - acc_2: 0.8320 - val_loss_1: 0.7656 - val_loss_2: 0.7656 - val_acc_ensemble: 0.7547 - val_acc_1: 0.7547 - val_acc_2: 0.7547\n",
      "Epoch 23/50\n",
      "100/100 - 6s - loss_1: 0.3035 - loss_2: 0.2998 - acc_ensemble: 0.8440 - acc_1: 0.8440 - acc_2: 0.8440 - val_loss_1: 0.7859 - val_loss_2: 0.7859 - val_acc_ensemble: 0.7531 - val_acc_1: 0.7531 - val_acc_2: 0.7531\n",
      "Epoch 24/50\n",
      "100/100 - 6s - loss_1: 0.2715 - loss_2: 0.2708 - acc_ensemble: 0.8500 - acc_1: 0.8500 - acc_2: 0.8500 - val_loss_1: 0.7930 - val_loss_2: 0.7930 - val_acc_ensemble: 0.7544 - val_acc_1: 0.7544 - val_acc_2: 0.7544\n",
      "Epoch 25/50\n",
      "100/100 - 6s - loss_1: 0.2680 - loss_2: 0.2426 - acc_ensemble: 0.8560 - acc_1: 0.8560 - acc_2: 0.8560 - val_loss_1: 0.8185 - val_loss_2: 0.8185 - val_acc_ensemble: 0.7484 - val_acc_1: 0.7484 - val_acc_2: 0.7484\n",
      "Epoch 26/50\n",
      "100/100 - 6s - loss_1: 0.2392 - loss_2: 0.2079 - acc_ensemble: 0.8760 - acc_1: 0.8760 - acc_2: 0.8760 - val_loss_1: 0.7784 - val_loss_2: 0.7784 - val_acc_ensemble: 0.7688 - val_acc_1: 0.7688 - val_acc_2: 0.7688\n",
      "Epoch 27/50\n",
      "100/100 - 6s - loss_1: 0.2104 - loss_2: 0.2128 - acc_ensemble: 0.8860 - acc_1: 0.8860 - acc_2: 0.8860 - val_loss_1: 0.7997 - val_loss_2: 0.7997 - val_acc_ensemble: 0.7598 - val_acc_1: 0.7598 - val_acc_2: 0.7598\n",
      "Epoch 28/50\n",
      "100/100 - 6s - loss_1: 0.2089 - loss_2: 0.1946 - acc_ensemble: 0.8700 - acc_1: 0.8700 - acc_2: 0.8700 - val_loss_1: 0.8276 - val_loss_2: 0.8276 - val_acc_ensemble: 0.7579 - val_acc_1: 0.7579 - val_acc_2: 0.7579\n",
      "Epoch 29/50\n",
      "100/100 - 6s - loss_1: 0.1963 - loss_2: 0.1972 - acc_ensemble: 0.8740 - acc_1: 0.8740 - acc_2: 0.8740 - val_loss_1: 0.8432 - val_loss_2: 0.8432 - val_acc_ensemble: 0.7565 - val_acc_1: 0.7565 - val_acc_2: 0.7565\n",
      "Epoch 30/50\n",
      "100/100 - 6s - loss_1: 0.1770 - loss_2: 0.1790 - acc_ensemble: 0.8680 - acc_1: 0.8680 - acc_2: 0.8680 - val_loss_1: 0.8232 - val_loss_2: 0.8232 - val_acc_ensemble: 0.7631 - val_acc_1: 0.7631 - val_acc_2: 0.7631\n",
      "Epoch 31/50\n",
      "100/100 - 6s - loss_1: 0.1694 - loss_2: 0.1497 - acc_ensemble: 0.9020 - acc_1: 0.9020 - acc_2: 0.9020 - val_loss_1: 0.8629 - val_loss_2: 0.8629 - val_acc_ensemble: 0.7549 - val_acc_1: 0.7549 - val_acc_2: 0.7549\n",
      "Epoch 32/50\n",
      "100/100 - 6s - loss_1: 0.1426 - loss_2: 0.1656 - acc_ensemble: 0.8820 - acc_1: 0.8820 - acc_2: 0.8820 - val_loss_1: 0.8770 - val_loss_2: 0.8770 - val_acc_ensemble: 0.7567 - val_acc_1: 0.7567 - val_acc_2: 0.7567\n",
      "Epoch 33/50\n",
      "100/100 - 6s - loss_1: 0.1471 - loss_2: 0.1460 - acc_ensemble: 0.8880 - acc_1: 0.8880 - acc_2: 0.8880 - val_loss_1: 0.8939 - val_loss_2: 0.8939 - val_acc_ensemble: 0.7507 - val_acc_1: 0.7507 - val_acc_2: 0.7507\n",
      "Epoch 34/50\n",
      "100/100 - 6s - loss_1: 0.1400 - loss_2: 0.1420 - acc_ensemble: 0.8860 - acc_1: 0.8860 - acc_2: 0.8860 - val_loss_1: 0.9137 - val_loss_2: 0.9137 - val_acc_ensemble: 0.7544 - val_acc_1: 0.7544 - val_acc_2: 0.7544\n",
      "Epoch 35/50\n",
      "100/100 - 6s - loss_1: 0.1398 - loss_2: 0.1334 - acc_ensemble: 0.8860 - acc_1: 0.8860 - acc_2: 0.8860 - val_loss_1: 0.9142 - val_loss_2: 0.9142 - val_acc_ensemble: 0.7536 - val_acc_1: 0.7536 - val_acc_2: 0.7536\n",
      "Epoch 36/50\n",
      "100/100 - 6s - loss_1: 0.1246 - loss_2: 0.1312 - acc_ensemble: 0.9000 - acc_1: 0.9000 - acc_2: 0.9000 - val_loss_1: 0.8675 - val_loss_2: 0.8675 - val_acc_ensemble: 0.7677 - val_acc_1: 0.7677 - val_acc_2: 0.7677\n",
      "Epoch 37/50\n",
      "100/100 - 6s - loss_1: 0.1033 - loss_2: 0.0945 - acc_ensemble: 0.9180 - acc_1: 0.9180 - acc_2: 0.9180 - val_loss_1: 0.9174 - val_loss_2: 0.9174 - val_acc_ensemble: 0.7626 - val_acc_1: 0.7626 - val_acc_2: 0.7626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50\n",
      "100/100 - 6s - loss_1: 0.1043 - loss_2: 0.1308 - acc_ensemble: 0.8880 - acc_1: 0.8880 - acc_2: 0.8880 - val_loss_1: 0.9742 - val_loss_2: 0.9742 - val_acc_ensemble: 0.7537 - val_acc_1: 0.7537 - val_acc_2: 0.7537\n",
      "Epoch 39/50\n",
      "100/100 - 6s - loss_1: 0.1230 - loss_2: 0.1168 - acc_ensemble: 0.9000 - acc_1: 0.9000 - acc_2: 0.9000 - val_loss_1: 0.9312 - val_loss_2: 0.9312 - val_acc_ensemble: 0.7603 - val_acc_1: 0.7603 - val_acc_2: 0.7603\n",
      "Epoch 40/50\n",
      "100/100 - 6s - loss_1: 0.0883 - loss_2: 0.0910 - acc_ensemble: 0.9100 - acc_1: 0.9100 - acc_2: 0.9100 - val_loss_1: 0.9342 - val_loss_2: 0.9342 - val_acc_ensemble: 0.7652 - val_acc_1: 0.7652 - val_acc_2: 0.7652\n",
      "Epoch 41/50\n",
      "100/100 - 6s - loss_1: 0.1012 - loss_2: 0.0945 - acc_ensemble: 0.8900 - acc_1: 0.8900 - acc_2: 0.8900 - val_loss_1: 1.0076 - val_loss_2: 1.0076 - val_acc_ensemble: 0.7455 - val_acc_1: 0.7455 - val_acc_2: 0.7455\n",
      "Epoch 42/50\n",
      "100/100 - 6s - loss_1: 0.0989 - loss_2: 0.0913 - acc_ensemble: 0.9100 - acc_1: 0.9100 - acc_2: 0.9100 - val_loss_1: 0.9748 - val_loss_2: 0.9748 - val_acc_ensemble: 0.7581 - val_acc_1: 0.7581 - val_acc_2: 0.7581\n",
      "Epoch 43/50\n",
      "100/100 - 6s - loss_1: 0.1027 - loss_2: 0.0918 - acc_ensemble: 0.9040 - acc_1: 0.9040 - acc_2: 0.9040 - val_loss_1: 0.9834 - val_loss_2: 0.9834 - val_acc_ensemble: 0.7602 - val_acc_1: 0.7602 - val_acc_2: 0.7602\n",
      "Epoch 44/50\n",
      "100/100 - 6s - loss_1: 0.0964 - loss_2: 0.0915 - acc_ensemble: 0.9040 - acc_1: 0.9040 - acc_2: 0.9040 - val_loss_1: 1.0128 - val_loss_2: 1.0128 - val_acc_ensemble: 0.7549 - val_acc_1: 0.7549 - val_acc_2: 0.7549\n",
      "Epoch 45/50\n",
      "100/100 - 6s - loss_1: 0.0968 - loss_2: 0.0842 - acc_ensemble: 0.9180 - acc_1: 0.9180 - acc_2: 0.9180 - val_loss_1: 0.9875 - val_loss_2: 0.9875 - val_acc_ensemble: 0.7617 - val_acc_1: 0.7617 - val_acc_2: 0.7617\n",
      "Epoch 46/50\n",
      "100/100 - 6s - loss_1: 0.0891 - loss_2: 0.1059 - acc_ensemble: 0.8840 - acc_1: 0.8840 - acc_2: 0.8840 - val_loss_1: 1.0255 - val_loss_2: 1.0255 - val_acc_ensemble: 0.7540 - val_acc_1: 0.7540 - val_acc_2: 0.7540\n",
      "Epoch 47/50\n",
      "100/100 - 6s - loss_1: 0.1082 - loss_2: 0.0976 - acc_ensemble: 0.9080 - acc_1: 0.9080 - acc_2: 0.9080 - val_loss_1: 0.9926 - val_loss_2: 0.9926 - val_acc_ensemble: 0.7580 - val_acc_1: 0.7580 - val_acc_2: 0.7580\n",
      "Epoch 48/50\n",
      "100/100 - 6s - loss_1: 0.0618 - loss_2: 0.0650 - acc_ensemble: 0.8980 - acc_1: 0.8980 - acc_2: 0.8980 - val_loss_1: 1.0164 - val_loss_2: 1.0164 - val_acc_ensemble: 0.7567 - val_acc_1: 0.7567 - val_acc_2: 0.7567\n",
      "Epoch 49/50\n",
      "100/100 - 6s - loss_1: 0.0588 - loss_2: 0.0635 - acc_ensemble: 0.9160 - acc_1: 0.9160 - acc_2: 0.9160 - val_loss_1: 1.0182 - val_loss_2: 1.0182 - val_acc_ensemble: 0.7673 - val_acc_1: 0.7673 - val_acc_2: 0.7673\n",
      "Epoch 50/50\n",
      "100/100 - 6s - loss_1: 0.0576 - loss_2: 0.0622 - acc_ensemble: 0.9120 - acc_1: 0.9120 - acc_2: 0.9120 - val_loss_1: 1.0343 - val_loss_2: 1.0343 - val_acc_ensemble: 0.7612 - val_acc_1: 0.7612 - val_acc_2: 0.7612\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B2/S1.00/model_4\n",
      "i   Layer name                      Output shape        Num param  Inbound            \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                    \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                    \n",
      "--------------------------------------------------------------------------------------\n",
      "0   conv2d_1_1 (Conv2D)             [None,32,32,32] []  896        input              \n",
      "                                    [None,32,32,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "1   bn_1_1 (BatchNormalization)     [None,32,32,32] []  64         conv2d_1_1         \n",
      "                                    [None,32,32,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "2   relu_1_1 (Activation)           [None,32,32,32] []  0          bn_1_1             \n",
      "                                    [None,32,32,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "3   conv2d_1_2 (Conv2D)             [None,32,32,32] []  9248       relu_1_1           \n",
      "                                    [None,32,32,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "4   bn_1_2 (BatchNormalization)     [None,32,32,32] []  64         conv2d_1_2         \n",
      "                                    [None,32,32,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "5   relu_1_2 (Activation)           [None,32,32,32] []  0          bn_1_2             \n",
      "                                    [None,32,32,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "6   avg_pool2d_1 (AveragePooling2D  [None,16,16,32] []  0          relu_1_2           \n",
      "                                    [None,16,16,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "7   conv2d_2_1 (Conv2D)             [None,16,16,64] []  18496      avg_pool2d_1       \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "8   bn_2_1 (BatchNormalization)     [None,16,16,64] []  128        conv2d_2_1         \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "9   relu_2_1 (Activation)           [None,16,16,64] []  0          bn_2_1             \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "10  conv2d_2_2 (Conv2D)             [None,16,16,64] []  36928      relu_2_1           \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "11  bn_2_2 (BatchNormalization)     [None,16,16,64] []  128        conv2d_2_2         \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "12  relu_2_2 (Activation)           [None,16,16,64] []  0          bn_2_2             \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "13  avg_pool2d_2 (AveragePooling2D  [None,8,8,64] []    0          relu_2_2           \n",
      "                                    [None,8,8,64] []                                  \n",
      "--------------------------------------------------------------------------------------\n",
      "14  conv2d_3_1 (Conv2D)             [None,8,8,128] []   73856      avg_pool2d_2       \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "15  bn_3_1 (BatchNormalization)     [None,8,8,128] []   256        conv2d_3_1         \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "16  relu_3_1 (Activation)           [None,8,8,128] []   0          bn_3_1             \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "17  conv2d_3_2 (Conv2D)             [None,8,8,128] []   147584     relu_3_1           \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "18  bn_3_2 (BatchNormalization)     [None,8,8,128] []   256        conv2d_3_2         \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "19  relu_3_2 (Activation)           [None,8,8,128] []   0          bn_3_2             \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "20  global_avg_pool2d (GlobalAvera  [None,128] []       0          relu_3_2           \n",
      "                                    [None,128] []                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "21  fc1 (Dense)                     [None,128] []       16512      global_avg_pool2d  \n",
      "                                    [None,128] []                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "22  bn_fc1 (BatchNormalization)     [None,128] []       256        fc1                \n",
      "                                    [None,128] []                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "23  relu_fc1 (Activation)           [None,128] []       0          bn_fc1             \n",
      "                                    [None,128] []                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "24  output (Dense)                  [None,10]           1290       relu_fc1           \n",
      "                                    [None,10]                                         \n",
      "--------------------------------------------------------------------------------------\n",
      "Total parameters: 305962\n",
      "50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 - 7s - loss_1: 1.6507 - loss_2: 1.6645 - acc_ensemble: 0.5220 - acc_1: 0.5220 - acc_2: 0.5220 - val_loss_1: 1.3917 - val_loss_2: 1.3917 - val_acc_ensemble: 0.4907 - val_acc_1: 0.4907 - val_acc_2: 0.4907\n",
      "Epoch 2/50\n",
      "100/100 - 6s - loss_1: 1.3293 - loss_2: 1.3344 - acc_ensemble: 0.5780 - acc_1: 0.5780 - acc_2: 0.5780 - val_loss_1: 1.2385 - val_loss_2: 1.2385 - val_acc_ensemble: 0.5595 - val_acc_1: 0.5595 - val_acc_2: 0.5595\n",
      "Epoch 3/50\n",
      "100/100 - 6s - loss_1: 1.1873 - loss_2: 1.2000 - acc_ensemble: 0.6260 - acc_1: 0.6260 - acc_2: 0.6260 - val_loss_1: 1.1340 - val_loss_2: 1.1340 - val_acc_ensemble: 0.5927 - val_acc_1: 0.5927 - val_acc_2: 0.5927\n",
      "Epoch 4/50\n",
      "100/100 - 6s - loss_1: 1.0512 - loss_2: 1.0548 - acc_ensemble: 0.6720 - acc_1: 0.6720 - acc_2: 0.6720 - val_loss_1: 1.0561 - val_loss_2: 1.0561 - val_acc_ensemble: 0.6274 - val_acc_1: 0.6274 - val_acc_2: 0.6274\n",
      "Epoch 5/50\n",
      "100/100 - 6s - loss_1: 0.9626 - loss_2: 0.9786 - acc_ensemble: 0.6480 - acc_1: 0.6480 - acc_2: 0.6480 - val_loss_1: 0.9872 - val_loss_2: 0.9872 - val_acc_ensemble: 0.6435 - val_acc_1: 0.6435 - val_acc_2: 0.6435\n",
      "Epoch 6/50\n",
      "100/100 - 6s - loss_1: 0.9041 - loss_2: 0.9043 - acc_ensemble: 0.7160 - acc_1: 0.7160 - acc_2: 0.7160 - val_loss_1: 0.9358 - val_loss_2: 0.9358 - val_acc_ensemble: 0.6658 - val_acc_1: 0.6658 - val_acc_2: 0.6658\n",
      "Epoch 7/50\n",
      "100/100 - 6s - loss_1: 0.8239 - loss_2: 0.8349 - acc_ensemble: 0.7560 - acc_1: 0.7560 - acc_2: 0.7560 - val_loss_1: 0.8799 - val_loss_2: 0.8799 - val_acc_ensemble: 0.6856 - val_acc_1: 0.6856 - val_acc_2: 0.6856\n",
      "Epoch 8/50\n",
      "100/100 - 6s - loss_1: 0.7716 - loss_2: 0.7782 - acc_ensemble: 0.7480 - acc_1: 0.7480 - acc_2: 0.7480 - val_loss_1: 0.8672 - val_loss_2: 0.8672 - val_acc_ensemble: 0.6866 - val_acc_1: 0.6866 - val_acc_2: 0.6866\n",
      "Epoch 9/50\n",
      "100/100 - 6s - loss_1: 0.6960 - loss_2: 0.7164 - acc_ensemble: 0.7520 - acc_1: 0.7520 - acc_2: 0.7520 - val_loss_1: 0.8408 - val_loss_2: 0.8408 - val_acc_ensemble: 0.7049 - val_acc_1: 0.7049 - val_acc_2: 0.7049\n",
      "Epoch 10/50\n",
      "100/100 - 6s - loss_1: 0.6524 - loss_2: 0.6807 - acc_ensemble: 0.7680 - acc_1: 0.7680 - acc_2: 0.7680 - val_loss_1: 0.8371 - val_loss_2: 0.8371 - val_acc_ensemble: 0.7090 - val_acc_1: 0.7090 - val_acc_2: 0.7090\n",
      "Epoch 11/50\n",
      "100/100 - 6s - loss_1: 0.6251 - loss_2: 0.6367 - acc_ensemble: 0.8000 - acc_1: 0.8000 - acc_2: 0.8000 - val_loss_1: 0.8045 - val_loss_2: 0.8045 - val_acc_ensemble: 0.7177 - val_acc_1: 0.7177 - val_acc_2: 0.7177\n",
      "Epoch 12/50\n",
      "100/100 - 6s - loss_1: 0.5979 - loss_2: 0.5825 - acc_ensemble: 0.7660 - acc_1: 0.7660 - acc_2: 0.7660 - val_loss_1: 0.8071 - val_loss_2: 0.8071 - val_acc_ensemble: 0.7191 - val_acc_1: 0.7191 - val_acc_2: 0.7191\n",
      "Epoch 13/50\n",
      "100/100 - 6s - loss_1: 0.5557 - loss_2: 0.5478 - acc_ensemble: 0.8060 - acc_1: 0.8060 - acc_2: 0.8060 - val_loss_1: 0.8031 - val_loss_2: 0.8031 - val_acc_ensemble: 0.7284 - val_acc_1: 0.7284 - val_acc_2: 0.7284\n",
      "Epoch 14/50\n",
      "100/100 - 6s - loss_1: 0.5088 - loss_2: 0.5346 - acc_ensemble: 0.8100 - acc_1: 0.8100 - acc_2: 0.8100 - val_loss_1: 0.7742 - val_loss_2: 0.7742 - val_acc_ensemble: 0.7309 - val_acc_1: 0.7309 - val_acc_2: 0.7309\n",
      "Epoch 15/50\n",
      "100/100 - 6s - loss_1: 0.4811 - loss_2: 0.4825 - acc_ensemble: 0.8200 - acc_1: 0.8200 - acc_2: 0.8200 - val_loss_1: 0.7605 - val_loss_2: 0.7605 - val_acc_ensemble: 0.7437 - val_acc_1: 0.7437 - val_acc_2: 0.7437\n",
      "Epoch 16/50\n",
      "100/100 - 6s - loss_1: 0.4517 - loss_2: 0.4413 - acc_ensemble: 0.8260 - acc_1: 0.8260 - acc_2: 0.8260 - val_loss_1: 0.7947 - val_loss_2: 0.7947 - val_acc_ensemble: 0.7314 - val_acc_1: 0.7314 - val_acc_2: 0.7314\n",
      "Epoch 17/50\n",
      "100/100 - 6s - loss_1: 0.4065 - loss_2: 0.4161 - acc_ensemble: 0.8540 - acc_1: 0.8540 - acc_2: 0.8540 - val_loss_1: 0.7740 - val_loss_2: 0.7740 - val_acc_ensemble: 0.7390 - val_acc_1: 0.7390 - val_acc_2: 0.7390\n",
      "Epoch 18/50\n",
      "100/100 - 6s - loss_1: 0.3735 - loss_2: 0.4265 - acc_ensemble: 0.8640 - acc_1: 0.8640 - acc_2: 0.8640 - val_loss_1: 0.7471 - val_loss_2: 0.7471 - val_acc_ensemble: 0.7523 - val_acc_1: 0.7523 - val_acc_2: 0.7523\n",
      "Epoch 19/50\n",
      "100/100 - 6s - loss_1: 0.3475 - loss_2: 0.3631 - acc_ensemble: 0.8600 - acc_1: 0.8600 - acc_2: 0.8600 - val_loss_1: 0.7676 - val_loss_2: 0.7676 - val_acc_ensemble: 0.7500 - val_acc_1: 0.7500 - val_acc_2: 0.7500\n",
      "Epoch 20/50\n",
      "100/100 - 6s - loss_1: 0.3130 - loss_2: 0.3205 - acc_ensemble: 0.8480 - acc_1: 0.8480 - acc_2: 0.8480 - val_loss_1: 0.7724 - val_loss_2: 0.7724 - val_acc_ensemble: 0.7555 - val_acc_1: 0.7555 - val_acc_2: 0.7555\n",
      "Epoch 21/50\n",
      "100/100 - 6s - loss_1: 0.3101 - loss_2: 0.3284 - acc_ensemble: 0.8580 - acc_1: 0.8580 - acc_2: 0.8580 - val_loss_1: 0.7830 - val_loss_2: 0.7830 - val_acc_ensemble: 0.7466 - val_acc_1: 0.7466 - val_acc_2: 0.7466\n",
      "Epoch 22/50\n",
      "100/100 - 6s - loss_1: 0.3103 - loss_2: 0.2949 - acc_ensemble: 0.8460 - acc_1: 0.8460 - acc_2: 0.8460 - val_loss_1: 0.7947 - val_loss_2: 0.7947 - val_acc_ensemble: 0.7463 - val_acc_1: 0.7463 - val_acc_2: 0.7463\n",
      "Epoch 23/50\n",
      "100/100 - 6s - loss_1: 0.2708 - loss_2: 0.2657 - acc_ensemble: 0.8440 - acc_1: 0.8440 - acc_2: 0.8440 - val_loss_1: 0.7983 - val_loss_2: 0.7983 - val_acc_ensemble: 0.7474 - val_acc_1: 0.7474 - val_acc_2: 0.7474\n",
      "Epoch 24/50\n",
      "100/100 - 6s - loss_1: 0.2547 - loss_2: 0.2534 - acc_ensemble: 0.8660 - acc_1: 0.8660 - acc_2: 0.8660 - val_loss_1: 0.8196 - val_loss_2: 0.8196 - val_acc_ensemble: 0.7462 - val_acc_1: 0.7462 - val_acc_2: 0.7462\n",
      "Epoch 25/50\n",
      "100/100 - 6s - loss_1: 0.2336 - loss_2: 0.2319 - acc_ensemble: 0.8560 - acc_1: 0.8560 - acc_2: 0.8560 - val_loss_1: 0.8129 - val_loss_2: 0.8129 - val_acc_ensemble: 0.7538 - val_acc_1: 0.7538 - val_acc_2: 0.7538\n",
      "Epoch 26/50\n",
      "100/100 - 6s - loss_1: 0.2464 - loss_2: 0.2245 - acc_ensemble: 0.8720 - acc_1: 0.8720 - acc_2: 0.8720 - val_loss_1: 0.8091 - val_loss_2: 0.8091 - val_acc_ensemble: 0.7580 - val_acc_1: 0.7580 - val_acc_2: 0.7580\n",
      "Epoch 27/50\n",
      "100/100 - 6s - loss_1: 0.1937 - loss_2: 0.2201 - acc_ensemble: 0.8700 - acc_1: 0.8700 - acc_2: 0.8700 - val_loss_1: 0.8383 - val_loss_2: 0.8383 - val_acc_ensemble: 0.7513 - val_acc_1: 0.7513 - val_acc_2: 0.7513\n",
      "Epoch 28/50\n",
      "100/100 - 6s - loss_1: 0.2031 - loss_2: 0.1857 - acc_ensemble: 0.8780 - acc_1: 0.8780 - acc_2: 0.8780 - val_loss_1: 0.8514 - val_loss_2: 0.8514 - val_acc_ensemble: 0.7508 - val_acc_1: 0.7508 - val_acc_2: 0.7508\n",
      "Epoch 29/50\n",
      "100/100 - 6s - loss_1: 0.1821 - loss_2: 0.1803 - acc_ensemble: 0.8920 - acc_1: 0.8920 - acc_2: 0.8920 - val_loss_1: 0.8524 - val_loss_2: 0.8524 - val_acc_ensemble: 0.7518 - val_acc_1: 0.7518 - val_acc_2: 0.7518\n",
      "Epoch 30/50\n",
      "100/100 - 6s - loss_1: 0.1686 - loss_2: 0.1673 - acc_ensemble: 0.8880 - acc_1: 0.8880 - acc_2: 0.8880 - val_loss_1: 0.8555 - val_loss_2: 0.8555 - val_acc_ensemble: 0.7566 - val_acc_1: 0.7566 - val_acc_2: 0.7566\n",
      "Epoch 31/50\n",
      "100/100 - 6s - loss_1: 0.1666 - loss_2: 0.1781 - acc_ensemble: 0.8860 - acc_1: 0.8860 - acc_2: 0.8860 - val_loss_1: 0.8737 - val_loss_2: 0.8737 - val_acc_ensemble: 0.7532 - val_acc_1: 0.7532 - val_acc_2: 0.7532\n",
      "Epoch 32/50\n",
      "100/100 - 6s - loss_1: 0.1587 - loss_2: 0.1589 - acc_ensemble: 0.8840 - acc_1: 0.8840 - acc_2: 0.8840 - val_loss_1: 0.8933 - val_loss_2: 0.8933 - val_acc_ensemble: 0.7539 - val_acc_1: 0.7539 - val_acc_2: 0.7539\n",
      "Epoch 33/50\n",
      "100/100 - 6s - loss_1: 0.1618 - loss_2: 0.1575 - acc_ensemble: 0.8940 - acc_1: 0.8940 - acc_2: 0.8940 - val_loss_1: 0.8971 - val_loss_2: 0.8971 - val_acc_ensemble: 0.7511 - val_acc_1: 0.7511 - val_acc_2: 0.7511\n",
      "Epoch 34/50\n",
      "100/100 - 6s - loss_1: 0.1544 - loss_2: 0.1568 - acc_ensemble: 0.8840 - acc_1: 0.8840 - acc_2: 0.8840 - val_loss_1: 0.9002 - val_loss_2: 0.9002 - val_acc_ensemble: 0.7546 - val_acc_1: 0.7546 - val_acc_2: 0.7546\n",
      "Epoch 35/50\n",
      "100/100 - 6s - loss_1: 0.1309 - loss_2: 0.1240 - acc_ensemble: 0.8960 - acc_1: 0.8960 - acc_2: 0.8960 - val_loss_1: 0.9074 - val_loss_2: 0.9074 - val_acc_ensemble: 0.7578 - val_acc_1: 0.7578 - val_acc_2: 0.7578\n",
      "Epoch 36/50\n",
      "100/100 - 6s - loss_1: 0.1022 - loss_2: 0.1116 - acc_ensemble: 0.9080 - acc_1: 0.9080 - acc_2: 0.9080 - val_loss_1: 0.9112 - val_loss_2: 0.9112 - val_acc_ensemble: 0.7612 - val_acc_1: 0.7612 - val_acc_2: 0.7612\n",
      "Epoch 37/50\n",
      "100/100 - 6s - loss_1: 0.0985 - loss_2: 0.1047 - acc_ensemble: 0.9160 - acc_1: 0.9160 - acc_2: 0.9160 - val_loss_1: 0.9301 - val_loss_2: 0.9301 - val_acc_ensemble: 0.7598 - val_acc_1: 0.7598 - val_acc_2: 0.7598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50\n",
      "100/100 - 6s - loss_1: 0.0926 - loss_2: 0.0931 - acc_ensemble: 0.9060 - acc_1: 0.9060 - acc_2: 0.9060 - val_loss_1: 0.9663 - val_loss_2: 0.9663 - val_acc_ensemble: 0.7560 - val_acc_1: 0.7560 - val_acc_2: 0.7560\n",
      "Epoch 39/50\n",
      "100/100 - 6s - loss_1: 0.1195 - loss_2: 0.1015 - acc_ensemble: 0.8780 - acc_1: 0.8780 - acc_2: 0.8780 - val_loss_1: 0.9828 - val_loss_2: 0.9828 - val_acc_ensemble: 0.7514 - val_acc_1: 0.7514 - val_acc_2: 0.7514\n",
      "Epoch 40/50\n",
      "100/100 - 6s - loss_1: 0.1076 - loss_2: 0.1135 - acc_ensemble: 0.9040 - acc_1: 0.9040 - acc_2: 0.9040 - val_loss_1: 0.9731 - val_loss_2: 0.9731 - val_acc_ensemble: 0.7568 - val_acc_1: 0.7568 - val_acc_2: 0.7568\n",
      "Epoch 41/50\n",
      "100/100 - 6s - loss_1: 0.0975 - loss_2: 0.1039 - acc_ensemble: 0.9040 - acc_1: 0.9040 - acc_2: 0.9040 - val_loss_1: 0.9668 - val_loss_2: 0.9668 - val_acc_ensemble: 0.7603 - val_acc_1: 0.7603 - val_acc_2: 0.7603\n",
      "Epoch 42/50\n",
      "100/100 - 6s - loss_1: 0.0825 - loss_2: 0.0801 - acc_ensemble: 0.9100 - acc_1: 0.9100 - acc_2: 0.9100 - val_loss_1: 0.9692 - val_loss_2: 0.9692 - val_acc_ensemble: 0.7564 - val_acc_1: 0.7564 - val_acc_2: 0.7564\n",
      "Epoch 43/50\n",
      "100/100 - 6s - loss_1: 0.0710 - loss_2: 0.1033 - acc_ensemble: 0.9040 - acc_1: 0.9040 - acc_2: 0.9040 - val_loss_1: 1.0104 - val_loss_2: 1.0104 - val_acc_ensemble: 0.7551 - val_acc_1: 0.7551 - val_acc_2: 0.7551\n",
      "Epoch 44/50\n",
      "100/100 - 6s - loss_1: 0.0885 - loss_2: 0.0898 - acc_ensemble: 0.9080 - acc_1: 0.9080 - acc_2: 0.9080 - val_loss_1: 1.0181 - val_loss_2: 1.0181 - val_acc_ensemble: 0.7574 - val_acc_1: 0.7574 - val_acc_2: 0.7574\n",
      "Epoch 45/50\n",
      "100/100 - 6s - loss_1: 0.0777 - loss_2: 0.0900 - acc_ensemble: 0.9040 - acc_1: 0.9040 - acc_2: 0.9040 - val_loss_1: 1.0388 - val_loss_2: 1.0388 - val_acc_ensemble: 0.7563 - val_acc_1: 0.7563 - val_acc_2: 0.7563\n",
      "Epoch 46/50\n",
      "100/100 - 6s - loss_1: 0.0737 - loss_2: 0.0877 - acc_ensemble: 0.8880 - acc_1: 0.8880 - acc_2: 0.8880 - val_loss_1: 1.0558 - val_loss_2: 1.0558 - val_acc_ensemble: 0.7507 - val_acc_1: 0.7507 - val_acc_2: 0.7507\n",
      "Epoch 47/50\n",
      "100/100 - 6s - loss_1: 0.0816 - loss_2: 0.0791 - acc_ensemble: 0.9180 - acc_1: 0.9180 - acc_2: 0.9180 - val_loss_1: 1.0548 - val_loss_2: 1.0548 - val_acc_ensemble: 0.7570 - val_acc_1: 0.7570 - val_acc_2: 0.7570\n",
      "Epoch 48/50\n",
      "100/100 - 6s - loss_1: 0.0830 - loss_2: 0.0678 - acc_ensemble: 0.9220 - acc_1: 0.9220 - acc_2: 0.9220 - val_loss_1: 1.0827 - val_loss_2: 1.0827 - val_acc_ensemble: 0.7533 - val_acc_1: 0.7533 - val_acc_2: 0.7533\n",
      "Epoch 49/50\n",
      "100/100 - 6s - loss_1: 0.0727 - loss_2: 0.0731 - acc_ensemble: 0.8860 - acc_1: 0.8860 - acc_2: 0.8860 - val_loss_1: 1.0921 - val_loss_2: 1.0921 - val_acc_ensemble: 0.7524 - val_acc_1: 0.7524 - val_acc_2: 0.7524\n",
      "Epoch 50/50\n",
      "100/100 - 6s - loss_1: 0.0610 - loss_2: 0.0730 - acc_ensemble: 0.8880 - acc_1: 0.8880 - acc_2: 0.8880 - val_loss_1: 1.1041 - val_loss_2: 1.1041 - val_acc_ensemble: 0.7506 - val_acc_1: 0.7506 - val_acc_2: 0.7506\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B3/S0.00/model_1\n",
      "i   Layer name                      Output shape        Num param  Inbound            \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                    \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                    \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                    \n",
      "--------------------------------------------------------------------------------------\n",
      "0   conv2d_1_1 (Conv2D)             [] [None,32,32,32]  2688       input              \n",
      "                                    [] [None,32,32,32]                                \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "1   bn_1_1 (BatchNormalization)     [] [None,32,32,32]  192        conv2d_1_1         \n",
      "                                    [] [None,32,32,32]                                \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "2   relu_1_1 (Activation)           [] [None,32,32,32]  0          bn_1_1             \n",
      "                                    [] [None,32,32,32]                                \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "3   conv2d_1_2 (Conv2D)             [] [None,32,32,32]  27744      relu_1_1           \n",
      "                                    [] [None,32,32,32]                                \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "4   bn_1_2 (BatchNormalization)     [] [None,32,32,32]  192        conv2d_1_2         \n",
      "                                    [] [None,32,32,32]                                \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "5   relu_1_2 (Activation)           [] [None,32,32,32]  0          bn_1_2             \n",
      "                                    [] [None,32,32,32]                                \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "6   avg_pool2d_1 (AveragePooling2D  [] [None,16,16,32]  0          relu_1_2           \n",
      "                                    [] [None,16,16,32]                                \n",
      "                                    [] [None,16,16,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "7   conv2d_2_1 (Conv2D)             [] [None,16,16,64]  55488      avg_pool2d_1       \n",
      "                                    [] [None,16,16,64]                                \n",
      "                                    [] [None,16,16,64]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "8   bn_2_1 (BatchNormalization)     [] [None,16,16,64]  384        conv2d_2_1         \n",
      "                                    [] [None,16,16,64]                                \n",
      "                                    [] [None,16,16,64]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "9   relu_2_1 (Activation)           [] [None,16,16,64]  0          bn_2_1             \n",
      "                                    [] [None,16,16,64]                                \n",
      "                                    [] [None,16,16,64]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "10  conv2d_2_2 (Conv2D)             [] [None,16,16,64]  110784     relu_2_1           \n",
      "                                    [] [None,16,16,64]                                \n",
      "                                    [] [None,16,16,64]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "11  bn_2_2 (BatchNormalization)     [] [None,16,16,64]  384        conv2d_2_2         \n",
      "                                    [] [None,16,16,64]                                \n",
      "                                    [] [None,16,16,64]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "12  relu_2_2 (Activation)           [] [None,16,16,64]  0          bn_2_2             \n",
      "                                    [] [None,16,16,64]                                \n",
      "                                    [] [None,16,16,64]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "13  avg_pool2d_2 (AveragePooling2D  [] [None,8,8,64]    0          relu_2_2           \n",
      "                                    [] [None,8,8,64]                                  \n",
      "                                    [] [None,8,8,64]                                  \n",
      "--------------------------------------------------------------------------------------\n",
      "14  conv2d_3_1 (Conv2D)             [] [None,8,8,128]   221568     avg_pool2d_2       \n",
      "                                    [] [None,8,8,128]                                 \n",
      "                                    [] [None,8,8,128]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "15  bn_3_1 (BatchNormalization)     [] [None,8,8,128]   768        conv2d_3_1         \n",
      "                                    [] [None,8,8,128]                                 \n",
      "                                    [] [None,8,8,128]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "16  relu_3_1 (Activation)           [] [None,8,8,128]   0          bn_3_1             \n",
      "                                    [] [None,8,8,128]                                 \n",
      "                                    [] [None,8,8,128]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "17  conv2d_3_2 (Conv2D)             [] [None,8,8,128]   442752     relu_3_1           \n",
      "                                    [] [None,8,8,128]                                 \n",
      "                                    [] [None,8,8,128]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "18  bn_3_2 (BatchNormalization)     [] [None,8,8,128]   768        conv2d_3_2         \n",
      "                                    [] [None,8,8,128]                                 \n",
      "                                    [] [None,8,8,128]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "19  relu_3_2 (Activation)           [] [None,8,8,128]   0          bn_3_2             \n",
      "                                    [] [None,8,8,128]                                 \n",
      "                                    [] [None,8,8,128]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "20  global_avg_pool2d (GlobalAvera  [] [None,128]       0          relu_3_2           \n",
      "                                    [] [None,128]                                     \n",
      "                                    [] [None,128]                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "21  fc1 (Dense)                     [] [None,128]       49536      global_avg_pool2d  \n",
      "                                    [] [None,128]                                     \n",
      "                                    [] [None,128]                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "22  bn_fc1 (BatchNormalization)     [] [None,128]       768        fc1                \n",
      "                                    [] [None,128]                                     \n",
      "                                    [] [None,128]                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "23  relu_fc1 (Activation)           [] [None,128]       0          bn_fc1             \n",
      "                                    [] [None,128]                                     \n",
      "                                    [] [None,128]                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "24  output (Dense)                  [None,10]           3870       relu_fc1           \n",
      "                                    [None,10]                                         \n",
      "                                    [None,10]                                         \n",
      "--------------------------------------------------------------------------------------\n",
      "Total parameters: 917886\n",
      "50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 - 11s - loss_1: 1.8215 - loss_2: 1.7552 - loss_3: 1.8277 - acc_ensemble: 0.4780 - acc_1: 0.4360 - acc_2: 0.4320 - acc_3: 0.4280 - val_loss_1: 1.5328 - val_loss_2: 1.5614 - val_loss_3: 1.5875 - val_acc_ensemble: 0.4769 - val_acc_1: 0.4339 - val_acc_2: 0.4325 - val_acc_3: 0.4128\n",
      "Epoch 2/50\n",
      "100/100 - 9s - loss_1: 1.5055 - loss_2: 1.4219 - loss_3: 1.5313 - acc_ensemble: 0.5600 - acc_1: 0.5000 - acc_2: 0.5020 - acc_3: 0.4920 - val_loss_1: 1.3935 - val_loss_2: 1.3665 - val_loss_3: 1.4610 - val_acc_ensemble: 0.5361 - val_acc_1: 0.4874 - val_acc_2: 0.4994 - val_acc_3: 0.4669\n",
      "Epoch 3/50\n",
      "100/100 - 9s - loss_1: 1.3366 - loss_2: 1.2754 - loss_3: 1.3725 - acc_ensemble: 0.6000 - acc_1: 0.4880 - acc_2: 0.6040 - acc_3: 0.5320 - val_loss_1: 1.2852 - val_loss_2: 1.2077 - val_loss_3: 1.3028 - val_acc_ensemble: 0.5982 - val_acc_1: 0.5306 - val_acc_2: 0.5645 - val_acc_3: 0.5194\n",
      "Epoch 4/50\n",
      "100/100 - 9s - loss_1: 1.2318 - loss_2: 1.1954 - loss_3: 1.2626 - acc_ensemble: 0.6580 - acc_1: 0.5780 - acc_2: 0.6360 - acc_3: 0.5960 - val_loss_1: 1.1604 - val_loss_2: 1.1214 - val_loss_3: 1.1679 - val_acc_ensemble: 0.6252 - val_acc_1: 0.5786 - val_acc_2: 0.5968 - val_acc_3: 0.5797\n",
      "Epoch 5/50\n",
      "100/100 - 9s - loss_1: 1.1243 - loss_2: 1.0728 - loss_3: 1.1552 - acc_ensemble: 0.6800 - acc_1: 0.6180 - acc_2: 0.6740 - acc_3: 0.6280 - val_loss_1: 1.0968 - val_loss_2: 1.0168 - val_loss_3: 1.1159 - val_acc_ensemble: 0.6527 - val_acc_1: 0.6057 - val_acc_2: 0.6338 - val_acc_3: 0.5990\n",
      "Epoch 6/50\n",
      "100/100 - 9s - loss_1: 1.0499 - loss_2: 0.9935 - loss_3: 1.0981 - acc_ensemble: 0.6800 - acc_1: 0.6040 - acc_2: 0.6320 - acc_3: 0.6440 - val_loss_1: 1.0655 - val_loss_2: 1.0307 - val_loss_3: 1.0347 - val_acc_ensemble: 0.6688 - val_acc_1: 0.6214 - val_acc_2: 0.6306 - val_acc_3: 0.6276\n",
      "Epoch 7/50\n",
      "100/100 - 9s - loss_1: 0.9931 - loss_2: 0.9568 - loss_3: 1.0270 - acc_ensemble: 0.6880 - acc_1: 0.6160 - acc_2: 0.6700 - acc_3: 0.6440 - val_loss_1: 1.0372 - val_loss_2: 0.9446 - val_loss_3: 1.0303 - val_acc_ensemble: 0.6852 - val_acc_1: 0.6269 - val_acc_2: 0.6636 - val_acc_3: 0.6336\n",
      "Epoch 8/50\n",
      "100/100 - 9s - loss_1: 0.9557 - loss_2: 0.8803 - loss_3: 0.9797 - acc_ensemble: 0.7240 - acc_1: 0.6680 - acc_2: 0.6680 - acc_3: 0.6580 - val_loss_1: 1.0099 - val_loss_2: 0.9710 - val_loss_3: 0.9776 - val_acc_ensemble: 0.6993 - val_acc_1: 0.6403 - val_acc_2: 0.6560 - val_acc_3: 0.6472\n",
      "Epoch 9/50\n",
      "100/100 - 9s - loss_1: 0.8915 - loss_2: 0.8528 - loss_3: 0.9107 - acc_ensemble: 0.7380 - acc_1: 0.6640 - acc_2: 0.6920 - acc_3: 0.7120 - val_loss_1: 0.9283 - val_loss_2: 0.8803 - val_loss_3: 0.8970 - val_acc_ensemble: 0.7163 - val_acc_1: 0.6669 - val_acc_2: 0.6837 - val_acc_3: 0.6817\n",
      "Epoch 10/50\n",
      "100/100 - 9s - loss_1: 0.8596 - loss_2: 0.8007 - loss_3: 0.8494 - acc_ensemble: 0.7620 - acc_1: 0.6960 - acc_2: 0.7060 - acc_3: 0.6800 - val_loss_1: 0.9097 - val_loss_2: 0.8313 - val_loss_3: 0.9015 - val_acc_ensemble: 0.7205 - val_acc_1: 0.6761 - val_acc_2: 0.7024 - val_acc_3: 0.6785\n",
      "Epoch 11/50\n",
      "100/100 - 9s - loss_1: 0.8391 - loss_2: 0.7711 - loss_3: 0.8263 - acc_ensemble: 0.7520 - acc_1: 0.7000 - acc_2: 0.7260 - acc_3: 0.7340 - val_loss_1: 0.8737 - val_loss_2: 0.8172 - val_loss_3: 0.8612 - val_acc_ensemble: 0.7343 - val_acc_1: 0.6862 - val_acc_2: 0.7089 - val_acc_3: 0.6947\n",
      "Epoch 12/50\n",
      "100/100 - 9s - loss_1: 0.7902 - loss_2: 0.7265 - loss_3: 0.8092 - acc_ensemble: 0.7700 - acc_1: 0.7080 - acc_2: 0.7520 - acc_3: 0.7040 - val_loss_1: 0.8336 - val_loss_2: 0.8032 - val_loss_3: 0.8539 - val_acc_ensemble: 0.7447 - val_acc_1: 0.7006 - val_acc_2: 0.7162 - val_acc_3: 0.6926\n",
      "Epoch 13/50\n",
      "100/100 - 9s - loss_1: 0.7716 - loss_2: 0.6960 - loss_3: 0.7224 - acc_ensemble: 0.7820 - acc_1: 0.7500 - acc_2: 0.7360 - acc_3: 0.7340 - val_loss_1: 0.8085 - val_loss_2: 0.7905 - val_loss_3: 0.8167 - val_acc_ensemble: 0.7565 - val_acc_1: 0.7123 - val_acc_2: 0.7204 - val_acc_3: 0.7127\n",
      "Epoch 14/50\n",
      "100/100 - 9s - loss_1: 0.6840 - loss_2: 0.6354 - loss_3: 0.7219 - acc_ensemble: 0.8100 - acc_1: 0.7460 - acc_2: 0.7500 - acc_3: 0.7680 - val_loss_1: 0.7773 - val_loss_2: 0.8013 - val_loss_3: 0.8020 - val_acc_ensemble: 0.7606 - val_acc_1: 0.7266 - val_acc_2: 0.7224 - val_acc_3: 0.7154\n",
      "Epoch 15/50\n",
      "100/100 - 9s - loss_1: 0.6686 - loss_2: 0.6260 - loss_3: 0.6530 - acc_ensemble: 0.8120 - acc_1: 0.7380 - acc_2: 0.7680 - acc_3: 0.7520 - val_loss_1: 0.7988 - val_loss_2: 0.7334 - val_loss_3: 0.7887 - val_acc_ensemble: 0.7725 - val_acc_1: 0.7188 - val_acc_2: 0.7425 - val_acc_3: 0.7215\n",
      "Epoch 16/50\n",
      "100/100 - 9s - loss_1: 0.6278 - loss_2: 0.5909 - loss_3: 0.6650 - acc_ensemble: 0.8100 - acc_1: 0.7680 - acc_2: 0.7440 - acc_3: 0.7340 - val_loss_1: 0.7577 - val_loss_2: 0.7737 - val_loss_3: 0.7974 - val_acc_ensemble: 0.7742 - val_acc_1: 0.7333 - val_acc_2: 0.7309 - val_acc_3: 0.7179\n",
      "Epoch 17/50\n",
      "100/100 - 9s - loss_1: 0.6439 - loss_2: 0.5631 - loss_3: 0.6108 - acc_ensemble: 0.8240 - acc_1: 0.7660 - acc_2: 0.7800 - acc_3: 0.7720 - val_loss_1: 0.7567 - val_loss_2: 0.7259 - val_loss_3: 0.7300 - val_acc_ensemble: 0.7835 - val_acc_1: 0.7381 - val_acc_2: 0.7475 - val_acc_3: 0.7486\n",
      "Epoch 18/50\n",
      "100/100 - 9s - loss_1: 0.5863 - loss_2: 0.5171 - loss_3: 0.5569 - acc_ensemble: 0.8460 - acc_1: 0.7880 - acc_2: 0.7980 - acc_3: 0.7840 - val_loss_1: 0.7226 - val_loss_2: 0.7094 - val_loss_3: 0.7541 - val_acc_ensemble: 0.7881 - val_acc_1: 0.7497 - val_acc_2: 0.7562 - val_acc_3: 0.7372\n",
      "Epoch 19/50\n",
      "100/100 - 9s - loss_1: 0.5884 - loss_2: 0.5232 - loss_3: 0.5408 - acc_ensemble: 0.8400 - acc_1: 0.7880 - acc_2: 0.7840 - acc_3: 0.7820 - val_loss_1: 0.7129 - val_loss_2: 0.6906 - val_loss_3: 0.7666 - val_acc_ensemble: 0.7883 - val_acc_1: 0.7499 - val_acc_2: 0.7619 - val_acc_3: 0.7309\n",
      "Epoch 20/50\n",
      "100/100 - 9s - loss_1: 0.5397 - loss_2: 0.4812 - loss_3: 0.5545 - acc_ensemble: 0.8420 - acc_1: 0.7900 - acc_2: 0.7840 - acc_3: 0.7780 - val_loss_1: 0.7110 - val_loss_2: 0.7135 - val_loss_3: 0.7379 - val_acc_ensemble: 0.8012 - val_acc_1: 0.7515 - val_acc_2: 0.7595 - val_acc_3: 0.7466\n",
      "Epoch 21/50\n",
      "100/100 - 9s - loss_1: 0.5037 - loss_2: 0.4852 - loss_3: 0.5148 - acc_ensemble: 0.8580 - acc_1: 0.8140 - acc_2: 0.8140 - acc_3: 0.7900 - val_loss_1: 0.7088 - val_loss_2: 0.6899 - val_loss_3: 0.6971 - val_acc_ensemble: 0.8026 - val_acc_1: 0.7535 - val_acc_2: 0.7669 - val_acc_3: 0.7557\n",
      "Epoch 22/50\n",
      "100/100 - 9s - loss_1: 0.5167 - loss_2: 0.4492 - loss_3: 0.4836 - acc_ensemble: 0.8600 - acc_1: 0.8040 - acc_2: 0.8060 - acc_3: 0.7960 - val_loss_1: 0.6885 - val_loss_2: 0.7395 - val_loss_3: 0.7282 - val_acc_ensemble: 0.8037 - val_acc_1: 0.7595 - val_acc_2: 0.7490 - val_acc_3: 0.7455\n",
      "Epoch 23/50\n",
      "100/100 - 9s - loss_1: 0.4538 - loss_2: 0.4363 - loss_3: 0.4750 - acc_ensemble: 0.8620 - acc_1: 0.7980 - acc_2: 0.8240 - acc_3: 0.7960 - val_loss_1: 0.7075 - val_loss_2: 0.6799 - val_loss_3: 0.7253 - val_acc_ensemble: 0.8066 - val_acc_1: 0.7540 - val_acc_2: 0.7734 - val_acc_3: 0.7494\n",
      "Epoch 24/50\n",
      "100/100 - 9s - loss_1: 0.4271 - loss_2: 0.4085 - loss_3: 0.4686 - acc_ensemble: 0.8660 - acc_1: 0.7880 - acc_2: 0.8400 - acc_3: 0.8080 - val_loss_1: 0.7129 - val_loss_2: 0.6867 - val_loss_3: 0.6860 - val_acc_ensemble: 0.8112 - val_acc_1: 0.7594 - val_acc_2: 0.7646 - val_acc_3: 0.7652\n",
      "Epoch 25/50\n",
      "100/100 - 9s - loss_1: 0.4509 - loss_2: 0.3908 - loss_3: 0.4055 - acc_ensemble: 0.8640 - acc_1: 0.8200 - acc_2: 0.8280 - acc_3: 0.8260 - val_loss_1: 0.7060 - val_loss_2: 0.6934 - val_loss_3: 0.7087 - val_acc_ensemble: 0.8107 - val_acc_1: 0.7618 - val_acc_2: 0.7686 - val_acc_3: 0.7604\n",
      "Epoch 26/50\n",
      "100/100 - 9s - loss_1: 0.4295 - loss_2: 0.3898 - loss_3: 0.3608 - acc_ensemble: 0.8800 - acc_1: 0.8100 - acc_2: 0.8240 - acc_3: 0.8240 - val_loss_1: 0.6980 - val_loss_2: 0.6689 - val_loss_3: 0.6926 - val_acc_ensemble: 0.8164 - val_acc_1: 0.7640 - val_acc_2: 0.7767 - val_acc_3: 0.7656\n",
      "Epoch 27/50\n",
      "100/100 - 9s - loss_1: 0.3928 - loss_2: 0.3446 - loss_3: 0.4124 - acc_ensemble: 0.8700 - acc_1: 0.8260 - acc_2: 0.8360 - acc_3: 0.8100 - val_loss_1: 0.6618 - val_loss_2: 0.7162 - val_loss_3: 0.6863 - val_acc_ensemble: 0.8172 - val_acc_1: 0.7728 - val_acc_2: 0.7690 - val_acc_3: 0.7700\n",
      "Epoch 28/50\n",
      "100/100 - 9s - loss_1: 0.3490 - loss_2: 0.3720 - loss_3: 0.3738 - acc_ensemble: 0.8860 - acc_1: 0.8400 - acc_2: 0.8320 - acc_3: 0.8280 - val_loss_1: 0.6817 - val_loss_2: 0.6955 - val_loss_3: 0.7195 - val_acc_ensemble: 0.8171 - val_acc_1: 0.7729 - val_acc_2: 0.7692 - val_acc_3: 0.7661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50\n",
      "100/100 - 9s - loss_1: 0.3454 - loss_2: 0.3439 - loss_3: 0.3508 - acc_ensemble: 0.8960 - acc_1: 0.8340 - acc_2: 0.8380 - acc_3: 0.8260 - val_loss_1: 0.6743 - val_loss_2: 0.6767 - val_loss_3: 0.6829 - val_acc_ensemble: 0.8240 - val_acc_1: 0.7770 - val_acc_2: 0.7768 - val_acc_3: 0.7727\n",
      "Epoch 30/50\n",
      "100/100 - 9s - loss_1: 0.3473 - loss_2: 0.3085 - loss_3: 0.3825 - acc_ensemble: 0.8900 - acc_1: 0.8000 - acc_2: 0.8560 - acc_3: 0.8080 - val_loss_1: 0.7769 - val_loss_2: 0.6647 - val_loss_3: 0.6829 - val_acc_ensemble: 0.8172 - val_acc_1: 0.7479 - val_acc_2: 0.7849 - val_acc_3: 0.7753\n",
      "Epoch 31/50\n",
      "100/100 - 9s - loss_1: 0.3182 - loss_2: 0.2900 - loss_3: 0.2976 - acc_ensemble: 0.8940 - acc_1: 0.8280 - acc_2: 0.8280 - acc_3: 0.8460 - val_loss_1: 0.6925 - val_loss_2: 0.7289 - val_loss_3: 0.6609 - val_acc_ensemble: 0.8233 - val_acc_1: 0.7742 - val_acc_2: 0.7721 - val_acc_3: 0.7855\n",
      "Epoch 32/50\n",
      "100/100 - 9s - loss_1: 0.3247 - loss_2: 0.2933 - loss_3: 0.2986 - acc_ensemble: 0.9040 - acc_1: 0.8560 - acc_2: 0.8360 - acc_3: 0.8500 - val_loss_1: 0.6922 - val_loss_2: 0.6862 - val_loss_3: 0.6841 - val_acc_ensemble: 0.8258 - val_acc_1: 0.7756 - val_acc_2: 0.7795 - val_acc_3: 0.7772\n",
      "Epoch 33/50\n",
      "100/100 - 9s - loss_1: 0.3024 - loss_2: 0.2711 - loss_3: 0.3016 - acc_ensemble: 0.8920 - acc_1: 0.8500 - acc_2: 0.8500 - acc_3: 0.8260 - val_loss_1: 0.7005 - val_loss_2: 0.7078 - val_loss_3: 0.7015 - val_acc_ensemble: 0.8254 - val_acc_1: 0.7701 - val_acc_2: 0.7829 - val_acc_3: 0.7786\n",
      "Epoch 34/50\n",
      "100/100 - 9s - loss_1: 0.2990 - loss_2: 0.2462 - loss_3: 0.2765 - acc_ensemble: 0.9000 - acc_1: 0.8420 - acc_2: 0.8680 - acc_3: 0.8320 - val_loss_1: 0.7238 - val_loss_2: 0.6771 - val_loss_3: 0.6891 - val_acc_ensemble: 0.8272 - val_acc_1: 0.7679 - val_acc_2: 0.7876 - val_acc_3: 0.7824\n",
      "Epoch 35/50\n",
      "100/100 - 9s - loss_1: 0.2640 - loss_2: 0.2306 - loss_3: 0.2584 - acc_ensemble: 0.8860 - acc_1: 0.8520 - acc_2: 0.8420 - acc_3: 0.8380 - val_loss_1: 0.6643 - val_loss_2: 0.7198 - val_loss_3: 0.7082 - val_acc_ensemble: 0.8282 - val_acc_1: 0.7871 - val_acc_2: 0.7761 - val_acc_3: 0.7762\n",
      "Epoch 36/50\n",
      "100/100 - 9s - loss_1: 0.2358 - loss_2: 0.2326 - loss_3: 0.2352 - acc_ensemble: 0.9180 - acc_1: 0.8620 - acc_2: 0.8640 - acc_3: 0.8720 - val_loss_1: 0.6788 - val_loss_2: 0.7150 - val_loss_3: 0.7063 - val_acc_ensemble: 0.8330 - val_acc_1: 0.7874 - val_acc_2: 0.7822 - val_acc_3: 0.7793\n",
      "Epoch 37/50\n",
      "100/100 - 9s - loss_1: 0.2285 - loss_2: 0.2241 - loss_3: 0.2275 - acc_ensemble: 0.9180 - acc_1: 0.8280 - acc_2: 0.8480 - acc_3: 0.8540 - val_loss_1: 0.7450 - val_loss_2: 0.7231 - val_loss_3: 0.7182 - val_acc_ensemble: 0.8323 - val_acc_1: 0.7698 - val_acc_2: 0.7804 - val_acc_3: 0.7821\n",
      "Epoch 38/50\n",
      "100/100 - 9s - loss_1: 0.2369 - loss_2: 0.1905 - loss_3: 0.2014 - acc_ensemble: 0.8940 - acc_1: 0.8340 - acc_2: 0.8560 - acc_3: 0.8560 - val_loss_1: 0.7305 - val_loss_2: 0.7634 - val_loss_3: 0.7065 - val_acc_ensemble: 0.8297 - val_acc_1: 0.7769 - val_acc_2: 0.7797 - val_acc_3: 0.7851\n",
      "Epoch 39/50\n",
      "100/100 - 9s - loss_1: 0.2041 - loss_2: 0.1897 - loss_3: 0.1952 - acc_ensemble: 0.9160 - acc_1: 0.8600 - acc_2: 0.8480 - acc_3: 0.8640 - val_loss_1: 0.7133 - val_loss_2: 0.7395 - val_loss_3: 0.7297 - val_acc_ensemble: 0.8325 - val_acc_1: 0.7818 - val_acc_2: 0.7858 - val_acc_3: 0.7832\n",
      "Epoch 40/50\n",
      "100/100 - 9s - loss_1: 0.2307 - loss_2: 0.1633 - loss_3: 0.1978 - acc_ensemble: 0.9080 - acc_1: 0.8400 - acc_2: 0.8620 - acc_3: 0.8520 - val_loss_1: 0.7666 - val_loss_2: 0.7445 - val_loss_3: 0.7514 - val_acc_ensemble: 0.8311 - val_acc_1: 0.7659 - val_acc_2: 0.7900 - val_acc_3: 0.7710\n",
      "Epoch 41/50\n",
      "100/100 - 9s - loss_1: 0.1920 - loss_2: 0.1545 - loss_3: 0.1892 - acc_ensemble: 0.9240 - acc_1: 0.8760 - acc_2: 0.8640 - acc_3: 0.8720 - val_loss_1: 0.7305 - val_loss_2: 0.8081 - val_loss_3: 0.7233 - val_acc_ensemble: 0.8302 - val_acc_1: 0.7822 - val_acc_2: 0.7682 - val_acc_3: 0.7876\n",
      "Epoch 42/50\n",
      "100/100 - 9s - loss_1: 0.1719 - loss_2: 0.1633 - loss_3: 0.1882 - acc_ensemble: 0.9220 - acc_1: 0.8720 - acc_2: 0.8760 - acc_3: 0.8680 - val_loss_1: 0.7466 - val_loss_2: 0.7487 - val_loss_3: 0.7565 - val_acc_ensemble: 0.8307 - val_acc_1: 0.7818 - val_acc_2: 0.7864 - val_acc_3: 0.7781\n",
      "Epoch 43/50\n",
      "100/100 - 9s - loss_1: 0.1908 - loss_2: 0.1589 - loss_3: 0.1586 - acc_ensemble: 0.9200 - acc_1: 0.8420 - acc_2: 0.8780 - acc_3: 0.8640 - val_loss_1: 0.8012 - val_loss_2: 0.7417 - val_loss_3: 0.7557 - val_acc_ensemble: 0.8342 - val_acc_1: 0.7654 - val_acc_2: 0.7894 - val_acc_3: 0.7831\n",
      "Epoch 44/50\n",
      "100/100 - 9s - loss_1: 0.1868 - loss_2: 0.1686 - loss_3: 0.1647 - acc_ensemble: 0.9260 - acc_1: 0.8620 - acc_2: 0.8680 - acc_3: 0.8560 - val_loss_1: 0.7410 - val_loss_2: 0.7534 - val_loss_3: 0.7637 - val_acc_ensemble: 0.8363 - val_acc_1: 0.7799 - val_acc_2: 0.7893 - val_acc_3: 0.7818\n",
      "Epoch 45/50\n",
      "100/100 - 9s - loss_1: 0.1614 - loss_2: 0.1637 - loss_3: 0.1523 - acc_ensemble: 0.9080 - acc_1: 0.8580 - acc_2: 0.8460 - acc_3: 0.8640 - val_loss_1: 0.7878 - val_loss_2: 0.7736 - val_loss_3: 0.7573 - val_acc_ensemble: 0.8385 - val_acc_1: 0.7737 - val_acc_2: 0.7865 - val_acc_3: 0.7869\n",
      "Epoch 46/50\n",
      "100/100 - 9s - loss_1: 0.1317 - loss_2: 0.1395 - loss_3: 0.1132 - acc_ensemble: 0.9120 - acc_1: 0.8820 - acc_2: 0.8640 - acc_3: 0.8700 - val_loss_1: 0.7437 - val_loss_2: 0.7507 - val_loss_3: 0.7589 - val_acc_ensemble: 0.8380 - val_acc_1: 0.7935 - val_acc_2: 0.7886 - val_acc_3: 0.7912\n",
      "Epoch 47/50\n",
      "100/100 - 9s - loss_1: 0.1283 - loss_2: 0.1283 - loss_3: 0.1126 - acc_ensemble: 0.9240 - acc_1: 0.8600 - acc_2: 0.8800 - acc_3: 0.8600 - val_loss_1: 0.7641 - val_loss_2: 0.7880 - val_loss_3: 0.8455 - val_acc_ensemble: 0.8353 - val_acc_1: 0.7869 - val_acc_2: 0.7897 - val_acc_3: 0.7691\n",
      "Epoch 48/50\n",
      "100/100 - 9s - loss_1: 0.1316 - loss_2: 0.1078 - loss_3: 0.1551 - acc_ensemble: 0.9240 - acc_1: 0.8720 - acc_2: 0.8700 - acc_3: 0.8640 - val_loss_1: 0.7876 - val_loss_2: 0.8048 - val_loss_3: 0.8159 - val_acc_ensemble: 0.8356 - val_acc_1: 0.7843 - val_acc_2: 0.7887 - val_acc_3: 0.7833\n",
      "Epoch 49/50\n",
      "100/100 - 9s - loss_1: 0.1356 - loss_2: 0.1271 - loss_3: 0.1291 - acc_ensemble: 0.9280 - acc_1: 0.8680 - acc_2: 0.8740 - acc_3: 0.8680 - val_loss_1: 0.8232 - val_loss_2: 0.8203 - val_loss_3: 0.7799 - val_acc_ensemble: 0.8356 - val_acc_1: 0.7738 - val_acc_2: 0.7869 - val_acc_3: 0.7850\n",
      "Epoch 50/50\n",
      "100/100 - 9s - loss_1: 0.1350 - loss_2: 0.1135 - loss_3: 0.1381 - acc_ensemble: 0.9400 - acc_1: 0.8660 - acc_2: 0.8740 - acc_3: 0.8780 - val_loss_1: 0.8096 - val_loss_2: 0.8171 - val_loss_3: 0.7716 - val_acc_ensemble: 0.8392 - val_acc_1: 0.7836 - val_acc_2: 0.7878 - val_acc_3: 0.7895\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B3/S0.00/model_2\n",
      "i   Layer name                      Output shape        Num param  Inbound            \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                    \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                    \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                    \n",
      "--------------------------------------------------------------------------------------\n",
      "0   conv2d_1_1 (Conv2D)             [] [None,32,32,32]  2688       input              \n",
      "                                    [] [None,32,32,32]                                \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "1   bn_1_1 (BatchNormalization)     [] [None,32,32,32]  192        conv2d_1_1         \n",
      "                                    [] [None,32,32,32]                                \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "2   relu_1_1 (Activation)           [] [None,32,32,32]  0          bn_1_1             \n",
      "                                    [] [None,32,32,32]                                \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "3   conv2d_1_2 (Conv2D)             [] [None,32,32,32]  27744      relu_1_1           \n",
      "                                    [] [None,32,32,32]                                \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "4   bn_1_2 (BatchNormalization)     [] [None,32,32,32]  192        conv2d_1_2         \n",
      "                                    [] [None,32,32,32]                                \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "5   relu_1_2 (Activation)           [] [None,32,32,32]  0          bn_1_2             \n",
      "                                    [] [None,32,32,32]                                \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "6   avg_pool2d_1 (AveragePooling2D  [] [None,16,16,32]  0          relu_1_2           \n",
      "                                    [] [None,16,16,32]                                \n",
      "                                    [] [None,16,16,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "7   conv2d_2_1 (Conv2D)             [] [None,16,16,64]  55488      avg_pool2d_1       \n",
      "                                    [] [None,16,16,64]                                \n",
      "                                    [] [None,16,16,64]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "8   bn_2_1 (BatchNormalization)     [] [None,16,16,64]  384        conv2d_2_1         \n",
      "                                    [] [None,16,16,64]                                \n",
      "                                    [] [None,16,16,64]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "9   relu_2_1 (Activation)           [] [None,16,16,64]  0          bn_2_1             \n",
      "                                    [] [None,16,16,64]                                \n",
      "                                    [] [None,16,16,64]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "10  conv2d_2_2 (Conv2D)             [] [None,16,16,64]  110784     relu_2_1           \n",
      "                                    [] [None,16,16,64]                                \n",
      "                                    [] [None,16,16,64]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "11  bn_2_2 (BatchNormalization)     [] [None,16,16,64]  384        conv2d_2_2         \n",
      "                                    [] [None,16,16,64]                                \n",
      "                                    [] [None,16,16,64]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "12  relu_2_2 (Activation)           [] [None,16,16,64]  0          bn_2_2             \n",
      "                                    [] [None,16,16,64]                                \n",
      "                                    [] [None,16,16,64]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "13  avg_pool2d_2 (AveragePooling2D  [] [None,8,8,64]    0          relu_2_2           \n",
      "                                    [] [None,8,8,64]                                  \n",
      "                                    [] [None,8,8,64]                                  \n",
      "--------------------------------------------------------------------------------------\n",
      "14  conv2d_3_1 (Conv2D)             [] [None,8,8,128]   221568     avg_pool2d_2       \n",
      "                                    [] [None,8,8,128]                                 \n",
      "                                    [] [None,8,8,128]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "15  bn_3_1 (BatchNormalization)     [] [None,8,8,128]   768        conv2d_3_1         \n",
      "                                    [] [None,8,8,128]                                 \n",
      "                                    [] [None,8,8,128]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "16  relu_3_1 (Activation)           [] [None,8,8,128]   0          bn_3_1             \n",
      "                                    [] [None,8,8,128]                                 \n",
      "                                    [] [None,8,8,128]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "17  conv2d_3_2 (Conv2D)             [] [None,8,8,128]   442752     relu_3_1           \n",
      "                                    [] [None,8,8,128]                                 \n",
      "                                    [] [None,8,8,128]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "18  bn_3_2 (BatchNormalization)     [] [None,8,8,128]   768        conv2d_3_2         \n",
      "                                    [] [None,8,8,128]                                 \n",
      "                                    [] [None,8,8,128]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "19  relu_3_2 (Activation)           [] [None,8,8,128]   0          bn_3_2             \n",
      "                                    [] [None,8,8,128]                                 \n",
      "                                    [] [None,8,8,128]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "20  global_avg_pool2d (GlobalAvera  [] [None,128]       0          relu_3_2           \n",
      "                                    [] [None,128]                                     \n",
      "                                    [] [None,128]                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "21  fc1 (Dense)                     [] [None,128]       49536      global_avg_pool2d  \n",
      "                                    [] [None,128]                                     \n",
      "                                    [] [None,128]                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "22  bn_fc1 (BatchNormalization)     [] [None,128]       768        fc1                \n",
      "                                    [] [None,128]                                     \n",
      "                                    [] [None,128]                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "23  relu_fc1 (Activation)           [] [None,128]       0          bn_fc1             \n",
      "                                    [] [None,128]                                     \n",
      "                                    [] [None,128]                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "24  output (Dense)                  [None,10]           3870       relu_fc1           \n",
      "                                    [None,10]                                         \n",
      "                                    [None,10]                                         \n",
      "--------------------------------------------------------------------------------------\n",
      "Total parameters: 917886\n",
      "50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 - 11s - loss_1: 1.8137 - loss_2: 1.7956 - loss_3: 1.8198 - acc_ensemble: 0.4140 - acc_1: 0.3900 - acc_2: 0.4220 - acc_3: 0.3840 - val_loss_1: 1.5911 - val_loss_2: 1.5992 - val_loss_3: 1.6008 - val_acc_ensemble: 0.4512 - val_acc_1: 0.4107 - val_acc_2: 0.3985 - val_acc_3: 0.4032\n",
      "Epoch 2/50\n",
      "100/100 - 9s - loss_1: 1.5256 - loss_2: 1.5330 - loss_3: 1.5214 - acc_ensemble: 0.5460 - acc_1: 0.5040 - acc_2: 0.4900 - acc_3: 0.4860 - val_loss_1: 1.4081 - val_loss_2: 1.4220 - val_loss_3: 1.4455 - val_acc_ensemble: 0.5245 - val_acc_1: 0.4837 - val_acc_2: 0.4719 - val_acc_3: 0.4725\n",
      "Epoch 3/50\n",
      "100/100 - 9s - loss_1: 1.3449 - loss_2: 1.3663 - loss_3: 1.3925 - acc_ensemble: 0.5680 - acc_1: 0.5300 - acc_2: 0.5360 - acc_3: 0.5280 - val_loss_1: 1.3048 - val_loss_2: 1.2578 - val_loss_3: 1.3248 - val_acc_ensemble: 0.5700 - val_acc_1: 0.5271 - val_acc_2: 0.5305 - val_acc_3: 0.5181\n",
      "Epoch 4/50\n",
      "100/100 - 9s - loss_1: 1.2093 - loss_2: 1.2045 - loss_3: 1.2553 - acc_ensemble: 0.6000 - acc_1: 0.5400 - acc_2: 0.6000 - acc_3: 0.6000 - val_loss_1: 1.1924 - val_loss_2: 1.1692 - val_loss_3: 1.1866 - val_acc_ensemble: 0.6131 - val_acc_1: 0.5608 - val_acc_2: 0.5816 - val_acc_3: 0.5684\n",
      "Epoch 5/50\n",
      "100/100 - 9s - loss_1: 1.1245 - loss_2: 1.1279 - loss_3: 1.1452 - acc_ensemble: 0.6500 - acc_1: 0.6360 - acc_2: 0.6120 - acc_3: 0.6040 - val_loss_1: 1.0703 - val_loss_2: 1.0959 - val_loss_3: 1.1299 - val_acc_ensemble: 0.6356 - val_acc_1: 0.6081 - val_acc_2: 0.6001 - val_acc_3: 0.5821\n",
      "Epoch 6/50\n",
      "100/100 - 9s - loss_1: 1.0422 - loss_2: 1.0288 - loss_3: 1.0646 - acc_ensemble: 0.6860 - acc_1: 0.6320 - acc_2: 0.6260 - acc_3: 0.6380 - val_loss_1: 1.0422 - val_loss_2: 1.0384 - val_loss_3: 1.1099 - val_acc_ensemble: 0.6583 - val_acc_1: 0.6226 - val_acc_2: 0.6238 - val_acc_3: 0.6021\n",
      "Epoch 7/50\n",
      "100/100 - 9s - loss_1: 0.9520 - loss_2: 0.9697 - loss_3: 1.0342 - acc_ensemble: 0.6940 - acc_1: 0.6740 - acc_2: 0.6420 - acc_3: 0.6500 - val_loss_1: 0.9669 - val_loss_2: 0.9894 - val_loss_3: 1.0045 - val_acc_ensemble: 0.6883 - val_acc_1: 0.6563 - val_acc_2: 0.6495 - val_acc_3: 0.6343\n",
      "Epoch 8/50\n",
      "100/100 - 9s - loss_1: 0.9044 - loss_2: 0.9322 - loss_3: 0.9652 - acc_ensemble: 0.7280 - acc_1: 0.6740 - acc_2: 0.6460 - acc_3: 0.6640 - val_loss_1: 0.9453 - val_loss_2: 0.9818 - val_loss_3: 0.9787 - val_acc_ensemble: 0.7006 - val_acc_1: 0.6661 - val_acc_2: 0.6449 - val_acc_3: 0.6522\n",
      "Epoch 9/50\n",
      "100/100 - 9s - loss_1: 0.8626 - loss_2: 0.8870 - loss_3: 0.8928 - acc_ensemble: 0.7260 - acc_1: 0.6900 - acc_2: 0.6860 - acc_3: 0.6660 - val_loss_1: 0.9032 - val_loss_2: 0.9209 - val_loss_3: 0.9148 - val_acc_ensemble: 0.7156 - val_acc_1: 0.6776 - val_acc_2: 0.6656 - val_acc_3: 0.6743\n",
      "Epoch 10/50\n",
      "100/100 - 9s - loss_1: 0.8100 - loss_2: 0.8185 - loss_3: 0.8540 - acc_ensemble: 0.7540 - acc_1: 0.6680 - acc_2: 0.7060 - acc_3: 0.7160 - val_loss_1: 0.8985 - val_loss_2: 0.8499 - val_loss_3: 0.8773 - val_acc_ensemble: 0.7297 - val_acc_1: 0.6836 - val_acc_2: 0.7007 - val_acc_3: 0.6862\n",
      "Epoch 11/50\n",
      "100/100 - 9s - loss_1: 0.7737 - loss_2: 0.7862 - loss_3: 0.8335 - acc_ensemble: 0.7800 - acc_1: 0.7400 - acc_2: 0.7360 - acc_3: 0.7260 - val_loss_1: 0.8314 - val_loss_2: 0.8662 - val_loss_3: 0.8398 - val_acc_ensemble: 0.7404 - val_acc_1: 0.7094 - val_acc_2: 0.6895 - val_acc_3: 0.7039\n",
      "Epoch 12/50\n",
      "100/100 - 9s - loss_1: 0.7344 - loss_2: 0.7307 - loss_3: 0.7827 - acc_ensemble: 0.7820 - acc_1: 0.7260 - acc_2: 0.7680 - acc_3: 0.7180 - val_loss_1: 0.8098 - val_loss_2: 0.8128 - val_loss_3: 0.8580 - val_acc_ensemble: 0.7531 - val_acc_1: 0.7148 - val_acc_2: 0.7110 - val_acc_3: 0.6911\n",
      "Epoch 13/50\n",
      "100/100 - 9s - loss_1: 0.7243 - loss_2: 0.7437 - loss_3: 0.7074 - acc_ensemble: 0.7880 - acc_1: 0.7420 - acc_2: 0.7360 - acc_3: 0.7240 - val_loss_1: 0.7937 - val_loss_2: 0.7901 - val_loss_3: 0.8443 - val_acc_ensemble: 0.7551 - val_acc_1: 0.7174 - val_acc_2: 0.7248 - val_acc_3: 0.6996\n",
      "Epoch 14/50\n",
      "100/100 - 9s - loss_1: 0.6306 - loss_2: 0.6726 - loss_3: 0.6936 - acc_ensemble: 0.8160 - acc_1: 0.7320 - acc_2: 0.7780 - acc_3: 0.7360 - val_loss_1: 0.7791 - val_loss_2: 0.7943 - val_loss_3: 0.7974 - val_acc_ensemble: 0.7681 - val_acc_1: 0.7267 - val_acc_2: 0.7214 - val_acc_3: 0.7190\n",
      "Epoch 15/50\n",
      "100/100 - 9s - loss_1: 0.6225 - loss_2: 0.6510 - loss_3: 0.6730 - acc_ensemble: 0.8120 - acc_1: 0.7620 - acc_2: 0.7600 - acc_3: 0.7520 - val_loss_1: 0.7654 - val_loss_2: 0.7797 - val_loss_3: 0.7515 - val_acc_ensemble: 0.7741 - val_acc_1: 0.7347 - val_acc_2: 0.7253 - val_acc_3: 0.7358\n",
      "Epoch 16/50\n",
      "100/100 - 8s - loss_1: 0.6191 - loss_2: 0.6032 - loss_3: 0.6374 - acc_ensemble: 0.8220 - acc_1: 0.7680 - acc_2: 0.7900 - acc_3: 0.7740 - val_loss_1: 0.7321 - val_loss_2: 0.7433 - val_loss_3: 0.7738 - val_acc_ensemble: 0.7791 - val_acc_1: 0.7407 - val_acc_2: 0.7349 - val_acc_3: 0.7274\n",
      "Epoch 17/50\n",
      "100/100 - 9s - loss_1: 0.5874 - loss_2: 0.5680 - loss_3: 0.6334 - acc_ensemble: 0.8260 - acc_1: 0.7860 - acc_2: 0.8040 - acc_3: 0.7760 - val_loss_1: 0.7384 - val_loss_2: 0.7338 - val_loss_3: 0.7308 - val_acc_ensemble: 0.7867 - val_acc_1: 0.7394 - val_acc_2: 0.7381 - val_acc_3: 0.7457\n",
      "Epoch 18/50\n",
      "100/100 - 9s - loss_1: 0.5685 - loss_2: 0.5672 - loss_3: 0.5720 - acc_ensemble: 0.8420 - acc_1: 0.8020 - acc_2: 0.7660 - acc_3: 0.7920 - val_loss_1: 0.6960 - val_loss_2: 0.7295 - val_loss_3: 0.7347 - val_acc_ensemble: 0.7876 - val_acc_1: 0.7543 - val_acc_2: 0.7451 - val_acc_3: 0.7445\n",
      "Epoch 19/50\n",
      "100/100 - 9s - loss_1: 0.5210 - loss_2: 0.5659 - loss_3: 0.5637 - acc_ensemble: 0.8440 - acc_1: 0.7960 - acc_2: 0.8100 - acc_3: 0.7800 - val_loss_1: 0.6970 - val_loss_2: 0.7013 - val_loss_3: 0.7498 - val_acc_ensemble: 0.7967 - val_acc_1: 0.7605 - val_acc_2: 0.7545 - val_acc_3: 0.7389\n",
      "Epoch 20/50\n",
      "100/100 - 9s - loss_1: 0.4761 - loss_2: 0.5080 - loss_3: 0.5645 - acc_ensemble: 0.8420 - acc_1: 0.7960 - acc_2: 0.7980 - acc_3: 0.7820 - val_loss_1: 0.6931 - val_loss_2: 0.7230 - val_loss_3: 0.7224 - val_acc_ensemble: 0.8002 - val_acc_1: 0.7629 - val_acc_2: 0.7512 - val_acc_3: 0.7516\n",
      "Epoch 21/50\n",
      "100/100 - 9s - loss_1: 0.4878 - loss_2: 0.5047 - loss_3: 0.5353 - acc_ensemble: 0.8540 - acc_1: 0.7960 - acc_2: 0.8120 - acc_3: 0.8100 - val_loss_1: 0.6960 - val_loss_2: 0.7232 - val_loss_3: 0.7022 - val_acc_ensemble: 0.8033 - val_acc_1: 0.7617 - val_acc_2: 0.7532 - val_acc_3: 0.7526\n",
      "Epoch 22/50\n",
      "100/100 - 9s - loss_1: 0.4523 - loss_2: 0.4794 - loss_3: 0.5103 - acc_ensemble: 0.8700 - acc_1: 0.8060 - acc_2: 0.8120 - acc_3: 0.7960 - val_loss_1: 0.6743 - val_loss_2: 0.6764 - val_loss_3: 0.6930 - val_acc_ensemble: 0.8050 - val_acc_1: 0.7666 - val_acc_2: 0.7659 - val_acc_3: 0.7571\n",
      "Epoch 23/50\n",
      "100/100 - 9s - loss_1: 0.4433 - loss_2: 0.4648 - loss_3: 0.4630 - acc_ensemble: 0.8660 - acc_1: 0.8140 - acc_2: 0.8040 - acc_3: 0.7740 - val_loss_1: 0.6772 - val_loss_2: 0.6817 - val_loss_3: 0.7255 - val_acc_ensemble: 0.8115 - val_acc_1: 0.7710 - val_acc_2: 0.7671 - val_acc_3: 0.7549\n",
      "Epoch 24/50\n",
      "100/100 - 9s - loss_1: 0.4261 - loss_2: 0.4192 - loss_3: 0.4574 - acc_ensemble: 0.8720 - acc_1: 0.8260 - acc_2: 0.8360 - acc_3: 0.7980 - val_loss_1: 0.6773 - val_loss_2: 0.6673 - val_loss_3: 0.7003 - val_acc_ensemble: 0.8098 - val_acc_1: 0.7734 - val_acc_2: 0.7745 - val_acc_3: 0.7565\n",
      "Epoch 25/50\n",
      "100/100 - 9s - loss_1: 0.3962 - loss_2: 0.4096 - loss_3: 0.4303 - acc_ensemble: 0.8800 - acc_1: 0.8240 - acc_2: 0.8380 - acc_3: 0.8100 - val_loss_1: 0.6693 - val_loss_2: 0.6939 - val_loss_3: 0.7119 - val_acc_ensemble: 0.8112 - val_acc_1: 0.7738 - val_acc_2: 0.7678 - val_acc_3: 0.7599\n",
      "Epoch 26/50\n",
      "100/100 - 9s - loss_1: 0.3670 - loss_2: 0.3793 - loss_3: 0.4263 - acc_ensemble: 0.8700 - acc_1: 0.8180 - acc_2: 0.8120 - acc_3: 0.8160 - val_loss_1: 0.7006 - val_loss_2: 0.6649 - val_loss_3: 0.6809 - val_acc_ensemble: 0.8124 - val_acc_1: 0.7682 - val_acc_2: 0.7809 - val_acc_3: 0.7700\n",
      "Epoch 27/50\n",
      "100/100 - 9s - loss_1: 0.3437 - loss_2: 0.3706 - loss_3: 0.3808 - acc_ensemble: 0.8900 - acc_1: 0.8420 - acc_2: 0.8300 - acc_3: 0.7980 - val_loss_1: 0.6508 - val_loss_2: 0.6794 - val_loss_3: 0.7080 - val_acc_ensemble: 0.8201 - val_acc_1: 0.7813 - val_acc_2: 0.7736 - val_acc_3: 0.7633\n",
      "Epoch 28/50\n",
      "100/100 - 9s - loss_1: 0.3468 - loss_2: 0.3489 - loss_3: 0.4159 - acc_ensemble: 0.8780 - acc_1: 0.8420 - acc_2: 0.8240 - acc_3: 0.8180 - val_loss_1: 0.6688 - val_loss_2: 0.6963 - val_loss_3: 0.6858 - val_acc_ensemble: 0.8199 - val_acc_1: 0.7790 - val_acc_2: 0.7704 - val_acc_3: 0.7691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50\n",
      "100/100 - 9s - loss_1: 0.2927 - loss_2: 0.3628 - loss_3: 0.3672 - acc_ensemble: 0.8860 - acc_1: 0.8520 - acc_2: 0.8320 - acc_3: 0.8360 - val_loss_1: 0.6648 - val_loss_2: 0.6515 - val_loss_3: 0.6703 - val_acc_ensemble: 0.8305 - val_acc_1: 0.7858 - val_acc_2: 0.7881 - val_acc_3: 0.7822\n",
      "Epoch 30/50\n",
      "100/100 - 9s - loss_1: 0.3196 - loss_2: 0.3364 - loss_3: 0.3471 - acc_ensemble: 0.8860 - acc_1: 0.8180 - acc_2: 0.8440 - acc_3: 0.8280 - val_loss_1: 0.6886 - val_loss_2: 0.6547 - val_loss_3: 0.6789 - val_acc_ensemble: 0.8263 - val_acc_1: 0.7805 - val_acc_2: 0.7811 - val_acc_3: 0.7775\n",
      "Epoch 31/50\n",
      "100/100 - 9s - loss_1: 0.3117 - loss_2: 0.3176 - loss_3: 0.3632 - acc_ensemble: 0.8780 - acc_1: 0.8380 - acc_2: 0.8400 - acc_3: 0.8280 - val_loss_1: 0.6830 - val_loss_2: 0.6759 - val_loss_3: 0.6835 - val_acc_ensemble: 0.8251 - val_acc_1: 0.7779 - val_acc_2: 0.7823 - val_acc_3: 0.7728\n",
      "Epoch 32/50\n",
      "100/100 - 9s - loss_1: 0.2869 - loss_2: 0.2904 - loss_3: 0.3331 - acc_ensemble: 0.9020 - acc_1: 0.8520 - acc_2: 0.8660 - acc_3: 0.8340 - val_loss_1: 0.6740 - val_loss_2: 0.6525 - val_loss_3: 0.6799 - val_acc_ensemble: 0.8326 - val_acc_1: 0.7874 - val_acc_2: 0.7899 - val_acc_3: 0.7751\n",
      "Epoch 33/50\n",
      "100/100 - 9s - loss_1: 0.2694 - loss_2: 0.2896 - loss_3: 0.3237 - acc_ensemble: 0.8860 - acc_1: 0.8240 - acc_2: 0.8280 - acc_3: 0.8640 - val_loss_1: 0.6847 - val_loss_2: 0.7259 - val_loss_3: 0.6519 - val_acc_ensemble: 0.8315 - val_acc_1: 0.7867 - val_acc_2: 0.7681 - val_acc_3: 0.7932\n",
      "Epoch 34/50\n",
      "100/100 - 9s - loss_1: 0.2716 - loss_2: 0.2652 - loss_3: 0.2855 - acc_ensemble: 0.8960 - acc_1: 0.8460 - acc_2: 0.8600 - acc_3: 0.8260 - val_loss_1: 0.7034 - val_loss_2: 0.6830 - val_loss_3: 0.6795 - val_acc_ensemble: 0.8284 - val_acc_1: 0.7780 - val_acc_2: 0.7836 - val_acc_3: 0.7808\n",
      "Epoch 35/50\n",
      "100/100 - 9s - loss_1: 0.2190 - loss_2: 0.2335 - loss_3: 0.2863 - acc_ensemble: 0.8980 - acc_1: 0.8320 - acc_2: 0.8400 - acc_3: 0.8340 - val_loss_1: 0.6947 - val_loss_2: 0.6732 - val_loss_3: 0.6820 - val_acc_ensemble: 0.8364 - val_acc_1: 0.7829 - val_acc_2: 0.7920 - val_acc_3: 0.7846\n",
      "Epoch 36/50\n",
      "100/100 - 9s - loss_1: 0.2087 - loss_2: 0.2362 - loss_3: 0.2610 - acc_ensemble: 0.9060 - acc_1: 0.8460 - acc_2: 0.8680 - acc_3: 0.8340 - val_loss_1: 0.7149 - val_loss_2: 0.6643 - val_loss_3: 0.7081 - val_acc_ensemble: 0.8351 - val_acc_1: 0.7805 - val_acc_2: 0.7925 - val_acc_3: 0.7765\n",
      "Epoch 37/50\n",
      "100/100 - 9s - loss_1: 0.2121 - loss_2: 0.2275 - loss_3: 0.2627 - acc_ensemble: 0.9060 - acc_1: 0.8720 - acc_2: 0.8600 - acc_3: 0.8460 - val_loss_1: 0.6943 - val_loss_2: 0.7247 - val_loss_3: 0.6889 - val_acc_ensemble: 0.8309 - val_acc_1: 0.7889 - val_acc_2: 0.7853 - val_acc_3: 0.7838\n",
      "Epoch 38/50\n",
      "100/100 - 9s - loss_1: 0.1955 - loss_2: 0.2257 - loss_3: 0.2174 - acc_ensemble: 0.9060 - acc_1: 0.8700 - acc_2: 0.8580 - acc_3: 0.8480 - val_loss_1: 0.6988 - val_loss_2: 0.7086 - val_loss_3: 0.7301 - val_acc_ensemble: 0.8359 - val_acc_1: 0.7911 - val_acc_2: 0.7862 - val_acc_3: 0.7801\n",
      "Epoch 39/50\n",
      "100/100 - 9s - loss_1: 0.2109 - loss_2: 0.2250 - loss_3: 0.2219 - acc_ensemble: 0.9140 - acc_1: 0.8540 - acc_2: 0.8380 - acc_3: 0.8620 - val_loss_1: 0.7421 - val_loss_2: 0.7405 - val_loss_3: 0.6800 - val_acc_ensemble: 0.8373 - val_acc_1: 0.7798 - val_acc_2: 0.7801 - val_acc_3: 0.7905\n",
      "Epoch 40/50\n",
      "100/100 - 9s - loss_1: 0.1848 - loss_2: 0.2023 - loss_3: 0.2514 - acc_ensemble: 0.9080 - acc_1: 0.8380 - acc_2: 0.8460 - acc_3: 0.8480 - val_loss_1: 0.7211 - val_loss_2: 0.7140 - val_loss_3: 0.7129 - val_acc_ensemble: 0.8341 - val_acc_1: 0.7909 - val_acc_2: 0.7907 - val_acc_3: 0.7804\n",
      "Epoch 41/50\n",
      "100/100 - 9s - loss_1: 0.1653 - loss_2: 0.1918 - loss_3: 0.2062 - acc_ensemble: 0.9140 - acc_1: 0.8380 - acc_2: 0.8700 - acc_3: 0.8540 - val_loss_1: 0.7418 - val_loss_2: 0.7297 - val_loss_3: 0.6942 - val_acc_ensemble: 0.8393 - val_acc_1: 0.7847 - val_acc_2: 0.7849 - val_acc_3: 0.7944\n",
      "Epoch 42/50\n",
      "100/100 - 9s - loss_1: 0.1476 - loss_2: 0.1575 - loss_3: 0.2067 - acc_ensemble: 0.9180 - acc_1: 0.8400 - acc_2: 0.8800 - acc_3: 0.8560 - val_loss_1: 0.7485 - val_loss_2: 0.7045 - val_loss_3: 0.7244 - val_acc_ensemble: 0.8361 - val_acc_1: 0.7872 - val_acc_2: 0.7935 - val_acc_3: 0.7810\n",
      "Epoch 43/50\n",
      "100/100 - 9s - loss_1: 0.1456 - loss_2: 0.1270 - loss_3: 0.1582 - acc_ensemble: 0.9140 - acc_1: 0.8700 - acc_2: 0.8540 - acc_3: 0.8480 - val_loss_1: 0.7097 - val_loss_2: 0.7454 - val_loss_3: 0.7313 - val_acc_ensemble: 0.8376 - val_acc_1: 0.7972 - val_acc_2: 0.7899 - val_acc_3: 0.7858\n",
      "Epoch 44/50\n",
      "100/100 - 9s - loss_1: 0.1413 - loss_2: 0.1609 - loss_3: 0.1483 - acc_ensemble: 0.9100 - acc_1: 0.8700 - acc_2: 0.8660 - acc_3: 0.8440 - val_loss_1: 0.7549 - val_loss_2: 0.7424 - val_loss_3: 0.7333 - val_acc_ensemble: 0.8413 - val_acc_1: 0.7852 - val_acc_2: 0.7840 - val_acc_3: 0.7839\n",
      "Epoch 45/50\n",
      "100/100 - 9s - loss_1: 0.1567 - loss_2: 0.1388 - loss_3: 0.2003 - acc_ensemble: 0.9200 - acc_1: 0.8740 - acc_2: 0.8660 - acc_3: 0.8600 - val_loss_1: 0.7340 - val_loss_2: 0.7496 - val_loss_3: 0.7534 - val_acc_ensemble: 0.8363 - val_acc_1: 0.7890 - val_acc_2: 0.7898 - val_acc_3: 0.7861\n",
      "Epoch 46/50\n",
      "100/100 - 9s - loss_1: 0.1534 - loss_2: 0.1464 - loss_3: 0.1553 - acc_ensemble: 0.9140 - acc_1: 0.8440 - acc_2: 0.8580 - acc_3: 0.8540 - val_loss_1: 0.7966 - val_loss_2: 0.7512 - val_loss_3: 0.7388 - val_acc_ensemble: 0.8397 - val_acc_1: 0.7834 - val_acc_2: 0.7880 - val_acc_3: 0.7873\n",
      "Epoch 47/50\n",
      "100/100 - 9s - loss_1: 0.1034 - loss_2: 0.1647 - loss_3: 0.1576 - acc_ensemble: 0.9220 - acc_1: 0.8720 - acc_2: 0.8620 - acc_3: 0.8500 - val_loss_1: 0.7425 - val_loss_2: 0.8270 - val_loss_3: 0.7500 - val_acc_ensemble: 0.8384 - val_acc_1: 0.7972 - val_acc_2: 0.7772 - val_acc_3: 0.7884\n",
      "Epoch 48/50\n",
      "100/100 - 9s - loss_1: 0.1106 - loss_2: 0.1544 - loss_3: 0.1422 - acc_ensemble: 0.9120 - acc_1: 0.8720 - acc_2: 0.8640 - acc_3: 0.8760 - val_loss_1: 0.8119 - val_loss_2: 0.7386 - val_loss_3: 0.7168 - val_acc_ensemble: 0.8410 - val_acc_1: 0.7874 - val_acc_2: 0.7956 - val_acc_3: 0.7944\n",
      "Epoch 49/50\n",
      "100/100 - 9s - loss_1: 0.1145 - loss_2: 0.1276 - loss_3: 0.1283 - acc_ensemble: 0.9240 - acc_1: 0.8700 - acc_2: 0.8660 - acc_3: 0.8380 - val_loss_1: 0.7852 - val_loss_2: 0.7755 - val_loss_3: 0.8009 - val_acc_ensemble: 0.8387 - val_acc_1: 0.7903 - val_acc_2: 0.7893 - val_acc_3: 0.7803\n",
      "Epoch 50/50\n",
      "100/100 - 9s - loss_1: 0.0996 - loss_2: 0.0974 - loss_3: 0.1522 - acc_ensemble: 0.9320 - acc_1: 0.8520 - acc_2: 0.8640 - acc_3: 0.8500 - val_loss_1: 0.8015 - val_loss_2: 0.7724 - val_loss_3: 0.7782 - val_acc_ensemble: 0.8411 - val_acc_1: 0.7899 - val_acc_2: 0.7952 - val_acc_3: 0.7815\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B3/S0.00/model_3\n",
      "i   Layer name                      Output shape        Num param  Inbound            \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                    \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                    \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                    \n",
      "--------------------------------------------------------------------------------------\n",
      "0   conv2d_1_1 (Conv2D)             [] [None,32,32,32]  2688       input              \n",
      "                                    [] [None,32,32,32]                                \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "1   bn_1_1 (BatchNormalization)     [] [None,32,32,32]  192        conv2d_1_1         \n",
      "                                    [] [None,32,32,32]                                \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "2   relu_1_1 (Activation)           [] [None,32,32,32]  0          bn_1_1             \n",
      "                                    [] [None,32,32,32]                                \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "3   conv2d_1_2 (Conv2D)             [] [None,32,32,32]  27744      relu_1_1           \n",
      "                                    [] [None,32,32,32]                                \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "4   bn_1_2 (BatchNormalization)     [] [None,32,32,32]  192        conv2d_1_2         \n",
      "                                    [] [None,32,32,32]                                \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "5   relu_1_2 (Activation)           [] [None,32,32,32]  0          bn_1_2             \n",
      "                                    [] [None,32,32,32]                                \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "6   avg_pool2d_1 (AveragePooling2D  [] [None,16,16,32]  0          relu_1_2           \n",
      "                                    [] [None,16,16,32]                                \n",
      "                                    [] [None,16,16,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "7   conv2d_2_1 (Conv2D)             [] [None,16,16,64]  55488      avg_pool2d_1       \n",
      "                                    [] [None,16,16,64]                                \n",
      "                                    [] [None,16,16,64]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "8   bn_2_1 (BatchNormalization)     [] [None,16,16,64]  384        conv2d_2_1         \n",
      "                                    [] [None,16,16,64]                                \n",
      "                                    [] [None,16,16,64]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "9   relu_2_1 (Activation)           [] [None,16,16,64]  0          bn_2_1             \n",
      "                                    [] [None,16,16,64]                                \n",
      "                                    [] [None,16,16,64]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "10  conv2d_2_2 (Conv2D)             [] [None,16,16,64]  110784     relu_2_1           \n",
      "                                    [] [None,16,16,64]                                \n",
      "                                    [] [None,16,16,64]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "11  bn_2_2 (BatchNormalization)     [] [None,16,16,64]  384        conv2d_2_2         \n",
      "                                    [] [None,16,16,64]                                \n",
      "                                    [] [None,16,16,64]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "12  relu_2_2 (Activation)           [] [None,16,16,64]  0          bn_2_2             \n",
      "                                    [] [None,16,16,64]                                \n",
      "                                    [] [None,16,16,64]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "13  avg_pool2d_2 (AveragePooling2D  [] [None,8,8,64]    0          relu_2_2           \n",
      "                                    [] [None,8,8,64]                                  \n",
      "                                    [] [None,8,8,64]                                  \n",
      "--------------------------------------------------------------------------------------\n",
      "14  conv2d_3_1 (Conv2D)             [] [None,8,8,128]   221568     avg_pool2d_2       \n",
      "                                    [] [None,8,8,128]                                 \n",
      "                                    [] [None,8,8,128]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "15  bn_3_1 (BatchNormalization)     [] [None,8,8,128]   768        conv2d_3_1         \n",
      "                                    [] [None,8,8,128]                                 \n",
      "                                    [] [None,8,8,128]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "16  relu_3_1 (Activation)           [] [None,8,8,128]   0          bn_3_1             \n",
      "                                    [] [None,8,8,128]                                 \n",
      "                                    [] [None,8,8,128]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "17  conv2d_3_2 (Conv2D)             [] [None,8,8,128]   442752     relu_3_1           \n",
      "                                    [] [None,8,8,128]                                 \n",
      "                                    [] [None,8,8,128]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "18  bn_3_2 (BatchNormalization)     [] [None,8,8,128]   768        conv2d_3_2         \n",
      "                                    [] [None,8,8,128]                                 \n",
      "                                    [] [None,8,8,128]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "19  relu_3_2 (Activation)           [] [None,8,8,128]   0          bn_3_2             \n",
      "                                    [] [None,8,8,128]                                 \n",
      "                                    [] [None,8,8,128]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "20  global_avg_pool2d (GlobalAvera  [] [None,128]       0          relu_3_2           \n",
      "                                    [] [None,128]                                     \n",
      "                                    [] [None,128]                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "21  fc1 (Dense)                     [] [None,128]       49536      global_avg_pool2d  \n",
      "                                    [] [None,128]                                     \n",
      "                                    [] [None,128]                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "22  bn_fc1 (BatchNormalization)     [] [None,128]       768        fc1                \n",
      "                                    [] [None,128]                                     \n",
      "                                    [] [None,128]                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "23  relu_fc1 (Activation)           [] [None,128]       0          bn_fc1             \n",
      "                                    [] [None,128]                                     \n",
      "                                    [] [None,128]                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "24  output (Dense)                  [None,10]           3870       relu_fc1           \n",
      "                                    [None,10]                                         \n",
      "                                    [None,10]                                         \n",
      "--------------------------------------------------------------------------------------\n",
      "Total parameters: 917886\n",
      "50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 - 11s - loss_1: 1.8097 - loss_2: 1.8020 - loss_3: 1.8352 - acc_ensemble: 0.4720 - acc_1: 0.4500 - acc_2: 0.4380 - acc_3: 0.4440 - val_loss_1: 1.5347 - val_loss_2: 1.5615 - val_loss_3: 1.5750 - val_acc_ensemble: 0.4479 - val_acc_1: 0.4196 - val_acc_2: 0.4052 - val_acc_3: 0.4093\n",
      "Epoch 2/50\n",
      "100/100 - 9s - loss_1: 1.5079 - loss_2: 1.5157 - loss_3: 1.5244 - acc_ensemble: 0.5180 - acc_1: 0.5000 - acc_2: 0.4800 - acc_3: 0.4720 - val_loss_1: 1.4003 - val_loss_2: 1.4068 - val_loss_3: 1.4059 - val_acc_ensemble: 0.5259 - val_acc_1: 0.4852 - val_acc_2: 0.4843 - val_acc_3: 0.4850\n",
      "Epoch 3/50\n",
      "100/100 - 9s - loss_1: 1.3866 - loss_2: 1.3243 - loss_3: 1.3689 - acc_ensemble: 0.5780 - acc_1: 0.5600 - acc_2: 0.5140 - acc_3: 0.5500 - val_loss_1: 1.2572 - val_loss_2: 1.3027 - val_loss_3: 1.2696 - val_acc_ensemble: 0.5798 - val_acc_1: 0.5453 - val_acc_2: 0.5245 - val_acc_3: 0.5354\n",
      "Epoch 4/50\n",
      "100/100 - 8s - loss_1: 1.2460 - loss_2: 1.2525 - loss_3: 1.2532 - acc_ensemble: 0.6140 - acc_1: 0.5500 - acc_2: 0.5640 - acc_3: 0.5880 - val_loss_1: 1.1858 - val_loss_2: 1.1936 - val_loss_3: 1.1536 - val_acc_ensemble: 0.6156 - val_acc_1: 0.5673 - val_acc_2: 0.5657 - val_acc_3: 0.5783\n",
      "Epoch 5/50\n",
      "100/100 - 8s - loss_1: 1.1466 - loss_2: 1.1450 - loss_3: 1.1561 - acc_ensemble: 0.6540 - acc_1: 0.5940 - acc_2: 0.6300 - acc_3: 0.6020 - val_loss_1: 1.0962 - val_loss_2: 1.1175 - val_loss_3: 1.0998 - val_acc_ensemble: 0.6446 - val_acc_1: 0.6083 - val_acc_2: 0.5958 - val_acc_3: 0.5996\n",
      "Epoch 6/50\n",
      "100/100 - 9s - loss_1: 1.0838 - loss_2: 1.0656 - loss_3: 1.0698 - acc_ensemble: 0.7020 - acc_1: 0.6280 - acc_2: 0.6180 - acc_3: 0.6800 - val_loss_1: 1.0339 - val_loss_2: 1.0805 - val_loss_3: 1.0738 - val_acc_ensemble: 0.6644 - val_acc_1: 0.6279 - val_acc_2: 0.6122 - val_acc_3: 0.6120\n",
      "Epoch 7/50\n",
      "100/100 - 8s - loss_1: 1.0271 - loss_2: 0.9988 - loss_3: 1.0083 - acc_ensemble: 0.7180 - acc_1: 0.6680 - acc_2: 0.6700 - acc_3: 0.6620 - val_loss_1: 0.9796 - val_loss_2: 0.9779 - val_loss_3: 1.0249 - val_acc_ensemble: 0.6797 - val_acc_1: 0.6483 - val_acc_2: 0.6513 - val_acc_3: 0.6328\n",
      "Epoch 8/50\n",
      "100/100 - 9s - loss_1: 0.9466 - loss_2: 0.9465 - loss_3: 0.9441 - acc_ensemble: 0.7400 - acc_1: 0.7060 - acc_2: 0.6940 - acc_3: 0.7140 - val_loss_1: 0.9165 - val_loss_2: 0.9375 - val_loss_3: 0.9264 - val_acc_ensemble: 0.7064 - val_acc_1: 0.6746 - val_acc_2: 0.6677 - val_acc_3: 0.6679\n",
      "Epoch 9/50\n",
      "100/100 - 8s - loss_1: 0.9105 - loss_2: 0.8552 - loss_3: 0.8900 - acc_ensemble: 0.7140 - acc_1: 0.6760 - acc_2: 0.6960 - acc_3: 0.7160 - val_loss_1: 0.9228 - val_loss_2: 0.9197 - val_loss_3: 0.9266 - val_acc_ensemble: 0.7063 - val_acc_1: 0.6612 - val_acc_2: 0.6700 - val_acc_3: 0.6694\n",
      "Epoch 10/50\n",
      "100/100 - 8s - loss_1: 0.8626 - loss_2: 0.8250 - loss_3: 0.8465 - acc_ensemble: 0.7460 - acc_1: 0.6880 - acc_2: 0.6980 - acc_3: 0.7020 - val_loss_1: 0.8662 - val_loss_2: 0.8818 - val_loss_3: 0.9274 - val_acc_ensemble: 0.7250 - val_acc_1: 0.6878 - val_acc_2: 0.6876 - val_acc_3: 0.6666\n",
      "Epoch 11/50\n",
      "100/100 - 9s - loss_1: 0.7963 - loss_2: 0.7989 - loss_3: 0.8215 - acc_ensemble: 0.7660 - acc_1: 0.7220 - acc_2: 0.7140 - acc_3: 0.7200 - val_loss_1: 0.8987 - val_loss_2: 0.8660 - val_loss_3: 0.8608 - val_acc_ensemble: 0.7320 - val_acc_1: 0.6773 - val_acc_2: 0.6930 - val_acc_3: 0.6983\n",
      "Epoch 12/50\n",
      "100/100 - 8s - loss_1: 0.7942 - loss_2: 0.7535 - loss_3: 0.7664 - acc_ensemble: 0.7740 - acc_1: 0.7260 - acc_2: 0.7400 - acc_3: 0.7620 - val_loss_1: 0.8327 - val_loss_2: 0.8400 - val_loss_3: 0.8344 - val_acc_ensemble: 0.7473 - val_acc_1: 0.7021 - val_acc_2: 0.7058 - val_acc_3: 0.7024\n",
      "Epoch 13/50\n",
      "100/100 - 9s - loss_1: 0.7757 - loss_2: 0.7206 - loss_3: 0.7351 - acc_ensemble: 0.7940 - acc_1: 0.7420 - acc_2: 0.7540 - acc_3: 0.7780 - val_loss_1: 0.8117 - val_loss_2: 0.8173 - val_loss_3: 0.7818 - val_acc_ensemble: 0.7522 - val_acc_1: 0.7086 - val_acc_2: 0.7113 - val_acc_3: 0.7209\n",
      "Epoch 14/50\n",
      "100/100 - 8s - loss_1: 0.7544 - loss_2: 0.6709 - loss_3: 0.7028 - acc_ensemble: 0.8040 - acc_1: 0.7200 - acc_2: 0.7860 - acc_3: 0.7800 - val_loss_1: 0.8075 - val_loss_2: 0.7712 - val_loss_3: 0.7973 - val_acc_ensemble: 0.7587 - val_acc_1: 0.7107 - val_acc_2: 0.7256 - val_acc_3: 0.7180\n",
      "Epoch 15/50\n",
      "100/100 - 8s - loss_1: 0.6734 - loss_2: 0.6518 - loss_3: 0.6295 - acc_ensemble: 0.8080 - acc_1: 0.7680 - acc_2: 0.7680 - acc_3: 0.7620 - val_loss_1: 0.7772 - val_loss_2: 0.7884 - val_loss_3: 0.7717 - val_acc_ensemble: 0.7714 - val_acc_1: 0.7207 - val_acc_2: 0.7223 - val_acc_3: 0.7215\n",
      "Epoch 16/50\n",
      "100/100 - 8s - loss_1: 0.6520 - loss_2: 0.6265 - loss_3: 0.6250 - acc_ensemble: 0.8220 - acc_1: 0.7880 - acc_2: 0.7520 - acc_3: 0.7940 - val_loss_1: 0.7476 - val_loss_2: 0.7968 - val_loss_3: 0.7499 - val_acc_ensemble: 0.7738 - val_acc_1: 0.7351 - val_acc_2: 0.7168 - val_acc_3: 0.7400\n",
      "Epoch 17/50\n",
      "100/100 - 8s - loss_1: 0.6515 - loss_2: 0.6015 - loss_3: 0.5890 - acc_ensemble: 0.8220 - acc_1: 0.7840 - acc_2: 0.7880 - acc_3: 0.7880 - val_loss_1: 0.7466 - val_loss_2: 0.7596 - val_loss_3: 0.7293 - val_acc_ensemble: 0.7763 - val_acc_1: 0.7316 - val_acc_2: 0.7305 - val_acc_3: 0.7431\n",
      "Epoch 18/50\n",
      "100/100 - 9s - loss_1: 0.6043 - loss_2: 0.5635 - loss_3: 0.5836 - acc_ensemble: 0.8380 - acc_1: 0.7760 - acc_2: 0.8080 - acc_3: 0.7960 - val_loss_1: 0.7685 - val_loss_2: 0.7258 - val_loss_3: 0.7364 - val_acc_ensemble: 0.7866 - val_acc_1: 0.7308 - val_acc_2: 0.7472 - val_acc_3: 0.7419\n",
      "Epoch 19/50\n",
      "100/100 - 8s - loss_1: 0.5678 - loss_2: 0.5424 - loss_3: 0.5633 - acc_ensemble: 0.8440 - acc_1: 0.7980 - acc_2: 0.8040 - acc_3: 0.8020 - val_loss_1: 0.7127 - val_loss_2: 0.7613 - val_loss_3: 0.7017 - val_acc_ensemble: 0.7910 - val_acc_1: 0.7463 - val_acc_2: 0.7301 - val_acc_3: 0.7563\n",
      "Epoch 20/50\n",
      "100/100 - 9s - loss_1: 0.5583 - loss_2: 0.5068 - loss_3: 0.4898 - acc_ensemble: 0.8500 - acc_1: 0.7800 - acc_2: 0.8160 - acc_3: 0.8120 - val_loss_1: 0.7301 - val_loss_2: 0.7298 - val_loss_3: 0.6807 - val_acc_ensemble: 0.7962 - val_acc_1: 0.7433 - val_acc_2: 0.7498 - val_acc_3: 0.7649\n",
      "Epoch 21/50\n",
      "100/100 - 8s - loss_1: 0.5273 - loss_2: 0.4749 - loss_3: 0.5165 - acc_ensemble: 0.8540 - acc_1: 0.7940 - acc_2: 0.7900 - acc_3: 0.8100 - val_loss_1: 0.7115 - val_loss_2: 0.7456 - val_loss_3: 0.7170 - val_acc_ensemble: 0.7971 - val_acc_1: 0.7526 - val_acc_2: 0.7444 - val_acc_3: 0.7526\n",
      "Epoch 22/50\n",
      "100/100 - 9s - loss_1: 0.5063 - loss_2: 0.5026 - loss_3: 0.4804 - acc_ensemble: 0.8500 - acc_1: 0.8360 - acc_2: 0.8160 - acc_3: 0.8000 - val_loss_1: 0.6848 - val_loss_2: 0.6960 - val_loss_3: 0.7281 - val_acc_ensemble: 0.8014 - val_acc_1: 0.7641 - val_acc_2: 0.7634 - val_acc_3: 0.7485\n",
      "Epoch 23/50\n",
      "100/100 - 9s - loss_1: 0.4986 - loss_2: 0.4681 - loss_3: 0.4626 - acc_ensemble: 0.8660 - acc_1: 0.8200 - acc_2: 0.8200 - acc_3: 0.8040 - val_loss_1: 0.7169 - val_loss_2: 0.7023 - val_loss_3: 0.7015 - val_acc_ensemble: 0.8059 - val_acc_1: 0.7562 - val_acc_2: 0.7593 - val_acc_3: 0.7589\n",
      "Epoch 24/50\n",
      "100/100 - 9s - loss_1: 0.4779 - loss_2: 0.4443 - loss_3: 0.3971 - acc_ensemble: 0.8580 - acc_1: 0.8120 - acc_2: 0.8200 - acc_3: 0.8360 - val_loss_1: 0.6977 - val_loss_2: 0.7105 - val_loss_3: 0.7175 - val_acc_ensemble: 0.8064 - val_acc_1: 0.7593 - val_acc_2: 0.7589 - val_acc_3: 0.7541\n",
      "Epoch 25/50\n",
      "100/100 - 8s - loss_1: 0.4496 - loss_2: 0.4163 - loss_3: 0.4107 - acc_ensemble: 0.8500 - acc_1: 0.8000 - acc_2: 0.8100 - acc_3: 0.8140 - val_loss_1: 0.7207 - val_loss_2: 0.7190 - val_loss_3: 0.6569 - val_acc_ensemble: 0.8102 - val_acc_1: 0.7555 - val_acc_2: 0.7594 - val_acc_3: 0.7738\n",
      "Epoch 26/50\n",
      "100/100 - 8s - loss_1: 0.4151 - loss_2: 0.3963 - loss_3: 0.4100 - acc_ensemble: 0.8740 - acc_1: 0.7960 - acc_2: 0.8220 - acc_3: 0.8380 - val_loss_1: 0.7071 - val_loss_2: 0.6896 - val_loss_3: 0.6709 - val_acc_ensemble: 0.8142 - val_acc_1: 0.7606 - val_acc_2: 0.7685 - val_acc_3: 0.7739\n",
      "Epoch 27/50\n",
      "100/100 - 9s - loss_1: 0.4357 - loss_2: 0.3508 - loss_3: 0.3740 - acc_ensemble: 0.8900 - acc_1: 0.8320 - acc_2: 0.8280 - acc_3: 0.8460 - val_loss_1: 0.6930 - val_loss_2: 0.6875 - val_loss_3: 0.6941 - val_acc_ensemble: 0.8168 - val_acc_1: 0.7637 - val_acc_2: 0.7717 - val_acc_3: 0.7631\n",
      "Epoch 28/50\n",
      "100/100 - 8s - loss_1: 0.3656 - loss_2: 0.3228 - loss_3: 0.3409 - acc_ensemble: 0.8960 - acc_1: 0.8400 - acc_2: 0.8500 - acc_3: 0.8460 - val_loss_1: 0.6655 - val_loss_2: 0.6998 - val_loss_3: 0.6791 - val_acc_ensemble: 0.8215 - val_acc_1: 0.7765 - val_acc_2: 0.7696 - val_acc_3: 0.7802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50\n",
      "100/100 - 8s - loss_1: 0.3762 - loss_2: 0.3358 - loss_3: 0.3364 - acc_ensemble: 0.9000 - acc_1: 0.8180 - acc_2: 0.8560 - acc_3: 0.8520 - val_loss_1: 0.7129 - val_loss_2: 0.6971 - val_loss_3: 0.6696 - val_acc_ensemble: 0.8211 - val_acc_1: 0.7650 - val_acc_2: 0.7735 - val_acc_3: 0.7736\n",
      "Epoch 30/50\n",
      "100/100 - 8s - loss_1: 0.3528 - loss_2: 0.3003 - loss_3: 0.3357 - acc_ensemble: 0.9040 - acc_1: 0.8220 - acc_2: 0.8480 - acc_3: 0.8520 - val_loss_1: 0.7114 - val_loss_2: 0.7258 - val_loss_3: 0.6581 - val_acc_ensemble: 0.8219 - val_acc_1: 0.7648 - val_acc_2: 0.7670 - val_acc_3: 0.7827\n",
      "Epoch 31/50\n",
      "100/100 - 8s - loss_1: 0.3245 - loss_2: 0.3240 - loss_3: 0.3001 - acc_ensemble: 0.9020 - acc_1: 0.8340 - acc_2: 0.8420 - acc_3: 0.8480 - val_loss_1: 0.6893 - val_loss_2: 0.6817 - val_loss_3: 0.6908 - val_acc_ensemble: 0.8298 - val_acc_1: 0.7775 - val_acc_2: 0.7751 - val_acc_3: 0.7775\n",
      "Epoch 32/50\n",
      "100/100 - 9s - loss_1: 0.3534 - loss_2: 0.2922 - loss_3: 0.2757 - acc_ensemble: 0.8960 - acc_1: 0.8360 - acc_2: 0.8420 - acc_3: 0.8640 - val_loss_1: 0.7189 - val_loss_2: 0.6883 - val_loss_3: 0.6947 - val_acc_ensemble: 0.8289 - val_acc_1: 0.7656 - val_acc_2: 0.7754 - val_acc_3: 0.7809\n",
      "Epoch 33/50\n",
      "100/100 - 8s - loss_1: 0.3208 - loss_2: 0.2641 - loss_3: 0.2606 - acc_ensemble: 0.9060 - acc_1: 0.8660 - acc_2: 0.8440 - acc_3: 0.8680 - val_loss_1: 0.6707 - val_loss_2: 0.7170 - val_loss_3: 0.6878 - val_acc_ensemble: 0.8301 - val_acc_1: 0.7825 - val_acc_2: 0.7704 - val_acc_3: 0.7844\n",
      "Epoch 34/50\n",
      "100/100 - 8s - loss_1: 0.2650 - loss_2: 0.2645 - loss_3: 0.2410 - acc_ensemble: 0.9080 - acc_1: 0.8460 - acc_2: 0.8320 - acc_3: 0.8640 - val_loss_1: 0.7249 - val_loss_2: 0.7474 - val_loss_3: 0.6891 - val_acc_ensemble: 0.8249 - val_acc_1: 0.7705 - val_acc_2: 0.7682 - val_acc_3: 0.7819\n",
      "Epoch 35/50\n",
      "100/100 - 8s - loss_1: 0.2813 - loss_2: 0.2516 - loss_3: 0.2492 - acc_ensemble: 0.9000 - acc_1: 0.8560 - acc_2: 0.8440 - acc_3: 0.8560 - val_loss_1: 0.6973 - val_loss_2: 0.7526 - val_loss_3: 0.7004 - val_acc_ensemble: 0.8285 - val_acc_1: 0.7807 - val_acc_2: 0.7690 - val_acc_3: 0.7836\n",
      "Epoch 36/50\n",
      "100/100 - 9s - loss_1: 0.2734 - loss_2: 0.2287 - loss_3: 0.2352 - acc_ensemble: 0.9100 - acc_1: 0.8600 - acc_2: 0.8260 - acc_3: 0.8780 - val_loss_1: 0.6792 - val_loss_2: 0.7607 - val_loss_3: 0.6932 - val_acc_ensemble: 0.8303 - val_acc_1: 0.7865 - val_acc_2: 0.7665 - val_acc_3: 0.7838\n",
      "Epoch 37/50\n",
      "100/100 - 8s - loss_1: 0.2351 - loss_2: 0.2196 - loss_3: 0.2485 - acc_ensemble: 0.9080 - acc_1: 0.8440 - acc_2: 0.8500 - acc_3: 0.8600 - val_loss_1: 0.7054 - val_loss_2: 0.7190 - val_loss_3: 0.7503 - val_acc_ensemble: 0.8274 - val_acc_1: 0.7768 - val_acc_2: 0.7809 - val_acc_3: 0.7722\n",
      "Epoch 38/50\n",
      "100/100 - 8s - loss_1: 0.2549 - loss_2: 0.2045 - loss_3: 0.2088 - acc_ensemble: 0.9260 - acc_1: 0.8560 - acc_2: 0.8560 - acc_3: 0.8740 - val_loss_1: 0.6954 - val_loss_2: 0.7477 - val_loss_3: 0.6865 - val_acc_ensemble: 0.8324 - val_acc_1: 0.7777 - val_acc_2: 0.7724 - val_acc_3: 0.7883\n",
      "Epoch 39/50\n",
      "100/100 - 9s - loss_1: 0.2159 - loss_2: 0.1920 - loss_3: 0.1885 - acc_ensemble: 0.9160 - acc_1: 0.8440 - acc_2: 0.8500 - acc_3: 0.8980 - val_loss_1: 0.7298 - val_loss_2: 0.7342 - val_loss_3: 0.7166 - val_acc_ensemble: 0.8325 - val_acc_1: 0.7781 - val_acc_2: 0.7829 - val_acc_3: 0.7875\n",
      "Epoch 40/50\n",
      "100/100 - 8s - loss_1: 0.2157 - loss_2: 0.2000 - loss_3: 0.1840 - acc_ensemble: 0.9080 - acc_1: 0.8500 - acc_2: 0.8380 - acc_3: 0.8840 - val_loss_1: 0.7361 - val_loss_2: 0.7662 - val_loss_3: 0.7211 - val_acc_ensemble: 0.8291 - val_acc_1: 0.7735 - val_acc_2: 0.7790 - val_acc_3: 0.7845\n",
      "Epoch 41/50\n",
      "100/100 - 8s - loss_1: 0.1976 - loss_2: 0.1746 - loss_3: 0.1726 - acc_ensemble: 0.9300 - acc_1: 0.8340 - acc_2: 0.8740 - acc_3: 0.8800 - val_loss_1: 0.7580 - val_loss_2: 0.7397 - val_loss_3: 0.7206 - val_acc_ensemble: 0.8352 - val_acc_1: 0.7743 - val_acc_2: 0.7862 - val_acc_3: 0.7921\n",
      "Epoch 42/50\n",
      "100/100 - 9s - loss_1: 0.2175 - loss_2: 0.1682 - loss_3: 0.1675 - acc_ensemble: 0.9240 - acc_1: 0.8580 - acc_2: 0.8760 - acc_3: 0.8600 - val_loss_1: 0.7587 - val_loss_2: 0.7423 - val_loss_3: 0.7889 - val_acc_ensemble: 0.8348 - val_acc_1: 0.7798 - val_acc_2: 0.7877 - val_acc_3: 0.7723\n",
      "Epoch 43/50\n",
      "100/100 - 8s - loss_1: 0.2005 - loss_2: 0.1735 - loss_3: 0.1798 - acc_ensemble: 0.9140 - acc_1: 0.8540 - acc_2: 0.8700 - acc_3: 0.9040 - val_loss_1: 0.7328 - val_loss_2: 0.7712 - val_loss_3: 0.7543 - val_acc_ensemble: 0.8364 - val_acc_1: 0.7853 - val_acc_2: 0.7790 - val_acc_3: 0.7839\n",
      "Epoch 44/50\n",
      "100/100 - 9s - loss_1: 0.1651 - loss_2: 0.1593 - loss_3: 0.1715 - acc_ensemble: 0.9300 - acc_1: 0.8720 - acc_2: 0.8840 - acc_3: 0.8960 - val_loss_1: 0.7582 - val_loss_2: 0.7908 - val_loss_3: 0.7184 - val_acc_ensemble: 0.8375 - val_acc_1: 0.7780 - val_acc_2: 0.7755 - val_acc_3: 0.7933\n",
      "Epoch 45/50\n",
      "100/100 - 8s - loss_1: 0.1525 - loss_2: 0.1621 - loss_3: 0.1483 - acc_ensemble: 0.9300 - acc_1: 0.8580 - acc_2: 0.8640 - acc_3: 0.8840 - val_loss_1: 0.7195 - val_loss_2: 0.7546 - val_loss_3: 0.7508 - val_acc_ensemble: 0.8405 - val_acc_1: 0.7893 - val_acc_2: 0.7812 - val_acc_3: 0.7882\n",
      "Epoch 46/50\n",
      "100/100 - 9s - loss_1: 0.1399 - loss_2: 0.1370 - loss_3: 0.1612 - acc_ensemble: 0.9280 - acc_1: 0.8560 - acc_2: 0.8780 - acc_3: 0.8840 - val_loss_1: 0.7610 - val_loss_2: 0.7569 - val_loss_3: 0.7583 - val_acc_ensemble: 0.8393 - val_acc_1: 0.7842 - val_acc_2: 0.7883 - val_acc_3: 0.7883\n",
      "Epoch 47/50\n",
      "100/100 - 8s - loss_1: 0.1640 - loss_2: 0.1124 - loss_3: 0.1328 - acc_ensemble: 0.9380 - acc_1: 0.8620 - acc_2: 0.8740 - acc_3: 0.8900 - val_loss_1: 0.7858 - val_loss_2: 0.7361 - val_loss_3: 0.7855 - val_acc_ensemble: 0.8408 - val_acc_1: 0.7785 - val_acc_2: 0.7935 - val_acc_3: 0.7860\n",
      "Epoch 48/50\n",
      "100/100 - 8s - loss_1: 0.1364 - loss_2: 0.1208 - loss_3: 0.1351 - acc_ensemble: 0.9340 - acc_1: 0.8580 - acc_2: 0.8700 - acc_3: 0.9080 - val_loss_1: 0.7804 - val_loss_2: 0.7889 - val_loss_3: 0.7578 - val_acc_ensemble: 0.8420 - val_acc_1: 0.7895 - val_acc_2: 0.7854 - val_acc_3: 0.7914\n",
      "Epoch 49/50\n",
      "100/100 - 8s - loss_1: 0.1495 - loss_2: 0.1211 - loss_3: 0.1123 - acc_ensemble: 0.9300 - acc_1: 0.8520 - acc_2: 0.8600 - acc_3: 0.9000 - val_loss_1: 0.7994 - val_loss_2: 0.8111 - val_loss_3: 0.7648 - val_acc_ensemble: 0.8399 - val_acc_1: 0.7802 - val_acc_2: 0.7797 - val_acc_3: 0.7931\n",
      "Epoch 50/50\n",
      "100/100 - 9s - loss_1: 0.1227 - loss_2: 0.1172 - loss_3: 0.0955 - acc_ensemble: 0.9360 - acc_1: 0.8640 - acc_2: 0.8720 - acc_3: 0.8940 - val_loss_1: 0.7728 - val_loss_2: 0.8165 - val_loss_3: 0.8134 - val_acc_ensemble: 0.8392 - val_acc_1: 0.7885 - val_acc_2: 0.7823 - val_acc_3: 0.7839\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B3/S0.00/model_4\n",
      "i   Layer name                      Output shape        Num param  Inbound            \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                    \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                    \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                    \n",
      "--------------------------------------------------------------------------------------\n",
      "0   conv2d_1_1 (Conv2D)             [] [None,32,32,32]  2688       input              \n",
      "                                    [] [None,32,32,32]                                \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "1   bn_1_1 (BatchNormalization)     [] [None,32,32,32]  192        conv2d_1_1         \n",
      "                                    [] [None,32,32,32]                                \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "2   relu_1_1 (Activation)           [] [None,32,32,32]  0          bn_1_1             \n",
      "                                    [] [None,32,32,32]                                \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "3   conv2d_1_2 (Conv2D)             [] [None,32,32,32]  27744      relu_1_1           \n",
      "                                    [] [None,32,32,32]                                \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "4   bn_1_2 (BatchNormalization)     [] [None,32,32,32]  192        conv2d_1_2         \n",
      "                                    [] [None,32,32,32]                                \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "5   relu_1_2 (Activation)           [] [None,32,32,32]  0          bn_1_2             \n",
      "                                    [] [None,32,32,32]                                \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "6   avg_pool2d_1 (AveragePooling2D  [] [None,16,16,32]  0          relu_1_2           \n",
      "                                    [] [None,16,16,32]                                \n",
      "                                    [] [None,16,16,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "7   conv2d_2_1 (Conv2D)             [] [None,16,16,64]  55488      avg_pool2d_1       \n",
      "                                    [] [None,16,16,64]                                \n",
      "                                    [] [None,16,16,64]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "8   bn_2_1 (BatchNormalization)     [] [None,16,16,64]  384        conv2d_2_1         \n",
      "                                    [] [None,16,16,64]                                \n",
      "                                    [] [None,16,16,64]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "9   relu_2_1 (Activation)           [] [None,16,16,64]  0          bn_2_1             \n",
      "                                    [] [None,16,16,64]                                \n",
      "                                    [] [None,16,16,64]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "10  conv2d_2_2 (Conv2D)             [] [None,16,16,64]  110784     relu_2_1           \n",
      "                                    [] [None,16,16,64]                                \n",
      "                                    [] [None,16,16,64]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "11  bn_2_2 (BatchNormalization)     [] [None,16,16,64]  384        conv2d_2_2         \n",
      "                                    [] [None,16,16,64]                                \n",
      "                                    [] [None,16,16,64]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "12  relu_2_2 (Activation)           [] [None,16,16,64]  0          bn_2_2             \n",
      "                                    [] [None,16,16,64]                                \n",
      "                                    [] [None,16,16,64]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "13  avg_pool2d_2 (AveragePooling2D  [] [None,8,8,64]    0          relu_2_2           \n",
      "                                    [] [None,8,8,64]                                  \n",
      "                                    [] [None,8,8,64]                                  \n",
      "--------------------------------------------------------------------------------------\n",
      "14  conv2d_3_1 (Conv2D)             [] [None,8,8,128]   221568     avg_pool2d_2       \n",
      "                                    [] [None,8,8,128]                                 \n",
      "                                    [] [None,8,8,128]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "15  bn_3_1 (BatchNormalization)     [] [None,8,8,128]   768        conv2d_3_1         \n",
      "                                    [] [None,8,8,128]                                 \n",
      "                                    [] [None,8,8,128]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "16  relu_3_1 (Activation)           [] [None,8,8,128]   0          bn_3_1             \n",
      "                                    [] [None,8,8,128]                                 \n",
      "                                    [] [None,8,8,128]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "17  conv2d_3_2 (Conv2D)             [] [None,8,8,128]   442752     relu_3_1           \n",
      "                                    [] [None,8,8,128]                                 \n",
      "                                    [] [None,8,8,128]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "18  bn_3_2 (BatchNormalization)     [] [None,8,8,128]   768        conv2d_3_2         \n",
      "                                    [] [None,8,8,128]                                 \n",
      "                                    [] [None,8,8,128]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "19  relu_3_2 (Activation)           [] [None,8,8,128]   0          bn_3_2             \n",
      "                                    [] [None,8,8,128]                                 \n",
      "                                    [] [None,8,8,128]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "20  global_avg_pool2d (GlobalAvera  [] [None,128]       0          relu_3_2           \n",
      "                                    [] [None,128]                                     \n",
      "                                    [] [None,128]                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "21  fc1 (Dense)                     [] [None,128]       49536      global_avg_pool2d  \n",
      "                                    [] [None,128]                                     \n",
      "                                    [] [None,128]                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "22  bn_fc1 (BatchNormalization)     [] [None,128]       768        fc1                \n",
      "                                    [] [None,128]                                     \n",
      "                                    [] [None,128]                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "23  relu_fc1 (Activation)           [] [None,128]       0          bn_fc1             \n",
      "                                    [] [None,128]                                     \n",
      "                                    [] [None,128]                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "24  output (Dense)                  [None,10]           3870       relu_fc1           \n",
      "                                    [None,10]                                         \n",
      "                                    [None,10]                                         \n",
      "--------------------------------------------------------------------------------------\n",
      "Total parameters: 917886\n",
      "50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 - 10s - loss_1: 1.8042 - loss_2: 1.7882 - loss_3: 1.7473 - acc_ensemble: 0.5000 - acc_1: 0.4440 - acc_2: 0.4560 - acc_3: 0.4460 - val_loss_1: 1.5579 - val_loss_2: 1.5991 - val_loss_3: 1.5322 - val_acc_ensemble: 0.4624 - val_acc_1: 0.4137 - val_acc_2: 0.4034 - val_acc_3: 0.4327\n",
      "Epoch 2/50\n",
      "100/100 - 9s - loss_1: 1.4880 - loss_2: 1.4683 - loss_3: 1.4662 - acc_ensemble: 0.5480 - acc_1: 0.5240 - acc_2: 0.5140 - acc_3: 0.4980 - val_loss_1: 1.3797 - val_loss_2: 1.3511 - val_loss_3: 1.3835 - val_acc_ensemble: 0.5447 - val_acc_1: 0.4871 - val_acc_2: 0.5046 - val_acc_3: 0.5042\n",
      "Epoch 3/50\n",
      "100/100 - 8s - loss_1: 1.3573 - loss_2: 1.3003 - loss_3: 1.2905 - acc_ensemble: 0.5980 - acc_1: 0.5380 - acc_2: 0.5280 - acc_3: 0.5740 - val_loss_1: 1.2585 - val_loss_2: 1.3767 - val_loss_3: 1.2140 - val_acc_ensemble: 0.5852 - val_acc_1: 0.5370 - val_acc_2: 0.5102 - val_acc_3: 0.5647\n",
      "Epoch 4/50\n",
      "100/100 - 8s - loss_1: 1.2177 - loss_2: 1.1980 - loss_3: 1.1673 - acc_ensemble: 0.6460 - acc_1: 0.5840 - acc_2: 0.5980 - acc_3: 0.6460 - val_loss_1: 1.2105 - val_loss_2: 1.1479 - val_loss_3: 1.1027 - val_acc_ensemble: 0.6355 - val_acc_1: 0.5609 - val_acc_2: 0.5854 - val_acc_3: 0.6055\n",
      "Epoch 5/50\n",
      "100/100 - 8s - loss_1: 1.1251 - loss_2: 1.0918 - loss_3: 1.0833 - acc_ensemble: 0.6920 - acc_1: 0.6360 - acc_2: 0.6120 - acc_3: 0.6660 - val_loss_1: 1.0709 - val_loss_2: 1.1207 - val_loss_3: 1.0331 - val_acc_ensemble: 0.6566 - val_acc_1: 0.6126 - val_acc_2: 0.5947 - val_acc_3: 0.6289\n",
      "Epoch 6/50\n",
      "100/100 - 8s - loss_1: 1.0729 - loss_2: 1.0370 - loss_3: 1.0240 - acc_ensemble: 0.7080 - acc_1: 0.6500 - acc_2: 0.6740 - acc_3: 0.6620 - val_loss_1: 1.0440 - val_loss_2: 0.9999 - val_loss_3: 1.0140 - val_acc_ensemble: 0.6754 - val_acc_1: 0.6230 - val_acc_2: 0.6447 - val_acc_3: 0.6392\n",
      "Epoch 7/50\n",
      "100/100 - 8s - loss_1: 0.9702 - loss_2: 0.9541 - loss_3: 0.9582 - acc_ensemble: 0.7220 - acc_1: 0.6800 - acc_2: 0.6820 - acc_3: 0.6700 - val_loss_1: 0.9655 - val_loss_2: 0.9773 - val_loss_3: 0.9849 - val_acc_ensemble: 0.6957 - val_acc_1: 0.6597 - val_acc_2: 0.6485 - val_acc_3: 0.6461\n",
      "Epoch 8/50\n",
      "100/100 - 8s - loss_1: 0.9191 - loss_2: 0.8862 - loss_3: 0.8905 - acc_ensemble: 0.7320 - acc_1: 0.6820 - acc_2: 0.7000 - acc_3: 0.6900 - val_loss_1: 0.9491 - val_loss_2: 0.9290 - val_loss_3: 0.9132 - val_acc_ensemble: 0.7111 - val_acc_1: 0.6602 - val_acc_2: 0.6722 - val_acc_3: 0.6745\n",
      "Epoch 9/50\n",
      "100/100 - 8s - loss_1: 0.8525 - loss_2: 0.8518 - loss_3: 0.8352 - acc_ensemble: 0.7520 - acc_1: 0.7180 - acc_2: 0.6900 - acc_3: 0.6880 - val_loss_1: 0.8959 - val_loss_2: 0.9033 - val_loss_3: 0.9059 - val_acc_ensemble: 0.7265 - val_acc_1: 0.6829 - val_acc_2: 0.6805 - val_acc_3: 0.6805\n",
      "Epoch 10/50\n",
      "100/100 - 8s - loss_1: 0.8432 - loss_2: 0.8196 - loss_3: 0.7902 - acc_ensemble: 0.7620 - acc_1: 0.7160 - acc_2: 0.7340 - acc_3: 0.7020 - val_loss_1: 0.8705 - val_loss_2: 0.8576 - val_loss_3: 0.8406 - val_acc_ensemble: 0.7364 - val_acc_1: 0.6895 - val_acc_2: 0.6936 - val_acc_3: 0.7052\n",
      "Epoch 11/50\n",
      "100/100 - 8s - loss_1: 0.7765 - loss_2: 0.7706 - loss_3: 0.7295 - acc_ensemble: 0.7820 - acc_1: 0.7420 - acc_2: 0.7160 - acc_3: 0.7320 - val_loss_1: 0.8342 - val_loss_2: 0.8569 - val_loss_3: 0.8160 - val_acc_ensemble: 0.7455 - val_acc_1: 0.7004 - val_acc_2: 0.7021 - val_acc_3: 0.7149\n",
      "Epoch 12/50\n",
      "100/100 - 8s - loss_1: 0.7420 - loss_2: 0.7395 - loss_3: 0.7118 - acc_ensemble: 0.8020 - acc_1: 0.7560 - acc_2: 0.7520 - acc_3: 0.7600 - val_loss_1: 0.8334 - val_loss_2: 0.7913 - val_loss_3: 0.8140 - val_acc_ensemble: 0.7567 - val_acc_1: 0.7033 - val_acc_2: 0.7219 - val_acc_3: 0.7186\n",
      "Epoch 13/50\n",
      "100/100 - 8s - loss_1: 0.7033 - loss_2: 0.7095 - loss_3: 0.6914 - acc_ensemble: 0.8040 - acc_1: 0.7440 - acc_2: 0.7700 - acc_3: 0.7660 - val_loss_1: 0.8131 - val_loss_2: 0.7898 - val_loss_3: 0.7714 - val_acc_ensemble: 0.7590 - val_acc_1: 0.7145 - val_acc_2: 0.7220 - val_acc_3: 0.7243\n",
      "Epoch 14/50\n",
      "100/100 - 8s - loss_1: 0.6945 - loss_2: 0.6801 - loss_3: 0.6363 - acc_ensemble: 0.8120 - acc_1: 0.7720 - acc_2: 0.7780 - acc_3: 0.7660 - val_loss_1: 0.7638 - val_loss_2: 0.7742 - val_loss_3: 0.7554 - val_acc_ensemble: 0.7704 - val_acc_1: 0.7328 - val_acc_2: 0.7295 - val_acc_3: 0.7401\n",
      "Epoch 15/50\n",
      "100/100 - 8s - loss_1: 0.6369 - loss_2: 0.6366 - loss_3: 0.6262 - acc_ensemble: 0.8240 - acc_1: 0.7720 - acc_2: 0.7660 - acc_3: 0.7560 - val_loss_1: 0.7579 - val_loss_2: 0.7504 - val_loss_3: 0.7332 - val_acc_ensemble: 0.7789 - val_acc_1: 0.7349 - val_acc_2: 0.7350 - val_acc_3: 0.7435\n",
      "Epoch 16/50\n",
      "100/100 - 8s - loss_1: 0.6433 - loss_2: 0.5991 - loss_3: 0.5834 - acc_ensemble: 0.8400 - acc_1: 0.7920 - acc_2: 0.7940 - acc_3: 0.7720 - val_loss_1: 0.7420 - val_loss_2: 0.7446 - val_loss_3: 0.7477 - val_acc_ensemble: 0.7797 - val_acc_1: 0.7405 - val_acc_2: 0.7444 - val_acc_3: 0.7420\n",
      "Epoch 17/50\n",
      "100/100 - 8s - loss_1: 0.5804 - loss_2: 0.5987 - loss_3: 0.5524 - acc_ensemble: 0.8500 - acc_1: 0.7860 - acc_2: 0.8060 - acc_3: 0.8160 - val_loss_1: 0.7379 - val_loss_2: 0.7372 - val_loss_3: 0.7126 - val_acc_ensemble: 0.7912 - val_acc_1: 0.7444 - val_acc_2: 0.7437 - val_acc_3: 0.7514\n",
      "Epoch 18/50\n",
      "100/100 - 8s - loss_1: 0.5531 - loss_2: 0.5427 - loss_3: 0.5414 - acc_ensemble: 0.8460 - acc_1: 0.7760 - acc_2: 0.8040 - acc_3: 0.7780 - val_loss_1: 0.7277 - val_loss_2: 0.7191 - val_loss_3: 0.7198 - val_acc_ensemble: 0.7955 - val_acc_1: 0.7471 - val_acc_2: 0.7513 - val_acc_3: 0.7486\n",
      "Epoch 19/50\n",
      "100/100 - 8s - loss_1: 0.4967 - loss_2: 0.5249 - loss_3: 0.5315 - acc_ensemble: 0.8620 - acc_1: 0.8120 - acc_2: 0.8200 - acc_3: 0.7820 - val_loss_1: 0.7177 - val_loss_2: 0.6857 - val_loss_3: 0.7099 - val_acc_ensemble: 0.7966 - val_acc_1: 0.7527 - val_acc_2: 0.7649 - val_acc_3: 0.7549\n",
      "Epoch 20/50\n",
      "100/100 - 8s - loss_1: 0.5328 - loss_2: 0.4703 - loss_3: 0.4597 - acc_ensemble: 0.8620 - acc_1: 0.7820 - acc_2: 0.8160 - acc_3: 0.7940 - val_loss_1: 0.7366 - val_loss_2: 0.7075 - val_loss_3: 0.7148 - val_acc_ensemble: 0.7958 - val_acc_1: 0.7499 - val_acc_2: 0.7588 - val_acc_3: 0.7553\n",
      "Epoch 21/50\n",
      "100/100 - 8s - loss_1: 0.5055 - loss_2: 0.4948 - loss_3: 0.4757 - acc_ensemble: 0.8840 - acc_1: 0.8160 - acc_2: 0.7960 - acc_3: 0.8160 - val_loss_1: 0.7170 - val_loss_2: 0.7331 - val_loss_3: 0.6652 - val_acc_ensemble: 0.8055 - val_acc_1: 0.7524 - val_acc_2: 0.7482 - val_acc_3: 0.7704\n",
      "Epoch 22/50\n",
      "100/100 - 8s - loss_1: 0.4677 - loss_2: 0.4806 - loss_3: 0.4352 - acc_ensemble: 0.8700 - acc_1: 0.8320 - acc_2: 0.8280 - acc_3: 0.7900 - val_loss_1: 0.7113 - val_loss_2: 0.6847 - val_loss_3: 0.6848 - val_acc_ensemble: 0.8101 - val_acc_1: 0.7578 - val_acc_2: 0.7725 - val_acc_3: 0.7693\n",
      "Epoch 23/50\n",
      "100/100 - 8s - loss_1: 0.4586 - loss_2: 0.4655 - loss_3: 0.4241 - acc_ensemble: 0.8840 - acc_1: 0.8260 - acc_2: 0.8040 - acc_3: 0.8400 - val_loss_1: 0.6806 - val_loss_2: 0.7084 - val_loss_3: 0.6763 - val_acc_ensemble: 0.8124 - val_acc_1: 0.7691 - val_acc_2: 0.7526 - val_acc_3: 0.7712\n",
      "Epoch 24/50\n",
      "100/100 - 8s - loss_1: 0.4342 - loss_2: 0.4228 - loss_3: 0.4030 - acc_ensemble: 0.8860 - acc_1: 0.8280 - acc_2: 0.8240 - acc_3: 0.8340 - val_loss_1: 0.6904 - val_loss_2: 0.6998 - val_loss_3: 0.6548 - val_acc_ensemble: 0.8112 - val_acc_1: 0.7663 - val_acc_2: 0.7662 - val_acc_3: 0.7796\n",
      "Epoch 25/50\n",
      "100/100 - 8s - loss_1: 0.4052 - loss_2: 0.3997 - loss_3: 0.3685 - acc_ensemble: 0.8960 - acc_1: 0.8420 - acc_2: 0.8600 - acc_3: 0.8120 - val_loss_1: 0.6771 - val_loss_2: 0.6505 - val_loss_3: 0.6545 - val_acc_ensemble: 0.8198 - val_acc_1: 0.7750 - val_acc_2: 0.7833 - val_acc_3: 0.7829\n",
      "Epoch 26/50\n",
      "100/100 - 8s - loss_1: 0.3905 - loss_2: 0.3915 - loss_3: 0.3669 - acc_ensemble: 0.8960 - acc_1: 0.8300 - acc_2: 0.8660 - acc_3: 0.8340 - val_loss_1: 0.6730 - val_loss_2: 0.6844 - val_loss_3: 0.6753 - val_acc_ensemble: 0.8240 - val_acc_1: 0.7782 - val_acc_2: 0.7716 - val_acc_3: 0.7764\n",
      "Epoch 27/50\n",
      "100/100 - 9s - loss_1: 0.3787 - loss_2: 0.3514 - loss_3: 0.3733 - acc_ensemble: 0.8880 - acc_1: 0.8320 - acc_2: 0.8420 - acc_3: 0.8300 - val_loss_1: 0.7105 - val_loss_2: 0.6778 - val_loss_3: 0.6739 - val_acc_ensemble: 0.8264 - val_acc_1: 0.7644 - val_acc_2: 0.7738 - val_acc_3: 0.7837\n",
      "Epoch 28/50\n",
      "100/100 - 8s - loss_1: 0.3601 - loss_2: 0.3655 - loss_3: 0.3349 - acc_ensemble: 0.8960 - acc_1: 0.8220 - acc_2: 0.8500 - acc_3: 0.8160 - val_loss_1: 0.7002 - val_loss_2: 0.6490 - val_loss_3: 0.6783 - val_acc_ensemble: 0.8255 - val_acc_1: 0.7676 - val_acc_2: 0.7838 - val_acc_3: 0.7760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50\n",
      "100/100 - 8s - loss_1: 0.3399 - loss_2: 0.3745 - loss_3: 0.2897 - acc_ensemble: 0.8920 - acc_1: 0.8260 - acc_2: 0.8340 - acc_3: 0.8400 - val_loss_1: 0.7086 - val_loss_2: 0.7108 - val_loss_3: 0.6575 - val_acc_ensemble: 0.8169 - val_acc_1: 0.7663 - val_acc_2: 0.7658 - val_acc_3: 0.7827\n",
      "Epoch 30/50\n",
      "100/100 - 8s - loss_1: 0.2960 - loss_2: 0.3215 - loss_3: 0.2898 - acc_ensemble: 0.8900 - acc_1: 0.8420 - acc_2: 0.8540 - acc_3: 0.8380 - val_loss_1: 0.6908 - val_loss_2: 0.6661 - val_loss_3: 0.6696 - val_acc_ensemble: 0.8263 - val_acc_1: 0.7738 - val_acc_2: 0.7840 - val_acc_3: 0.7821\n",
      "Epoch 31/50\n",
      "100/100 - 8s - loss_1: 0.3195 - loss_2: 0.2921 - loss_3: 0.2956 - acc_ensemble: 0.9100 - acc_1: 0.8440 - acc_2: 0.8640 - acc_3: 0.8380 - val_loss_1: 0.6797 - val_loss_2: 0.6888 - val_loss_3: 0.6545 - val_acc_ensemble: 0.8310 - val_acc_1: 0.7756 - val_acc_2: 0.7805 - val_acc_3: 0.7879\n",
      "Epoch 32/50\n",
      "100/100 - 8s - loss_1: 0.2727 - loss_2: 0.2737 - loss_3: 0.3047 - acc_ensemble: 0.9100 - acc_1: 0.8580 - acc_2: 0.8700 - acc_3: 0.8340 - val_loss_1: 0.6998 - val_loss_2: 0.7093 - val_loss_3: 0.6727 - val_acc_ensemble: 0.8330 - val_acc_1: 0.7774 - val_acc_2: 0.7780 - val_acc_3: 0.7823\n",
      "Epoch 33/50\n",
      "100/100 - 8s - loss_1: 0.2590 - loss_2: 0.2755 - loss_3: 0.2550 - acc_ensemble: 0.9160 - acc_1: 0.8560 - acc_2: 0.8660 - acc_3: 0.8600 - val_loss_1: 0.6706 - val_loss_2: 0.6987 - val_loss_3: 0.6613 - val_acc_ensemble: 0.8331 - val_acc_1: 0.7897 - val_acc_2: 0.7804 - val_acc_3: 0.7862\n",
      "Epoch 34/50\n",
      "100/100 - 8s - loss_1: 0.2296 - loss_2: 0.2959 - loss_3: 0.2261 - acc_ensemble: 0.9080 - acc_1: 0.8480 - acc_2: 0.8600 - acc_3: 0.8540 - val_loss_1: 0.6898 - val_loss_2: 0.6640 - val_loss_3: 0.6654 - val_acc_ensemble: 0.8341 - val_acc_1: 0.7893 - val_acc_2: 0.7866 - val_acc_3: 0.7883\n",
      "Epoch 35/50\n",
      "100/100 - 8s - loss_1: 0.2673 - loss_2: 0.2606 - loss_3: 0.2313 - acc_ensemble: 0.9060 - acc_1: 0.8260 - acc_2: 0.8520 - acc_3: 0.8520 - val_loss_1: 0.7648 - val_loss_2: 0.7071 - val_loss_3: 0.6723 - val_acc_ensemble: 0.8282 - val_acc_1: 0.7637 - val_acc_2: 0.7826 - val_acc_3: 0.7876\n",
      "Epoch 36/50\n",
      "100/100 - 8s - loss_1: 0.2539 - loss_2: 0.2509 - loss_3: 0.2182 - acc_ensemble: 0.9240 - acc_1: 0.8560 - acc_2: 0.8920 - acc_3: 0.8600 - val_loss_1: 0.7064 - val_loss_2: 0.6746 - val_loss_3: 0.6964 - val_acc_ensemble: 0.8363 - val_acc_1: 0.7810 - val_acc_2: 0.7864 - val_acc_3: 0.7901\n",
      "Epoch 37/50\n",
      "100/100 - 8s - loss_1: 0.2373 - loss_2: 0.1976 - loss_3: 0.2169 - acc_ensemble: 0.9200 - acc_1: 0.8540 - acc_2: 0.8740 - acc_3: 0.8400 - val_loss_1: 0.7192 - val_loss_2: 0.6759 - val_loss_3: 0.7175 - val_acc_ensemble: 0.8410 - val_acc_1: 0.7818 - val_acc_2: 0.7913 - val_acc_3: 0.7836\n",
      "Epoch 38/50\n",
      "100/100 - 8s - loss_1: 0.1843 - loss_2: 0.2246 - loss_3: 0.2106 - acc_ensemble: 0.9280 - acc_1: 0.8540 - acc_2: 0.8780 - acc_3: 0.8680 - val_loss_1: 0.6961 - val_loss_2: 0.7009 - val_loss_3: 0.6922 - val_acc_ensemble: 0.8394 - val_acc_1: 0.7885 - val_acc_2: 0.7856 - val_acc_3: 0.7917\n",
      "Epoch 39/50\n",
      "100/100 - 8s - loss_1: 0.2054 - loss_2: 0.1889 - loss_3: 0.1826 - acc_ensemble: 0.9200 - acc_1: 0.8700 - acc_2: 0.8740 - acc_3: 0.8600 - val_loss_1: 0.7326 - val_loss_2: 0.7256 - val_loss_3: 0.6733 - val_acc_ensemble: 0.8394 - val_acc_1: 0.7760 - val_acc_2: 0.7861 - val_acc_3: 0.7969\n",
      "Epoch 40/50\n",
      "100/100 - 8s - loss_1: 0.2035 - loss_2: 0.1650 - loss_3: 0.1607 - acc_ensemble: 0.9320 - acc_1: 0.8700 - acc_2: 0.8860 - acc_3: 0.8740 - val_loss_1: 0.7108 - val_loss_2: 0.7443 - val_loss_3: 0.7163 - val_acc_ensemble: 0.8354 - val_acc_1: 0.7892 - val_acc_2: 0.7795 - val_acc_3: 0.7964\n",
      "Epoch 41/50\n",
      "100/100 - 8s - loss_1: 0.1545 - loss_2: 0.1821 - loss_3: 0.1646 - acc_ensemble: 0.9260 - acc_1: 0.8620 - acc_2: 0.8980 - acc_3: 0.8640 - val_loss_1: 0.7276 - val_loss_2: 0.7076 - val_loss_3: 0.6754 - val_acc_ensemble: 0.8418 - val_acc_1: 0.7894 - val_acc_2: 0.7929 - val_acc_3: 0.8006\n",
      "Epoch 42/50\n",
      "100/100 - 8s - loss_1: 0.2005 - loss_2: 0.1624 - loss_3: 0.1909 - acc_ensemble: 0.9340 - acc_1: 0.8560 - acc_2: 0.8900 - acc_3: 0.8660 - val_loss_1: 0.7650 - val_loss_2: 0.7116 - val_loss_3: 0.7190 - val_acc_ensemble: 0.8388 - val_acc_1: 0.7788 - val_acc_2: 0.7974 - val_acc_3: 0.7844\n",
      "Epoch 43/50\n",
      "100/100 - 8s - loss_1: 0.1720 - loss_2: 0.1677 - loss_3: 0.1460 - acc_ensemble: 0.9300 - acc_1: 0.8620 - acc_2: 0.8920 - acc_3: 0.8700 - val_loss_1: 0.7753 - val_loss_2: 0.7656 - val_loss_3: 0.7197 - val_acc_ensemble: 0.8417 - val_acc_1: 0.7797 - val_acc_2: 0.7810 - val_acc_3: 0.7939\n",
      "Epoch 44/50\n",
      "100/100 - 8s - loss_1: 0.1678 - loss_2: 0.1541 - loss_3: 0.1235 - acc_ensemble: 0.9360 - acc_1: 0.8520 - acc_2: 0.8880 - acc_3: 0.8680 - val_loss_1: 0.7408 - val_loss_2: 0.7502 - val_loss_3: 0.7203 - val_acc_ensemble: 0.8441 - val_acc_1: 0.7894 - val_acc_2: 0.7922 - val_acc_3: 0.7982\n",
      "Epoch 45/50\n",
      "100/100 - 8s - loss_1: 0.1370 - loss_2: 0.1689 - loss_3: 0.1261 - acc_ensemble: 0.9320 - acc_1: 0.8740 - acc_2: 0.8680 - acc_3: 0.8700 - val_loss_1: 0.7375 - val_loss_2: 0.7654 - val_loss_3: 0.7487 - val_acc_ensemble: 0.8412 - val_acc_1: 0.7903 - val_acc_2: 0.7831 - val_acc_3: 0.7918\n",
      "Epoch 46/50\n",
      "100/100 - 8s - loss_1: 0.1324 - loss_2: 0.1566 - loss_3: 0.1526 - acc_ensemble: 0.9280 - acc_1: 0.8700 - acc_2: 0.8920 - acc_3: 0.8500 - val_loss_1: 0.7518 - val_loss_2: 0.7575 - val_loss_3: 0.7556 - val_acc_ensemble: 0.8362 - val_acc_1: 0.7898 - val_acc_2: 0.7897 - val_acc_3: 0.7884\n",
      "Epoch 47/50\n",
      "100/100 - 8s - loss_1: 0.1342 - loss_2: 0.1344 - loss_3: 0.1351 - acc_ensemble: 0.9320 - acc_1: 0.8600 - acc_2: 0.8880 - acc_3: 0.8640 - val_loss_1: 0.7438 - val_loss_2: 0.7743 - val_loss_3: 0.7601 - val_acc_ensemble: 0.8424 - val_acc_1: 0.7919 - val_acc_2: 0.7897 - val_acc_3: 0.7920\n",
      "Epoch 48/50\n",
      "100/100 - 8s - loss_1: 0.1020 - loss_2: 0.1255 - loss_3: 0.1127 - acc_ensemble: 0.9500 - acc_1: 0.8620 - acc_2: 0.9000 - acc_3: 0.8640 - val_loss_1: 0.7943 - val_loss_2: 0.7660 - val_loss_3: 0.7505 - val_acc_ensemble: 0.8444 - val_acc_1: 0.7889 - val_acc_2: 0.7890 - val_acc_3: 0.7974\n",
      "Epoch 49/50\n",
      "100/100 - 8s - loss_1: 0.1153 - loss_2: 0.1160 - loss_3: 0.0963 - acc_ensemble: 0.9480 - acc_1: 0.8540 - acc_2: 0.9080 - acc_3: 0.8880 - val_loss_1: 0.7699 - val_loss_2: 0.7687 - val_loss_3: 0.7594 - val_acc_ensemble: 0.8463 - val_acc_1: 0.7905 - val_acc_2: 0.7953 - val_acc_3: 0.8009\n",
      "Epoch 50/50\n",
      "100/100 - 8s - loss_1: 0.1288 - loss_2: 0.1333 - loss_3: 0.1044 - acc_ensemble: 0.9480 - acc_1: 0.8740 - acc_2: 0.8920 - acc_3: 0.8800 - val_loss_1: 0.8161 - val_loss_2: 0.7992 - val_loss_3: 0.7718 - val_acc_ensemble: 0.8420 - val_acc_1: 0.7866 - val_acc_2: 0.7872 - val_acc_3: 0.7932\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B3/S0.25/model_1\n",
      "i   Layer name                      Output shape                     Num param  Inbound            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "0   conv2d_1_1 (Conv2D)             [None,32,32,8] [None,32,32,24]   2240       input              \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "1   bn_1_1 (BatchNormalization)     [None,32,32,8] [None,32,32,24]   160        conv2d_1_1         \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "2   relu_1_1 (Activation)           [None,32,32,8] [None,32,32,24]   0          bn_1_1             \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "3   conv2d_1_2 (Conv2D)             [None,32,32,8] [None,32,32,24]   26672      relu_1_1           \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "4   bn_1_2 (BatchNormalization)     [None,32,32,8] [None,32,32,24]   160        conv2d_1_2         \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "5   relu_1_2 (Activation)           [None,32,32,8] [None,32,32,24]   0          bn_1_2             \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "6   avg_pool2d_1 (AveragePooling2D  [None,16,16,8] [None,16,16,24]   0          relu_1_2           \n",
      "                                    [None,16,16,8] [None,16,16,24]                                 \n",
      "                                    [None,16,16,8] [None,16,16,24]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "7   conv2d_2_1 (Conv2D)             [None,16,16,16] [None,16,16,48]  53344      avg_pool2d_1       \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "8   bn_2_1 (BatchNormalization)     [None,16,16,16] [None,16,16,48]  320        conv2d_2_1         \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "9   relu_2_1 (Activation)           [None,16,16,16] [None,16,16,48]  0          bn_2_1             \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "10  conv2d_2_2 (Conv2D)             [None,16,16,16] [None,16,16,48]  106336     relu_2_1           \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "11  bn_2_2 (BatchNormalization)     [None,16,16,16] [None,16,16,48]  320        conv2d_2_2         \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "12  relu_2_2 (Activation)           [None,16,16,16] [None,16,16,48]  0          bn_2_2             \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "13  avg_pool2d_2 (AveragePooling2D  [None,8,8,16] [None,8,8,48]      0          relu_2_2           \n",
      "                                    [None,8,8,16] [None,8,8,48]                                    \n",
      "                                    [None,8,8,16] [None,8,8,48]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "14  conv2d_3_1 (Conv2D)             [None,8,8,32] [None,8,8,96]      212672     avg_pool2d_2       \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "15  bn_3_1 (BatchNormalization)     [None,8,8,32] [None,8,8,96]      640        conv2d_3_1         \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "16  relu_3_1 (Activation)           [None,8,8,32] [None,8,8,96]      0          bn_3_1             \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "17  conv2d_3_2 (Conv2D)             [None,8,8,32] [None,8,8,96]      424640     relu_3_1           \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "18  bn_3_2 (BatchNormalization)     [None,8,8,32] [None,8,8,96]      640        conv2d_3_2         \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "19  relu_3_2 (Activation)           [None,8,8,32] [None,8,8,96]      0          bn_3_2             \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "20  global_avg_pool2d (GlobalAvera  [None,32] [None,96]              0          relu_3_2           \n",
      "                                    [None,32] [None,96]                                            \n",
      "                                    [None,32] [None,96]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "21  fc1 (Dense)                     [None,32] [None,96]              47808      global_avg_pool2d  \n",
      "                                    [None,32] [None,96]                                            \n",
      "                                    [None,32] [None,96]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "22  bn_fc1 (BatchNormalization)     [None,32] [None,96]              640        fc1                \n",
      "                                    [None,32] [None,96]                                            \n",
      "                                    [None,32] [None,96]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "23  relu_fc1 (Activation)           [None,32] [None,96]              0          bn_fc1             \n",
      "                                    [None,32] [None,96]                                            \n",
      "                                    [None,32] [None,96]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "24  output (Dense)                  [None,10]                        3768       relu_fc1           \n",
      "                                    [None,10]                                                      \n",
      "                                    [None,10]                                                      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "Total parameters: 880360\n",
      "50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 - 20s - loss_1: 1.7704 - loss_2: 1.7693 - loss_3: 1.8125 - acc_ensemble: 0.5120 - acc_1: 0.4680 - acc_2: 0.4580 - acc_3: 0.4540 - val_loss_1: 1.5189 - val_loss_2: 1.4925 - val_loss_3: 1.5234 - val_acc_ensemble: 0.4795 - val_acc_1: 0.4387 - val_acc_2: 0.4468 - val_acc_3: 0.4375\n",
      "Epoch 2/50\n",
      "100/100 - 12s - loss_1: 1.4557 - loss_2: 1.4257 - loss_3: 1.4278 - acc_ensemble: 0.5860 - acc_1: 0.5340 - acc_2: 0.5200 - acc_3: 0.5240 - val_loss_1: 1.3467 - val_loss_2: 1.3797 - val_loss_3: 1.3499 - val_acc_ensemble: 0.5565 - val_acc_1: 0.5176 - val_acc_2: 0.4961 - val_acc_3: 0.5065\n",
      "Epoch 3/50\n",
      "100/100 - 12s - loss_1: 1.2686 - loss_2: 1.2645 - loss_3: 1.2900 - acc_ensemble: 0.6500 - acc_1: 0.5540 - acc_2: 0.5840 - acc_3: 0.5900 - val_loss_1: 1.2465 - val_loss_2: 1.2197 - val_loss_3: 1.2065 - val_acc_ensemble: 0.6027 - val_acc_1: 0.5457 - val_acc_2: 0.5540 - val_acc_3: 0.5624\n",
      "Epoch 4/50\n",
      "100/100 - 12s - loss_1: 1.1606 - loss_2: 1.1586 - loss_3: 1.1562 - acc_ensemble: 0.6740 - acc_1: 0.6260 - acc_2: 0.5940 - acc_3: 0.6120 - val_loss_1: 1.1291 - val_loss_2: 1.1158 - val_loss_3: 1.1496 - val_acc_ensemble: 0.6447 - val_acc_1: 0.5929 - val_acc_2: 0.6013 - val_acc_3: 0.5904\n",
      "Epoch 5/50\n",
      "100/100 - 12s - loss_1: 1.0600 - loss_2: 1.0664 - loss_3: 1.0472 - acc_ensemble: 0.7100 - acc_1: 0.6500 - acc_2: 0.6460 - acc_3: 0.6340 - val_loss_1: 1.0788 - val_loss_2: 1.0588 - val_loss_3: 1.0608 - val_acc_ensemble: 0.6690 - val_acc_1: 0.6107 - val_acc_2: 0.6190 - val_acc_3: 0.6207\n",
      "Epoch 6/50\n",
      "100/100 - 12s - loss_1: 0.9939 - loss_2: 0.9815 - loss_3: 0.9952 - acc_ensemble: 0.7000 - acc_1: 0.6460 - acc_2: 0.6620 - acc_3: 0.6600 - val_loss_1: 0.9886 - val_loss_2: 1.0026 - val_loss_3: 1.0058 - val_acc_ensemble: 0.6876 - val_acc_1: 0.6504 - val_acc_2: 0.6359 - val_acc_3: 0.6384\n",
      "Epoch 7/50\n",
      "100/100 - 12s - loss_1: 0.9033 - loss_2: 0.9043 - loss_3: 0.9044 - acc_ensemble: 0.7420 - acc_1: 0.6920 - acc_2: 0.6540 - acc_3: 0.6960 - val_loss_1: 0.9556 - val_loss_2: 0.9735 - val_loss_3: 0.9635 - val_acc_ensemble: 0.7075 - val_acc_1: 0.6646 - val_acc_2: 0.6508 - val_acc_3: 0.6590\n",
      "Epoch 8/50\n",
      "100/100 - 12s - loss_1: 0.8225 - loss_2: 0.8634 - loss_3: 0.8572 - acc_ensemble: 0.7660 - acc_1: 0.6900 - acc_2: 0.6900 - acc_3: 0.7300 - val_loss_1: 1.0037 - val_loss_2: 0.9328 - val_loss_3: 0.9169 - val_acc_ensemble: 0.7105 - val_acc_1: 0.6460 - val_acc_2: 0.6696 - val_acc_3: 0.6739\n",
      "Epoch 9/50\n",
      "100/100 - 12s - loss_1: 0.8129 - loss_2: 0.8137 - loss_3: 0.8290 - acc_ensemble: 0.7800 - acc_1: 0.7300 - acc_2: 0.7020 - acc_3: 0.7540 - val_loss_1: 0.8996 - val_loss_2: 0.8724 - val_loss_3: 0.8853 - val_acc_ensemble: 0.7311 - val_acc_1: 0.6793 - val_acc_2: 0.6884 - val_acc_3: 0.6867\n",
      "Epoch 10/50\n",
      "100/100 - 12s - loss_1: 0.7799 - loss_2: 0.7537 - loss_3: 0.7729 - acc_ensemble: 0.7760 - acc_1: 0.7540 - acc_2: 0.7120 - acc_3: 0.7500 - val_loss_1: 0.8520 - val_loss_2: 0.8707 - val_loss_3: 0.8838 - val_acc_ensemble: 0.7354 - val_acc_1: 0.6995 - val_acc_2: 0.6959 - val_acc_3: 0.6904\n",
      "Epoch 11/50\n",
      "100/100 - 12s - loss_1: 0.6831 - loss_2: 0.7281 - loss_3: 0.7147 - acc_ensemble: 0.7880 - acc_1: 0.7440 - acc_2: 0.7480 - acc_3: 0.7520 - val_loss_1: 0.8310 - val_loss_2: 0.8736 - val_loss_3: 0.8459 - val_acc_ensemble: 0.7496 - val_acc_1: 0.7106 - val_acc_2: 0.6955 - val_acc_3: 0.6992\n",
      "Epoch 12/50\n",
      "100/100 - 12s - loss_1: 0.6965 - loss_2: 0.7045 - loss_3: 0.6602 - acc_ensemble: 0.7860 - acc_1: 0.7820 - acc_2: 0.7280 - acc_3: 0.7600 - val_loss_1: 0.7977 - val_loss_2: 0.8196 - val_loss_3: 0.8172 - val_acc_ensemble: 0.7572 - val_acc_1: 0.7226 - val_acc_2: 0.7092 - val_acc_3: 0.7138\n",
      "Epoch 13/50\n",
      "100/100 - 12s - loss_1: 0.6191 - loss_2: 0.6362 - loss_3: 0.6476 - acc_ensemble: 0.8040 - acc_1: 0.7640 - acc_2: 0.7820 - acc_3: 0.7360 - val_loss_1: 0.7914 - val_loss_2: 0.7968 - val_loss_3: 0.8491 - val_acc_ensemble: 0.7621 - val_acc_1: 0.7254 - val_acc_2: 0.7241 - val_acc_3: 0.7057\n",
      "Epoch 14/50\n",
      "100/100 - 12s - loss_1: 0.5796 - loss_2: 0.6311 - loss_3: 0.6087 - acc_ensemble: 0.8340 - acc_1: 0.7720 - acc_2: 0.7800 - acc_3: 0.7900 - val_loss_1: 0.8044 - val_loss_2: 0.7639 - val_loss_3: 0.8336 - val_acc_ensemble: 0.7707 - val_acc_1: 0.7229 - val_acc_2: 0.7338 - val_acc_3: 0.7102\n",
      "Epoch 15/50\n",
      "100/100 - 12s - loss_1: 0.6030 - loss_2: 0.5868 - loss_3: 0.5774 - acc_ensemble: 0.8400 - acc_1: 0.7720 - acc_2: 0.7660 - acc_3: 0.7760 - val_loss_1: 0.8151 - val_loss_2: 0.7778 - val_loss_3: 0.8021 - val_acc_ensemble: 0.7715 - val_acc_1: 0.7203 - val_acc_2: 0.7296 - val_acc_3: 0.7231\n",
      "Epoch 16/50\n",
      "100/100 - 12s - loss_1: 0.5152 - loss_2: 0.5252 - loss_3: 0.5254 - acc_ensemble: 0.8480 - acc_1: 0.7880 - acc_2: 0.7720 - acc_3: 0.7980 - val_loss_1: 0.7956 - val_loss_2: 0.7605 - val_loss_3: 0.8081 - val_acc_ensemble: 0.7811 - val_acc_1: 0.7272 - val_acc_2: 0.7384 - val_acc_3: 0.7215\n",
      "Epoch 17/50\n",
      "100/100 - 12s - loss_1: 0.5067 - loss_2: 0.5050 - loss_3: 0.5065 - acc_ensemble: 0.8460 - acc_1: 0.7960 - acc_2: 0.8000 - acc_3: 0.7860 - val_loss_1: 0.7905 - val_loss_2: 0.7487 - val_loss_3: 0.7887 - val_acc_ensemble: 0.7836 - val_acc_1: 0.7329 - val_acc_2: 0.7442 - val_acc_3: 0.7290\n",
      "Epoch 18/50\n",
      "100/100 - 12s - loss_1: 0.4763 - loss_2: 0.4623 - loss_3: 0.4813 - acc_ensemble: 0.8720 - acc_1: 0.7960 - acc_2: 0.7940 - acc_3: 0.7880 - val_loss_1: 0.7887 - val_loss_2: 0.7594 - val_loss_3: 0.8004 - val_acc_ensemble: 0.7886 - val_acc_1: 0.7353 - val_acc_2: 0.7445 - val_acc_3: 0.7284\n",
      "Epoch 19/50\n",
      "100/100 - 12s - loss_1: 0.4578 - loss_2: 0.4901 - loss_3: 0.4671 - acc_ensemble: 0.8540 - acc_1: 0.7980 - acc_2: 0.8040 - acc_3: 0.8080 - val_loss_1: 0.7783 - val_loss_2: 0.7869 - val_loss_3: 0.7958 - val_acc_ensemble: 0.7895 - val_acc_1: 0.7381 - val_acc_2: 0.7370 - val_acc_3: 0.7339\n",
      "Epoch 20/50\n",
      "100/100 - 12s - loss_1: 0.4230 - loss_2: 0.4633 - loss_3: 0.4223 - acc_ensemble: 0.8680 - acc_1: 0.8280 - acc_2: 0.7800 - acc_3: 0.7920 - val_loss_1: 0.7503 - val_loss_2: 0.7419 - val_loss_3: 0.8099 - val_acc_ensemble: 0.7961 - val_acc_1: 0.7495 - val_acc_2: 0.7513 - val_acc_3: 0.7273\n",
      "Epoch 21/50\n",
      "100/100 - 12s - loss_1: 0.3855 - loss_2: 0.4298 - loss_3: 0.4257 - acc_ensemble: 0.8720 - acc_1: 0.8060 - acc_2: 0.8100 - acc_3: 0.7980 - val_loss_1: 0.7591 - val_loss_2: 0.7430 - val_loss_3: 0.7897 - val_acc_ensemble: 0.7947 - val_acc_1: 0.7502 - val_acc_2: 0.7528 - val_acc_3: 0.7394\n",
      "Epoch 22/50\n",
      "100/100 - 12s - loss_1: 0.3773 - loss_2: 0.3816 - loss_3: 0.3627 - acc_ensemble: 0.8760 - acc_1: 0.8160 - acc_2: 0.7940 - acc_3: 0.8260 - val_loss_1: 0.7883 - val_loss_2: 0.7622 - val_loss_3: 0.7573 - val_acc_ensemble: 0.8003 - val_acc_1: 0.7407 - val_acc_2: 0.7450 - val_acc_3: 0.7461\n",
      "Epoch 23/50\n",
      "100/100 - 12s - loss_1: 0.3463 - loss_2: 0.3626 - loss_3: 0.3647 - acc_ensemble: 0.8760 - acc_1: 0.8220 - acc_2: 0.8280 - acc_3: 0.8120 - val_loss_1: 0.7903 - val_loss_2: 0.7236 - val_loss_3: 0.7967 - val_acc_ensemble: 0.8000 - val_acc_1: 0.7441 - val_acc_2: 0.7632 - val_acc_3: 0.7390\n",
      "Epoch 24/50\n",
      "100/100 - 12s - loss_1: 0.3548 - loss_2: 0.3556 - loss_3: 0.3352 - acc_ensemble: 0.8780 - acc_1: 0.8380 - acc_2: 0.8180 - acc_3: 0.8280 - val_loss_1: 0.8062 - val_loss_2: 0.7546 - val_loss_3: 0.8037 - val_acc_ensemble: 0.8037 - val_acc_1: 0.7460 - val_acc_2: 0.7549 - val_acc_3: 0.7402\n",
      "Epoch 25/50\n",
      "100/100 - 12s - loss_1: 0.3026 - loss_2: 0.3121 - loss_3: 0.3180 - acc_ensemble: 0.8760 - acc_1: 0.8280 - acc_2: 0.7920 - acc_3: 0.8180 - val_loss_1: 0.7877 - val_loss_2: 0.8035 - val_loss_3: 0.7952 - val_acc_ensemble: 0.8032 - val_acc_1: 0.7533 - val_acc_2: 0.7416 - val_acc_3: 0.7441\n",
      "Epoch 26/50\n",
      "100/100 - 12s - loss_1: 0.2975 - loss_2: 0.3087 - loss_3: 0.2887 - acc_ensemble: 0.8900 - acc_1: 0.8120 - acc_2: 0.8200 - acc_3: 0.8280 - val_loss_1: 0.8284 - val_loss_2: 0.7839 - val_loss_3: 0.7885 - val_acc_ensemble: 0.8048 - val_acc_1: 0.7409 - val_acc_2: 0.7480 - val_acc_3: 0.7518\n",
      "Epoch 27/50\n",
      "100/100 - 12s - loss_1: 0.3088 - loss_2: 0.2734 - loss_3: 0.2823 - acc_ensemble: 0.8840 - acc_1: 0.8160 - acc_2: 0.8360 - acc_3: 0.8440 - val_loss_1: 0.8115 - val_loss_2: 0.7927 - val_loss_3: 0.8248 - val_acc_ensemble: 0.8076 - val_acc_1: 0.7449 - val_acc_2: 0.7516 - val_acc_3: 0.7498\n",
      "Epoch 28/50\n",
      "100/100 - 12s - loss_1: 0.3024 - loss_2: 0.2761 - loss_3: 0.2598 - acc_ensemble: 0.8820 - acc_1: 0.8240 - acc_2: 0.8260 - acc_3: 0.8300 - val_loss_1: 0.8357 - val_loss_2: 0.7730 - val_loss_3: 0.7900 - val_acc_ensemble: 0.8088 - val_acc_1: 0.7452 - val_acc_2: 0.7584 - val_acc_3: 0.7601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50\n",
      "100/100 - 12s - loss_1: 0.2326 - loss_2: 0.2294 - loss_3: 0.2280 - acc_ensemble: 0.8880 - acc_1: 0.8380 - acc_2: 0.8100 - acc_3: 0.8440 - val_loss_1: 0.8040 - val_loss_2: 0.8066 - val_loss_3: 0.8276 - val_acc_ensemble: 0.8088 - val_acc_1: 0.7566 - val_acc_2: 0.7568 - val_acc_3: 0.7555\n",
      "Epoch 30/50\n",
      "100/100 - 12s - loss_1: 0.2324 - loss_2: 0.2256 - loss_3: 0.2362 - acc_ensemble: 0.8960 - acc_1: 0.8100 - acc_2: 0.8040 - acc_3: 0.8420 - val_loss_1: 0.8363 - val_loss_2: 0.7794 - val_loss_3: 0.8238 - val_acc_ensemble: 0.8090 - val_acc_1: 0.7463 - val_acc_2: 0.7619 - val_acc_3: 0.7541\n",
      "Epoch 31/50\n",
      "100/100 - 12s - loss_1: 0.2210 - loss_2: 0.2153 - loss_3: 0.2350 - acc_ensemble: 0.8900 - acc_1: 0.8320 - acc_2: 0.8260 - acc_3: 0.8340 - val_loss_1: 0.8378 - val_loss_2: 0.8088 - val_loss_3: 0.8113 - val_acc_ensemble: 0.8108 - val_acc_1: 0.7519 - val_acc_2: 0.7568 - val_acc_3: 0.7519\n",
      "Epoch 32/50\n",
      "100/100 - 12s - loss_1: 0.1755 - loss_2: 0.1909 - loss_3: 0.2215 - acc_ensemble: 0.8860 - acc_1: 0.8320 - acc_2: 0.8060 - acc_3: 0.8200 - val_loss_1: 0.8465 - val_loss_2: 0.8399 - val_loss_3: 0.8471 - val_acc_ensemble: 0.8102 - val_acc_1: 0.7507 - val_acc_2: 0.7554 - val_acc_3: 0.7505\n",
      "Epoch 33/50\n",
      "100/100 - 12s - loss_1: 0.1825 - loss_2: 0.1868 - loss_3: 0.1872 - acc_ensemble: 0.8980 - acc_1: 0.8220 - acc_2: 0.8380 - acc_3: 0.8520 - val_loss_1: 0.8824 - val_loss_2: 0.8148 - val_loss_3: 0.8641 - val_acc_ensemble: 0.8142 - val_acc_1: 0.7518 - val_acc_2: 0.7621 - val_acc_3: 0.7474\n",
      "Epoch 34/50\n",
      "100/100 - 12s - loss_1: 0.1728 - loss_2: 0.2017 - loss_3: 0.1691 - acc_ensemble: 0.9000 - acc_1: 0.8360 - acc_2: 0.8000 - acc_3: 0.8380 - val_loss_1: 0.8622 - val_loss_2: 0.8584 - val_loss_3: 0.8679 - val_acc_ensemble: 0.8126 - val_acc_1: 0.7570 - val_acc_2: 0.7536 - val_acc_3: 0.7542\n",
      "Epoch 35/50\n",
      "100/100 - 12s - loss_1: 0.1800 - loss_2: 0.1782 - loss_3: 0.1433 - acc_ensemble: 0.9120 - acc_1: 0.8700 - acc_2: 0.8340 - acc_3: 0.8360 - val_loss_1: 0.8775 - val_loss_2: 0.8138 - val_loss_3: 0.8677 - val_acc_ensemble: 0.8166 - val_acc_1: 0.7577 - val_acc_2: 0.7655 - val_acc_3: 0.7573\n",
      "Epoch 36/50\n",
      "100/100 - 12s - loss_1: 0.1503 - loss_2: 0.1427 - loss_3: 0.1504 - acc_ensemble: 0.8980 - acc_1: 0.8440 - acc_2: 0.8460 - acc_3: 0.8360 - val_loss_1: 0.9142 - val_loss_2: 0.8658 - val_loss_3: 0.8835 - val_acc_ensemble: 0.8132 - val_acc_1: 0.7500 - val_acc_2: 0.7595 - val_acc_3: 0.7522\n",
      "Epoch 37/50\n",
      "100/100 - 12s - loss_1: 0.1292 - loss_2: 0.1678 - loss_3: 0.1693 - acc_ensemble: 0.9040 - acc_1: 0.8360 - acc_2: 0.8140 - acc_3: 0.8300 - val_loss_1: 0.9010 - val_loss_2: 0.9033 - val_loss_3: 0.9720 - val_acc_ensemble: 0.8101 - val_acc_1: 0.7546 - val_acc_2: 0.7509 - val_acc_3: 0.7366\n",
      "Epoch 38/50\n",
      "100/100 - 12s - loss_1: 0.1213 - loss_2: 0.1456 - loss_3: 0.1607 - acc_ensemble: 0.9060 - acc_1: 0.8520 - acc_2: 0.8340 - acc_3: 0.8480 - val_loss_1: 0.9064 - val_loss_2: 0.8419 - val_loss_3: 0.9120 - val_acc_ensemble: 0.8197 - val_acc_1: 0.7604 - val_acc_2: 0.7686 - val_acc_3: 0.7547\n",
      "Epoch 39/50\n",
      "100/100 - 12s - loss_1: 0.1284 - loss_2: 0.1805 - loss_3: 0.1742 - acc_ensemble: 0.9100 - acc_1: 0.8500 - acc_2: 0.8460 - acc_3: 0.8440 - val_loss_1: 0.9373 - val_loss_2: 0.8496 - val_loss_3: 0.9513 - val_acc_ensemble: 0.8153 - val_acc_1: 0.7531 - val_acc_2: 0.7631 - val_acc_3: 0.7443\n",
      "Epoch 40/50\n",
      "100/100 - 12s - loss_1: 0.1277 - loss_2: 0.1122 - loss_3: 0.1376 - acc_ensemble: 0.9160 - acc_1: 0.8560 - acc_2: 0.8500 - acc_3: 0.8520 - val_loss_1: 0.9344 - val_loss_2: 0.8230 - val_loss_3: 0.9673 - val_acc_ensemble: 0.8174 - val_acc_1: 0.7519 - val_acc_2: 0.7759 - val_acc_3: 0.7450\n",
      "Epoch 41/50\n",
      "100/100 - 12s - loss_1: 0.1228 - loss_2: 0.1008 - loss_3: 0.1233 - acc_ensemble: 0.9240 - acc_1: 0.8560 - acc_2: 0.8440 - acc_3: 0.8640 - val_loss_1: 0.9626 - val_loss_2: 0.8932 - val_loss_3: 0.9609 - val_acc_ensemble: 0.8143 - val_acc_1: 0.7466 - val_acc_2: 0.7661 - val_acc_3: 0.7481\n",
      "Epoch 42/50\n",
      "100/100 - 12s - loss_1: 0.1147 - loss_2: 0.0845 - loss_3: 0.0915 - acc_ensemble: 0.9080 - acc_1: 0.8760 - acc_2: 0.8620 - acc_3: 0.8580 - val_loss_1: 0.9670 - val_loss_2: 0.8868 - val_loss_3: 0.9447 - val_acc_ensemble: 0.8175 - val_acc_1: 0.7537 - val_acc_2: 0.7698 - val_acc_3: 0.7556\n",
      "Epoch 43/50\n",
      "100/100 - 12s - loss_1: 0.0943 - loss_2: 0.0881 - loss_3: 0.0827 - acc_ensemble: 0.9160 - acc_1: 0.8760 - acc_2: 0.8420 - acc_3: 0.8700 - val_loss_1: 0.9222 - val_loss_2: 0.9066 - val_loss_3: 0.9943 - val_acc_ensemble: 0.8183 - val_acc_1: 0.7670 - val_acc_2: 0.7697 - val_acc_3: 0.7505\n",
      "Epoch 44/50\n",
      "100/100 - 12s - loss_1: 0.0778 - loss_2: 0.0891 - loss_3: 0.1059 - acc_ensemble: 0.9300 - acc_1: 0.8460 - acc_2: 0.8560 - acc_3: 0.8400 - val_loss_1: 0.9870 - val_loss_2: 0.9114 - val_loss_3: 1.0114 - val_acc_ensemble: 0.8196 - val_acc_1: 0.7541 - val_acc_2: 0.7697 - val_acc_3: 0.7458\n",
      "Epoch 45/50\n",
      "100/100 - 12s - loss_1: 0.1050 - loss_2: 0.1007 - loss_3: 0.1099 - acc_ensemble: 0.9100 - acc_1: 0.8660 - acc_2: 0.8400 - acc_3: 0.8640 - val_loss_1: 1.0411 - val_loss_2: 0.9858 - val_loss_3: 0.9751 - val_acc_ensemble: 0.8171 - val_acc_1: 0.7495 - val_acc_2: 0.7571 - val_acc_3: 0.7549\n",
      "Epoch 46/50\n",
      "100/100 - 12s - loss_1: 0.0900 - loss_2: 0.0938 - loss_3: 0.0893 - acc_ensemble: 0.9240 - acc_1: 0.8700 - acc_2: 0.8500 - acc_3: 0.8900 - val_loss_1: 1.0213 - val_loss_2: 0.9463 - val_loss_3: 1.0199 - val_acc_ensemble: 0.8185 - val_acc_1: 0.7551 - val_acc_2: 0.7651 - val_acc_3: 0.7533\n",
      "Epoch 47/50\n",
      "100/100 - 12s - loss_1: 0.0973 - loss_2: 0.0767 - loss_3: 0.0866 - acc_ensemble: 0.9260 - acc_1: 0.8480 - acc_2: 0.8360 - acc_3: 0.8600 - val_loss_1: 1.0275 - val_loss_2: 0.9454 - val_loss_3: 1.0026 - val_acc_ensemble: 0.8150 - val_acc_1: 0.7516 - val_acc_2: 0.7653 - val_acc_3: 0.7567\n",
      "Epoch 48/50\n",
      "100/100 - 12s - loss_1: 0.1168 - loss_2: 0.0681 - loss_3: 0.0644 - acc_ensemble: 0.9200 - acc_1: 0.8480 - acc_2: 0.8540 - acc_3: 0.8620 - val_loss_1: 1.0736 - val_loss_2: 0.9721 - val_loss_3: 1.0655 - val_acc_ensemble: 0.8147 - val_acc_1: 0.7454 - val_acc_2: 0.7646 - val_acc_3: 0.7461\n",
      "Epoch 49/50\n",
      "100/100 - 12s - loss_1: 0.0979 - loss_2: 0.0766 - loss_3: 0.0581 - acc_ensemble: 0.9260 - acc_1: 0.8560 - acc_2: 0.8360 - acc_3: 0.8580 - val_loss_1: 1.0554 - val_loss_2: 1.0311 - val_loss_3: 1.0223 - val_acc_ensemble: 0.8159 - val_acc_1: 0.7483 - val_acc_2: 0.7561 - val_acc_3: 0.7587\n",
      "Epoch 50/50\n",
      "100/100 - 12s - loss_1: 0.0984 - loss_2: 0.1069 - loss_3: 0.0901 - acc_ensemble: 0.9120 - acc_1: 0.8240 - acc_2: 0.8380 - acc_3: 0.8280 - val_loss_1: 1.0112 - val_loss_2: 1.0109 - val_loss_3: 1.1327 - val_acc_ensemble: 0.8185 - val_acc_1: 0.7557 - val_acc_2: 0.7602 - val_acc_3: 0.7402\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B3/S0.25/model_2\n",
      "i   Layer name                      Output shape                     Num param  Inbound            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "0   conv2d_1_1 (Conv2D)             [None,32,32,8] [None,32,32,24]   2240       input              \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "1   bn_1_1 (BatchNormalization)     [None,32,32,8] [None,32,32,24]   160        conv2d_1_1         \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "2   relu_1_1 (Activation)           [None,32,32,8] [None,32,32,24]   0          bn_1_1             \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "3   conv2d_1_2 (Conv2D)             [None,32,32,8] [None,32,32,24]   26672      relu_1_1           \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "4   bn_1_2 (BatchNormalization)     [None,32,32,8] [None,32,32,24]   160        conv2d_1_2         \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "5   relu_1_2 (Activation)           [None,32,32,8] [None,32,32,24]   0          bn_1_2             \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "6   avg_pool2d_1 (AveragePooling2D  [None,16,16,8] [None,16,16,24]   0          relu_1_2           \n",
      "                                    [None,16,16,8] [None,16,16,24]                                 \n",
      "                                    [None,16,16,8] [None,16,16,24]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "7   conv2d_2_1 (Conv2D)             [None,16,16,16] [None,16,16,48]  53344      avg_pool2d_1       \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "8   bn_2_1 (BatchNormalization)     [None,16,16,16] [None,16,16,48]  320        conv2d_2_1         \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "9   relu_2_1 (Activation)           [None,16,16,16] [None,16,16,48]  0          bn_2_1             \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "10  conv2d_2_2 (Conv2D)             [None,16,16,16] [None,16,16,48]  106336     relu_2_1           \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "11  bn_2_2 (BatchNormalization)     [None,16,16,16] [None,16,16,48]  320        conv2d_2_2         \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "12  relu_2_2 (Activation)           [None,16,16,16] [None,16,16,48]  0          bn_2_2             \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "13  avg_pool2d_2 (AveragePooling2D  [None,8,8,16] [None,8,8,48]      0          relu_2_2           \n",
      "                                    [None,8,8,16] [None,8,8,48]                                    \n",
      "                                    [None,8,8,16] [None,8,8,48]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "14  conv2d_3_1 (Conv2D)             [None,8,8,32] [None,8,8,96]      212672     avg_pool2d_2       \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "15  bn_3_1 (BatchNormalization)     [None,8,8,32] [None,8,8,96]      640        conv2d_3_1         \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "16  relu_3_1 (Activation)           [None,8,8,32] [None,8,8,96]      0          bn_3_1             \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "17  conv2d_3_2 (Conv2D)             [None,8,8,32] [None,8,8,96]      424640     relu_3_1           \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "18  bn_3_2 (BatchNormalization)     [None,8,8,32] [None,8,8,96]      640        conv2d_3_2         \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "19  relu_3_2 (Activation)           [None,8,8,32] [None,8,8,96]      0          bn_3_2             \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "20  global_avg_pool2d (GlobalAvera  [None,32] [None,96]              0          relu_3_2           \n",
      "                                    [None,32] [None,96]                                            \n",
      "                                    [None,32] [None,96]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "21  fc1 (Dense)                     [None,32] [None,96]              47808      global_avg_pool2d  \n",
      "                                    [None,32] [None,96]                                            \n",
      "                                    [None,32] [None,96]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "22  bn_fc1 (BatchNormalization)     [None,32] [None,96]              640        fc1                \n",
      "                                    [None,32] [None,96]                                            \n",
      "                                    [None,32] [None,96]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "23  relu_fc1 (Activation)           [None,32] [None,96]              0          bn_fc1             \n",
      "                                    [None,32] [None,96]                                            \n",
      "                                    [None,32] [None,96]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "24  output (Dense)                  [None,10]                        3768       relu_fc1           \n",
      "                                    [None,10]                                                      \n",
      "                                    [None,10]                                                      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "Total parameters: 880360\n",
      "50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 - 20s - loss_1: 1.7590 - loss_2: 1.7809 - loss_3: 1.7862 - acc_ensemble: 0.5000 - acc_1: 0.4520 - acc_2: 0.4660 - acc_3: 0.4520 - val_loss_1: 1.5263 - val_loss_2: 1.5445 - val_loss_3: 1.5453 - val_acc_ensemble: 0.4859 - val_acc_1: 0.4311 - val_acc_2: 0.4309 - val_acc_3: 0.4327\n",
      "Epoch 2/50\n",
      "100/100 - 13s - loss_1: 1.4409 - loss_2: 1.4540 - loss_3: 1.4326 - acc_ensemble: 0.5840 - acc_1: 0.5260 - acc_2: 0.5260 - acc_3: 0.5120 - val_loss_1: 1.3386 - val_loss_2: 1.3150 - val_loss_3: 1.3497 - val_acc_ensemble: 0.5509 - val_acc_1: 0.4993 - val_acc_2: 0.5178 - val_acc_3: 0.5008\n",
      "Epoch 3/50\n",
      "100/100 - 12s - loss_1: 1.2989 - loss_2: 1.2887 - loss_3: 1.2965 - acc_ensemble: 0.6140 - acc_1: 0.5880 - acc_2: 0.5700 - acc_3: 0.5560 - val_loss_1: 1.2121 - val_loss_2: 1.2356 - val_loss_3: 1.2360 - val_acc_ensemble: 0.5997 - val_acc_1: 0.5525 - val_acc_2: 0.5481 - val_acc_3: 0.5505\n",
      "Epoch 4/50\n",
      "100/100 - 12s - loss_1: 1.1748 - loss_2: 1.2181 - loss_3: 1.2153 - acc_ensemble: 0.6580 - acc_1: 0.6140 - acc_2: 0.5840 - acc_3: 0.6240 - val_loss_1: 1.1253 - val_loss_2: 1.1416 - val_loss_3: 1.1067 - val_acc_ensemble: 0.6382 - val_acc_1: 0.5904 - val_acc_2: 0.5886 - val_acc_3: 0.5957\n",
      "Epoch 5/50\n",
      "100/100 - 12s - loss_1: 1.0789 - loss_2: 1.0620 - loss_3: 1.0778 - acc_ensemble: 0.6840 - acc_1: 0.6300 - acc_2: 0.6460 - acc_3: 0.6340 - val_loss_1: 1.0771 - val_loss_2: 1.0755 - val_loss_3: 1.0349 - val_acc_ensemble: 0.6631 - val_acc_1: 0.6170 - val_acc_2: 0.6120 - val_acc_3: 0.6336\n",
      "Epoch 6/50\n",
      "100/100 - 12s - loss_1: 1.0341 - loss_2: 0.9883 - loss_3: 1.0101 - acc_ensemble: 0.7180 - acc_1: 0.6540 - acc_2: 0.6500 - acc_3: 0.6580 - val_loss_1: 1.0236 - val_loss_2: 1.0420 - val_loss_3: 1.0006 - val_acc_ensemble: 0.6761 - val_acc_1: 0.6291 - val_acc_2: 0.6267 - val_acc_3: 0.6404\n",
      "Epoch 7/50\n",
      "100/100 - 13s - loss_1: 0.9398 - loss_2: 0.9393 - loss_3: 0.9288 - acc_ensemble: 0.7160 - acc_1: 0.6760 - acc_2: 0.6620 - acc_3: 0.7000 - val_loss_1: 0.9881 - val_loss_2: 0.9609 - val_loss_3: 0.9768 - val_acc_ensemble: 0.6948 - val_acc_1: 0.6512 - val_acc_2: 0.6555 - val_acc_3: 0.6528\n",
      "Epoch 8/50\n",
      "100/100 - 12s - loss_1: 0.8868 - loss_2: 0.8655 - loss_3: 0.8841 - acc_ensemble: 0.7240 - acc_1: 0.6900 - acc_2: 0.6560 - acc_3: 0.6880 - val_loss_1: 0.9470 - val_loss_2: 0.9640 - val_loss_3: 0.9581 - val_acc_ensemble: 0.7069 - val_acc_1: 0.6606 - val_acc_2: 0.6546 - val_acc_3: 0.6561\n",
      "Epoch 9/50\n",
      "100/100 - 12s - loss_1: 0.8432 - loss_2: 0.8341 - loss_3: 0.8248 - acc_ensemble: 0.7580 - acc_1: 0.7340 - acc_2: 0.7240 - acc_3: 0.7140 - val_loss_1: 0.8732 - val_loss_2: 0.8990 - val_loss_3: 0.9088 - val_acc_ensemble: 0.7190 - val_acc_1: 0.6902 - val_acc_2: 0.6763 - val_acc_3: 0.6718\n",
      "Epoch 10/50\n",
      "100/100 - 12s - loss_1: 0.7772 - loss_2: 0.7840 - loss_3: 0.7706 - acc_ensemble: 0.8040 - acc_1: 0.7440 - acc_2: 0.7360 - acc_3: 0.7440 - val_loss_1: 0.8588 - val_loss_2: 0.8473 - val_loss_3: 0.8637 - val_acc_ensemble: 0.7334 - val_acc_1: 0.6953 - val_acc_2: 0.6986 - val_acc_3: 0.6972\n",
      "Epoch 11/50\n",
      "100/100 - 12s - loss_1: 0.7335 - loss_2: 0.7343 - loss_3: 0.7520 - acc_ensemble: 0.7880 - acc_1: 0.7380 - acc_2: 0.7180 - acc_3: 0.7660 - val_loss_1: 0.8259 - val_loss_2: 0.8844 - val_loss_3: 0.8659 - val_acc_ensemble: 0.7437 - val_acc_1: 0.7114 - val_acc_2: 0.6860 - val_acc_3: 0.6907\n",
      "Epoch 12/50\n",
      "100/100 - 12s - loss_1: 0.7189 - loss_2: 0.6884 - loss_3: 0.7155 - acc_ensemble: 0.8140 - acc_1: 0.7600 - acc_2: 0.7400 - acc_3: 0.7600 - val_loss_1: 0.8008 - val_loss_2: 0.8506 - val_loss_3: 0.8474 - val_acc_ensemble: 0.7517 - val_acc_1: 0.7181 - val_acc_2: 0.7002 - val_acc_3: 0.7004\n",
      "Epoch 13/50\n",
      "100/100 - 12s - loss_1: 0.6335 - loss_2: 0.6676 - loss_3: 0.6573 - acc_ensemble: 0.8300 - acc_1: 0.7780 - acc_2: 0.7500 - acc_3: 0.7720 - val_loss_1: 0.7769 - val_loss_2: 0.8595 - val_loss_3: 0.8387 - val_acc_ensemble: 0.7543 - val_acc_1: 0.7262 - val_acc_2: 0.6994 - val_acc_3: 0.7024\n",
      "Epoch 14/50\n",
      "100/100 - 12s - loss_1: 0.5943 - loss_2: 0.6305 - loss_3: 0.6353 - acc_ensemble: 0.8200 - acc_1: 0.7540 - acc_2: 0.7860 - acc_3: 0.7600 - val_loss_1: 0.7913 - val_loss_2: 0.8088 - val_loss_3: 0.8442 - val_acc_ensemble: 0.7644 - val_acc_1: 0.7198 - val_acc_2: 0.7170 - val_acc_3: 0.7065\n",
      "Epoch 15/50\n",
      "100/100 - 12s - loss_1: 0.5947 - loss_2: 0.5708 - loss_3: 0.6268 - acc_ensemble: 0.8300 - acc_1: 0.7620 - acc_2: 0.7740 - acc_3: 0.7920 - val_loss_1: 0.8057 - val_loss_2: 0.7763 - val_loss_3: 0.8024 - val_acc_ensemble: 0.7678 - val_acc_1: 0.7157 - val_acc_2: 0.7312 - val_acc_3: 0.7226\n",
      "Epoch 16/50\n",
      "100/100 - 12s - loss_1: 0.5543 - loss_2: 0.5428 - loss_3: 0.5776 - acc_ensemble: 0.8200 - acc_1: 0.7680 - acc_2: 0.7920 - acc_3: 0.7920 - val_loss_1: 0.7982 - val_loss_2: 0.7581 - val_loss_3: 0.8130 - val_acc_ensemble: 0.7738 - val_acc_1: 0.7219 - val_acc_2: 0.7342 - val_acc_3: 0.7215\n",
      "Epoch 17/50\n",
      "100/100 - 12s - loss_1: 0.5169 - loss_2: 0.5288 - loss_3: 0.5456 - acc_ensemble: 0.8320 - acc_1: 0.7900 - acc_2: 0.7580 - acc_3: 0.7980 - val_loss_1: 0.7772 - val_loss_2: 0.7903 - val_loss_3: 0.7680 - val_acc_ensemble: 0.7808 - val_acc_1: 0.7297 - val_acc_2: 0.7307 - val_acc_3: 0.7372\n",
      "Epoch 18/50\n",
      "100/100 - 12s - loss_1: 0.5024 - loss_2: 0.4942 - loss_3: 0.5213 - acc_ensemble: 0.8260 - acc_1: 0.7780 - acc_2: 0.7760 - acc_3: 0.7960 - val_loss_1: 0.7670 - val_loss_2: 0.7694 - val_loss_3: 0.7891 - val_acc_ensemble: 0.7829 - val_acc_1: 0.7367 - val_acc_2: 0.7317 - val_acc_3: 0.7298\n",
      "Epoch 19/50\n",
      "100/100 - 12s - loss_1: 0.4774 - loss_2: 0.4976 - loss_3: 0.4779 - acc_ensemble: 0.8500 - acc_1: 0.8000 - acc_2: 0.7760 - acc_3: 0.7920 - val_loss_1: 0.7564 - val_loss_2: 0.7773 - val_loss_3: 0.7935 - val_acc_ensemble: 0.7857 - val_acc_1: 0.7437 - val_acc_2: 0.7329 - val_acc_3: 0.7303\n",
      "Epoch 20/50\n",
      "100/100 - 12s - loss_1: 0.4582 - loss_2: 0.4351 - loss_3: 0.4603 - acc_ensemble: 0.8380 - acc_1: 0.7660 - acc_2: 0.7900 - acc_3: 0.8060 - val_loss_1: 0.7771 - val_loss_2: 0.7976 - val_loss_3: 0.8226 - val_acc_ensemble: 0.7833 - val_acc_1: 0.7381 - val_acc_2: 0.7322 - val_acc_3: 0.7222\n",
      "Epoch 21/50\n",
      "100/100 - 12s - loss_1: 0.4187 - loss_2: 0.3940 - loss_3: 0.4171 - acc_ensemble: 0.8740 - acc_1: 0.8260 - acc_2: 0.7960 - acc_3: 0.7980 - val_loss_1: 0.7663 - val_loss_2: 0.7651 - val_loss_3: 0.8190 - val_acc_ensemble: 0.7924 - val_acc_1: 0.7429 - val_acc_2: 0.7427 - val_acc_3: 0.7323\n",
      "Epoch 22/50\n",
      "100/100 - 12s - loss_1: 0.4116 - loss_2: 0.3881 - loss_3: 0.4178 - acc_ensemble: 0.8460 - acc_1: 0.7920 - acc_2: 0.7960 - acc_3: 0.8240 - val_loss_1: 0.7488 - val_loss_2: 0.7657 - val_loss_3: 0.7742 - val_acc_ensemble: 0.7963 - val_acc_1: 0.7458 - val_acc_2: 0.7480 - val_acc_3: 0.7462\n",
      "Epoch 23/50\n",
      "100/100 - 12s - loss_1: 0.3586 - loss_2: 0.3825 - loss_3: 0.3903 - acc_ensemble: 0.8560 - acc_1: 0.8000 - acc_2: 0.8220 - acc_3: 0.8200 - val_loss_1: 0.7768 - val_loss_2: 0.7991 - val_loss_3: 0.7877 - val_acc_ensemble: 0.7970 - val_acc_1: 0.7431 - val_acc_2: 0.7336 - val_acc_3: 0.7350\n",
      "Epoch 24/50\n",
      "100/100 - 12s - loss_1: 0.3508 - loss_2: 0.3528 - loss_3: 0.3442 - acc_ensemble: 0.8880 - acc_1: 0.8200 - acc_2: 0.8060 - acc_3: 0.8420 - val_loss_1: 0.7502 - val_loss_2: 0.7760 - val_loss_3: 0.7669 - val_acc_ensemble: 0.8025 - val_acc_1: 0.7524 - val_acc_2: 0.7452 - val_acc_3: 0.7518\n",
      "Epoch 25/50\n",
      "100/100 - 12s - loss_1: 0.3154 - loss_2: 0.3535 - loss_3: 0.3424 - acc_ensemble: 0.8700 - acc_1: 0.8040 - acc_2: 0.8040 - acc_3: 0.8080 - val_loss_1: 0.7896 - val_loss_2: 0.7738 - val_loss_3: 0.8237 - val_acc_ensemble: 0.7958 - val_acc_1: 0.7444 - val_acc_2: 0.7465 - val_acc_3: 0.7365\n",
      "Epoch 26/50\n",
      "100/100 - 12s - loss_1: 0.2878 - loss_2: 0.3219 - loss_3: 0.3125 - acc_ensemble: 0.8860 - acc_1: 0.8240 - acc_2: 0.8240 - acc_3: 0.8360 - val_loss_1: 0.8033 - val_loss_2: 0.7856 - val_loss_3: 0.8215 - val_acc_ensemble: 0.7993 - val_acc_1: 0.7440 - val_acc_2: 0.7477 - val_acc_3: 0.7440\n",
      "Epoch 27/50\n",
      "100/100 - 12s - loss_1: 0.3007 - loss_2: 0.2635 - loss_3: 0.2846 - acc_ensemble: 0.8860 - acc_1: 0.8140 - acc_2: 0.8240 - acc_3: 0.8160 - val_loss_1: 0.7841 - val_loss_2: 0.7916 - val_loss_3: 0.8431 - val_acc_ensemble: 0.8067 - val_acc_1: 0.7513 - val_acc_2: 0.7510 - val_acc_3: 0.7383\n",
      "Epoch 28/50\n",
      "100/100 - 12s - loss_1: 0.2485 - loss_2: 0.2568 - loss_3: 0.3141 - acc_ensemble: 0.8840 - acc_1: 0.7920 - acc_2: 0.8200 - acc_3: 0.8380 - val_loss_1: 0.8175 - val_loss_2: 0.8174 - val_loss_3: 0.8703 - val_acc_ensemble: 0.7987 - val_acc_1: 0.7481 - val_acc_2: 0.7501 - val_acc_3: 0.7301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50\n",
      "100/100 - 12s - loss_1: 0.2714 - loss_2: 0.2366 - loss_3: 0.2769 - acc_ensemble: 0.8700 - acc_1: 0.8060 - acc_2: 0.8380 - acc_3: 0.8340 - val_loss_1: 0.7894 - val_loss_2: 0.8041 - val_loss_3: 0.8361 - val_acc_ensemble: 0.8029 - val_acc_1: 0.7548 - val_acc_2: 0.7556 - val_acc_3: 0.7441\n",
      "Epoch 30/50\n",
      "100/100 - 12s - loss_1: 0.2261 - loss_2: 0.2773 - loss_3: 0.2371 - acc_ensemble: 0.8760 - acc_1: 0.7980 - acc_2: 0.8220 - acc_3: 0.8200 - val_loss_1: 0.8334 - val_loss_2: 0.8116 - val_loss_3: 0.8373 - val_acc_ensemble: 0.8038 - val_acc_1: 0.7467 - val_acc_2: 0.7491 - val_acc_3: 0.7492\n",
      "Epoch 31/50\n",
      "100/100 - 12s - loss_1: 0.2281 - loss_2: 0.2280 - loss_3: 0.2306 - acc_ensemble: 0.8900 - acc_1: 0.8220 - acc_2: 0.8220 - acc_3: 0.8400 - val_loss_1: 0.8433 - val_loss_2: 0.7883 - val_loss_3: 0.8456 - val_acc_ensemble: 0.8063 - val_acc_1: 0.7483 - val_acc_2: 0.7617 - val_acc_3: 0.7494\n",
      "Epoch 32/50\n",
      "100/100 - 12s - loss_1: 0.2193 - loss_2: 0.2140 - loss_3: 0.2027 - acc_ensemble: 0.8880 - acc_1: 0.8140 - acc_2: 0.8240 - acc_3: 0.8400 - val_loss_1: 0.8260 - val_loss_2: 0.8287 - val_loss_3: 0.8194 - val_acc_ensemble: 0.8084 - val_acc_1: 0.7547 - val_acc_2: 0.7547 - val_acc_3: 0.7500\n",
      "Epoch 33/50\n",
      "100/100 - 12s - loss_1: 0.1718 - loss_2: 0.1733 - loss_3: 0.2312 - acc_ensemble: 0.8960 - acc_1: 0.8360 - acc_2: 0.8320 - acc_3: 0.8540 - val_loss_1: 0.8482 - val_loss_2: 0.8508 - val_loss_3: 0.8457 - val_acc_ensemble: 0.8097 - val_acc_1: 0.7504 - val_acc_2: 0.7528 - val_acc_3: 0.7564\n",
      "Epoch 34/50\n",
      "100/100 - 12s - loss_1: 0.1588 - loss_2: 0.1603 - loss_3: 0.1875 - acc_ensemble: 0.9020 - acc_1: 0.8280 - acc_2: 0.8320 - acc_3: 0.8440 - val_loss_1: 0.8695 - val_loss_2: 0.8373 - val_loss_3: 0.8697 - val_acc_ensemble: 0.8094 - val_acc_1: 0.7490 - val_acc_2: 0.7519 - val_acc_3: 0.7477\n",
      "Epoch 35/50\n",
      "100/100 - 12s - loss_1: 0.1675 - loss_2: 0.1716 - loss_3: 0.1853 - acc_ensemble: 0.8880 - acc_1: 0.8140 - acc_2: 0.8360 - acc_3: 0.8160 - val_loss_1: 0.8728 - val_loss_2: 0.8654 - val_loss_3: 0.8991 - val_acc_ensemble: 0.8091 - val_acc_1: 0.7500 - val_acc_2: 0.7537 - val_acc_3: 0.7424\n",
      "Epoch 36/50\n",
      "100/100 - 12s - loss_1: 0.1548 - loss_2: 0.1806 - loss_3: 0.1436 - acc_ensemble: 0.9160 - acc_1: 0.8260 - acc_2: 0.8300 - acc_3: 0.8600 - val_loss_1: 0.8996 - val_loss_2: 0.8583 - val_loss_3: 0.8910 - val_acc_ensemble: 0.8093 - val_acc_1: 0.7460 - val_acc_2: 0.7537 - val_acc_3: 0.7507\n",
      "Epoch 37/50\n",
      "100/100 - 12s - loss_1: 0.1577 - loss_2: 0.1304 - loss_3: 0.1440 - acc_ensemble: 0.8980 - acc_1: 0.8280 - acc_2: 0.8340 - acc_3: 0.8460 - val_loss_1: 0.8870 - val_loss_2: 0.8941 - val_loss_3: 0.9241 - val_acc_ensemble: 0.8082 - val_acc_1: 0.7505 - val_acc_2: 0.7525 - val_acc_3: 0.7475\n",
      "Epoch 38/50\n",
      "100/100 - 12s - loss_1: 0.1355 - loss_2: 0.1420 - loss_3: 0.1549 - acc_ensemble: 0.9020 - acc_1: 0.8280 - acc_2: 0.8420 - acc_3: 0.8520 - val_loss_1: 0.8942 - val_loss_2: 0.8964 - val_loss_3: 0.9170 - val_acc_ensemble: 0.8119 - val_acc_1: 0.7568 - val_acc_2: 0.7540 - val_acc_3: 0.7501\n",
      "Epoch 39/50\n",
      "100/100 - 12s - loss_1: 0.1089 - loss_2: 0.1331 - loss_3: 0.1512 - acc_ensemble: 0.8940 - acc_1: 0.8480 - acc_2: 0.8220 - acc_3: 0.8400 - val_loss_1: 0.8920 - val_loss_2: 0.9372 - val_loss_3: 0.9413 - val_acc_ensemble: 0.8073 - val_acc_1: 0.7574 - val_acc_2: 0.7436 - val_acc_3: 0.7440\n",
      "Epoch 40/50\n",
      "100/100 - 12s - loss_1: 0.1164 - loss_2: 0.1212 - loss_3: 0.1156 - acc_ensemble: 0.9160 - acc_1: 0.8260 - acc_2: 0.8400 - acc_3: 0.8460 - val_loss_1: 0.9233 - val_loss_2: 0.9243 - val_loss_3: 0.9361 - val_acc_ensemble: 0.8143 - val_acc_1: 0.7588 - val_acc_2: 0.7546 - val_acc_3: 0.7488\n",
      "Epoch 41/50\n",
      "100/100 - 12s - loss_1: 0.1059 - loss_2: 0.1138 - loss_3: 0.1204 - acc_ensemble: 0.9100 - acc_1: 0.8440 - acc_2: 0.8240 - acc_3: 0.8520 - val_loss_1: 0.9453 - val_loss_2: 0.9089 - val_loss_3: 0.9468 - val_acc_ensemble: 0.8141 - val_acc_1: 0.7605 - val_acc_2: 0.7591 - val_acc_3: 0.7553\n",
      "Epoch 42/50\n",
      "100/100 - 12s - loss_1: 0.1145 - loss_2: 0.1309 - loss_3: 0.1058 - acc_ensemble: 0.9060 - acc_1: 0.8420 - acc_2: 0.8380 - acc_3: 0.8520 - val_loss_1: 0.9433 - val_loss_2: 0.9511 - val_loss_3: 0.9227 - val_acc_ensemble: 0.8143 - val_acc_1: 0.7564 - val_acc_2: 0.7510 - val_acc_3: 0.7563\n",
      "Epoch 43/50\n",
      "100/100 - 12s - loss_1: 0.1477 - loss_2: 0.1013 - loss_3: 0.0904 - acc_ensemble: 0.9100 - acc_1: 0.8220 - acc_2: 0.8500 - acc_3: 0.8440 - val_loss_1: 1.0027 - val_loss_2: 0.9207 - val_loss_3: 0.9646 - val_acc_ensemble: 0.8150 - val_acc_1: 0.7401 - val_acc_2: 0.7681 - val_acc_3: 0.7550\n",
      "Epoch 44/50\n",
      "100/100 - 12s - loss_1: 0.1194 - loss_2: 0.0930 - loss_3: 0.1074 - acc_ensemble: 0.9140 - acc_1: 0.8440 - acc_2: 0.8420 - acc_3: 0.8520 - val_loss_1: 0.9550 - val_loss_2: 0.9264 - val_loss_3: 0.9897 - val_acc_ensemble: 0.8163 - val_acc_1: 0.7554 - val_acc_2: 0.7624 - val_acc_3: 0.7527\n",
      "Epoch 45/50\n",
      "100/100 - 12s - loss_1: 0.0926 - loss_2: 0.1100 - loss_3: 0.0933 - acc_ensemble: 0.9100 - acc_1: 0.8340 - acc_2: 0.8380 - acc_3: 0.8420 - val_loss_1: 0.9808 - val_loss_2: 0.9610 - val_loss_3: 0.9980 - val_acc_ensemble: 0.8149 - val_acc_1: 0.7543 - val_acc_2: 0.7568 - val_acc_3: 0.7520\n",
      "Epoch 46/50\n",
      "100/100 - 12s - loss_1: 0.1034 - loss_2: 0.0840 - loss_3: 0.1180 - acc_ensemble: 0.9120 - acc_1: 0.8380 - acc_2: 0.8300 - acc_3: 0.8520 - val_loss_1: 0.9266 - val_loss_2: 0.9663 - val_loss_3: 1.0412 - val_acc_ensemble: 0.8151 - val_acc_1: 0.7624 - val_acc_2: 0.7591 - val_acc_3: 0.7433\n",
      "Epoch 47/50\n",
      "100/100 - 12s - loss_1: 0.0784 - loss_2: 0.0717 - loss_3: 0.0968 - acc_ensemble: 0.9180 - acc_1: 0.8360 - acc_2: 0.8400 - acc_3: 0.8540 - val_loss_1: 1.0030 - val_loss_2: 0.9511 - val_loss_3: 1.0397 - val_acc_ensemble: 0.8146 - val_acc_1: 0.7589 - val_acc_2: 0.7579 - val_acc_3: 0.7520\n",
      "Epoch 48/50\n",
      "100/100 - 12s - loss_1: 0.1051 - loss_2: 0.0778 - loss_3: 0.0744 - acc_ensemble: 0.9220 - acc_1: 0.8260 - acc_2: 0.8640 - acc_3: 0.8460 - val_loss_1: 0.9517 - val_loss_2: 0.9465 - val_loss_3: 1.0458 - val_acc_ensemble: 0.8152 - val_acc_1: 0.7655 - val_acc_2: 0.7659 - val_acc_3: 0.7445\n",
      "Epoch 49/50\n",
      "100/100 - 12s - loss_1: 0.0451 - loss_2: 0.0963 - loss_3: 0.0820 - acc_ensemble: 0.9220 - acc_1: 0.8400 - acc_2: 0.8480 - acc_3: 0.8720 - val_loss_1: 0.9855 - val_loss_2: 1.0269 - val_loss_3: 1.0319 - val_acc_ensemble: 0.8136 - val_acc_1: 0.7605 - val_acc_2: 0.7457 - val_acc_3: 0.7477\n",
      "Epoch 50/50\n",
      "100/100 - 12s - loss_1: 0.0647 - loss_2: 0.0804 - loss_3: 0.0728 - acc_ensemble: 0.9120 - acc_1: 0.8200 - acc_2: 0.8600 - acc_3: 0.8560 - val_loss_1: 1.1028 - val_loss_2: 1.0424 - val_loss_3: 1.0283 - val_acc_ensemble: 0.8117 - val_acc_1: 0.7426 - val_acc_2: 0.7523 - val_acc_3: 0.7532\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B3/S0.25/model_3\n",
      "i   Layer name                      Output shape                     Num param  Inbound            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "0   conv2d_1_1 (Conv2D)             [None,32,32,8] [None,32,32,24]   2240       input              \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "1   bn_1_1 (BatchNormalization)     [None,32,32,8] [None,32,32,24]   160        conv2d_1_1         \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "2   relu_1_1 (Activation)           [None,32,32,8] [None,32,32,24]   0          bn_1_1             \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "3   conv2d_1_2 (Conv2D)             [None,32,32,8] [None,32,32,24]   26672      relu_1_1           \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "4   bn_1_2 (BatchNormalization)     [None,32,32,8] [None,32,32,24]   160        conv2d_1_2         \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "5   relu_1_2 (Activation)           [None,32,32,8] [None,32,32,24]   0          bn_1_2             \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "6   avg_pool2d_1 (AveragePooling2D  [None,16,16,8] [None,16,16,24]   0          relu_1_2           \n",
      "                                    [None,16,16,8] [None,16,16,24]                                 \n",
      "                                    [None,16,16,8] [None,16,16,24]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "7   conv2d_2_1 (Conv2D)             [None,16,16,16] [None,16,16,48]  53344      avg_pool2d_1       \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "8   bn_2_1 (BatchNormalization)     [None,16,16,16] [None,16,16,48]  320        conv2d_2_1         \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "9   relu_2_1 (Activation)           [None,16,16,16] [None,16,16,48]  0          bn_2_1             \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "10  conv2d_2_2 (Conv2D)             [None,16,16,16] [None,16,16,48]  106336     relu_2_1           \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "11  bn_2_2 (BatchNormalization)     [None,16,16,16] [None,16,16,48]  320        conv2d_2_2         \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "12  relu_2_2 (Activation)           [None,16,16,16] [None,16,16,48]  0          bn_2_2             \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "13  avg_pool2d_2 (AveragePooling2D  [None,8,8,16] [None,8,8,48]      0          relu_2_2           \n",
      "                                    [None,8,8,16] [None,8,8,48]                                    \n",
      "                                    [None,8,8,16] [None,8,8,48]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "14  conv2d_3_1 (Conv2D)             [None,8,8,32] [None,8,8,96]      212672     avg_pool2d_2       \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "15  bn_3_1 (BatchNormalization)     [None,8,8,32] [None,8,8,96]      640        conv2d_3_1         \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "16  relu_3_1 (Activation)           [None,8,8,32] [None,8,8,96]      0          bn_3_1             \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "17  conv2d_3_2 (Conv2D)             [None,8,8,32] [None,8,8,96]      424640     relu_3_1           \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "18  bn_3_2 (BatchNormalization)     [None,8,8,32] [None,8,8,96]      640        conv2d_3_2         \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "19  relu_3_2 (Activation)           [None,8,8,32] [None,8,8,96]      0          bn_3_2             \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "20  global_avg_pool2d (GlobalAvera  [None,32] [None,96]              0          relu_3_2           \n",
      "                                    [None,32] [None,96]                                            \n",
      "                                    [None,32] [None,96]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "21  fc1 (Dense)                     [None,32] [None,96]              47808      global_avg_pool2d  \n",
      "                                    [None,32] [None,96]                                            \n",
      "                                    [None,32] [None,96]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "22  bn_fc1 (BatchNormalization)     [None,32] [None,96]              640        fc1                \n",
      "                                    [None,32] [None,96]                                            \n",
      "                                    [None,32] [None,96]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "23  relu_fc1 (Activation)           [None,32] [None,96]              0          bn_fc1             \n",
      "                                    [None,32] [None,96]                                            \n",
      "                                    [None,32] [None,96]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "24  output (Dense)                  [None,10]                        3768       relu_fc1           \n",
      "                                    [None,10]                                                      \n",
      "                                    [None,10]                                                      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "Total parameters: 880360\n",
      "50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 - 20s - loss_1: 1.7699 - loss_2: 1.7794 - loss_3: 1.7909 - acc_ensemble: 0.4980 - acc_1: 0.4300 - acc_2: 0.4820 - acc_3: 0.4660 - val_loss_1: 1.5416 - val_loss_2: 1.5225 - val_loss_3: 1.5236 - val_acc_ensemble: 0.4787 - val_acc_1: 0.4254 - val_acc_2: 0.4355 - val_acc_3: 0.4391\n",
      "Epoch 2/50\n",
      "100/100 - 15s - loss_1: 1.4518 - loss_2: 1.4422 - loss_3: 1.4664 - acc_ensemble: 0.5620 - acc_1: 0.4560 - acc_2: 0.5380 - acc_3: 0.4940 - val_loss_1: 1.4232 - val_loss_2: 1.3263 - val_loss_3: 1.3522 - val_acc_ensemble: 0.5543 - val_acc_1: 0.4784 - val_acc_2: 0.5181 - val_acc_3: 0.5104\n",
      "Epoch 3/50\n",
      "100/100 - 12s - loss_1: 1.3141 - loss_2: 1.2759 - loss_3: 1.2653 - acc_ensemble: 0.6060 - acc_1: 0.5280 - acc_2: 0.5780 - acc_3: 0.5700 - val_loss_1: 1.2879 - val_loss_2: 1.2069 - val_loss_3: 1.2338 - val_acc_ensemble: 0.5952 - val_acc_1: 0.5244 - val_acc_2: 0.5604 - val_acc_3: 0.5561\n",
      "Epoch 4/50\n",
      "100/100 - 12s - loss_1: 1.1831 - loss_2: 1.1391 - loss_3: 1.1657 - acc_ensemble: 0.6540 - acc_1: 0.5800 - acc_2: 0.5940 - acc_3: 0.6080 - val_loss_1: 1.2017 - val_loss_2: 1.1393 - val_loss_3: 1.1347 - val_acc_ensemble: 0.6287 - val_acc_1: 0.5621 - val_acc_2: 0.5861 - val_acc_3: 0.5851\n",
      "Epoch 5/50\n",
      "100/100 - 12s - loss_1: 1.1264 - loss_2: 1.0581 - loss_3: 1.0471 - acc_ensemble: 0.6900 - acc_1: 0.6560 - acc_2: 0.6260 - acc_3: 0.6160 - val_loss_1: 1.0710 - val_loss_2: 1.0540 - val_loss_3: 1.1009 - val_acc_ensemble: 0.6611 - val_acc_1: 0.6189 - val_acc_2: 0.6173 - val_acc_3: 0.5968\n",
      "Epoch 6/50\n",
      "100/100 - 12s - loss_1: 1.0248 - loss_2: 0.9907 - loss_3: 0.9499 - acc_ensemble: 0.7220 - acc_1: 0.6680 - acc_2: 0.6580 - acc_3: 0.6580 - val_loss_1: 1.0286 - val_loss_2: 1.0302 - val_loss_3: 1.0222 - val_acc_ensemble: 0.6784 - val_acc_1: 0.6276 - val_acc_2: 0.6349 - val_acc_3: 0.6351\n",
      "Epoch 7/50\n",
      "100/100 - 12s - loss_1: 0.9469 - loss_2: 0.9098 - loss_3: 0.9408 - acc_ensemble: 0.7240 - acc_1: 0.6560 - acc_2: 0.6660 - acc_3: 0.7020 - val_loss_1: 1.0271 - val_loss_2: 0.9527 - val_loss_3: 0.9495 - val_acc_ensemble: 0.7010 - val_acc_1: 0.6320 - val_acc_2: 0.6558 - val_acc_3: 0.6584\n",
      "Epoch 8/50\n",
      "100/100 - 12s - loss_1: 0.9074 - loss_2: 0.9027 - loss_3: 0.8859 - acc_ensemble: 0.7600 - acc_1: 0.6840 - acc_2: 0.6820 - acc_3: 0.6740 - val_loss_1: 0.9496 - val_loss_2: 0.9213 - val_loss_3: 0.9091 - val_acc_ensemble: 0.7136 - val_acc_1: 0.6558 - val_acc_2: 0.6665 - val_acc_3: 0.6766\n",
      "Epoch 9/50\n",
      "100/100 - 12s - loss_1: 0.8360 - loss_2: 0.8075 - loss_3: 0.8088 - acc_ensemble: 0.7800 - acc_1: 0.7120 - acc_2: 0.6940 - acc_3: 0.7260 - val_loss_1: 0.9305 - val_loss_2: 0.9061 - val_loss_3: 0.8699 - val_acc_ensemble: 0.7229 - val_acc_1: 0.6677 - val_acc_2: 0.6800 - val_acc_3: 0.6914\n",
      "Epoch 10/50\n",
      "100/100 - 12s - loss_1: 0.7676 - loss_2: 0.7855 - loss_3: 0.7517 - acc_ensemble: 0.7700 - acc_1: 0.7540 - acc_2: 0.7040 - acc_3: 0.7160 - val_loss_1: 0.8919 - val_loss_2: 0.8738 - val_loss_3: 0.8671 - val_acc_ensemble: 0.7328 - val_acc_1: 0.6798 - val_acc_2: 0.6942 - val_acc_3: 0.6966\n",
      "Epoch 11/50\n",
      "100/100 - 13s - loss_1: 0.7487 - loss_2: 0.7177 - loss_3: 0.7443 - acc_ensemble: 0.8000 - acc_1: 0.7420 - acc_2: 0.7320 - acc_3: 0.7440 - val_loss_1: 0.8732 - val_loss_2: 0.8527 - val_loss_3: 0.8493 - val_acc_ensemble: 0.7426 - val_acc_1: 0.6913 - val_acc_2: 0.6980 - val_acc_3: 0.6998\n",
      "Epoch 12/50\n",
      "100/100 - 12s - loss_1: 0.7270 - loss_2: 0.6907 - loss_3: 0.6682 - acc_ensemble: 0.8040 - acc_1: 0.7600 - acc_2: 0.7380 - acc_3: 0.7520 - val_loss_1: 0.8574 - val_loss_2: 0.8295 - val_loss_3: 0.8262 - val_acc_ensemble: 0.7458 - val_acc_1: 0.6959 - val_acc_2: 0.7070 - val_acc_3: 0.7081\n",
      "Epoch 13/50\n",
      "100/100 - 12s - loss_1: 0.6906 - loss_2: 0.6505 - loss_3: 0.6448 - acc_ensemble: 0.8040 - acc_1: 0.7300 - acc_2: 0.7520 - acc_3: 0.7360 - val_loss_1: 0.8855 - val_loss_2: 0.8180 - val_loss_3: 0.8161 - val_acc_ensemble: 0.7529 - val_acc_1: 0.6893 - val_acc_2: 0.7124 - val_acc_3: 0.7121\n",
      "Epoch 14/50\n",
      "100/100 - 12s - loss_1: 0.6598 - loss_2: 0.5999 - loss_3: 0.5943 - acc_ensemble: 0.8260 - acc_1: 0.7600 - acc_2: 0.7680 - acc_3: 0.7960 - val_loss_1: 0.8597 - val_loss_2: 0.7909 - val_loss_3: 0.7810 - val_acc_ensemble: 0.7620 - val_acc_1: 0.7009 - val_acc_2: 0.7244 - val_acc_3: 0.7284\n",
      "Epoch 15/50\n",
      "100/100 - 13s - loss_1: 0.6188 - loss_2: 0.5871 - loss_3: 0.5935 - acc_ensemble: 0.8220 - acc_1: 0.7600 - acc_2: 0.7880 - acc_3: 0.7580 - val_loss_1: 0.8253 - val_loss_2: 0.7859 - val_loss_3: 0.7877 - val_acc_ensemble: 0.7717 - val_acc_1: 0.7124 - val_acc_2: 0.7257 - val_acc_3: 0.7259\n",
      "Epoch 16/50\n",
      "100/100 - 12s - loss_1: 0.5852 - loss_2: 0.5386 - loss_3: 0.5690 - acc_ensemble: 0.8460 - acc_1: 0.7720 - acc_2: 0.7980 - acc_3: 0.7960 - val_loss_1: 0.8167 - val_loss_2: 0.7780 - val_loss_3: 0.7791 - val_acc_ensemble: 0.7707 - val_acc_1: 0.7191 - val_acc_2: 0.7274 - val_acc_3: 0.7289\n",
      "Epoch 17/50\n",
      "100/100 - 12s - loss_1: 0.5292 - loss_2: 0.5261 - loss_3: 0.5196 - acc_ensemble: 0.8400 - acc_1: 0.7920 - acc_2: 0.7780 - acc_3: 0.7880 - val_loss_1: 0.7951 - val_loss_2: 0.7942 - val_loss_3: 0.7815 - val_acc_ensemble: 0.7743 - val_acc_1: 0.7224 - val_acc_2: 0.7276 - val_acc_3: 0.7287\n",
      "Epoch 18/50\n",
      "100/100 - 12s - loss_1: 0.5379 - loss_2: 0.4646 - loss_3: 0.4945 - acc_ensemble: 0.8560 - acc_1: 0.7980 - acc_2: 0.7960 - acc_3: 0.7940 - val_loss_1: 0.7811 - val_loss_2: 0.8356 - val_loss_3: 0.7784 - val_acc_ensemble: 0.7772 - val_acc_1: 0.7359 - val_acc_2: 0.7176 - val_acc_3: 0.7345\n",
      "Epoch 19/50\n",
      "100/100 - 12s - loss_1: 0.5036 - loss_2: 0.4504 - loss_3: 0.4697 - acc_ensemble: 0.8460 - acc_1: 0.8000 - acc_2: 0.7900 - acc_3: 0.7940 - val_loss_1: 0.7918 - val_loss_2: 0.7800 - val_loss_3: 0.7844 - val_acc_ensemble: 0.7795 - val_acc_1: 0.7331 - val_acc_2: 0.7385 - val_acc_3: 0.7309\n",
      "Epoch 20/50\n",
      "100/100 - 12s - loss_1: 0.4496 - loss_2: 0.4240 - loss_3: 0.4482 - acc_ensemble: 0.8500 - acc_1: 0.7940 - acc_2: 0.8200 - acc_3: 0.8000 - val_loss_1: 0.8022 - val_loss_2: 0.8022 - val_loss_3: 0.7940 - val_acc_ensemble: 0.7854 - val_acc_1: 0.7298 - val_acc_2: 0.7333 - val_acc_3: 0.7312\n",
      "Epoch 21/50\n",
      "100/100 - 12s - loss_1: 0.4151 - loss_2: 0.4205 - loss_3: 0.4356 - acc_ensemble: 0.8680 - acc_1: 0.7840 - acc_2: 0.7940 - acc_3: 0.8040 - val_loss_1: 0.7905 - val_loss_2: 0.7753 - val_loss_3: 0.7672 - val_acc_ensemble: 0.7899 - val_acc_1: 0.7374 - val_acc_2: 0.7397 - val_acc_3: 0.7439\n",
      "Epoch 22/50\n",
      "100/100 - 12s - loss_1: 0.4229 - loss_2: 0.4063 - loss_3: 0.4126 - acc_ensemble: 0.8740 - acc_1: 0.8000 - acc_2: 0.8160 - acc_3: 0.8240 - val_loss_1: 0.8068 - val_loss_2: 0.8188 - val_loss_3: 0.7404 - val_acc_ensemble: 0.7895 - val_acc_1: 0.7320 - val_acc_2: 0.7363 - val_acc_3: 0.7502\n",
      "Epoch 23/50\n",
      "100/100 - 12s - loss_1: 0.4111 - loss_2: 0.3631 - loss_3: 0.3901 - acc_ensemble: 0.8680 - acc_1: 0.8140 - acc_2: 0.8040 - acc_3: 0.7920 - val_loss_1: 0.7876 - val_loss_2: 0.7694 - val_loss_3: 0.7718 - val_acc_ensemble: 0.7955 - val_acc_1: 0.7369 - val_acc_2: 0.7526 - val_acc_3: 0.7436\n",
      "Epoch 24/50\n",
      "100/100 - 12s - loss_1: 0.3952 - loss_2: 0.3608 - loss_3: 0.3358 - acc_ensemble: 0.8740 - acc_1: 0.8160 - acc_2: 0.8080 - acc_3: 0.8020 - val_loss_1: 0.7888 - val_loss_2: 0.7643 - val_loss_3: 0.7859 - val_acc_ensemble: 0.7998 - val_acc_1: 0.7428 - val_acc_2: 0.7536 - val_acc_3: 0.7411\n",
      "Epoch 25/50\n",
      "100/100 - 12s - loss_1: 0.3504 - loss_2: 0.2896 - loss_3: 0.3267 - acc_ensemble: 0.8460 - acc_1: 0.8000 - acc_2: 0.8040 - acc_3: 0.8200 - val_loss_1: 0.7890 - val_loss_2: 0.7889 - val_loss_3: 0.7702 - val_acc_ensemble: 0.7966 - val_acc_1: 0.7403 - val_acc_2: 0.7507 - val_acc_3: 0.7475\n",
      "Epoch 26/50\n",
      "100/100 - 12s - loss_1: 0.3328 - loss_2: 0.3265 - loss_3: 0.3179 - acc_ensemble: 0.8640 - acc_1: 0.7900 - acc_2: 0.8260 - acc_3: 0.8260 - val_loss_1: 0.8032 - val_loss_2: 0.7716 - val_loss_3: 0.8034 - val_acc_ensemble: 0.8026 - val_acc_1: 0.7394 - val_acc_2: 0.7519 - val_acc_3: 0.7506\n",
      "Epoch 27/50\n",
      "100/100 - 12s - loss_1: 0.2916 - loss_2: 0.3253 - loss_3: 0.2759 - acc_ensemble: 0.8820 - acc_1: 0.8120 - acc_2: 0.8400 - acc_3: 0.8340 - val_loss_1: 0.8038 - val_loss_2: 0.7667 - val_loss_3: 0.7579 - val_acc_ensemble: 0.8081 - val_acc_1: 0.7439 - val_acc_2: 0.7604 - val_acc_3: 0.7604\n",
      "Epoch 28/50\n",
      "100/100 - 12s - loss_1: 0.2963 - loss_2: 0.2805 - loss_3: 0.2561 - acc_ensemble: 0.8720 - acc_1: 0.8020 - acc_2: 0.8280 - acc_3: 0.8040 - val_loss_1: 0.8168 - val_loss_2: 0.7953 - val_loss_3: 0.8040 - val_acc_ensemble: 0.8050 - val_acc_1: 0.7459 - val_acc_2: 0.7529 - val_acc_3: 0.7443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50\n",
      "100/100 - 12s - loss_1: 0.2590 - loss_2: 0.2271 - loss_3: 0.2621 - acc_ensemble: 0.8860 - acc_1: 0.8400 - acc_2: 0.8180 - acc_3: 0.8140 - val_loss_1: 0.7814 - val_loss_2: 0.8115 - val_loss_3: 0.8089 - val_acc_ensemble: 0.8026 - val_acc_1: 0.7542 - val_acc_2: 0.7531 - val_acc_3: 0.7490\n",
      "Epoch 30/50\n",
      "100/100 - 12s - loss_1: 0.2434 - loss_2: 0.2311 - loss_3: 0.2361 - acc_ensemble: 0.8800 - acc_1: 0.8100 - acc_2: 0.8440 - acc_3: 0.8140 - val_loss_1: 0.8097 - val_loss_2: 0.8106 - val_loss_3: 0.8370 - val_acc_ensemble: 0.8057 - val_acc_1: 0.7548 - val_acc_2: 0.7539 - val_acc_3: 0.7525\n",
      "Epoch 31/50\n",
      "100/100 - 13s - loss_1: 0.2303 - loss_2: 0.2283 - loss_3: 0.2402 - acc_ensemble: 0.8760 - acc_1: 0.8060 - acc_2: 0.8260 - acc_3: 0.8180 - val_loss_1: 0.8437 - val_loss_2: 0.8390 - val_loss_3: 0.8108 - val_acc_ensemble: 0.8043 - val_acc_1: 0.7477 - val_acc_2: 0.7463 - val_acc_3: 0.7532\n",
      "Epoch 32/50\n",
      "100/100 - 12s - loss_1: 0.2305 - loss_2: 0.1972 - loss_3: 0.1990 - acc_ensemble: 0.8860 - acc_1: 0.8140 - acc_2: 0.8280 - acc_3: 0.8280 - val_loss_1: 0.8520 - val_loss_2: 0.8058 - val_loss_3: 0.8133 - val_acc_ensemble: 0.8058 - val_acc_1: 0.7429 - val_acc_2: 0.7579 - val_acc_3: 0.7589\n",
      "Epoch 33/50\n",
      "100/100 - 12s - loss_1: 0.2036 - loss_2: 0.2012 - loss_3: 0.1702 - acc_ensemble: 0.8900 - acc_1: 0.8160 - acc_2: 0.8320 - acc_3: 0.8460 - val_loss_1: 0.8612 - val_loss_2: 0.8689 - val_loss_3: 0.8261 - val_acc_ensemble: 0.8098 - val_acc_1: 0.7451 - val_acc_2: 0.7456 - val_acc_3: 0.7564\n",
      "Epoch 34/50\n",
      "100/100 - 12s - loss_1: 0.1846 - loss_2: 0.2210 - loss_3: 0.2009 - acc_ensemble: 0.8660 - acc_1: 0.8160 - acc_2: 0.8280 - acc_3: 0.8340 - val_loss_1: 0.8390 - val_loss_2: 0.8393 - val_loss_3: 0.8786 - val_acc_ensemble: 0.8086 - val_acc_1: 0.7544 - val_acc_2: 0.7526 - val_acc_3: 0.7452\n",
      "Epoch 35/50\n",
      "100/100 - 12s - loss_1: 0.1588 - loss_2: 0.1804 - loss_3: 0.1993 - acc_ensemble: 0.8920 - acc_1: 0.8180 - acc_2: 0.8420 - acc_3: 0.8360 - val_loss_1: 0.8644 - val_loss_2: 0.8796 - val_loss_3: 0.8562 - val_acc_ensemble: 0.8112 - val_acc_1: 0.7556 - val_acc_2: 0.7543 - val_acc_3: 0.7534\n",
      "Epoch 36/50\n",
      "100/100 - 12s - loss_1: 0.1878 - loss_2: 0.1413 - loss_3: 0.1534 - acc_ensemble: 0.8820 - acc_1: 0.8000 - acc_2: 0.8340 - acc_3: 0.8080 - val_loss_1: 0.8905 - val_loss_2: 0.8922 - val_loss_3: 0.8544 - val_acc_ensemble: 0.8078 - val_acc_1: 0.7477 - val_acc_2: 0.7546 - val_acc_3: 0.7556\n",
      "Epoch 37/50\n",
      "100/100 - 12s - loss_1: 0.1998 - loss_2: 0.1334 - loss_3: 0.1538 - acc_ensemble: 0.8980 - acc_1: 0.8080 - acc_2: 0.8420 - acc_3: 0.8300 - val_loss_1: 0.9113 - val_loss_2: 0.8812 - val_loss_3: 0.8775 - val_acc_ensemble: 0.8104 - val_acc_1: 0.7489 - val_acc_2: 0.7562 - val_acc_3: 0.7621\n",
      "Epoch 38/50\n",
      "100/100 - 12s - loss_1: 0.1657 - loss_2: 0.1207 - loss_3: 0.1454 - acc_ensemble: 0.8940 - acc_1: 0.8160 - acc_2: 0.8420 - acc_3: 0.8320 - val_loss_1: 0.9033 - val_loss_2: 0.9075 - val_loss_3: 0.8864 - val_acc_ensemble: 0.8121 - val_acc_1: 0.7451 - val_acc_2: 0.7574 - val_acc_3: 0.7542\n",
      "Epoch 39/50\n",
      "100/100 - 12s - loss_1: 0.1385 - loss_2: 0.1498 - loss_3: 0.1318 - acc_ensemble: 0.8880 - acc_1: 0.8240 - acc_2: 0.8340 - acc_3: 0.8340 - val_loss_1: 0.8552 - val_loss_2: 0.9280 - val_loss_3: 0.8749 - val_acc_ensemble: 0.8078 - val_acc_1: 0.7605 - val_acc_2: 0.7503 - val_acc_3: 0.7624\n",
      "Epoch 40/50\n",
      "100/100 - 12s - loss_1: 0.1275 - loss_2: 0.1278 - loss_3: 0.1186 - acc_ensemble: 0.8960 - acc_1: 0.8320 - acc_2: 0.8180 - acc_3: 0.8520 - val_loss_1: 0.8909 - val_loss_2: 0.9445 - val_loss_3: 0.8636 - val_acc_ensemble: 0.8074 - val_acc_1: 0.7515 - val_acc_2: 0.7453 - val_acc_3: 0.7663\n",
      "Epoch 41/50\n",
      "100/100 - 12s - loss_1: 0.1222 - loss_2: 0.1245 - loss_3: 0.0946 - acc_ensemble: 0.8880 - acc_1: 0.8220 - acc_2: 0.8220 - acc_3: 0.8420 - val_loss_1: 0.9658 - val_loss_2: 0.9538 - val_loss_3: 0.9393 - val_acc_ensemble: 0.8111 - val_acc_1: 0.7431 - val_acc_2: 0.7480 - val_acc_3: 0.7548\n",
      "Epoch 42/50\n",
      "100/100 - 12s - loss_1: 0.1185 - loss_2: 0.1234 - loss_3: 0.1291 - acc_ensemble: 0.9020 - acc_1: 0.8120 - acc_2: 0.8480 - acc_3: 0.8360 - val_loss_1: 0.9327 - val_loss_2: 0.9329 - val_loss_3: 0.9044 - val_acc_ensemble: 0.8144 - val_acc_1: 0.7466 - val_acc_2: 0.7532 - val_acc_3: 0.7632\n",
      "Epoch 43/50\n",
      "100/100 - 12s - loss_1: 0.1457 - loss_2: 0.1045 - loss_3: 0.0893 - acc_ensemble: 0.9000 - acc_1: 0.8340 - acc_2: 0.8300 - acc_3: 0.8480 - val_loss_1: 0.9652 - val_loss_2: 0.9560 - val_loss_3: 0.9413 - val_acc_ensemble: 0.8126 - val_acc_1: 0.7494 - val_acc_2: 0.7515 - val_acc_3: 0.7589\n",
      "Epoch 44/50\n",
      "100/100 - 12s - loss_1: 0.1103 - loss_2: 0.1310 - loss_3: 0.0951 - acc_ensemble: 0.8920 - acc_1: 0.8160 - acc_2: 0.8380 - acc_3: 0.8500 - val_loss_1: 0.9464 - val_loss_2: 0.9548 - val_loss_3: 0.9696 - val_acc_ensemble: 0.8098 - val_acc_1: 0.7502 - val_acc_2: 0.7550 - val_acc_3: 0.7509\n",
      "Epoch 45/50\n",
      "100/100 - 12s - loss_1: 0.1074 - loss_2: 0.1085 - loss_3: 0.1089 - acc_ensemble: 0.8900 - acc_1: 0.8380 - acc_2: 0.8500 - acc_3: 0.8500 - val_loss_1: 0.9447 - val_loss_2: 0.9458 - val_loss_3: 0.9514 - val_acc_ensemble: 0.8108 - val_acc_1: 0.7570 - val_acc_2: 0.7595 - val_acc_3: 0.7567\n",
      "Epoch 46/50\n",
      "100/100 - 12s - loss_1: 0.0906 - loss_2: 0.0970 - loss_3: 0.1069 - acc_ensemble: 0.8980 - acc_1: 0.8380 - acc_2: 0.8420 - acc_3: 0.8420 - val_loss_1: 0.9843 - val_loss_2: 0.9261 - val_loss_3: 0.9556 - val_acc_ensemble: 0.8141 - val_acc_1: 0.7527 - val_acc_2: 0.7618 - val_acc_3: 0.7586\n",
      "Epoch 47/50\n",
      "100/100 - 12s - loss_1: 0.0759 - loss_2: 0.0806 - loss_3: 0.1044 - acc_ensemble: 0.9020 - acc_1: 0.8320 - acc_2: 0.8500 - acc_3: 0.8520 - val_loss_1: 0.9673 - val_loss_2: 0.9739 - val_loss_3: 0.9308 - val_acc_ensemble: 0.8145 - val_acc_1: 0.7544 - val_acc_2: 0.7545 - val_acc_3: 0.7650\n",
      "Epoch 48/50\n",
      "100/100 - 12s - loss_1: 0.0566 - loss_2: 0.0865 - loss_3: 0.0859 - acc_ensemble: 0.9020 - acc_1: 0.8400 - acc_2: 0.8300 - acc_3: 0.8340 - val_loss_1: 0.9830 - val_loss_2: 0.9802 - val_loss_3: 0.9702 - val_acc_ensemble: 0.8149 - val_acc_1: 0.7593 - val_acc_2: 0.7557 - val_acc_3: 0.7626\n",
      "Epoch 49/50\n",
      "100/100 - 12s - loss_1: 0.0675 - loss_2: 0.1003 - loss_3: 0.1229 - acc_ensemble: 0.9000 - acc_1: 0.8300 - acc_2: 0.8300 - acc_3: 0.8040 - val_loss_1: 1.0217 - val_loss_2: 1.0545 - val_loss_3: 0.9833 - val_acc_ensemble: 0.8151 - val_acc_1: 0.7537 - val_acc_2: 0.7485 - val_acc_3: 0.7543\n",
      "Epoch 50/50\n",
      "100/100 - 12s - loss_1: 0.0903 - loss_2: 0.1150 - loss_3: 0.0922 - acc_ensemble: 0.9080 - acc_1: 0.8480 - acc_2: 0.8280 - acc_3: 0.8440 - val_loss_1: 1.0775 - val_loss_2: 1.0176 - val_loss_3: 0.9790 - val_acc_ensemble: 0.8112 - val_acc_1: 0.7435 - val_acc_2: 0.7506 - val_acc_3: 0.7620\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B3/S0.25/model_4\n",
      "i   Layer name                      Output shape                     Num param  Inbound            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "0   conv2d_1_1 (Conv2D)             [None,32,32,8] [None,32,32,24]   2240       input              \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "1   bn_1_1 (BatchNormalization)     [None,32,32,8] [None,32,32,24]   160        conv2d_1_1         \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "2   relu_1_1 (Activation)           [None,32,32,8] [None,32,32,24]   0          bn_1_1             \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "3   conv2d_1_2 (Conv2D)             [None,32,32,8] [None,32,32,24]   26672      relu_1_1           \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "4   bn_1_2 (BatchNormalization)     [None,32,32,8] [None,32,32,24]   160        conv2d_1_2         \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "5   relu_1_2 (Activation)           [None,32,32,8] [None,32,32,24]   0          bn_1_2             \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "                                    [None,32,32,8] [None,32,32,24]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "6   avg_pool2d_1 (AveragePooling2D  [None,16,16,8] [None,16,16,24]   0          relu_1_2           \n",
      "                                    [None,16,16,8] [None,16,16,24]                                 \n",
      "                                    [None,16,16,8] [None,16,16,24]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "7   conv2d_2_1 (Conv2D)             [None,16,16,16] [None,16,16,48]  53344      avg_pool2d_1       \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "8   bn_2_1 (BatchNormalization)     [None,16,16,16] [None,16,16,48]  320        conv2d_2_1         \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "9   relu_2_1 (Activation)           [None,16,16,16] [None,16,16,48]  0          bn_2_1             \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "10  conv2d_2_2 (Conv2D)             [None,16,16,16] [None,16,16,48]  106336     relu_2_1           \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "11  bn_2_2 (BatchNormalization)     [None,16,16,16] [None,16,16,48]  320        conv2d_2_2         \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "12  relu_2_2 (Activation)           [None,16,16,16] [None,16,16,48]  0          bn_2_2             \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "                                    [None,16,16,16] [None,16,16,48]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "13  avg_pool2d_2 (AveragePooling2D  [None,8,8,16] [None,8,8,48]      0          relu_2_2           \n",
      "                                    [None,8,8,16] [None,8,8,48]                                    \n",
      "                                    [None,8,8,16] [None,8,8,48]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "14  conv2d_3_1 (Conv2D)             [None,8,8,32] [None,8,8,96]      212672     avg_pool2d_2       \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "15  bn_3_1 (BatchNormalization)     [None,8,8,32] [None,8,8,96]      640        conv2d_3_1         \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "16  relu_3_1 (Activation)           [None,8,8,32] [None,8,8,96]      0          bn_3_1             \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "17  conv2d_3_2 (Conv2D)             [None,8,8,32] [None,8,8,96]      424640     relu_3_1           \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "18  bn_3_2 (BatchNormalization)     [None,8,8,32] [None,8,8,96]      640        conv2d_3_2         \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "19  relu_3_2 (Activation)           [None,8,8,32] [None,8,8,96]      0          bn_3_2             \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "                                    [None,8,8,32] [None,8,8,96]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "20  global_avg_pool2d (GlobalAvera  [None,32] [None,96]              0          relu_3_2           \n",
      "                                    [None,32] [None,96]                                            \n",
      "                                    [None,32] [None,96]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "21  fc1 (Dense)                     [None,32] [None,96]              47808      global_avg_pool2d  \n",
      "                                    [None,32] [None,96]                                            \n",
      "                                    [None,32] [None,96]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "22  bn_fc1 (BatchNormalization)     [None,32] [None,96]              640        fc1                \n",
      "                                    [None,32] [None,96]                                            \n",
      "                                    [None,32] [None,96]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "23  relu_fc1 (Activation)           [None,32] [None,96]              0          bn_fc1             \n",
      "                                    [None,32] [None,96]                                            \n",
      "                                    [None,32] [None,96]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "24  output (Dense)                  [None,10]                        3768       relu_fc1           \n",
      "                                    [None,10]                                                      \n",
      "                                    [None,10]                                                      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "Total parameters: 880360\n",
      "50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 - 20s - loss_1: 1.7632 - loss_2: 1.7781 - loss_3: 1.7656 - acc_ensemble: 0.5160 - acc_1: 0.4880 - acc_2: 0.4240 - acc_3: 0.4560 - val_loss_1: 1.5076 - val_loss_2: 1.5608 - val_loss_3: 1.5131 - val_acc_ensemble: 0.4749 - val_acc_1: 0.4428 - val_acc_2: 0.4247 - val_acc_3: 0.4428\n",
      "Epoch 2/50\n",
      "100/100 - 12s - loss_1: 1.4619 - loss_2: 1.4734 - loss_3: 1.4546 - acc_ensemble: 0.5620 - acc_1: 0.5160 - acc_2: 0.4980 - acc_3: 0.5240 - val_loss_1: 1.3640 - val_loss_2: 1.3561 - val_loss_3: 1.3159 - val_acc_ensemble: 0.5506 - val_acc_1: 0.5048 - val_acc_2: 0.4992 - val_acc_3: 0.5116\n",
      "Epoch 3/50\n",
      "100/100 - 13s - loss_1: 1.3359 - loss_2: 1.3046 - loss_3: 1.2494 - acc_ensemble: 0.6100 - acc_1: 0.5460 - acc_2: 0.5760 - acc_3: 0.5740 - val_loss_1: 1.2630 - val_loss_2: 1.2195 - val_loss_3: 1.2022 - val_acc_ensemble: 0.5964 - val_acc_1: 0.5358 - val_acc_2: 0.5566 - val_acc_3: 0.5651\n",
      "Epoch 4/50\n",
      "100/100 - 12s - loss_1: 1.1968 - loss_2: 1.1555 - loss_3: 1.1624 - acc_ensemble: 0.6460 - acc_1: 0.6040 - acc_2: 0.6100 - acc_3: 0.6120 - val_loss_1: 1.1483 - val_loss_2: 1.1187 - val_loss_3: 1.1450 - val_acc_ensemble: 0.6306 - val_acc_1: 0.5905 - val_acc_2: 0.5965 - val_acc_3: 0.5859\n",
      "Epoch 5/50\n",
      "100/100 - 12s - loss_1: 1.0899 - loss_2: 1.0990 - loss_3: 1.0846 - acc_ensemble: 0.6820 - acc_1: 0.6280 - acc_2: 0.6600 - acc_3: 0.6480 - val_loss_1: 1.0874 - val_loss_2: 1.0687 - val_loss_3: 1.0413 - val_acc_ensemble: 0.6593 - val_acc_1: 0.6101 - val_acc_2: 0.6164 - val_acc_3: 0.6265\n",
      "Epoch 6/50\n",
      "100/100 - 12s - loss_1: 1.0033 - loss_2: 1.0093 - loss_3: 1.0162 - acc_ensemble: 0.7140 - acc_1: 0.6780 - acc_2: 0.6640 - acc_3: 0.6620 - val_loss_1: 1.0262 - val_loss_2: 1.0079 - val_loss_3: 1.0378 - val_acc_ensemble: 0.6825 - val_acc_1: 0.6293 - val_acc_2: 0.6395 - val_acc_3: 0.6288\n",
      "Epoch 7/50\n",
      "100/100 - 12s - loss_1: 0.9525 - loss_2: 0.9283 - loss_3: 0.9393 - acc_ensemble: 0.7060 - acc_1: 0.6680 - acc_2: 0.6920 - acc_3: 0.6700 - val_loss_1: 0.9937 - val_loss_2: 0.9469 - val_loss_3: 0.9779 - val_acc_ensemble: 0.6999 - val_acc_1: 0.6490 - val_acc_2: 0.6610 - val_acc_3: 0.6556\n",
      "Epoch 8/50\n",
      "100/100 - 12s - loss_1: 0.8871 - loss_2: 0.8614 - loss_3: 0.9017 - acc_ensemble: 0.7280 - acc_1: 0.6660 - acc_2: 0.7240 - acc_3: 0.6880 - val_loss_1: 0.9386 - val_loss_2: 0.9161 - val_loss_3: 0.9629 - val_acc_ensemble: 0.7092 - val_acc_1: 0.6625 - val_acc_2: 0.6773 - val_acc_3: 0.6572\n",
      "Epoch 9/50\n",
      "100/100 - 12s - loss_1: 0.8277 - loss_2: 0.8212 - loss_3: 0.8670 - acc_ensemble: 0.7500 - acc_1: 0.7020 - acc_2: 0.7080 - acc_3: 0.7140 - val_loss_1: 0.8972 - val_loss_2: 0.9019 - val_loss_3: 0.9374 - val_acc_ensemble: 0.7128 - val_acc_1: 0.6782 - val_acc_2: 0.6730 - val_acc_3: 0.6695\n",
      "Epoch 10/50\n",
      "100/100 - 12s - loss_1: 0.8050 - loss_2: 0.7813 - loss_3: 0.8034 - acc_ensemble: 0.7520 - acc_1: 0.7240 - acc_2: 0.7320 - acc_3: 0.7000 - val_loss_1: 0.8684 - val_loss_2: 0.8655 - val_loss_3: 0.9157 - val_acc_ensemble: 0.7297 - val_acc_1: 0.6876 - val_acc_2: 0.6899 - val_acc_3: 0.6750\n",
      "Epoch 11/50\n",
      "100/100 - 12s - loss_1: 0.7432 - loss_2: 0.7523 - loss_3: 0.7577 - acc_ensemble: 0.7840 - acc_1: 0.7080 - acc_2: 0.7340 - acc_3: 0.7160 - val_loss_1: 0.8922 - val_loss_2: 0.8281 - val_loss_3: 0.9038 - val_acc_ensemble: 0.7416 - val_acc_1: 0.6867 - val_acc_2: 0.7089 - val_acc_3: 0.6792\n",
      "Epoch 12/50\n",
      "100/100 - 12s - loss_1: 0.7246 - loss_2: 0.6944 - loss_3: 0.7234 - acc_ensemble: 0.7760 - acc_1: 0.7400 - acc_2: 0.7340 - acc_3: 0.7500 - val_loss_1: 0.8280 - val_loss_2: 0.8299 - val_loss_3: 0.8264 - val_acc_ensemble: 0.7479 - val_acc_1: 0.7084 - val_acc_2: 0.7066 - val_acc_3: 0.7088\n",
      "Epoch 13/50\n",
      "100/100 - 12s - loss_1: 0.6838 - loss_2: 0.6656 - loss_3: 0.7006 - acc_ensemble: 0.8120 - acc_1: 0.7420 - acc_2: 0.7420 - acc_3: 0.7420 - val_loss_1: 0.8104 - val_loss_2: 0.8200 - val_loss_3: 0.8444 - val_acc_ensemble: 0.7559 - val_acc_1: 0.7150 - val_acc_2: 0.7133 - val_acc_3: 0.7021\n",
      "Epoch 14/50\n",
      "100/100 - 12s - loss_1: 0.6513 - loss_2: 0.6118 - loss_3: 0.6242 - acc_ensemble: 0.8080 - acc_1: 0.7540 - acc_2: 0.7440 - acc_3: 0.7560 - val_loss_1: 0.8176 - val_loss_2: 0.7869 - val_loss_3: 0.8203 - val_acc_ensemble: 0.7631 - val_acc_1: 0.7140 - val_acc_2: 0.7272 - val_acc_3: 0.7192\n",
      "Epoch 15/50\n",
      "100/100 - 12s - loss_1: 0.6173 - loss_2: 0.5824 - loss_3: 0.6049 - acc_ensemble: 0.8180 - acc_1: 0.7640 - acc_2: 0.7580 - acc_3: 0.7520 - val_loss_1: 0.8042 - val_loss_2: 0.8177 - val_loss_3: 0.8319 - val_acc_ensemble: 0.7645 - val_acc_1: 0.7204 - val_acc_2: 0.7162 - val_acc_3: 0.7110\n",
      "Epoch 16/50\n",
      "100/100 - 12s - loss_1: 0.5869 - loss_2: 0.5495 - loss_3: 0.5669 - acc_ensemble: 0.8320 - acc_1: 0.7640 - acc_2: 0.7760 - acc_3: 0.7600 - val_loss_1: 0.7978 - val_loss_2: 0.7791 - val_loss_3: 0.7976 - val_acc_ensemble: 0.7737 - val_acc_1: 0.7243 - val_acc_2: 0.7274 - val_acc_3: 0.7294\n",
      "Epoch 17/50\n",
      "100/100 - 12s - loss_1: 0.5460 - loss_2: 0.5292 - loss_3: 0.5296 - acc_ensemble: 0.8360 - acc_1: 0.7880 - acc_2: 0.7580 - acc_3: 0.7740 - val_loss_1: 0.7852 - val_loss_2: 0.8137 - val_loss_3: 0.7767 - val_acc_ensemble: 0.7753 - val_acc_1: 0.7290 - val_acc_2: 0.7270 - val_acc_3: 0.7335\n",
      "Epoch 18/50\n",
      "100/100 - 12s - loss_1: 0.5162 - loss_2: 0.4855 - loss_3: 0.5174 - acc_ensemble: 0.8380 - acc_1: 0.7920 - acc_2: 0.7760 - acc_3: 0.7960 - val_loss_1: 0.7767 - val_loss_2: 0.7743 - val_loss_3: 0.7958 - val_acc_ensemble: 0.7809 - val_acc_1: 0.7339 - val_acc_2: 0.7333 - val_acc_3: 0.7346\n",
      "Epoch 19/50\n",
      "100/100 - 12s - loss_1: 0.4928 - loss_2: 0.4953 - loss_3: 0.4995 - acc_ensemble: 0.8500 - acc_1: 0.8060 - acc_2: 0.7980 - acc_3: 0.8000 - val_loss_1: 0.7389 - val_loss_2: 0.7543 - val_loss_3: 0.7965 - val_acc_ensemble: 0.7887 - val_acc_1: 0.7472 - val_acc_2: 0.7401 - val_acc_3: 0.7359\n",
      "Epoch 20/50\n",
      "100/100 - 12s - loss_1: 0.4248 - loss_2: 0.4210 - loss_3: 0.4516 - acc_ensemble: 0.8560 - acc_1: 0.8040 - acc_2: 0.8060 - acc_3: 0.7860 - val_loss_1: 0.7381 - val_loss_2: 0.7486 - val_loss_3: 0.8022 - val_acc_ensemble: 0.7929 - val_acc_1: 0.7506 - val_acc_2: 0.7431 - val_acc_3: 0.7348\n",
      "Epoch 21/50\n",
      "100/100 - 12s - loss_1: 0.4291 - loss_2: 0.4387 - loss_3: 0.4229 - acc_ensemble: 0.8340 - acc_1: 0.7800 - acc_2: 0.8100 - acc_3: 0.7900 - val_loss_1: 0.7801 - val_loss_2: 0.7481 - val_loss_3: 0.7985 - val_acc_ensemble: 0.7918 - val_acc_1: 0.7396 - val_acc_2: 0.7460 - val_acc_3: 0.7336\n",
      "Epoch 22/50\n",
      "100/100 - 12s - loss_1: 0.4106 - loss_2: 0.3653 - loss_3: 0.4193 - acc_ensemble: 0.8660 - acc_1: 0.7940 - acc_2: 0.7960 - acc_3: 0.8080 - val_loss_1: 0.7472 - val_loss_2: 0.7630 - val_loss_3: 0.8086 - val_acc_ensemble: 0.7962 - val_acc_1: 0.7513 - val_acc_2: 0.7511 - val_acc_3: 0.7338\n",
      "Epoch 23/50\n",
      "100/100 - 12s - loss_1: 0.3956 - loss_2: 0.3703 - loss_3: 0.3874 - acc_ensemble: 0.8620 - acc_1: 0.7940 - acc_2: 0.8220 - acc_3: 0.7980 - val_loss_1: 0.7791 - val_loss_2: 0.7641 - val_loss_3: 0.7926 - val_acc_ensemble: 0.7969 - val_acc_1: 0.7475 - val_acc_2: 0.7474 - val_acc_3: 0.7426\n",
      "Epoch 24/50\n",
      "100/100 - 12s - loss_1: 0.3475 - loss_2: 0.3620 - loss_3: 0.3691 - acc_ensemble: 0.8700 - acc_1: 0.8180 - acc_2: 0.8040 - acc_3: 0.8060 - val_loss_1: 0.7630 - val_loss_2: 0.7601 - val_loss_3: 0.7766 - val_acc_ensemble: 0.7998 - val_acc_1: 0.7518 - val_acc_2: 0.7476 - val_acc_3: 0.7443\n",
      "Epoch 25/50\n",
      "100/100 - 12s - loss_1: 0.3591 - loss_2: 0.3195 - loss_3: 0.3465 - acc_ensemble: 0.8780 - acc_1: 0.8320 - acc_2: 0.8180 - acc_3: 0.8100 - val_loss_1: 0.7637 - val_loss_2: 0.7529 - val_loss_3: 0.7813 - val_acc_ensemble: 0.8005 - val_acc_1: 0.7553 - val_acc_2: 0.7543 - val_acc_3: 0.7444\n",
      "Epoch 26/50\n",
      "100/100 - 12s - loss_1: 0.2743 - loss_2: 0.2867 - loss_3: 0.3534 - acc_ensemble: 0.8800 - acc_1: 0.8260 - acc_2: 0.8200 - acc_3: 0.8100 - val_loss_1: 0.7988 - val_loss_2: 0.7643 - val_loss_3: 0.8061 - val_acc_ensemble: 0.7996 - val_acc_1: 0.7463 - val_acc_2: 0.7551 - val_acc_3: 0.7423\n",
      "Epoch 27/50\n",
      "100/100 - 12s - loss_1: 0.3059 - loss_2: 0.2546 - loss_3: 0.3192 - acc_ensemble: 0.8900 - acc_1: 0.8280 - acc_2: 0.8240 - acc_3: 0.8160 - val_loss_1: 0.7934 - val_loss_2: 0.7921 - val_loss_3: 0.7943 - val_acc_ensemble: 0.8023 - val_acc_1: 0.7486 - val_acc_2: 0.7495 - val_acc_3: 0.7478\n",
      "Epoch 28/50\n",
      "100/100 - 12s - loss_1: 0.2859 - loss_2: 0.2445 - loss_3: 0.3130 - acc_ensemble: 0.8780 - acc_1: 0.8240 - acc_2: 0.8480 - acc_3: 0.8260 - val_loss_1: 0.7687 - val_loss_2: 0.7797 - val_loss_3: 0.8183 - val_acc_ensemble: 0.8081 - val_acc_1: 0.7590 - val_acc_2: 0.7580 - val_acc_3: 0.7496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50\n",
      "100/100 - 12s - loss_1: 0.2674 - loss_2: 0.2528 - loss_3: 0.2934 - acc_ensemble: 0.8920 - acc_1: 0.8280 - acc_2: 0.8080 - acc_3: 0.8400 - val_loss_1: 0.7871 - val_loss_2: 0.8729 - val_loss_3: 0.8397 - val_acc_ensemble: 0.8043 - val_acc_1: 0.7511 - val_acc_2: 0.7307 - val_acc_3: 0.7419\n",
      "Epoch 30/50\n",
      "100/100 - 12s - loss_1: 0.2374 - loss_2: 0.2335 - loss_3: 0.2287 - acc_ensemble: 0.8980 - acc_1: 0.8400 - acc_2: 0.8340 - acc_3: 0.8240 - val_loss_1: 0.8174 - val_loss_2: 0.7999 - val_loss_3: 0.8276 - val_acc_ensemble: 0.8067 - val_acc_1: 0.7547 - val_acc_2: 0.7599 - val_acc_3: 0.7498\n",
      "Epoch 31/50\n",
      "100/100 - 12s - loss_1: 0.2229 - loss_2: 0.1961 - loss_3: 0.2062 - acc_ensemble: 0.8940 - acc_1: 0.8260 - acc_2: 0.8420 - acc_3: 0.8280 - val_loss_1: 0.8009 - val_loss_2: 0.8391 - val_loss_3: 0.8237 - val_acc_ensemble: 0.8085 - val_acc_1: 0.7635 - val_acc_2: 0.7572 - val_acc_3: 0.7531\n",
      "Epoch 32/50\n",
      "100/100 - 12s - loss_1: 0.2013 - loss_2: 0.2335 - loss_3: 0.1798 - acc_ensemble: 0.9040 - acc_1: 0.8400 - acc_2: 0.8220 - acc_3: 0.8200 - val_loss_1: 0.8203 - val_loss_2: 0.8540 - val_loss_3: 0.8961 - val_acc_ensemble: 0.8068 - val_acc_1: 0.7565 - val_acc_2: 0.7511 - val_acc_3: 0.7398\n",
      "Epoch 33/50\n",
      "100/100 - 12s - loss_1: 0.2114 - loss_2: 0.1798 - loss_3: 0.2670 - acc_ensemble: 0.9000 - acc_1: 0.8280 - acc_2: 0.8400 - acc_3: 0.8040 - val_loss_1: 0.8300 - val_loss_2: 0.8588 - val_loss_3: 0.8870 - val_acc_ensemble: 0.8090 - val_acc_1: 0.7550 - val_acc_2: 0.7528 - val_acc_3: 0.7369\n",
      "Epoch 34/50\n",
      "100/100 - 12s - loss_1: 0.1688 - loss_2: 0.1784 - loss_3: 0.2165 - acc_ensemble: 0.8900 - acc_1: 0.8400 - acc_2: 0.8200 - acc_3: 0.8460 - val_loss_1: 0.8375 - val_loss_2: 0.8450 - val_loss_3: 0.8534 - val_acc_ensemble: 0.8081 - val_acc_1: 0.7590 - val_acc_2: 0.7557 - val_acc_3: 0.7513\n",
      "Epoch 35/50\n",
      "100/100 - 12s - loss_1: 0.1763 - loss_2: 0.1655 - loss_3: 0.1792 - acc_ensemble: 0.9060 - acc_1: 0.8220 - acc_2: 0.8260 - acc_3: 0.8480 - val_loss_1: 0.8893 - val_loss_2: 0.9323 - val_loss_3: 0.8532 - val_acc_ensemble: 0.8088 - val_acc_1: 0.7442 - val_acc_2: 0.7362 - val_acc_3: 0.7499\n",
      "Epoch 36/50\n",
      "100/100 - 12s - loss_1: 0.1820 - loss_2: 0.1818 - loss_3: 0.1758 - acc_ensemble: 0.8940 - acc_1: 0.8020 - acc_2: 0.8520 - acc_3: 0.8480 - val_loss_1: 0.9249 - val_loss_2: 0.8790 - val_loss_3: 0.8615 - val_acc_ensemble: 0.8104 - val_acc_1: 0.7424 - val_acc_2: 0.7500 - val_acc_3: 0.7480\n",
      "Epoch 37/50\n",
      "100/100 - 12s - loss_1: 0.1797 - loss_2: 0.1647 - loss_3: 0.1747 - acc_ensemble: 0.9100 - acc_1: 0.8380 - acc_2: 0.8240 - acc_3: 0.8260 - val_loss_1: 0.8664 - val_loss_2: 0.8797 - val_loss_3: 0.8941 - val_acc_ensemble: 0.8107 - val_acc_1: 0.7595 - val_acc_2: 0.7498 - val_acc_3: 0.7476\n",
      "Epoch 38/50\n",
      "100/100 - 12s - loss_1: 0.1408 - loss_2: 0.1499 - loss_3: 0.1710 - acc_ensemble: 0.8920 - acc_1: 0.8140 - acc_2: 0.8400 - acc_3: 0.8260 - val_loss_1: 0.9705 - val_loss_2: 0.8615 - val_loss_3: 0.9699 - val_acc_ensemble: 0.8056 - val_acc_1: 0.7380 - val_acc_2: 0.7613 - val_acc_3: 0.7308\n",
      "Epoch 39/50\n",
      "100/100 - 12s - loss_1: 0.1591 - loss_2: 0.1023 - loss_3: 0.1985 - acc_ensemble: 0.9120 - acc_1: 0.8360 - acc_2: 0.8580 - acc_3: 0.8380 - val_loss_1: 0.8973 - val_loss_2: 0.8779 - val_loss_3: 0.9371 - val_acc_ensemble: 0.8107 - val_acc_1: 0.7578 - val_acc_2: 0.7628 - val_acc_3: 0.7409\n",
      "Epoch 40/50\n",
      "100/100 - 12s - loss_1: 0.1564 - loss_2: 0.0916 - loss_3: 0.1548 - acc_ensemble: 0.9200 - acc_1: 0.8360 - acc_2: 0.8400 - acc_3: 0.8440 - val_loss_1: 0.9456 - val_loss_2: 0.9082 - val_loss_3: 0.8899 - val_acc_ensemble: 0.8118 - val_acc_1: 0.7454 - val_acc_2: 0.7596 - val_acc_3: 0.7488\n",
      "Epoch 41/50\n",
      "100/100 - 12s - loss_1: 0.1566 - loss_2: 0.1141 - loss_3: 0.1367 - acc_ensemble: 0.9000 - acc_1: 0.8420 - acc_2: 0.8440 - acc_3: 0.8240 - val_loss_1: 0.9028 - val_loss_2: 0.9417 - val_loss_3: 0.9449 - val_acc_ensemble: 0.8104 - val_acc_1: 0.7567 - val_acc_2: 0.7612 - val_acc_3: 0.7405\n",
      "Epoch 42/50\n",
      "100/100 - 12s - loss_1: 0.1053 - loss_2: 0.1113 - loss_3: 0.1163 - acc_ensemble: 0.9140 - acc_1: 0.8540 - acc_2: 0.8440 - acc_3: 0.8300 - val_loss_1: 0.9010 - val_loss_2: 0.9685 - val_loss_3: 0.9177 - val_acc_ensemble: 0.8121 - val_acc_1: 0.7628 - val_acc_2: 0.7546 - val_acc_3: 0.7542\n",
      "Epoch 43/50\n",
      "100/100 - 12s - loss_1: 0.0817 - loss_2: 0.1141 - loss_3: 0.1086 - acc_ensemble: 0.9140 - acc_1: 0.8500 - acc_2: 0.8480 - acc_3: 0.8400 - val_loss_1: 0.8920 - val_loss_2: 0.9291 - val_loss_3: 0.8914 - val_acc_ensemble: 0.8161 - val_acc_1: 0.7636 - val_acc_2: 0.7574 - val_acc_3: 0.7623\n",
      "Epoch 44/50\n",
      "100/100 - 12s - loss_1: 0.0881 - loss_2: 0.1186 - loss_3: 0.0755 - acc_ensemble: 0.9160 - acc_1: 0.8540 - acc_2: 0.8480 - acc_3: 0.8380 - val_loss_1: 0.9330 - val_loss_2: 0.9579 - val_loss_3: 0.9516 - val_acc_ensemble: 0.8175 - val_acc_1: 0.7659 - val_acc_2: 0.7536 - val_acc_3: 0.7545\n",
      "Epoch 45/50\n",
      "100/100 - 12s - loss_1: 0.0977 - loss_2: 0.1062 - loss_3: 0.0739 - acc_ensemble: 0.9200 - acc_1: 0.8480 - acc_2: 0.8540 - acc_3: 0.8400 - val_loss_1: 0.9579 - val_loss_2: 0.9528 - val_loss_3: 0.9614 - val_acc_ensemble: 0.8166 - val_acc_1: 0.7615 - val_acc_2: 0.7589 - val_acc_3: 0.7536\n",
      "Epoch 46/50\n",
      "100/100 - 12s - loss_1: 0.1040 - loss_2: 0.0904 - loss_3: 0.0734 - acc_ensemble: 0.9220 - acc_1: 0.8480 - acc_2: 0.8300 - acc_3: 0.8360 - val_loss_1: 0.9463 - val_loss_2: 0.9612 - val_loss_3: 0.9856 - val_acc_ensemble: 0.8162 - val_acc_1: 0.7644 - val_acc_2: 0.7577 - val_acc_3: 0.7537\n",
      "Epoch 47/50\n",
      "100/100 - 12s - loss_1: 0.1015 - loss_2: 0.0862 - loss_3: 0.0702 - acc_ensemble: 0.9300 - acc_1: 0.8480 - acc_2: 0.8520 - acc_3: 0.8500 - val_loss_1: 0.9796 - val_loss_2: 1.0367 - val_loss_3: 1.0334 - val_acc_ensemble: 0.8114 - val_acc_1: 0.7579 - val_acc_2: 0.7358 - val_acc_3: 0.7454\n",
      "Epoch 48/50\n",
      "100/100 - 12s - loss_1: 0.0655 - loss_2: 0.1053 - loss_3: 0.0848 - acc_ensemble: 0.9100 - acc_1: 0.8520 - acc_2: 0.8440 - acc_3: 0.8380 - val_loss_1: 0.9641 - val_loss_2: 1.0036 - val_loss_3: 1.0243 - val_acc_ensemble: 0.8164 - val_acc_1: 0.7627 - val_acc_2: 0.7547 - val_acc_3: 0.7488\n",
      "Epoch 49/50\n",
      "100/100 - 12s - loss_1: 0.0728 - loss_2: 0.1057 - loss_3: 0.0971 - acc_ensemble: 0.9140 - acc_1: 0.8560 - acc_2: 0.8640 - acc_3: 0.8420 - val_loss_1: 1.0085 - val_loss_2: 0.9798 - val_loss_3: 1.0483 - val_acc_ensemble: 0.8149 - val_acc_1: 0.7580 - val_acc_2: 0.7627 - val_acc_3: 0.7426\n",
      "Epoch 50/50\n",
      "100/100 - 12s - loss_1: 0.0893 - loss_2: 0.0744 - loss_3: 0.1276 - acc_ensemble: 0.9200 - acc_1: 0.8280 - acc_2: 0.8600 - acc_3: 0.8200 - val_loss_1: 1.0384 - val_loss_2: 0.9857 - val_loss_3: 1.0849 - val_acc_ensemble: 0.8140 - val_acc_1: 0.7499 - val_acc_2: 0.7576 - val_acc_3: 0.7342\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B3/S0.50/model_1\n",
      "i   Layer name                      Output shape                     Num param  Inbound            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "0   conv2d_1_1 (Conv2D)             [None,32,32,16] [None,32,32,16]  1792       input              \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "1   bn_1_1 (BatchNormalization)     [None,32,32,16] [None,32,32,16]  128        conv2d_1_1         \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "2   relu_1_1 (Activation)           [None,32,32,16] [None,32,32,16]  0          bn_1_1             \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "3   conv2d_1_2 (Conv2D)             [None,32,32,16] [None,32,32,16]  23200      relu_1_1           \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "4   bn_1_2 (BatchNormalization)     [None,32,32,16] [None,32,32,16]  128        conv2d_1_2         \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "5   relu_1_2 (Activation)           [None,32,32,16] [None,32,32,16]  0          bn_1_2             \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "6   avg_pool2d_1 (AveragePooling2D  [None,16,16,16] [None,16,16,16]  0          relu_1_2           \n",
      "                                    [None,16,16,16] [None,16,16,16]                                \n",
      "                                    [None,16,16,16] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "7   conv2d_2_1 (Conv2D)             [None,16,16,32] [None,16,16,32]  46400      avg_pool2d_1       \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "8   bn_2_1 (BatchNormalization)     [None,16,16,32] [None,16,16,32]  256        conv2d_2_1         \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "9   relu_2_1 (Activation)           [None,16,16,32] [None,16,16,32]  0          bn_2_1             \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "10  conv2d_2_2 (Conv2D)             [None,16,16,32] [None,16,16,32]  92480      relu_2_1           \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "11  bn_2_2 (BatchNormalization)     [None,16,16,32] [None,16,16,32]  256        conv2d_2_2         \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "12  relu_2_2 (Activation)           [None,16,16,32] [None,16,16,32]  0          bn_2_2             \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "13  avg_pool2d_2 (AveragePooling2D  [None,8,8,32] [None,8,8,32]      0          relu_2_2           \n",
      "                                    [None,8,8,32] [None,8,8,32]                                    \n",
      "                                    [None,8,8,32] [None,8,8,32]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "14  conv2d_3_1 (Conv2D)             [None,8,8,64] [None,8,8,64]      184960     avg_pool2d_2       \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "15  bn_3_1 (BatchNormalization)     [None,8,8,64] [None,8,8,64]      512        conv2d_3_1         \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "16  relu_3_1 (Activation)           [None,8,8,64] [None,8,8,64]      0          bn_3_1             \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "17  conv2d_3_2 (Conv2D)             [None,8,8,64] [None,8,8,64]      369280     relu_3_1           \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "18  bn_3_2 (BatchNormalization)     [None,8,8,64] [None,8,8,64]      512        conv2d_3_2         \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "19  relu_3_2 (Activation)           [None,8,8,64] [None,8,8,64]      0          bn_3_2             \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "20  global_avg_pool2d (GlobalAvera  [None,64] [None,64]              0          relu_3_2           \n",
      "                                    [None,64] [None,64]                                            \n",
      "                                    [None,64] [None,64]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "21  fc1 (Dense)                     [None,64] [None,64]              41600      global_avg_pool2d  \n",
      "                                    [None,64] [None,64]                                            \n",
      "                                    [None,64] [None,64]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "22  bn_fc1 (BatchNormalization)     [None,64] [None,64]              512        fc1                \n",
      "                                    [None,64] [None,64]                                            \n",
      "                                    [None,64] [None,64]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "23  relu_fc1 (Activation)           [None,64] [None,64]              0          bn_fc1             \n",
      "                                    [None,64] [None,64]                                            \n",
      "                                    [None,64] [None,64]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "24  output (Dense)                  [None,10]                        3250       relu_fc1           \n",
      "                                    [None,10]                                                      \n",
      "                                    [None,10]                                                      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "Total parameters: 765266\n",
      "50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 - 20s - loss_1: 1.8021 - loss_2: 1.7821 - loss_3: 1.8038 - acc_ensemble: 0.4920 - acc_1: 0.4600 - acc_2: 0.4680 - acc_3: 0.4280 - val_loss_1: 1.5249 - val_loss_2: 1.5547 - val_loss_3: 1.5307 - val_acc_ensemble: 0.4815 - val_acc_1: 0.4343 - val_acc_2: 0.4298 - val_acc_3: 0.4341\n",
      "Epoch 2/50\n",
      "100/100 - 13s - loss_1: 1.4749 - loss_2: 1.4701 - loss_3: 1.4393 - acc_ensemble: 0.5800 - acc_1: 0.4880 - acc_2: 0.5580 - acc_3: 0.5440 - val_loss_1: 1.3667 - val_loss_2: 1.3679 - val_loss_3: 1.3234 - val_acc_ensemble: 0.5455 - val_acc_1: 0.4996 - val_acc_2: 0.4982 - val_acc_3: 0.5131\n",
      "Epoch 3/50\n",
      "100/100 - 12s - loss_1: 1.2803 - loss_2: 1.2856 - loss_3: 1.2661 - acc_ensemble: 0.6260 - acc_1: 0.5980 - acc_2: 0.5900 - acc_3: 0.5740 - val_loss_1: 1.2319 - val_loss_2: 1.2095 - val_loss_3: 1.2826 - val_acc_ensemble: 0.5980 - val_acc_1: 0.5472 - val_acc_2: 0.5661 - val_acc_3: 0.5388\n",
      "Epoch 4/50\n",
      "100/100 - 12s - loss_1: 1.1752 - loss_2: 1.1289 - loss_3: 1.1824 - acc_ensemble: 0.6620 - acc_1: 0.6360 - acc_2: 0.6160 - acc_3: 0.6000 - val_loss_1: 1.1120 - val_loss_2: 1.1291 - val_loss_3: 1.1402 - val_acc_ensemble: 0.6383 - val_acc_1: 0.6023 - val_acc_2: 0.5954 - val_acc_3: 0.5937\n",
      "Epoch 5/50\n",
      "100/100 - 12s - loss_1: 1.0549 - loss_2: 1.0928 - loss_3: 1.0595 - acc_ensemble: 0.6880 - acc_1: 0.6700 - acc_2: 0.6400 - acc_3: 0.6280 - val_loss_1: 1.0437 - val_loss_2: 1.0293 - val_loss_3: 1.0792 - val_acc_ensemble: 0.6602 - val_acc_1: 0.6213 - val_acc_2: 0.6292 - val_acc_3: 0.6110\n",
      "Epoch 6/50\n",
      "100/100 - 12s - loss_1: 1.0016 - loss_2: 0.9883 - loss_3: 0.9761 - acc_ensemble: 0.7160 - acc_1: 0.6620 - acc_2: 0.6820 - acc_3: 0.6700 - val_loss_1: 0.9999 - val_loss_2: 1.0045 - val_loss_3: 1.0453 - val_acc_ensemble: 0.6809 - val_acc_1: 0.6414 - val_acc_2: 0.6462 - val_acc_3: 0.6301\n",
      "Epoch 7/50\n",
      "100/100 - 12s - loss_1: 0.9251 - loss_2: 0.9188 - loss_3: 0.9381 - acc_ensemble: 0.7240 - acc_1: 0.6680 - acc_2: 0.6880 - acc_3: 0.6660 - val_loss_1: 0.9682 - val_loss_2: 0.9420 - val_loss_3: 0.9775 - val_acc_ensemble: 0.7016 - val_acc_1: 0.6524 - val_acc_2: 0.6612 - val_acc_3: 0.6530\n",
      "Epoch 8/50\n",
      "100/100 - 12s - loss_1: 0.8888 - loss_2: 0.8762 - loss_3: 0.8759 - acc_ensemble: 0.7360 - acc_1: 0.6780 - acc_2: 0.7060 - acc_3: 0.6960 - val_loss_1: 0.9298 - val_loss_2: 0.9202 - val_loss_3: 0.9729 - val_acc_ensemble: 0.7112 - val_acc_1: 0.6665 - val_acc_2: 0.6713 - val_acc_3: 0.6537\n",
      "Epoch 9/50\n",
      "100/100 - 12s - loss_1: 0.8272 - loss_2: 0.8006 - loss_3: 0.8044 - acc_ensemble: 0.7760 - acc_1: 0.6980 - acc_2: 0.7260 - acc_3: 0.7180 - val_loss_1: 0.8938 - val_loss_2: 0.8784 - val_loss_3: 0.9053 - val_acc_ensemble: 0.7239 - val_acc_1: 0.6828 - val_acc_2: 0.6870 - val_acc_3: 0.6822\n",
      "Epoch 10/50\n",
      "100/100 - 12s - loss_1: 0.7805 - loss_2: 0.7267 - loss_3: 0.7763 - acc_ensemble: 0.7700 - acc_1: 0.7160 - acc_2: 0.7280 - acc_3: 0.7160 - val_loss_1: 0.8507 - val_loss_2: 0.8649 - val_loss_3: 0.8924 - val_acc_ensemble: 0.7311 - val_acc_1: 0.6995 - val_acc_2: 0.6945 - val_acc_3: 0.6839\n",
      "Epoch 11/50\n",
      "100/100 - 12s - loss_1: 0.7347 - loss_2: 0.7172 - loss_3: 0.7085 - acc_ensemble: 0.7880 - acc_1: 0.7440 - acc_2: 0.7300 - acc_3: 0.7140 - val_loss_1: 0.8345 - val_loss_2: 0.8418 - val_loss_3: 0.8712 - val_acc_ensemble: 0.7423 - val_acc_1: 0.7076 - val_acc_2: 0.7020 - val_acc_3: 0.6896\n",
      "Epoch 12/50\n",
      "100/100 - 12s - loss_1: 0.7045 - loss_2: 0.6767 - loss_3: 0.7068 - acc_ensemble: 0.8000 - acc_1: 0.7440 - acc_2: 0.7500 - acc_3: 0.7380 - val_loss_1: 0.8234 - val_loss_2: 0.8025 - val_loss_3: 0.8609 - val_acc_ensemble: 0.7508 - val_acc_1: 0.7112 - val_acc_2: 0.7177 - val_acc_3: 0.6954\n",
      "Epoch 13/50\n",
      "100/100 - 12s - loss_1: 0.6659 - loss_2: 0.6048 - loss_3: 0.6505 - acc_ensemble: 0.8160 - acc_1: 0.7540 - acc_2: 0.7240 - acc_3: 0.7860 - val_loss_1: 0.8369 - val_loss_2: 0.8200 - val_loss_3: 0.7956 - val_acc_ensemble: 0.7594 - val_acc_1: 0.7122 - val_acc_2: 0.7138 - val_acc_3: 0.7241\n",
      "Epoch 14/50\n",
      "100/100 - 12s - loss_1: 0.6062 - loss_2: 0.6248 - loss_3: 0.6182 - acc_ensemble: 0.8260 - acc_1: 0.7820 - acc_2: 0.7640 - acc_3: 0.7760 - val_loss_1: 0.8212 - val_loss_2: 0.8087 - val_loss_3: 0.8224 - val_acc_ensemble: 0.7611 - val_acc_1: 0.7148 - val_acc_2: 0.7145 - val_acc_3: 0.7113\n",
      "Epoch 15/50\n",
      "100/100 - 12s - loss_1: 0.5997 - loss_2: 0.5521 - loss_3: 0.5599 - acc_ensemble: 0.8240 - acc_1: 0.7720 - acc_2: 0.7640 - acc_3: 0.7680 - val_loss_1: 0.7965 - val_loss_2: 0.7911 - val_loss_3: 0.7992 - val_acc_ensemble: 0.7736 - val_acc_1: 0.7253 - val_acc_2: 0.7259 - val_acc_3: 0.7171\n",
      "Epoch 16/50\n",
      "100/100 - 12s - loss_1: 0.5608 - loss_2: 0.5367 - loss_3: 0.5772 - acc_ensemble: 0.8280 - acc_1: 0.7660 - acc_2: 0.7800 - acc_3: 0.7800 - val_loss_1: 0.8107 - val_loss_2: 0.7932 - val_loss_3: 0.7748 - val_acc_ensemble: 0.7678 - val_acc_1: 0.7180 - val_acc_2: 0.7291 - val_acc_3: 0.7277\n",
      "Epoch 17/50\n",
      "100/100 - 12s - loss_1: 0.5296 - loss_2: 0.5056 - loss_3: 0.5162 - acc_ensemble: 0.8480 - acc_1: 0.7960 - acc_2: 0.7780 - acc_3: 0.7760 - val_loss_1: 0.7697 - val_loss_2: 0.7976 - val_loss_3: 0.7754 - val_acc_ensemble: 0.7760 - val_acc_1: 0.7315 - val_acc_2: 0.7284 - val_acc_3: 0.7338\n",
      "Epoch 18/50\n",
      "100/100 - 12s - loss_1: 0.4949 - loss_2: 0.5027 - loss_3: 0.5236 - acc_ensemble: 0.8480 - acc_1: 0.8040 - acc_2: 0.7840 - acc_3: 0.7920 - val_loss_1: 0.7839 - val_loss_2: 0.7781 - val_loss_3: 0.7540 - val_acc_ensemble: 0.7818 - val_acc_1: 0.7334 - val_acc_2: 0.7336 - val_acc_3: 0.7380\n",
      "Epoch 19/50\n",
      "100/100 - 12s - loss_1: 0.4814 - loss_2: 0.4277 - loss_3: 0.4341 - acc_ensemble: 0.8700 - acc_1: 0.7880 - acc_2: 0.8320 - acc_3: 0.8180 - val_loss_1: 0.8246 - val_loss_2: 0.7767 - val_loss_3: 0.7583 - val_acc_ensemble: 0.7816 - val_acc_1: 0.7188 - val_acc_2: 0.7374 - val_acc_3: 0.7458\n",
      "Epoch 20/50\n",
      "100/100 - 12s - loss_1: 0.4537 - loss_2: 0.4251 - loss_3: 0.4328 - acc_ensemble: 0.8620 - acc_1: 0.8200 - acc_2: 0.7880 - acc_3: 0.7960 - val_loss_1: 0.7700 - val_loss_2: 0.7797 - val_loss_3: 0.7933 - val_acc_ensemble: 0.7868 - val_acc_1: 0.7428 - val_acc_2: 0.7390 - val_acc_3: 0.7319\n",
      "Epoch 21/50\n",
      "100/100 - 12s - loss_1: 0.4600 - loss_2: 0.3876 - loss_3: 0.4263 - acc_ensemble: 0.8760 - acc_1: 0.8380 - acc_2: 0.8080 - acc_3: 0.8260 - val_loss_1: 0.7888 - val_loss_2: 0.7559 - val_loss_3: 0.7612 - val_acc_ensemble: 0.7914 - val_acc_1: 0.7366 - val_acc_2: 0.7491 - val_acc_3: 0.7443\n",
      "Epoch 22/50\n",
      "100/100 - 12s - loss_1: 0.3844 - loss_2: 0.4151 - loss_3: 0.3651 - acc_ensemble: 0.8920 - acc_1: 0.8140 - acc_2: 0.8040 - acc_3: 0.8420 - val_loss_1: 0.7764 - val_loss_2: 0.7887 - val_loss_3: 0.7812 - val_acc_ensemble: 0.7910 - val_acc_1: 0.7427 - val_acc_2: 0.7370 - val_acc_3: 0.7464\n",
      "Epoch 23/50\n",
      "100/100 - 12s - loss_1: 0.3641 - loss_2: 0.3608 - loss_3: 0.3649 - acc_ensemble: 0.8640 - acc_1: 0.8180 - acc_2: 0.8280 - acc_3: 0.8180 - val_loss_1: 0.7899 - val_loss_2: 0.7413 - val_loss_3: 0.7764 - val_acc_ensemble: 0.7940 - val_acc_1: 0.7435 - val_acc_2: 0.7562 - val_acc_3: 0.7431\n",
      "Epoch 24/50\n",
      "100/100 - 12s - loss_1: 0.3499 - loss_2: 0.3243 - loss_3: 0.3397 - acc_ensemble: 0.8800 - acc_1: 0.8060 - acc_2: 0.7980 - acc_3: 0.8280 - val_loss_1: 0.8085 - val_loss_2: 0.7671 - val_loss_3: 0.8019 - val_acc_ensemble: 0.7965 - val_acc_1: 0.7369 - val_acc_2: 0.7535 - val_acc_3: 0.7393\n",
      "Epoch 25/50\n",
      "100/100 - 12s - loss_1: 0.3423 - loss_2: 0.2917 - loss_3: 0.3346 - acc_ensemble: 0.9140 - acc_1: 0.8280 - acc_2: 0.8180 - acc_3: 0.8360 - val_loss_1: 0.7754 - val_loss_2: 0.7928 - val_loss_3: 0.8126 - val_acc_ensemble: 0.7981 - val_acc_1: 0.7487 - val_acc_2: 0.7477 - val_acc_3: 0.7441\n",
      "Epoch 26/50\n",
      "100/100 - 12s - loss_1: 0.3061 - loss_2: 0.2606 - loss_3: 0.2845 - acc_ensemble: 0.8820 - acc_1: 0.8220 - acc_2: 0.8180 - acc_3: 0.8320 - val_loss_1: 0.7936 - val_loss_2: 0.7942 - val_loss_3: 0.7971 - val_acc_ensemble: 0.7974 - val_acc_1: 0.7429 - val_acc_2: 0.7500 - val_acc_3: 0.7457\n",
      "Epoch 27/50\n",
      "100/100 - 12s - loss_1: 0.2797 - loss_2: 0.2829 - loss_3: 0.3061 - acc_ensemble: 0.9020 - acc_1: 0.8480 - acc_2: 0.8320 - acc_3: 0.8320 - val_loss_1: 0.8255 - val_loss_2: 0.8237 - val_loss_3: 0.7938 - val_acc_ensemble: 0.8053 - val_acc_1: 0.7449 - val_acc_2: 0.7417 - val_acc_3: 0.7519\n",
      "Epoch 28/50\n",
      "100/100 - 12s - loss_1: 0.2807 - loss_2: 0.2682 - loss_3: 0.2795 - acc_ensemble: 0.9060 - acc_1: 0.8500 - acc_2: 0.8060 - acc_3: 0.8440 - val_loss_1: 0.8202 - val_loss_2: 0.8115 - val_loss_3: 0.8046 - val_acc_ensemble: 0.8024 - val_acc_1: 0.7388 - val_acc_2: 0.7500 - val_acc_3: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50\n",
      "100/100 - 12s - loss_1: 0.2664 - loss_2: 0.2479 - loss_3: 0.2600 - acc_ensemble: 0.9120 - acc_1: 0.8520 - acc_2: 0.8440 - acc_3: 0.8380 - val_loss_1: 0.8272 - val_loss_2: 0.8090 - val_loss_3: 0.8026 - val_acc_ensemble: 0.8032 - val_acc_1: 0.7444 - val_acc_2: 0.7530 - val_acc_3: 0.7505\n",
      "Epoch 30/50\n",
      "100/100 - 12s - loss_1: 0.2244 - loss_2: 0.2011 - loss_3: 0.2364 - acc_ensemble: 0.9160 - acc_1: 0.8240 - acc_2: 0.8260 - acc_3: 0.8480 - val_loss_1: 0.8307 - val_loss_2: 0.8090 - val_loss_3: 0.8026 - val_acc_ensemble: 0.8084 - val_acc_1: 0.7488 - val_acc_2: 0.7579 - val_acc_3: 0.7526\n",
      "Epoch 31/50\n",
      "100/100 - 12s - loss_1: 0.2325 - loss_2: 0.2229 - loss_3: 0.2108 - acc_ensemble: 0.9060 - acc_1: 0.8460 - acc_2: 0.8380 - acc_3: 0.8520 - val_loss_1: 0.8331 - val_loss_2: 0.8223 - val_loss_3: 0.8126 - val_acc_ensemble: 0.8065 - val_acc_1: 0.7479 - val_acc_2: 0.7541 - val_acc_3: 0.7558\n",
      "Epoch 32/50\n",
      "100/100 - 12s - loss_1: 0.2000 - loss_2: 0.2355 - loss_3: 0.2206 - acc_ensemble: 0.9020 - acc_1: 0.8500 - acc_2: 0.8300 - acc_3: 0.8300 - val_loss_1: 0.8301 - val_loss_2: 0.8557 - val_loss_3: 0.8484 - val_acc_ensemble: 0.8021 - val_acc_1: 0.7540 - val_acc_2: 0.7443 - val_acc_3: 0.7484\n",
      "Epoch 33/50\n",
      "100/100 - 12s - loss_1: 0.2272 - loss_2: 0.1632 - loss_3: 0.2248 - acc_ensemble: 0.9040 - acc_1: 0.8400 - acc_2: 0.8340 - acc_3: 0.8360 - val_loss_1: 0.8825 - val_loss_2: 0.8552 - val_loss_3: 0.8617 - val_acc_ensemble: 0.8051 - val_acc_1: 0.7415 - val_acc_2: 0.7537 - val_acc_3: 0.7450\n",
      "Epoch 34/50\n",
      "100/100 - 12s - loss_1: 0.1933 - loss_2: 0.1758 - loss_3: 0.1791 - acc_ensemble: 0.9160 - acc_1: 0.8580 - acc_2: 0.8460 - acc_3: 0.8540 - val_loss_1: 0.8772 - val_loss_2: 0.8474 - val_loss_3: 0.8569 - val_acc_ensemble: 0.8118 - val_acc_1: 0.7521 - val_acc_2: 0.7572 - val_acc_3: 0.7553\n",
      "Epoch 35/50\n",
      "100/100 - 12s - loss_1: 0.1826 - loss_2: 0.1554 - loss_3: 0.1716 - acc_ensemble: 0.8940 - acc_1: 0.8600 - acc_2: 0.8220 - acc_3: 0.8540 - val_loss_1: 0.8737 - val_loss_2: 0.8728 - val_loss_3: 0.8552 - val_acc_ensemble: 0.8048 - val_acc_1: 0.7480 - val_acc_2: 0.7531 - val_acc_3: 0.7560\n",
      "Epoch 36/50\n",
      "100/100 - 12s - loss_1: 0.1676 - loss_2: 0.1578 - loss_3: 0.1552 - acc_ensemble: 0.9180 - acc_1: 0.8840 - acc_2: 0.8480 - acc_3: 0.8400 - val_loss_1: 0.9039 - val_loss_2: 0.8657 - val_loss_3: 0.8643 - val_acc_ensemble: 0.8104 - val_acc_1: 0.7465 - val_acc_2: 0.7576 - val_acc_3: 0.7577\n",
      "Epoch 37/50\n",
      "100/100 - 12s - loss_1: 0.1545 - loss_2: 0.1210 - loss_3: 0.1281 - acc_ensemble: 0.9260 - acc_1: 0.8280 - acc_2: 0.8360 - acc_3: 0.8780 - val_loss_1: 0.9233 - val_loss_2: 0.8858 - val_loss_3: 0.8638 - val_acc_ensemble: 0.8117 - val_acc_1: 0.7489 - val_acc_2: 0.7576 - val_acc_3: 0.7614\n",
      "Epoch 38/50\n",
      "100/100 - 12s - loss_1: 0.1299 - loss_2: 0.1326 - loss_3: 0.1369 - acc_ensemble: 0.9120 - acc_1: 0.8560 - acc_2: 0.8420 - acc_3: 0.8400 - val_loss_1: 0.8995 - val_loss_2: 0.8938 - val_loss_3: 0.9080 - val_acc_ensemble: 0.8071 - val_acc_1: 0.7501 - val_acc_2: 0.7548 - val_acc_3: 0.7526\n",
      "Epoch 39/50\n",
      "100/100 - 12s - loss_1: 0.1183 - loss_2: 0.1247 - loss_3: 0.1569 - acc_ensemble: 0.9160 - acc_1: 0.8660 - acc_2: 0.8420 - acc_3: 0.8460 - val_loss_1: 0.9158 - val_loss_2: 0.9259 - val_loss_3: 0.9014 - val_acc_ensemble: 0.8150 - val_acc_1: 0.7523 - val_acc_2: 0.7513 - val_acc_3: 0.7550\n",
      "Epoch 40/50\n",
      "100/100 - 12s - loss_1: 0.1034 - loss_2: 0.1341 - loss_3: 0.1443 - acc_ensemble: 0.9260 - acc_1: 0.8400 - acc_2: 0.8440 - acc_3: 0.8420 - val_loss_1: 0.9452 - val_loss_2: 0.9327 - val_loss_3: 0.9053 - val_acc_ensemble: 0.8102 - val_acc_1: 0.7481 - val_acc_2: 0.7516 - val_acc_3: 0.7568\n",
      "Epoch 41/50\n",
      "100/100 - 12s - loss_1: 0.0898 - loss_2: 0.0986 - loss_3: 0.1432 - acc_ensemble: 0.9160 - acc_1: 0.8740 - acc_2: 0.8500 - acc_3: 0.8440 - val_loss_1: 0.9416 - val_loss_2: 0.9253 - val_loss_3: 0.9498 - val_acc_ensemble: 0.8106 - val_acc_1: 0.7534 - val_acc_2: 0.7568 - val_acc_3: 0.7475\n",
      "Epoch 42/50\n",
      "100/100 - 12s - loss_1: 0.1029 - loss_2: 0.1165 - loss_3: 0.1215 - acc_ensemble: 0.9080 - acc_1: 0.8680 - acc_2: 0.8400 - acc_3: 0.8480 - val_loss_1: 0.9641 - val_loss_2: 0.9510 - val_loss_3: 0.9766 - val_acc_ensemble: 0.8093 - val_acc_1: 0.7470 - val_acc_2: 0.7500 - val_acc_3: 0.7401\n",
      "Epoch 43/50\n",
      "100/100 - 12s - loss_1: 0.0739 - loss_2: 0.0945 - loss_3: 0.1094 - acc_ensemble: 0.9260 - acc_1: 0.8700 - acc_2: 0.8480 - acc_3: 0.8620 - val_loss_1: 0.9924 - val_loss_2: 0.9576 - val_loss_3: 0.9674 - val_acc_ensemble: 0.8125 - val_acc_1: 0.7471 - val_acc_2: 0.7577 - val_acc_3: 0.7545\n",
      "Epoch 44/50\n",
      "100/100 - 12s - loss_1: 0.1070 - loss_2: 0.1234 - loss_3: 0.0822 - acc_ensemble: 0.9080 - acc_1: 0.8580 - acc_2: 0.8400 - acc_3: 0.8460 - val_loss_1: 1.0283 - val_loss_2: 0.9648 - val_loss_3: 0.9854 - val_acc_ensemble: 0.8103 - val_acc_1: 0.7419 - val_acc_2: 0.7542 - val_acc_3: 0.7548\n",
      "Epoch 45/50\n",
      "100/100 - 12s - loss_1: 0.1386 - loss_2: 0.0982 - loss_3: 0.1061 - acc_ensemble: 0.9320 - acc_1: 0.8620 - acc_2: 0.8560 - acc_3: 0.8640 - val_loss_1: 1.0079 - val_loss_2: 0.9756 - val_loss_3: 0.9862 - val_acc_ensemble: 0.8109 - val_acc_1: 0.7495 - val_acc_2: 0.7543 - val_acc_3: 0.7576\n",
      "Epoch 46/50\n",
      "100/100 - 12s - loss_1: 0.1479 - loss_2: 0.1084 - loss_3: 0.0986 - acc_ensemble: 0.9400 - acc_1: 0.8460 - acc_2: 0.8600 - acc_3: 0.8620 - val_loss_1: 1.0489 - val_loss_2: 0.9841 - val_loss_3: 1.0123 - val_acc_ensemble: 0.8142 - val_acc_1: 0.7347 - val_acc_2: 0.7645 - val_acc_3: 0.7536\n",
      "Epoch 47/50\n",
      "100/100 - 12s - loss_1: 0.1071 - loss_2: 0.0847 - loss_3: 0.0831 - acc_ensemble: 0.9400 - acc_1: 0.8700 - acc_2: 0.8620 - acc_3: 0.8680 - val_loss_1: 1.0286 - val_loss_2: 0.9568 - val_loss_3: 0.9524 - val_acc_ensemble: 0.8187 - val_acc_1: 0.7391 - val_acc_2: 0.7646 - val_acc_3: 0.7641\n",
      "Epoch 48/50\n",
      "100/100 - 12s - loss_1: 0.0886 - loss_2: 0.0774 - loss_3: 0.0616 - acc_ensemble: 0.9240 - acc_1: 0.8720 - acc_2: 0.8600 - acc_3: 0.8780 - val_loss_1: 1.0077 - val_loss_2: 1.0277 - val_loss_3: 1.0080 - val_acc_ensemble: 0.8127 - val_acc_1: 0.7502 - val_acc_2: 0.7523 - val_acc_3: 0.7586\n",
      "Epoch 49/50\n",
      "100/100 - 12s - loss_1: 0.0747 - loss_2: 0.0982 - loss_3: 0.0870 - acc_ensemble: 0.9300 - acc_1: 0.8620 - acc_2: 0.8360 - acc_3: 0.8700 - val_loss_1: 1.0336 - val_loss_2: 1.0241 - val_loss_3: 0.9984 - val_acc_ensemble: 0.8169 - val_acc_1: 0.7507 - val_acc_2: 0.7567 - val_acc_3: 0.7608\n",
      "Epoch 50/50\n",
      "100/100 - 12s - loss_1: 0.0887 - loss_2: 0.0981 - loss_3: 0.1146 - acc_ensemble: 0.9160 - acc_1: 0.8780 - acc_2: 0.8440 - acc_3: 0.8260 - val_loss_1: 1.0408 - val_loss_2: 1.0888 - val_loss_3: 1.1005 - val_acc_ensemble: 0.8074 - val_acc_1: 0.7516 - val_acc_2: 0.7433 - val_acc_3: 0.7429\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B3/S0.50/model_2\n",
      "i   Layer name                      Output shape                     Num param  Inbound            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "0   conv2d_1_1 (Conv2D)             [None,32,32,16] [None,32,32,16]  1792       input              \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "1   bn_1_1 (BatchNormalization)     [None,32,32,16] [None,32,32,16]  128        conv2d_1_1         \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "2   relu_1_1 (Activation)           [None,32,32,16] [None,32,32,16]  0          bn_1_1             \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "3   conv2d_1_2 (Conv2D)             [None,32,32,16] [None,32,32,16]  23200      relu_1_1           \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "4   bn_1_2 (BatchNormalization)     [None,32,32,16] [None,32,32,16]  128        conv2d_1_2         \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "5   relu_1_2 (Activation)           [None,32,32,16] [None,32,32,16]  0          bn_1_2             \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "6   avg_pool2d_1 (AveragePooling2D  [None,16,16,16] [None,16,16,16]  0          relu_1_2           \n",
      "                                    [None,16,16,16] [None,16,16,16]                                \n",
      "                                    [None,16,16,16] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "7   conv2d_2_1 (Conv2D)             [None,16,16,32] [None,16,16,32]  46400      avg_pool2d_1       \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "8   bn_2_1 (BatchNormalization)     [None,16,16,32] [None,16,16,32]  256        conv2d_2_1         \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "9   relu_2_1 (Activation)           [None,16,16,32] [None,16,16,32]  0          bn_2_1             \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "10  conv2d_2_2 (Conv2D)             [None,16,16,32] [None,16,16,32]  92480      relu_2_1           \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "11  bn_2_2 (BatchNormalization)     [None,16,16,32] [None,16,16,32]  256        conv2d_2_2         \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "12  relu_2_2 (Activation)           [None,16,16,32] [None,16,16,32]  0          bn_2_2             \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "13  avg_pool2d_2 (AveragePooling2D  [None,8,8,32] [None,8,8,32]      0          relu_2_2           \n",
      "                                    [None,8,8,32] [None,8,8,32]                                    \n",
      "                                    [None,8,8,32] [None,8,8,32]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "14  conv2d_3_1 (Conv2D)             [None,8,8,64] [None,8,8,64]      184960     avg_pool2d_2       \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "15  bn_3_1 (BatchNormalization)     [None,8,8,64] [None,8,8,64]      512        conv2d_3_1         \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "16  relu_3_1 (Activation)           [None,8,8,64] [None,8,8,64]      0          bn_3_1             \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "17  conv2d_3_2 (Conv2D)             [None,8,8,64] [None,8,8,64]      369280     relu_3_1           \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "18  bn_3_2 (BatchNormalization)     [None,8,8,64] [None,8,8,64]      512        conv2d_3_2         \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "19  relu_3_2 (Activation)           [None,8,8,64] [None,8,8,64]      0          bn_3_2             \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "20  global_avg_pool2d (GlobalAvera  [None,64] [None,64]              0          relu_3_2           \n",
      "                                    [None,64] [None,64]                                            \n",
      "                                    [None,64] [None,64]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "21  fc1 (Dense)                     [None,64] [None,64]              41600      global_avg_pool2d  \n",
      "                                    [None,64] [None,64]                                            \n",
      "                                    [None,64] [None,64]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "22  bn_fc1 (BatchNormalization)     [None,64] [None,64]              512        fc1                \n",
      "                                    [None,64] [None,64]                                            \n",
      "                                    [None,64] [None,64]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "23  relu_fc1 (Activation)           [None,64] [None,64]              0          bn_fc1             \n",
      "                                    [None,64] [None,64]                                            \n",
      "                                    [None,64] [None,64]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "24  output (Dense)                  [None,10]                        3250       relu_fc1           \n",
      "                                    [None,10]                                                      \n",
      "                                    [None,10]                                                      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "Total parameters: 765266\n",
      "50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 - 20s - loss_1: 1.7739 - loss_2: 1.7786 - loss_3: 1.8048 - acc_ensemble: 0.4940 - acc_1: 0.4560 - acc_2: 0.4300 - acc_3: 0.4280 - val_loss_1: 1.5018 - val_loss_2: 1.5310 - val_loss_3: 1.5278 - val_acc_ensemble: 0.4773 - val_acc_1: 0.4451 - val_acc_2: 0.4264 - val_acc_3: 0.4324\n",
      "Epoch 2/50\n",
      "100/100 - 12s - loss_1: 1.4447 - loss_2: 1.4610 - loss_3: 1.4419 - acc_ensemble: 0.5600 - acc_1: 0.5320 - acc_2: 0.4880 - acc_3: 0.4860 - val_loss_1: 1.3671 - val_loss_2: 1.3883 - val_loss_3: 1.3766 - val_acc_ensemble: 0.5345 - val_acc_1: 0.5071 - val_acc_2: 0.4870 - val_acc_3: 0.4998\n",
      "Epoch 3/50\n",
      "100/100 - 12s - loss_1: 1.2996 - loss_2: 1.2880 - loss_3: 1.2796 - acc_ensemble: 0.6080 - acc_1: 0.5820 - acc_2: 0.5840 - acc_3: 0.5600 - val_loss_1: 1.2174 - val_loss_2: 1.2020 - val_loss_3: 1.2528 - val_acc_ensemble: 0.5900 - val_acc_1: 0.5604 - val_acc_2: 0.5591 - val_acc_3: 0.5428\n",
      "Epoch 4/50\n",
      "100/100 - 12s - loss_1: 1.1783 - loss_2: 1.1840 - loss_3: 1.1923 - acc_ensemble: 0.6600 - acc_1: 0.6080 - acc_2: 0.6260 - acc_3: 0.6140 - val_loss_1: 1.1457 - val_loss_2: 1.1117 - val_loss_3: 1.1480 - val_acc_ensemble: 0.6304 - val_acc_1: 0.5873 - val_acc_2: 0.5960 - val_acc_3: 0.5852\n",
      "Epoch 5/50\n",
      "100/100 - 12s - loss_1: 1.0927 - loss_2: 1.1109 - loss_3: 1.0748 - acc_ensemble: 0.7000 - acc_1: 0.6280 - acc_2: 0.6220 - acc_3: 0.6220 - val_loss_1: 1.0812 - val_loss_2: 1.0871 - val_loss_3: 1.0833 - val_acc_ensemble: 0.6550 - val_acc_1: 0.6123 - val_acc_2: 0.6074 - val_acc_3: 0.6104\n",
      "Epoch 6/50\n",
      "100/100 - 12s - loss_1: 1.0197 - loss_2: 1.0250 - loss_3: 1.0023 - acc_ensemble: 0.7060 - acc_1: 0.6460 - acc_2: 0.6540 - acc_3: 0.6580 - val_loss_1: 1.0173 - val_loss_2: 1.0240 - val_loss_3: 1.0297 - val_acc_ensemble: 0.6717 - val_acc_1: 0.6348 - val_acc_2: 0.6349 - val_acc_3: 0.6276\n",
      "Epoch 7/50\n",
      "100/100 - 12s - loss_1: 0.9483 - loss_2: 0.9623 - loss_3: 0.9273 - acc_ensemble: 0.7220 - acc_1: 0.6820 - acc_2: 0.6620 - acc_3: 0.6920 - val_loss_1: 0.9576 - val_loss_2: 1.0022 - val_loss_3: 0.9857 - val_acc_ensemble: 0.6948 - val_acc_1: 0.6530 - val_acc_2: 0.6472 - val_acc_3: 0.6522\n",
      "Epoch 8/50\n",
      "100/100 - 12s - loss_1: 0.8929 - loss_2: 0.8974 - loss_3: 0.8819 - acc_ensemble: 0.7440 - acc_1: 0.7000 - acc_2: 0.6780 - acc_3: 0.7060 - val_loss_1: 0.9394 - val_loss_2: 0.9541 - val_loss_3: 0.9251 - val_acc_ensemble: 0.7025 - val_acc_1: 0.6625 - val_acc_2: 0.6599 - val_acc_3: 0.6744\n",
      "Epoch 9/50\n",
      "100/100 - 12s - loss_1: 0.8663 - loss_2: 0.8425 - loss_3: 0.8374 - acc_ensemble: 0.7480 - acc_1: 0.7000 - acc_2: 0.6860 - acc_3: 0.7140 - val_loss_1: 0.9225 - val_loss_2: 0.9164 - val_loss_3: 0.8941 - val_acc_ensemble: 0.7183 - val_acc_1: 0.6690 - val_acc_2: 0.6716 - val_acc_3: 0.6865\n",
      "Epoch 10/50\n",
      "100/100 - 12s - loss_1: 0.7885 - loss_2: 0.7934 - loss_3: 0.7617 - acc_ensemble: 0.7780 - acc_1: 0.7200 - acc_2: 0.7020 - acc_3: 0.6960 - val_loss_1: 0.8957 - val_loss_2: 0.9019 - val_loss_3: 0.8751 - val_acc_ensemble: 0.7322 - val_acc_1: 0.6825 - val_acc_2: 0.6791 - val_acc_3: 0.6925\n",
      "Epoch 11/50\n",
      "100/100 - 12s - loss_1: 0.7915 - loss_2: 0.7634 - loss_3: 0.7200 - acc_ensemble: 0.7880 - acc_1: 0.7360 - acc_2: 0.7240 - acc_3: 0.7300 - val_loss_1: 0.8504 - val_loss_2: 0.8821 - val_loss_3: 0.8826 - val_acc_ensemble: 0.7405 - val_acc_1: 0.6989 - val_acc_2: 0.6895 - val_acc_3: 0.6913\n",
      "Epoch 12/50\n",
      "100/100 - 12s - loss_1: 0.7096 - loss_2: 0.7409 - loss_3: 0.6898 - acc_ensemble: 0.8080 - acc_1: 0.7520 - acc_2: 0.7440 - acc_3: 0.7320 - val_loss_1: 0.8442 - val_loss_2: 0.8778 - val_loss_3: 0.8428 - val_acc_ensemble: 0.7432 - val_acc_1: 0.7036 - val_acc_2: 0.6937 - val_acc_3: 0.7035\n",
      "Epoch 13/50\n",
      "100/100 - 12s - loss_1: 0.6931 - loss_2: 0.6886 - loss_3: 0.6569 - acc_ensemble: 0.7760 - acc_1: 0.7660 - acc_2: 0.7580 - acc_3: 0.7680 - val_loss_1: 0.8300 - val_loss_2: 0.8301 - val_loss_3: 0.8097 - val_acc_ensemble: 0.7515 - val_acc_1: 0.7126 - val_acc_2: 0.7112 - val_acc_3: 0.7176\n",
      "Epoch 14/50\n",
      "100/100 - 12s - loss_1: 0.6346 - loss_2: 0.6118 - loss_3: 0.6333 - acc_ensemble: 0.8040 - acc_1: 0.7520 - acc_2: 0.7300 - acc_3: 0.7620 - val_loss_1: 0.8045 - val_loss_2: 0.8182 - val_loss_3: 0.8486 - val_acc_ensemble: 0.7531 - val_acc_1: 0.7192 - val_acc_2: 0.7142 - val_acc_3: 0.7041\n",
      "Epoch 15/50\n",
      "100/100 - 12s - loss_1: 0.6070 - loss_2: 0.5951 - loss_3: 0.6041 - acc_ensemble: 0.8160 - acc_1: 0.7820 - acc_2: 0.7580 - acc_3: 0.7820 - val_loss_1: 0.8065 - val_loss_2: 0.8145 - val_loss_3: 0.8349 - val_acc_ensemble: 0.7616 - val_acc_1: 0.7267 - val_acc_2: 0.7212 - val_acc_3: 0.7100\n",
      "Epoch 16/50\n",
      "100/100 - 12s - loss_1: 0.5558 - loss_2: 0.5680 - loss_3: 0.5571 - acc_ensemble: 0.8360 - acc_1: 0.7740 - acc_2: 0.7720 - acc_3: 0.7800 - val_loss_1: 0.7801 - val_loss_2: 0.7856 - val_loss_3: 0.8098 - val_acc_ensemble: 0.7688 - val_acc_1: 0.7325 - val_acc_2: 0.7234 - val_acc_3: 0.7204\n",
      "Epoch 17/50\n",
      "100/100 - 12s - loss_1: 0.5620 - loss_2: 0.5415 - loss_3: 0.5285 - acc_ensemble: 0.8500 - acc_1: 0.7860 - acc_2: 0.7660 - acc_3: 0.7880 - val_loss_1: 0.8128 - val_loss_2: 0.8055 - val_loss_3: 0.7989 - val_acc_ensemble: 0.7713 - val_acc_1: 0.7201 - val_acc_2: 0.7220 - val_acc_3: 0.7228\n",
      "Epoch 18/50\n",
      "100/100 - 12s - loss_1: 0.5051 - loss_2: 0.5075 - loss_3: 0.4723 - acc_ensemble: 0.8500 - acc_1: 0.7860 - acc_2: 0.7980 - acc_3: 0.7980 - val_loss_1: 0.7962 - val_loss_2: 0.7903 - val_loss_3: 0.7903 - val_acc_ensemble: 0.7750 - val_acc_1: 0.7295 - val_acc_2: 0.7302 - val_acc_3: 0.7316\n",
      "Epoch 19/50\n",
      "100/100 - 12s - loss_1: 0.5161 - loss_2: 0.4755 - loss_3: 0.4684 - acc_ensemble: 0.8480 - acc_1: 0.7800 - acc_2: 0.7920 - acc_3: 0.7880 - val_loss_1: 0.8118 - val_loss_2: 0.7799 - val_loss_3: 0.7858 - val_acc_ensemble: 0.7785 - val_acc_1: 0.7277 - val_acc_2: 0.7295 - val_acc_3: 0.7359\n",
      "Epoch 20/50\n",
      "100/100 - 12s - loss_1: 0.4705 - loss_2: 0.4523 - loss_3: 0.4465 - acc_ensemble: 0.8600 - acc_1: 0.8100 - acc_2: 0.7860 - acc_3: 0.8000 - val_loss_1: 0.7912 - val_loss_2: 0.8253 - val_loss_3: 0.8135 - val_acc_ensemble: 0.7760 - val_acc_1: 0.7356 - val_acc_2: 0.7232 - val_acc_3: 0.7326\n",
      "Epoch 21/50\n",
      "100/100 - 12s - loss_1: 0.4627 - loss_2: 0.4479 - loss_3: 0.4171 - acc_ensemble: 0.8540 - acc_1: 0.8080 - acc_2: 0.7680 - acc_3: 0.8100 - val_loss_1: 0.7754 - val_loss_2: 0.8002 - val_loss_3: 0.7812 - val_acc_ensemble: 0.7864 - val_acc_1: 0.7421 - val_acc_2: 0.7361 - val_acc_3: 0.7432\n",
      "Epoch 22/50\n",
      "100/100 - 12s - loss_1: 0.4145 - loss_2: 0.4248 - loss_3: 0.4054 - acc_ensemble: 0.8500 - acc_1: 0.8120 - acc_2: 0.7740 - acc_3: 0.7940 - val_loss_1: 0.7783 - val_loss_2: 0.8176 - val_loss_3: 0.7966 - val_acc_ensemble: 0.7892 - val_acc_1: 0.7433 - val_acc_2: 0.7250 - val_acc_3: 0.7380\n",
      "Epoch 23/50\n",
      "100/100 - 12s - loss_1: 0.3800 - loss_2: 0.3725 - loss_3: 0.3798 - acc_ensemble: 0.8680 - acc_1: 0.8000 - acc_2: 0.8220 - acc_3: 0.7860 - val_loss_1: 0.8055 - val_loss_2: 0.7668 - val_loss_3: 0.8119 - val_acc_ensemble: 0.7885 - val_acc_1: 0.7296 - val_acc_2: 0.7448 - val_acc_3: 0.7349\n",
      "Epoch 24/50\n",
      "100/100 - 12s - loss_1: 0.3712 - loss_2: 0.3214 - loss_3: 0.3319 - acc_ensemble: 0.8800 - acc_1: 0.8320 - acc_2: 0.7960 - acc_3: 0.8180 - val_loss_1: 0.7881 - val_loss_2: 0.7951 - val_loss_3: 0.8117 - val_acc_ensemble: 0.7901 - val_acc_1: 0.7480 - val_acc_2: 0.7445 - val_acc_3: 0.7376\n",
      "Epoch 25/50\n",
      "100/100 - 12s - loss_1: 0.3628 - loss_2: 0.3349 - loss_3: 0.3175 - acc_ensemble: 0.8760 - acc_1: 0.8140 - acc_2: 0.8180 - acc_3: 0.8120 - val_loss_1: 0.7852 - val_loss_2: 0.8133 - val_loss_3: 0.8314 - val_acc_ensemble: 0.7912 - val_acc_1: 0.7445 - val_acc_2: 0.7410 - val_acc_3: 0.7336\n",
      "Epoch 26/50\n",
      "100/100 - 12s - loss_1: 0.3191 - loss_2: 0.3300 - loss_3: 0.3059 - acc_ensemble: 0.8720 - acc_1: 0.7880 - acc_2: 0.8140 - acc_3: 0.8140 - val_loss_1: 0.8174 - val_loss_2: 0.8309 - val_loss_3: 0.8265 - val_acc_ensemble: 0.7937 - val_acc_1: 0.7327 - val_acc_2: 0.7334 - val_acc_3: 0.7388\n",
      "Epoch 27/50\n",
      "100/100 - 12s - loss_1: 0.2743 - loss_2: 0.3190 - loss_3: 0.2667 - acc_ensemble: 0.8840 - acc_1: 0.8240 - acc_2: 0.7960 - acc_3: 0.8100 - val_loss_1: 0.7885 - val_loss_2: 0.8247 - val_loss_3: 0.8580 - val_acc_ensemble: 0.7965 - val_acc_1: 0.7487 - val_acc_2: 0.7439 - val_acc_3: 0.7380\n",
      "Epoch 28/50\n",
      "100/100 - 12s - loss_1: 0.2600 - loss_2: 0.2884 - loss_3: 0.2952 - acc_ensemble: 0.8840 - acc_1: 0.8300 - acc_2: 0.7980 - acc_3: 0.8120 - val_loss_1: 0.8147 - val_loss_2: 0.8444 - val_loss_3: 0.8400 - val_acc_ensemble: 0.8005 - val_acc_1: 0.7531 - val_acc_2: 0.7382 - val_acc_3: 0.7393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50\n",
      "100/100 - 12s - loss_1: 0.2728 - loss_2: 0.3026 - loss_3: 0.2637 - acc_ensemble: 0.9040 - acc_1: 0.8280 - acc_2: 0.8260 - acc_3: 0.8160 - val_loss_1: 0.8410 - val_loss_2: 0.8165 - val_loss_3: 0.8735 - val_acc_ensemble: 0.7993 - val_acc_1: 0.7428 - val_acc_2: 0.7436 - val_acc_3: 0.7358\n",
      "Epoch 30/50\n",
      "100/100 - 12s - loss_1: 0.2408 - loss_2: 0.2152 - loss_3: 0.2223 - acc_ensemble: 0.9060 - acc_1: 0.8480 - acc_2: 0.8040 - acc_3: 0.8320 - val_loss_1: 0.8377 - val_loss_2: 0.8502 - val_loss_3: 0.8577 - val_acc_ensemble: 0.7987 - val_acc_1: 0.7531 - val_acc_2: 0.7414 - val_acc_3: 0.7405\n",
      "Epoch 31/50\n",
      "100/100 - 12s - loss_1: 0.1932 - loss_2: 0.2309 - loss_3: 0.1950 - acc_ensemble: 0.8980 - acc_1: 0.8220 - acc_2: 0.8280 - acc_3: 0.8320 - val_loss_1: 0.8597 - val_loss_2: 0.8827 - val_loss_3: 0.8550 - val_acc_ensemble: 0.8020 - val_acc_1: 0.7412 - val_acc_2: 0.7377 - val_acc_3: 0.7461\n",
      "Epoch 32/50\n",
      "100/100 - 12s - loss_1: 0.2268 - loss_2: 0.2105 - loss_3: 0.2012 - acc_ensemble: 0.8980 - acc_1: 0.8160 - acc_2: 0.8180 - acc_3: 0.8380 - val_loss_1: 0.9092 - val_loss_2: 0.9153 - val_loss_3: 0.8679 - val_acc_ensemble: 0.7977 - val_acc_1: 0.7344 - val_acc_2: 0.7374 - val_acc_3: 0.7469\n",
      "Epoch 33/50\n",
      "100/100 - 12s - loss_1: 0.2546 - loss_2: 0.1920 - loss_3: 0.1811 - acc_ensemble: 0.8960 - acc_1: 0.8400 - acc_2: 0.8200 - acc_3: 0.8160 - val_loss_1: 0.8550 - val_loss_2: 0.8786 - val_loss_3: 0.8967 - val_acc_ensemble: 0.8039 - val_acc_1: 0.7463 - val_acc_2: 0.7481 - val_acc_3: 0.7431\n",
      "Epoch 34/50\n",
      "100/100 - 12s - loss_1: 0.2062 - loss_2: 0.1856 - loss_3: 0.1781 - acc_ensemble: 0.8960 - acc_1: 0.8380 - acc_2: 0.8180 - acc_3: 0.8360 - val_loss_1: 0.8790 - val_loss_2: 0.8905 - val_loss_3: 0.8830 - val_acc_ensemble: 0.8029 - val_acc_1: 0.7451 - val_acc_2: 0.7511 - val_acc_3: 0.7459\n",
      "Epoch 35/50\n",
      "100/100 - 12s - loss_1: 0.1747 - loss_2: 0.1645 - loss_3: 0.1595 - acc_ensemble: 0.8940 - acc_1: 0.8640 - acc_2: 0.8300 - acc_3: 0.8400 - val_loss_1: 0.8418 - val_loss_2: 0.9175 - val_loss_3: 0.9119 - val_acc_ensemble: 0.8043 - val_acc_1: 0.7545 - val_acc_2: 0.7404 - val_acc_3: 0.7470\n",
      "Epoch 36/50\n",
      "100/100 - 12s - loss_1: 0.1737 - loss_2: 0.1776 - loss_3: 0.1465 - acc_ensemble: 0.9220 - acc_1: 0.8400 - acc_2: 0.8160 - acc_3: 0.8220 - val_loss_1: 0.9175 - val_loss_2: 0.8854 - val_loss_3: 0.9216 - val_acc_ensemble: 0.8009 - val_acc_1: 0.7404 - val_acc_2: 0.7503 - val_acc_3: 0.7474\n",
      "Epoch 37/50\n",
      "100/100 - 12s - loss_1: 0.1815 - loss_2: 0.1592 - loss_3: 0.1320 - acc_ensemble: 0.9100 - acc_1: 0.8120 - acc_2: 0.8280 - acc_3: 0.8300 - val_loss_1: 0.9476 - val_loss_2: 0.9341 - val_loss_3: 0.9917 - val_acc_ensemble: 0.7987 - val_acc_1: 0.7386 - val_acc_2: 0.7439 - val_acc_3: 0.7417\n",
      "Epoch 38/50\n",
      "100/100 - 12s - loss_1: 0.1631 - loss_2: 0.1813 - loss_3: 0.1481 - acc_ensemble: 0.9220 - acc_1: 0.8580 - acc_2: 0.8380 - acc_3: 0.8200 - val_loss_1: 0.9190 - val_loss_2: 0.9267 - val_loss_3: 0.9772 - val_acc_ensemble: 0.8032 - val_acc_1: 0.7478 - val_acc_2: 0.7459 - val_acc_3: 0.7402\n",
      "Epoch 39/50\n",
      "100/100 - 12s - loss_1: 0.1538 - loss_2: 0.1334 - loss_3: 0.1296 - acc_ensemble: 0.9080 - acc_1: 0.8600 - acc_2: 0.8500 - acc_3: 0.8540 - val_loss_1: 0.8783 - val_loss_2: 0.9142 - val_loss_3: 0.9675 - val_acc_ensemble: 0.8055 - val_acc_1: 0.7601 - val_acc_2: 0.7473 - val_acc_3: 0.7434\n",
      "Epoch 40/50\n",
      "100/100 - 12s - loss_1: 0.1287 - loss_2: 0.1040 - loss_3: 0.1121 - acc_ensemble: 0.9160 - acc_1: 0.8620 - acc_2: 0.8500 - acc_3: 0.8320 - val_loss_1: 0.9428 - val_loss_2: 0.9218 - val_loss_3: 0.9610 - val_acc_ensemble: 0.8056 - val_acc_1: 0.7476 - val_acc_2: 0.7522 - val_acc_3: 0.7504\n",
      "Epoch 41/50\n",
      "100/100 - 12s - loss_1: 0.1250 - loss_2: 0.1080 - loss_3: 0.1287 - acc_ensemble: 0.9020 - acc_1: 0.8780 - acc_2: 0.8320 - acc_3: 0.8240 - val_loss_1: 0.9122 - val_loss_2: 0.9789 - val_loss_3: 1.0368 - val_acc_ensemble: 0.8029 - val_acc_1: 0.7583 - val_acc_2: 0.7456 - val_acc_3: 0.7331\n",
      "Epoch 42/50\n",
      "100/100 - 12s - loss_1: 0.1095 - loss_2: 0.1149 - loss_3: 0.1378 - acc_ensemble: 0.9160 - acc_1: 0.8380 - acc_2: 0.8280 - acc_3: 0.8580 - val_loss_1: 0.9768 - val_loss_2: 0.9882 - val_loss_3: 0.9569 - val_acc_ensemble: 0.8035 - val_acc_1: 0.7473 - val_acc_2: 0.7456 - val_acc_3: 0.7501\n",
      "Epoch 43/50\n",
      "100/100 - 12s - loss_1: 0.1366 - loss_2: 0.1197 - loss_3: 0.1241 - acc_ensemble: 0.9240 - acc_1: 0.8660 - acc_2: 0.8220 - acc_3: 0.8240 - val_loss_1: 0.9768 - val_loss_2: 1.0017 - val_loss_3: 1.0252 - val_acc_ensemble: 0.8009 - val_acc_1: 0.7509 - val_acc_2: 0.7422 - val_acc_3: 0.7416\n",
      "Epoch 44/50\n",
      "100/100 - 12s - loss_1: 0.1376 - loss_2: 0.1364 - loss_3: 0.1037 - acc_ensemble: 0.9040 - acc_1: 0.8460 - acc_2: 0.8360 - acc_3: 0.8440 - val_loss_1: 0.9953 - val_loss_2: 1.0431 - val_loss_3: 1.0419 - val_acc_ensemble: 0.8005 - val_acc_1: 0.7395 - val_acc_2: 0.7388 - val_acc_3: 0.7410\n",
      "Epoch 45/50\n",
      "100/100 - 12s - loss_1: 0.1140 - loss_2: 0.1492 - loss_3: 0.1035 - acc_ensemble: 0.9080 - acc_1: 0.8540 - acc_2: 0.8320 - acc_3: 0.8360 - val_loss_1: 0.9719 - val_loss_2: 1.0128 - val_loss_3: 0.9709 - val_acc_ensemble: 0.8063 - val_acc_1: 0.7519 - val_acc_2: 0.7467 - val_acc_3: 0.7575\n",
      "Epoch 46/50\n",
      "100/100 - 12s - loss_1: 0.0926 - loss_2: 0.1008 - loss_3: 0.0957 - acc_ensemble: 0.9200 - acc_1: 0.8500 - acc_2: 0.8340 - acc_3: 0.8360 - val_loss_1: 0.9887 - val_loss_2: 0.9818 - val_loss_3: 1.0058 - val_acc_ensemble: 0.8090 - val_acc_1: 0.7507 - val_acc_2: 0.7507 - val_acc_3: 0.7538\n",
      "Epoch 47/50\n",
      "100/100 - 12s - loss_1: 0.0893 - loss_2: 0.0798 - loss_3: 0.0964 - acc_ensemble: 0.9340 - acc_1: 0.8740 - acc_2: 0.8240 - acc_3: 0.8380 - val_loss_1: 0.9567 - val_loss_2: 1.0183 - val_loss_3: 1.0468 - val_acc_ensemble: 0.8119 - val_acc_1: 0.7617 - val_acc_2: 0.7467 - val_acc_3: 0.7454\n",
      "Epoch 48/50\n",
      "100/100 - 12s - loss_1: 0.0682 - loss_2: 0.0930 - loss_3: 0.0685 - acc_ensemble: 0.9280 - acc_1: 0.8740 - acc_2: 0.8400 - acc_3: 0.8440 - val_loss_1: 0.9636 - val_loss_2: 1.0485 - val_loss_3: 1.0374 - val_acc_ensemble: 0.8096 - val_acc_1: 0.7576 - val_acc_2: 0.7421 - val_acc_3: 0.7529\n",
      "Epoch 49/50\n",
      "100/100 - 12s - loss_1: 0.0764 - loss_2: 0.0904 - loss_3: 0.0690 - acc_ensemble: 0.9100 - acc_1: 0.8540 - acc_2: 0.8440 - acc_3: 0.8300 - val_loss_1: 1.0308 - val_loss_2: 1.0758 - val_loss_3: 1.1193 - val_acc_ensemble: 0.8049 - val_acc_1: 0.7507 - val_acc_2: 0.7393 - val_acc_3: 0.7382\n",
      "Epoch 50/50\n",
      "100/100 - 12s - loss_1: 0.0782 - loss_2: 0.0815 - loss_3: 0.0768 - acc_ensemble: 0.9200 - acc_1: 0.8560 - acc_2: 0.8480 - acc_3: 0.8520 - val_loss_1: 1.0396 - val_loss_2: 1.0927 - val_loss_3: 1.0742 - val_acc_ensemble: 0.8087 - val_acc_1: 0.7521 - val_acc_2: 0.7423 - val_acc_3: 0.7461\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B3/S0.50/model_3\n",
      "i   Layer name                      Output shape                     Num param  Inbound            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "0   conv2d_1_1 (Conv2D)             [None,32,32,16] [None,32,32,16]  1792       input              \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "1   bn_1_1 (BatchNormalization)     [None,32,32,16] [None,32,32,16]  128        conv2d_1_1         \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "2   relu_1_1 (Activation)           [None,32,32,16] [None,32,32,16]  0          bn_1_1             \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "3   conv2d_1_2 (Conv2D)             [None,32,32,16] [None,32,32,16]  23200      relu_1_1           \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "4   bn_1_2 (BatchNormalization)     [None,32,32,16] [None,32,32,16]  128        conv2d_1_2         \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "5   relu_1_2 (Activation)           [None,32,32,16] [None,32,32,16]  0          bn_1_2             \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "6   avg_pool2d_1 (AveragePooling2D  [None,16,16,16] [None,16,16,16]  0          relu_1_2           \n",
      "                                    [None,16,16,16] [None,16,16,16]                                \n",
      "                                    [None,16,16,16] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "7   conv2d_2_1 (Conv2D)             [None,16,16,32] [None,16,16,32]  46400      avg_pool2d_1       \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "8   bn_2_1 (BatchNormalization)     [None,16,16,32] [None,16,16,32]  256        conv2d_2_1         \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "9   relu_2_1 (Activation)           [None,16,16,32] [None,16,16,32]  0          bn_2_1             \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "10  conv2d_2_2 (Conv2D)             [None,16,16,32] [None,16,16,32]  92480      relu_2_1           \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "11  bn_2_2 (BatchNormalization)     [None,16,16,32] [None,16,16,32]  256        conv2d_2_2         \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "12  relu_2_2 (Activation)           [None,16,16,32] [None,16,16,32]  0          bn_2_2             \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "13  avg_pool2d_2 (AveragePooling2D  [None,8,8,32] [None,8,8,32]      0          relu_2_2           \n",
      "                                    [None,8,8,32] [None,8,8,32]                                    \n",
      "                                    [None,8,8,32] [None,8,8,32]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "14  conv2d_3_1 (Conv2D)             [None,8,8,64] [None,8,8,64]      184960     avg_pool2d_2       \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "15  bn_3_1 (BatchNormalization)     [None,8,8,64] [None,8,8,64]      512        conv2d_3_1         \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "16  relu_3_1 (Activation)           [None,8,8,64] [None,8,8,64]      0          bn_3_1             \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "17  conv2d_3_2 (Conv2D)             [None,8,8,64] [None,8,8,64]      369280     relu_3_1           \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "18  bn_3_2 (BatchNormalization)     [None,8,8,64] [None,8,8,64]      512        conv2d_3_2         \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "19  relu_3_2 (Activation)           [None,8,8,64] [None,8,8,64]      0          bn_3_2             \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "20  global_avg_pool2d (GlobalAvera  [None,64] [None,64]              0          relu_3_2           \n",
      "                                    [None,64] [None,64]                                            \n",
      "                                    [None,64] [None,64]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "21  fc1 (Dense)                     [None,64] [None,64]              41600      global_avg_pool2d  \n",
      "                                    [None,64] [None,64]                                            \n",
      "                                    [None,64] [None,64]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "22  bn_fc1 (BatchNormalization)     [None,64] [None,64]              512        fc1                \n",
      "                                    [None,64] [None,64]                                            \n",
      "                                    [None,64] [None,64]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "23  relu_fc1 (Activation)           [None,64] [None,64]              0          bn_fc1             \n",
      "                                    [None,64] [None,64]                                            \n",
      "                                    [None,64] [None,64]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "24  output (Dense)                  [None,10]                        3250       relu_fc1           \n",
      "                                    [None,10]                                                      \n",
      "                                    [None,10]                                                      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "Total parameters: 765266\n",
      "50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 - 20s - loss_1: 1.7812 - loss_2: 1.7690 - loss_3: 1.7723 - acc_ensemble: 0.4880 - acc_1: 0.4520 - acc_2: 0.4260 - acc_3: 0.4520 - val_loss_1: 1.5207 - val_loss_2: 1.5255 - val_loss_3: 1.4888 - val_acc_ensemble: 0.4855 - val_acc_1: 0.4365 - val_acc_2: 0.4315 - val_acc_3: 0.4535\n",
      "Epoch 2/50\n",
      "100/100 - 12s - loss_1: 1.4149 - loss_2: 1.4465 - loss_3: 1.4558 - acc_ensemble: 0.5540 - acc_1: 0.5060 - acc_2: 0.5320 - acc_3: 0.5220 - val_loss_1: 1.3078 - val_loss_2: 1.3124 - val_loss_3: 1.3316 - val_acc_ensemble: 0.5634 - val_acc_1: 0.5255 - val_acc_2: 0.5238 - val_acc_3: 0.5105\n",
      "Epoch 3/50\n",
      "100/100 - 12s - loss_1: 1.2786 - loss_2: 1.2410 - loss_3: 1.2629 - acc_ensemble: 0.6200 - acc_1: 0.5360 - acc_2: 0.6320 - acc_3: 0.5580 - val_loss_1: 1.2300 - val_loss_2: 1.1894 - val_loss_3: 1.2287 - val_acc_ensemble: 0.6068 - val_acc_1: 0.5522 - val_acc_2: 0.5730 - val_acc_3: 0.5514\n",
      "Epoch 4/50\n",
      "100/100 - 12s - loss_1: 1.1462 - loss_2: 1.1282 - loss_3: 1.1474 - acc_ensemble: 0.6400 - acc_1: 0.6320 - acc_2: 0.5940 - acc_3: 0.6300 - val_loss_1: 1.1027 - val_loss_2: 1.1420 - val_loss_3: 1.1225 - val_acc_ensemble: 0.6317 - val_acc_1: 0.6020 - val_acc_2: 0.5825 - val_acc_3: 0.5969\n",
      "Epoch 5/50\n",
      "100/100 - 12s - loss_1: 1.0736 - loss_2: 1.0484 - loss_3: 1.0677 - acc_ensemble: 0.6720 - acc_1: 0.6320 - acc_2: 0.6500 - acc_3: 0.6420 - val_loss_1: 1.0453 - val_loss_2: 1.0352 - val_loss_3: 1.0696 - val_acc_ensemble: 0.6648 - val_acc_1: 0.6258 - val_acc_2: 0.6296 - val_acc_3: 0.6146\n",
      "Epoch 6/50\n",
      "100/100 - 12s - loss_1: 0.9804 - loss_2: 0.9945 - loss_3: 0.9893 - acc_ensemble: 0.7160 - acc_1: 0.6620 - acc_2: 0.6380 - acc_3: 0.6580 - val_loss_1: 1.0385 - val_loss_2: 1.0273 - val_loss_3: 0.9917 - val_acc_ensemble: 0.6797 - val_acc_1: 0.6255 - val_acc_2: 0.6343 - val_acc_3: 0.6410\n",
      "Epoch 7/50\n",
      "100/100 - 12s - loss_1: 0.9241 - loss_2: 0.9068 - loss_3: 0.9103 - acc_ensemble: 0.7420 - acc_1: 0.6840 - acc_2: 0.6840 - acc_3: 0.6880 - val_loss_1: 0.9627 - val_loss_2: 0.9587 - val_loss_3: 0.9493 - val_acc_ensemble: 0.6933 - val_acc_1: 0.6583 - val_acc_2: 0.6602 - val_acc_3: 0.6603\n",
      "Epoch 8/50\n",
      "100/100 - 12s - loss_1: 0.8779 - loss_2: 0.8459 - loss_3: 0.8520 - acc_ensemble: 0.7700 - acc_1: 0.7080 - acc_2: 0.7160 - acc_3: 0.7180 - val_loss_1: 0.9016 - val_loss_2: 0.9023 - val_loss_3: 0.9205 - val_acc_ensemble: 0.7123 - val_acc_1: 0.6778 - val_acc_2: 0.6746 - val_acc_3: 0.6749\n",
      "Epoch 9/50\n",
      "100/100 - 12s - loss_1: 0.8220 - loss_2: 0.7941 - loss_3: 0.8032 - acc_ensemble: 0.7620 - acc_1: 0.7040 - acc_2: 0.6880 - acc_3: 0.7340 - val_loss_1: 0.9147 - val_loss_2: 0.9332 - val_loss_3: 0.8999 - val_acc_ensemble: 0.7134 - val_acc_1: 0.6736 - val_acc_2: 0.6678 - val_acc_3: 0.6799\n",
      "Epoch 10/50\n",
      "100/100 - 12s - loss_1: 0.7708 - loss_2: 0.7679 - loss_3: 0.7640 - acc_ensemble: 0.7780 - acc_1: 0.7040 - acc_2: 0.7480 - acc_3: 0.7240 - val_loss_1: 0.8887 - val_loss_2: 0.8509 - val_loss_3: 0.9095 - val_acc_ensemble: 0.7315 - val_acc_1: 0.6857 - val_acc_2: 0.6971 - val_acc_3: 0.6766\n",
      "Epoch 11/50\n",
      "100/100 - 12s - loss_1: 0.7326 - loss_2: 0.7144 - loss_3: 0.7129 - acc_ensemble: 0.8000 - acc_1: 0.7480 - acc_2: 0.7420 - acc_3: 0.7660 - val_loss_1: 0.8502 - val_loss_2: 0.8698 - val_loss_3: 0.8469 - val_acc_ensemble: 0.7418 - val_acc_1: 0.6967 - val_acc_2: 0.6969 - val_acc_3: 0.7043\n",
      "Epoch 12/50\n",
      "100/100 - 12s - loss_1: 0.6723 - loss_2: 0.6895 - loss_3: 0.6786 - acc_ensemble: 0.7980 - acc_1: 0.7740 - acc_2: 0.7600 - acc_3: 0.7320 - val_loss_1: 0.8229 - val_loss_2: 0.8200 - val_loss_3: 0.8721 - val_acc_ensemble: 0.7495 - val_acc_1: 0.7118 - val_acc_2: 0.7124 - val_acc_3: 0.7004\n",
      "Epoch 13/50\n",
      "100/100 - 12s - loss_1: 0.6490 - loss_2: 0.6288 - loss_3: 0.6140 - acc_ensemble: 0.7940 - acc_1: 0.7140 - acc_2: 0.7580 - acc_3: 0.7500 - val_loss_1: 0.8504 - val_loss_2: 0.8008 - val_loss_3: 0.8369 - val_acc_ensemble: 0.7577 - val_acc_1: 0.7060 - val_acc_2: 0.7151 - val_acc_3: 0.7118\n",
      "Epoch 14/50\n",
      "100/100 - 12s - loss_1: 0.6302 - loss_2: 0.5858 - loss_3: 0.6145 - acc_ensemble: 0.8100 - acc_1: 0.7460 - acc_2: 0.7620 - acc_3: 0.7800 - val_loss_1: 0.7904 - val_loss_2: 0.8169 - val_loss_3: 0.8172 - val_acc_ensemble: 0.7589 - val_acc_1: 0.7199 - val_acc_2: 0.7094 - val_acc_3: 0.7156\n",
      "Epoch 15/50\n",
      "100/100 - 12s - loss_1: 0.5880 - loss_2: 0.5628 - loss_3: 0.5796 - acc_ensemble: 0.8300 - acc_1: 0.7640 - acc_2: 0.7820 - acc_3: 0.7900 - val_loss_1: 0.7840 - val_loss_2: 0.7958 - val_loss_3: 0.7825 - val_acc_ensemble: 0.7705 - val_acc_1: 0.7318 - val_acc_2: 0.7259 - val_acc_3: 0.7292\n",
      "Epoch 16/50\n",
      "100/100 - 12s - loss_1: 0.5474 - loss_2: 0.5254 - loss_3: 0.5502 - acc_ensemble: 0.8200 - acc_1: 0.7580 - acc_2: 0.7880 - acc_3: 0.8100 - val_loss_1: 0.7823 - val_loss_2: 0.7872 - val_loss_3: 0.7620 - val_acc_ensemble: 0.7729 - val_acc_1: 0.7325 - val_acc_2: 0.7294 - val_acc_3: 0.7411\n",
      "Epoch 17/50\n",
      "100/100 - 12s - loss_1: 0.5398 - loss_2: 0.5341 - loss_3: 0.5192 - acc_ensemble: 0.8420 - acc_1: 0.7720 - acc_2: 0.7860 - acc_3: 0.7840 - val_loss_1: 0.7992 - val_loss_2: 0.7865 - val_loss_3: 0.7969 - val_acc_ensemble: 0.7733 - val_acc_1: 0.7229 - val_acc_2: 0.7302 - val_acc_3: 0.7300\n",
      "Epoch 18/50\n",
      "100/100 - 12s - loss_1: 0.4975 - loss_2: 0.4823 - loss_3: 0.5079 - acc_ensemble: 0.8620 - acc_1: 0.7980 - acc_2: 0.7820 - acc_3: 0.8000 - val_loss_1: 0.7709 - val_loss_2: 0.7743 - val_loss_3: 0.7574 - val_acc_ensemble: 0.7810 - val_acc_1: 0.7319 - val_acc_2: 0.7351 - val_acc_3: 0.7419\n",
      "Epoch 19/50\n",
      "100/100 - 12s - loss_1: 0.4549 - loss_2: 0.4405 - loss_3: 0.4498 - acc_ensemble: 0.8440 - acc_1: 0.7980 - acc_2: 0.8000 - acc_3: 0.8140 - val_loss_1: 0.7593 - val_loss_2: 0.7932 - val_loss_3: 0.7689 - val_acc_ensemble: 0.7869 - val_acc_1: 0.7407 - val_acc_2: 0.7352 - val_acc_3: 0.7440\n",
      "Epoch 20/50\n",
      "100/100 - 12s - loss_1: 0.4343 - loss_2: 0.4108 - loss_3: 0.4247 - acc_ensemble: 0.8580 - acc_1: 0.8040 - acc_2: 0.7940 - acc_3: 0.8040 - val_loss_1: 0.7582 - val_loss_2: 0.7684 - val_loss_3: 0.8160 - val_acc_ensemble: 0.7886 - val_acc_1: 0.7434 - val_acc_2: 0.7404 - val_acc_3: 0.7323\n",
      "Epoch 21/50\n",
      "100/100 - 12s - loss_1: 0.3975 - loss_2: 0.4043 - loss_3: 0.4073 - acc_ensemble: 0.8500 - acc_1: 0.8020 - acc_2: 0.7620 - acc_3: 0.8060 - val_loss_1: 0.7923 - val_loss_2: 0.8123 - val_loss_3: 0.7804 - val_acc_ensemble: 0.7879 - val_acc_1: 0.7352 - val_acc_2: 0.7272 - val_acc_3: 0.7369\n",
      "Epoch 22/50\n",
      "100/100 - 12s - loss_1: 0.4165 - loss_2: 0.3720 - loss_3: 0.3642 - acc_ensemble: 0.8560 - acc_1: 0.8140 - acc_2: 0.8120 - acc_3: 0.8100 - val_loss_1: 0.7770 - val_loss_2: 0.8076 - val_loss_3: 0.7866 - val_acc_ensemble: 0.7906 - val_acc_1: 0.7412 - val_acc_2: 0.7384 - val_acc_3: 0.7389\n",
      "Epoch 23/50\n",
      "100/100 - 12s - loss_1: 0.3794 - loss_2: 0.3791 - loss_3: 0.3756 - acc_ensemble: 0.8800 - acc_1: 0.8140 - acc_2: 0.8080 - acc_3: 0.8240 - val_loss_1: 0.7999 - val_loss_2: 0.7832 - val_loss_3: 0.7919 - val_acc_ensemble: 0.7952 - val_acc_1: 0.7346 - val_acc_2: 0.7434 - val_acc_3: 0.7419\n",
      "Epoch 24/50\n",
      "100/100 - 12s - loss_1: 0.3182 - loss_2: 0.3357 - loss_3: 0.3532 - acc_ensemble: 0.8820 - acc_1: 0.8360 - acc_2: 0.8220 - acc_3: 0.8280 - val_loss_1: 0.8022 - val_loss_2: 0.7983 - val_loss_3: 0.7973 - val_acc_ensemble: 0.7953 - val_acc_1: 0.7469 - val_acc_2: 0.7469 - val_acc_3: 0.7444\n",
      "Epoch 25/50\n",
      "100/100 - 12s - loss_1: 0.3164 - loss_2: 0.3196 - loss_3: 0.3230 - acc_ensemble: 0.8880 - acc_1: 0.8320 - acc_2: 0.8060 - acc_3: 0.8480 - val_loss_1: 0.7870 - val_loss_2: 0.7957 - val_loss_3: 0.7866 - val_acc_ensemble: 0.7988 - val_acc_1: 0.7509 - val_acc_2: 0.7490 - val_acc_3: 0.7462\n",
      "Epoch 26/50\n",
      "100/100 - 12s - loss_1: 0.3389 - loss_2: 0.2946 - loss_3: 0.3112 - acc_ensemble: 0.8820 - acc_1: 0.8140 - acc_2: 0.7920 - acc_3: 0.8620 - val_loss_1: 0.8137 - val_loss_2: 0.8116 - val_loss_3: 0.7673 - val_acc_ensemble: 0.8029 - val_acc_1: 0.7444 - val_acc_2: 0.7485 - val_acc_3: 0.7592\n",
      "Epoch 27/50\n",
      "100/100 - 12s - loss_1: 0.2877 - loss_2: 0.2573 - loss_3: 0.2889 - acc_ensemble: 0.8820 - acc_1: 0.8240 - acc_2: 0.8100 - acc_3: 0.8600 - val_loss_1: 0.7979 - val_loss_2: 0.8560 - val_loss_3: 0.7835 - val_acc_ensemble: 0.8005 - val_acc_1: 0.7491 - val_acc_2: 0.7338 - val_acc_3: 0.7545\n",
      "Epoch 28/50\n",
      "100/100 - 12s - loss_1: 0.2609 - loss_2: 0.2256 - loss_3: 0.2743 - acc_ensemble: 0.8980 - acc_1: 0.8440 - acc_2: 0.8320 - acc_3: 0.8640 - val_loss_1: 0.8150 - val_loss_2: 0.8168 - val_loss_3: 0.7969 - val_acc_ensemble: 0.8050 - val_acc_1: 0.7465 - val_acc_2: 0.7536 - val_acc_3: 0.7565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50\n",
      "100/100 - 12s - loss_1: 0.2704 - loss_2: 0.2400 - loss_3: 0.2466 - acc_ensemble: 0.8880 - acc_1: 0.8080 - acc_2: 0.8140 - acc_3: 0.8500 - val_loss_1: 0.8471 - val_loss_2: 0.8546 - val_loss_3: 0.8239 - val_acc_ensemble: 0.8007 - val_acc_1: 0.7407 - val_acc_2: 0.7390 - val_acc_3: 0.7531\n",
      "Epoch 30/50\n",
      "100/100 - 12s - loss_1: 0.2478 - loss_2: 0.2051 - loss_3: 0.2429 - acc_ensemble: 0.9020 - acc_1: 0.8420 - acc_2: 0.8240 - acc_3: 0.8440 - val_loss_1: 0.8306 - val_loss_2: 0.8356 - val_loss_3: 0.8292 - val_acc_ensemble: 0.8039 - val_acc_1: 0.7489 - val_acc_2: 0.7509 - val_acc_3: 0.7511\n",
      "Epoch 31/50\n",
      "100/100 - 12s - loss_1: 0.2059 - loss_2: 0.2194 - loss_3: 0.2241 - acc_ensemble: 0.9080 - acc_1: 0.8360 - acc_2: 0.8340 - acc_3: 0.8600 - val_loss_1: 0.8313 - val_loss_2: 0.8660 - val_loss_3: 0.8382 - val_acc_ensemble: 0.8056 - val_acc_1: 0.7447 - val_acc_2: 0.7480 - val_acc_3: 0.7479\n",
      "Epoch 32/50\n",
      "100/100 - 12s - loss_1: 0.1973 - loss_2: 0.2199 - loss_3: 0.1988 - acc_ensemble: 0.8960 - acc_1: 0.8340 - acc_2: 0.8300 - acc_3: 0.8560 - val_loss_1: 0.8672 - val_loss_2: 0.8606 - val_loss_3: 0.8488 - val_acc_ensemble: 0.7980 - val_acc_1: 0.7430 - val_acc_2: 0.7487 - val_acc_3: 0.7510\n",
      "Epoch 33/50\n",
      "100/100 - 12s - loss_1: 0.1889 - loss_2: 0.1852 - loss_3: 0.1903 - acc_ensemble: 0.9160 - acc_1: 0.8460 - acc_2: 0.8180 - acc_3: 0.8520 - val_loss_1: 0.8793 - val_loss_2: 0.8597 - val_loss_3: 0.8794 - val_acc_ensemble: 0.8055 - val_acc_1: 0.7468 - val_acc_2: 0.7529 - val_acc_3: 0.7460\n",
      "Epoch 34/50\n",
      "100/100 - 12s - loss_1: 0.1882 - loss_2: 0.1634 - loss_3: 0.2025 - acc_ensemble: 0.9220 - acc_1: 0.8320 - acc_2: 0.8400 - acc_3: 0.8460 - val_loss_1: 0.8676 - val_loss_2: 0.9430 - val_loss_3: 0.8858 - val_acc_ensemble: 0.8093 - val_acc_1: 0.7494 - val_acc_2: 0.7433 - val_acc_3: 0.7453\n",
      "Epoch 35/50\n",
      "100/100 - 12s - loss_1: 0.1886 - loss_2: 0.1848 - loss_3: 0.1589 - acc_ensemble: 0.9080 - acc_1: 0.8240 - acc_2: 0.8160 - acc_3: 0.8640 - val_loss_1: 0.8824 - val_loss_2: 0.9069 - val_loss_3: 0.8541 - val_acc_ensemble: 0.8085 - val_acc_1: 0.7485 - val_acc_2: 0.7491 - val_acc_3: 0.7559\n",
      "Epoch 36/50\n",
      "100/100 - 12s - loss_1: 0.1722 - loss_2: 0.1449 - loss_3: 0.1359 - acc_ensemble: 0.9220 - acc_1: 0.8380 - acc_2: 0.8440 - acc_3: 0.8480 - val_loss_1: 0.8916 - val_loss_2: 0.9012 - val_loss_3: 0.9085 - val_acc_ensemble: 0.8080 - val_acc_1: 0.7453 - val_acc_2: 0.7541 - val_acc_3: 0.7469\n",
      "Epoch 37/50\n",
      "100/100 - 12s - loss_1: 0.1414 - loss_2: 0.1597 - loss_3: 0.1509 - acc_ensemble: 0.9180 - acc_1: 0.8260 - acc_2: 0.8360 - acc_3: 0.8840 - val_loss_1: 0.9415 - val_loss_2: 0.9502 - val_loss_3: 0.8808 - val_acc_ensemble: 0.8077 - val_acc_1: 0.7449 - val_acc_2: 0.7467 - val_acc_3: 0.7601\n",
      "Epoch 38/50\n",
      "100/100 - 12s - loss_1: 0.1514 - loss_2: 0.1566 - loss_3: 0.1275 - acc_ensemble: 0.9180 - acc_1: 0.8540 - acc_2: 0.8500 - acc_3: 0.8860 - val_loss_1: 0.9082 - val_loss_2: 0.8900 - val_loss_3: 0.8852 - val_acc_ensemble: 0.8126 - val_acc_1: 0.7492 - val_acc_2: 0.7583 - val_acc_3: 0.7656\n",
      "Epoch 39/50\n",
      "100/100 - 12s - loss_1: 0.1253 - loss_2: 0.1401 - loss_3: 0.1009 - acc_ensemble: 0.9020 - acc_1: 0.8440 - acc_2: 0.8040 - acc_3: 0.8560 - val_loss_1: 0.9158 - val_loss_2: 0.9812 - val_loss_3: 0.9254 - val_acc_ensemble: 0.8102 - val_acc_1: 0.7534 - val_acc_2: 0.7427 - val_acc_3: 0.7542\n",
      "Epoch 40/50\n",
      "100/100 - 12s - loss_1: 0.1188 - loss_2: 0.1150 - loss_3: 0.1028 - acc_ensemble: 0.9280 - acc_1: 0.8480 - acc_2: 0.8260 - acc_3: 0.8700 - val_loss_1: 0.8925 - val_loss_2: 0.9556 - val_loss_3: 0.9306 - val_acc_ensemble: 0.8162 - val_acc_1: 0.7582 - val_acc_2: 0.7439 - val_acc_3: 0.7580\n",
      "Epoch 41/50\n",
      "100/100 - 12s - loss_1: 0.1491 - loss_2: 0.1001 - loss_3: 0.1182 - acc_ensemble: 0.9200 - acc_1: 0.8340 - acc_2: 0.8340 - acc_3: 0.8840 - val_loss_1: 0.9301 - val_loss_2: 0.9303 - val_loss_3: 0.9319 - val_acc_ensemble: 0.8139 - val_acc_1: 0.7541 - val_acc_2: 0.7565 - val_acc_3: 0.7585\n",
      "Epoch 42/50\n",
      "100/100 - 12s - loss_1: 0.1164 - loss_2: 0.1162 - loss_3: 0.1052 - acc_ensemble: 0.9300 - acc_1: 0.8540 - acc_2: 0.8380 - acc_3: 0.8660 - val_loss_1: 0.9181 - val_loss_2: 1.0444 - val_loss_3: 0.9534 - val_acc_ensemble: 0.8096 - val_acc_1: 0.7559 - val_acc_2: 0.7410 - val_acc_3: 0.7527\n",
      "Epoch 43/50\n",
      "100/100 - 12s - loss_1: 0.0931 - loss_2: 0.1157 - loss_3: 0.1298 - acc_ensemble: 0.9300 - acc_1: 0.8500 - acc_2: 0.8360 - acc_3: 0.8560 - val_loss_1: 0.9193 - val_loss_2: 1.0218 - val_loss_3: 0.9977 - val_acc_ensemble: 0.8075 - val_acc_1: 0.7603 - val_acc_2: 0.7394 - val_acc_3: 0.7470\n",
      "Epoch 44/50\n",
      "100/100 - 12s - loss_1: 0.0840 - loss_2: 0.0993 - loss_3: 0.1176 - acc_ensemble: 0.9340 - acc_1: 0.8500 - acc_2: 0.8620 - acc_3: 0.8720 - val_loss_1: 0.9617 - val_loss_2: 0.9793 - val_loss_3: 0.9922 - val_acc_ensemble: 0.8109 - val_acc_1: 0.7541 - val_acc_2: 0.7541 - val_acc_3: 0.7569\n",
      "Epoch 45/50\n",
      "100/100 - 12s - loss_1: 0.0990 - loss_2: 0.1068 - loss_3: 0.0767 - acc_ensemble: 0.9340 - acc_1: 0.8500 - acc_2: 0.8360 - acc_3: 0.8740 - val_loss_1: 0.9602 - val_loss_2: 1.0457 - val_loss_3: 0.9572 - val_acc_ensemble: 0.8133 - val_acc_1: 0.7587 - val_acc_2: 0.7443 - val_acc_3: 0.7585\n",
      "Epoch 46/50\n",
      "100/100 - 12s - loss_1: 0.0949 - loss_2: 0.0986 - loss_3: 0.0836 - acc_ensemble: 0.9340 - acc_1: 0.8460 - acc_2: 0.8520 - acc_3: 0.8920 - val_loss_1: 0.9789 - val_loss_2: 1.0389 - val_loss_3: 0.9922 - val_acc_ensemble: 0.8092 - val_acc_1: 0.7505 - val_acc_2: 0.7468 - val_acc_3: 0.7496\n",
      "Epoch 47/50\n",
      "100/100 - 12s - loss_1: 0.1063 - loss_2: 0.0935 - loss_3: 0.0932 - acc_ensemble: 0.9180 - acc_1: 0.8380 - acc_2: 0.8600 - acc_3: 0.8780 - val_loss_1: 0.9652 - val_loss_2: 0.9981 - val_loss_3: 1.0240 - val_acc_ensemble: 0.8155 - val_acc_1: 0.7536 - val_acc_2: 0.7584 - val_acc_3: 0.7519\n",
      "Epoch 48/50\n",
      "100/100 - 12s - loss_1: 0.0614 - loss_2: 0.0671 - loss_3: 0.0956 - acc_ensemble: 0.9280 - acc_1: 0.8360 - acc_2: 0.8600 - acc_3: 0.8720 - val_loss_1: 0.9964 - val_loss_2: 0.9990 - val_loss_3: 1.0135 - val_acc_ensemble: 0.8139 - val_acc_1: 0.7554 - val_acc_2: 0.7565 - val_acc_3: 0.7513\n",
      "Epoch 49/50\n",
      "100/100 - 12s - loss_1: 0.0692 - loss_2: 0.0624 - loss_3: 0.0937 - acc_ensemble: 0.9340 - acc_1: 0.8380 - acc_2: 0.8740 - acc_3: 0.8680 - val_loss_1: 1.0110 - val_loss_2: 0.9990 - val_loss_3: 1.0282 - val_acc_ensemble: 0.8138 - val_acc_1: 0.7546 - val_acc_2: 0.7632 - val_acc_3: 0.7501\n",
      "Epoch 50/50\n",
      "100/100 - 12s - loss_1: 0.0750 - loss_2: 0.0632 - loss_3: 0.0762 - acc_ensemble: 0.9180 - acc_1: 0.8260 - acc_2: 0.8620 - acc_3: 0.8720 - val_loss_1: 1.0548 - val_loss_2: 1.0534 - val_loss_3: 1.0174 - val_acc_ensemble: 0.8103 - val_acc_1: 0.7486 - val_acc_2: 0.7483 - val_acc_3: 0.7588\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B3/S0.50/model_4\n",
      "i   Layer name                      Output shape                     Num param  Inbound            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "0   conv2d_1_1 (Conv2D)             [None,32,32,16] [None,32,32,16]  1792       input              \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "1   bn_1_1 (BatchNormalization)     [None,32,32,16] [None,32,32,16]  128        conv2d_1_1         \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "2   relu_1_1 (Activation)           [None,32,32,16] [None,32,32,16]  0          bn_1_1             \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "3   conv2d_1_2 (Conv2D)             [None,32,32,16] [None,32,32,16]  23200      relu_1_1           \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "4   bn_1_2 (BatchNormalization)     [None,32,32,16] [None,32,32,16]  128        conv2d_1_2         \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "5   relu_1_2 (Activation)           [None,32,32,16] [None,32,32,16]  0          bn_1_2             \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "6   avg_pool2d_1 (AveragePooling2D  [None,16,16,16] [None,16,16,16]  0          relu_1_2           \n",
      "                                    [None,16,16,16] [None,16,16,16]                                \n",
      "                                    [None,16,16,16] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "7   conv2d_2_1 (Conv2D)             [None,16,16,32] [None,16,16,32]  46400      avg_pool2d_1       \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "8   bn_2_1 (BatchNormalization)     [None,16,16,32] [None,16,16,32]  256        conv2d_2_1         \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "9   relu_2_1 (Activation)           [None,16,16,32] [None,16,16,32]  0          bn_2_1             \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "10  conv2d_2_2 (Conv2D)             [None,16,16,32] [None,16,16,32]  92480      relu_2_1           \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "11  bn_2_2 (BatchNormalization)     [None,16,16,32] [None,16,16,32]  256        conv2d_2_2         \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "12  relu_2_2 (Activation)           [None,16,16,32] [None,16,16,32]  0          bn_2_2             \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "                                    [None,16,16,32] [None,16,16,32]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "13  avg_pool2d_2 (AveragePooling2D  [None,8,8,32] [None,8,8,32]      0          relu_2_2           \n",
      "                                    [None,8,8,32] [None,8,8,32]                                    \n",
      "                                    [None,8,8,32] [None,8,8,32]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "14  conv2d_3_1 (Conv2D)             [None,8,8,64] [None,8,8,64]      184960     avg_pool2d_2       \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "15  bn_3_1 (BatchNormalization)     [None,8,8,64] [None,8,8,64]      512        conv2d_3_1         \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "16  relu_3_1 (Activation)           [None,8,8,64] [None,8,8,64]      0          bn_3_1             \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "17  conv2d_3_2 (Conv2D)             [None,8,8,64] [None,8,8,64]      369280     relu_3_1           \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "18  bn_3_2 (BatchNormalization)     [None,8,8,64] [None,8,8,64]      512        conv2d_3_2         \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "19  relu_3_2 (Activation)           [None,8,8,64] [None,8,8,64]      0          bn_3_2             \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "                                    [None,8,8,64] [None,8,8,64]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "20  global_avg_pool2d (GlobalAvera  [None,64] [None,64]              0          relu_3_2           \n",
      "                                    [None,64] [None,64]                                            \n",
      "                                    [None,64] [None,64]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "21  fc1 (Dense)                     [None,64] [None,64]              41600      global_avg_pool2d  \n",
      "                                    [None,64] [None,64]                                            \n",
      "                                    [None,64] [None,64]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "22  bn_fc1 (BatchNormalization)     [None,64] [None,64]              512        fc1                \n",
      "                                    [None,64] [None,64]                                            \n",
      "                                    [None,64] [None,64]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "23  relu_fc1 (Activation)           [None,64] [None,64]              0          bn_fc1             \n",
      "                                    [None,64] [None,64]                                            \n",
      "                                    [None,64] [None,64]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "24  output (Dense)                  [None,10]                        3250       relu_fc1           \n",
      "                                    [None,10]                                                      \n",
      "                                    [None,10]                                                      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "Total parameters: 765266\n",
      "50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 - 20s - loss_1: 1.7995 - loss_2: 1.8019 - loss_3: 1.7824 - acc_ensemble: 0.4800 - acc_1: 0.4340 - acc_2: 0.4400 - acc_3: 0.4380 - val_loss_1: 1.5385 - val_loss_2: 1.5243 - val_loss_3: 1.5363 - val_acc_ensemble: 0.4756 - val_acc_1: 0.4337 - val_acc_2: 0.4361 - val_acc_3: 0.4403\n",
      "Epoch 2/50\n",
      "100/100 - 12s - loss_1: 1.4197 - loss_2: 1.4308 - loss_3: 1.4394 - acc_ensemble: 0.5940 - acc_1: 0.5340 - acc_2: 0.5140 - acc_3: 0.5240 - val_loss_1: 1.3255 - val_loss_2: 1.3236 - val_loss_3: 1.3701 - val_acc_ensemble: 0.5547 - val_acc_1: 0.5144 - val_acc_2: 0.5141 - val_acc_3: 0.4885\n",
      "Epoch 3/50\n",
      "100/100 - 12s - loss_1: 1.2665 - loss_2: 1.2775 - loss_3: 1.2900 - acc_ensemble: 0.6160 - acc_1: 0.5700 - acc_2: 0.5660 - acc_3: 0.5660 - val_loss_1: 1.2137 - val_loss_2: 1.2038 - val_loss_3: 1.2331 - val_acc_ensemble: 0.5966 - val_acc_1: 0.5569 - val_acc_2: 0.5654 - val_acc_3: 0.5451\n",
      "Epoch 4/50\n",
      "100/100 - 12s - loss_1: 1.1443 - loss_2: 1.1357 - loss_3: 1.1403 - acc_ensemble: 0.6660 - acc_1: 0.5940 - acc_2: 0.6440 - acc_3: 0.6240 - val_loss_1: 1.1196 - val_loss_2: 1.1162 - val_loss_3: 1.1229 - val_acc_ensemble: 0.6418 - val_acc_1: 0.5898 - val_acc_2: 0.5941 - val_acc_3: 0.5913\n",
      "Epoch 5/50\n",
      "100/100 - 12s - loss_1: 1.0390 - loss_2: 1.0607 - loss_3: 1.0520 - acc_ensemble: 0.7000 - acc_1: 0.6260 - acc_2: 0.6380 - acc_3: 0.6540 - val_loss_1: 1.0611 - val_loss_2: 1.0509 - val_loss_3: 1.0667 - val_acc_ensemble: 0.6600 - val_acc_1: 0.6175 - val_acc_2: 0.6176 - val_acc_3: 0.6217\n",
      "Epoch 6/50\n",
      "100/100 - 12s - loss_1: 0.9666 - loss_2: 0.9561 - loss_3: 0.9921 - acc_ensemble: 0.7340 - acc_1: 0.6800 - acc_2: 0.6620 - acc_3: 0.6680 - val_loss_1: 0.9829 - val_loss_2: 1.0109 - val_loss_3: 1.0356 - val_acc_ensemble: 0.6801 - val_acc_1: 0.6480 - val_acc_2: 0.6440 - val_acc_3: 0.6301\n",
      "Epoch 7/50\n",
      "100/100 - 12s - loss_1: 0.9174 - loss_2: 0.9195 - loss_3: 0.9397 - acc_ensemble: 0.7500 - acc_1: 0.7160 - acc_2: 0.6700 - acc_3: 0.7100 - val_loss_1: 0.9395 - val_loss_2: 0.9819 - val_loss_3: 0.9680 - val_acc_ensemble: 0.6977 - val_acc_1: 0.6624 - val_acc_2: 0.6479 - val_acc_3: 0.6520\n",
      "Epoch 8/50\n",
      "100/100 - 12s - loss_1: 0.8258 - loss_2: 0.8546 - loss_3: 0.8521 - acc_ensemble: 0.7700 - acc_1: 0.7000 - acc_2: 0.6820 - acc_3: 0.7540 - val_loss_1: 0.9093 - val_loss_2: 0.9299 - val_loss_3: 0.9308 - val_acc_ensemble: 0.7084 - val_acc_1: 0.6717 - val_acc_2: 0.6663 - val_acc_3: 0.6668\n",
      "Epoch 9/50\n",
      "100/100 - 12s - loss_1: 0.8097 - loss_2: 0.7815 - loss_3: 0.8302 - acc_ensemble: 0.7720 - acc_1: 0.7400 - acc_2: 0.6960 - acc_3: 0.7580 - val_loss_1: 0.8776 - val_loss_2: 0.9104 - val_loss_3: 0.8918 - val_acc_ensemble: 0.7235 - val_acc_1: 0.6866 - val_acc_2: 0.6741 - val_acc_3: 0.6809\n",
      "Epoch 10/50\n",
      "100/100 - 12s - loss_1: 0.7550 - loss_2: 0.7773 - loss_3: 0.7530 - acc_ensemble: 0.7960 - acc_1: 0.7600 - acc_2: 0.7260 - acc_3: 0.7460 - val_loss_1: 0.8736 - val_loss_2: 0.8607 - val_loss_3: 0.8775 - val_acc_ensemble: 0.7368 - val_acc_1: 0.6842 - val_acc_2: 0.6930 - val_acc_3: 0.6905\n",
      "Epoch 11/50\n",
      "100/100 - 12s - loss_1: 0.6981 - loss_2: 0.7220 - loss_3: 0.7173 - acc_ensemble: 0.8120 - acc_1: 0.7540 - acc_2: 0.7540 - acc_3: 0.7620 - val_loss_1: 0.8516 - val_loss_2: 0.8266 - val_loss_3: 0.8499 - val_acc_ensemble: 0.7439 - val_acc_1: 0.6994 - val_acc_2: 0.7064 - val_acc_3: 0.6960\n",
      "Epoch 12/50\n",
      "100/100 - 12s - loss_1: 0.6766 - loss_2: 0.7082 - loss_3: 0.6965 - acc_ensemble: 0.8040 - acc_1: 0.7320 - acc_2: 0.7220 - acc_3: 0.7840 - val_loss_1: 0.8220 - val_loss_2: 0.8061 - val_loss_3: 0.8269 - val_acc_ensemble: 0.7531 - val_acc_1: 0.7098 - val_acc_2: 0.7110 - val_acc_3: 0.7015\n",
      "Epoch 13/50\n",
      "100/100 - 12s - loss_1: 0.6391 - loss_2: 0.6596 - loss_3: 0.6670 - acc_ensemble: 0.8340 - acc_1: 0.7700 - acc_2: 0.7680 - acc_3: 0.7920 - val_loss_1: 0.7932 - val_loss_2: 0.7941 - val_loss_3: 0.7997 - val_acc_ensemble: 0.7582 - val_acc_1: 0.7157 - val_acc_2: 0.7223 - val_acc_3: 0.7181\n",
      "Epoch 14/50\n",
      "100/100 - 12s - loss_1: 0.5932 - loss_2: 0.6043 - loss_3: 0.6028 - acc_ensemble: 0.8480 - acc_1: 0.8040 - acc_2: 0.7480 - acc_3: 0.7960 - val_loss_1: 0.7815 - val_loss_2: 0.7824 - val_loss_3: 0.7842 - val_acc_ensemble: 0.7692 - val_acc_1: 0.7267 - val_acc_2: 0.7242 - val_acc_3: 0.7244\n",
      "Epoch 15/50\n",
      "100/100 - 12s - loss_1: 0.5906 - loss_2: 0.5597 - loss_3: 0.5511 - acc_ensemble: 0.8240 - acc_1: 0.7680 - acc_2: 0.7600 - acc_3: 0.8120 - val_loss_1: 0.7905 - val_loss_2: 0.7688 - val_loss_3: 0.7886 - val_acc_ensemble: 0.7730 - val_acc_1: 0.7232 - val_acc_2: 0.7321 - val_acc_3: 0.7267\n",
      "Epoch 16/50\n",
      "100/100 - 12s - loss_1: 0.5213 - loss_2: 0.5268 - loss_3: 0.5505 - acc_ensemble: 0.8420 - acc_1: 0.8140 - acc_2: 0.7740 - acc_3: 0.7900 - val_loss_1: 0.7526 - val_loss_2: 0.7910 - val_loss_3: 0.7724 - val_acc_ensemble: 0.7759 - val_acc_1: 0.7399 - val_acc_2: 0.7229 - val_acc_3: 0.7268\n",
      "Epoch 17/50\n",
      "100/100 - 12s - loss_1: 0.4904 - loss_2: 0.5321 - loss_3: 0.4991 - acc_ensemble: 0.8520 - acc_1: 0.7700 - acc_2: 0.7860 - acc_3: 0.8180 - val_loss_1: 0.7984 - val_loss_2: 0.7743 - val_loss_3: 0.7647 - val_acc_ensemble: 0.7739 - val_acc_1: 0.7206 - val_acc_2: 0.7309 - val_acc_3: 0.7351\n",
      "Epoch 18/50\n",
      "100/100 - 12s - loss_1: 0.4798 - loss_2: 0.4886 - loss_3: 0.4841 - acc_ensemble: 0.8480 - acc_1: 0.7880 - acc_2: 0.7720 - acc_3: 0.7880 - val_loss_1: 0.8048 - val_loss_2: 0.7692 - val_loss_3: 0.8228 - val_acc_ensemble: 0.7817 - val_acc_1: 0.7284 - val_acc_2: 0.7339 - val_acc_3: 0.7141\n",
      "Epoch 19/50\n",
      "100/100 - 12s - loss_1: 0.4665 - loss_2: 0.4894 - loss_3: 0.4782 - acc_ensemble: 0.8740 - acc_1: 0.8040 - acc_2: 0.8040 - acc_3: 0.8000 - val_loss_1: 0.8115 - val_loss_2: 0.7588 - val_loss_3: 0.7692 - val_acc_ensemble: 0.7875 - val_acc_1: 0.7295 - val_acc_2: 0.7466 - val_acc_3: 0.7347\n",
      "Epoch 20/50\n",
      "100/100 - 12s - loss_1: 0.4191 - loss_2: 0.4356 - loss_3: 0.4363 - acc_ensemble: 0.8640 - acc_1: 0.8040 - acc_2: 0.7620 - acc_3: 0.7840 - val_loss_1: 0.7911 - val_loss_2: 0.7630 - val_loss_3: 0.7800 - val_acc_ensemble: 0.7920 - val_acc_1: 0.7325 - val_acc_2: 0.7399 - val_acc_3: 0.7350\n",
      "Epoch 21/50\n",
      "100/100 - 12s - loss_1: 0.3806 - loss_2: 0.3983 - loss_3: 0.3800 - acc_ensemble: 0.8800 - acc_1: 0.8180 - acc_2: 0.7920 - acc_3: 0.8380 - val_loss_1: 0.7925 - val_loss_2: 0.7544 - val_loss_3: 0.7728 - val_acc_ensemble: 0.7945 - val_acc_1: 0.7399 - val_acc_2: 0.7434 - val_acc_3: 0.7414\n",
      "Epoch 22/50\n",
      "100/100 - 12s - loss_1: 0.3577 - loss_2: 0.3898 - loss_3: 0.3816 - acc_ensemble: 0.8720 - acc_1: 0.8020 - acc_2: 0.8200 - acc_3: 0.8140 - val_loss_1: 0.8110 - val_loss_2: 0.7570 - val_loss_3: 0.7834 - val_acc_ensemble: 0.7949 - val_acc_1: 0.7397 - val_acc_2: 0.7469 - val_acc_3: 0.7468\n",
      "Epoch 23/50\n",
      "100/100 - 12s - loss_1: 0.3698 - loss_2: 0.3706 - loss_3: 0.3864 - acc_ensemble: 0.8820 - acc_1: 0.8220 - acc_2: 0.8200 - acc_3: 0.8180 - val_loss_1: 0.7707 - val_loss_2: 0.7282 - val_loss_3: 0.7728 - val_acc_ensemble: 0.8015 - val_acc_1: 0.7482 - val_acc_2: 0.7578 - val_acc_3: 0.7470\n",
      "Epoch 24/50\n",
      "100/100 - 12s - loss_1: 0.3197 - loss_2: 0.3621 - loss_3: 0.3293 - acc_ensemble: 0.8840 - acc_1: 0.8260 - acc_2: 0.7920 - acc_3: 0.8220 - val_loss_1: 0.8079 - val_loss_2: 0.7638 - val_loss_3: 0.7912 - val_acc_ensemble: 0.7985 - val_acc_1: 0.7409 - val_acc_2: 0.7488 - val_acc_3: 0.7418\n",
      "Epoch 25/50\n",
      "100/100 - 12s - loss_1: 0.3063 - loss_2: 0.3033 - loss_3: 0.3117 - acc_ensemble: 0.8860 - acc_1: 0.8160 - acc_2: 0.8400 - acc_3: 0.8420 - val_loss_1: 0.8132 - val_loss_2: 0.7441 - val_loss_3: 0.7744 - val_acc_ensemble: 0.8035 - val_acc_1: 0.7444 - val_acc_2: 0.7606 - val_acc_3: 0.7475\n",
      "Epoch 26/50\n",
      "100/100 - 12s - loss_1: 0.2778 - loss_2: 0.3007 - loss_3: 0.2957 - acc_ensemble: 0.8980 - acc_1: 0.8440 - acc_2: 0.8140 - acc_3: 0.8600 - val_loss_1: 0.7999 - val_loss_2: 0.7549 - val_loss_3: 0.8079 - val_acc_ensemble: 0.8036 - val_acc_1: 0.7492 - val_acc_2: 0.7575 - val_acc_3: 0.7429\n",
      "Epoch 27/50\n",
      "100/100 - 12s - loss_1: 0.2364 - loss_2: 0.2781 - loss_3: 0.2751 - acc_ensemble: 0.8940 - acc_1: 0.8260 - acc_2: 0.8280 - acc_3: 0.8380 - val_loss_1: 0.8284 - val_loss_2: 0.7739 - val_loss_3: 0.8070 - val_acc_ensemble: 0.8041 - val_acc_1: 0.7451 - val_acc_2: 0.7603 - val_acc_3: 0.7506\n",
      "Epoch 28/50\n",
      "100/100 - 12s - loss_1: 0.2667 - loss_2: 0.2633 - loss_3: 0.2655 - acc_ensemble: 0.9060 - acc_1: 0.8600 - acc_2: 0.8360 - acc_3: 0.8360 - val_loss_1: 0.8275 - val_loss_2: 0.7823 - val_loss_3: 0.8155 - val_acc_ensemble: 0.8047 - val_acc_1: 0.7493 - val_acc_2: 0.7646 - val_acc_3: 0.7480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50\n",
      "100/100 - 12s - loss_1: 0.2281 - loss_2: 0.2686 - loss_3: 0.2438 - acc_ensemble: 0.9020 - acc_1: 0.8520 - acc_2: 0.8280 - acc_3: 0.8420 - val_loss_1: 0.8227 - val_loss_2: 0.7676 - val_loss_3: 0.8289 - val_acc_ensemble: 0.8071 - val_acc_1: 0.7491 - val_acc_2: 0.7634 - val_acc_3: 0.7485\n",
      "Epoch 30/50\n",
      "100/100 - 12s - loss_1: 0.2230 - loss_2: 0.2131 - loss_3: 0.2214 - acc_ensemble: 0.9020 - acc_1: 0.8300 - acc_2: 0.8500 - acc_3: 0.8480 - val_loss_1: 0.8484 - val_loss_2: 0.8041 - val_loss_3: 0.8106 - val_acc_ensemble: 0.7992 - val_acc_1: 0.7461 - val_acc_2: 0.7572 - val_acc_3: 0.7502\n",
      "Epoch 31/50\n",
      "100/100 - 12s - loss_1: 0.2077 - loss_2: 0.2412 - loss_3: 0.2232 - acc_ensemble: 0.9060 - acc_1: 0.8500 - acc_2: 0.8400 - acc_3: 0.8460 - val_loss_1: 0.8484 - val_loss_2: 0.8032 - val_loss_3: 0.8405 - val_acc_ensemble: 0.8044 - val_acc_1: 0.7528 - val_acc_2: 0.7591 - val_acc_3: 0.7511\n",
      "Epoch 32/50\n",
      "100/100 - 12s - loss_1: 0.1623 - loss_2: 0.2103 - loss_3: 0.1879 - acc_ensemble: 0.9160 - acc_1: 0.8420 - acc_2: 0.8400 - acc_3: 0.8700 - val_loss_1: 0.8578 - val_loss_2: 0.7981 - val_loss_3: 0.8091 - val_acc_ensemble: 0.8120 - val_acc_1: 0.7476 - val_acc_2: 0.7580 - val_acc_3: 0.7603\n",
      "Epoch 33/50\n",
      "100/100 - 12s - loss_1: 0.1833 - loss_2: 0.2050 - loss_3: 0.1756 - acc_ensemble: 0.9040 - acc_1: 0.8560 - acc_2: 0.8360 - acc_3: 0.8460 - val_loss_1: 0.8433 - val_loss_2: 0.8293 - val_loss_3: 0.8606 - val_acc_ensemble: 0.8101 - val_acc_1: 0.7592 - val_acc_2: 0.7580 - val_acc_3: 0.7494\n",
      "Epoch 34/50\n",
      "100/100 - 12s - loss_1: 0.1702 - loss_2: 0.1828 - loss_3: 0.1650 - acc_ensemble: 0.9160 - acc_1: 0.8400 - acc_2: 0.8480 - acc_3: 0.8640 - val_loss_1: 0.8744 - val_loss_2: 0.8240 - val_loss_3: 0.8517 - val_acc_ensemble: 0.8097 - val_acc_1: 0.7538 - val_acc_2: 0.7550 - val_acc_3: 0.7599\n",
      "Epoch 35/50\n",
      "100/100 - 12s - loss_1: 0.1591 - loss_2: 0.1384 - loss_3: 0.1804 - acc_ensemble: 0.8940 - acc_1: 0.8400 - acc_2: 0.8240 - acc_3: 0.8500 - val_loss_1: 0.9061 - val_loss_2: 0.8937 - val_loss_3: 0.8755 - val_acc_ensemble: 0.8100 - val_acc_1: 0.7509 - val_acc_2: 0.7493 - val_acc_3: 0.7495\n",
      "Epoch 36/50\n",
      "100/100 - 12s - loss_1: 0.1515 - loss_2: 0.1613 - loss_3: 0.1670 - acc_ensemble: 0.9120 - acc_1: 0.8580 - acc_2: 0.8280 - acc_3: 0.8720 - val_loss_1: 0.9235 - val_loss_2: 0.9082 - val_loss_3: 0.8764 - val_acc_ensemble: 0.8075 - val_acc_1: 0.7508 - val_acc_2: 0.7532 - val_acc_3: 0.7543\n",
      "Epoch 37/50\n",
      "100/100 - 12s - loss_1: 0.1156 - loss_2: 0.1547 - loss_3: 0.1178 - acc_ensemble: 0.9080 - acc_1: 0.8580 - acc_2: 0.8560 - acc_3: 0.8440 - val_loss_1: 0.9186 - val_loss_2: 0.8580 - val_loss_3: 0.9031 - val_acc_ensemble: 0.8134 - val_acc_1: 0.7545 - val_acc_2: 0.7606 - val_acc_3: 0.7488\n",
      "Epoch 38/50\n",
      "100/100 - 12s - loss_1: 0.1481 - loss_2: 0.1351 - loss_3: 0.1269 - acc_ensemble: 0.9160 - acc_1: 0.8580 - acc_2: 0.8620 - acc_3: 0.8600 - val_loss_1: 0.9495 - val_loss_2: 0.8785 - val_loss_3: 0.9083 - val_acc_ensemble: 0.8116 - val_acc_1: 0.7544 - val_acc_2: 0.7621 - val_acc_3: 0.7562\n",
      "Epoch 39/50\n",
      "100/100 - 12s - loss_1: 0.1507 - loss_2: 0.1224 - loss_3: 0.1369 - acc_ensemble: 0.9180 - acc_1: 0.8420 - acc_2: 0.8520 - acc_3: 0.8580 - val_loss_1: 0.9421 - val_loss_2: 0.9224 - val_loss_3: 0.9529 - val_acc_ensemble: 0.8107 - val_acc_1: 0.7497 - val_acc_2: 0.7546 - val_acc_3: 0.7452\n",
      "Epoch 40/50\n",
      "100/100 - 12s - loss_1: 0.1200 - loss_2: 0.1365 - loss_3: 0.1648 - acc_ensemble: 0.9220 - acc_1: 0.8680 - acc_2: 0.8280 - acc_3: 0.8540 - val_loss_1: 0.9214 - val_loss_2: 0.8899 - val_loss_3: 0.9431 - val_acc_ensemble: 0.8135 - val_acc_1: 0.7583 - val_acc_2: 0.7646 - val_acc_3: 0.7500\n",
      "Epoch 41/50\n",
      "100/100 - 12s - loss_1: 0.0834 - loss_2: 0.1173 - loss_3: 0.1565 - acc_ensemble: 0.9260 - acc_1: 0.8760 - acc_2: 0.8580 - acc_3: 0.8540 - val_loss_1: 0.9312 - val_loss_2: 0.9079 - val_loss_3: 0.9325 - val_acc_ensemble: 0.8148 - val_acc_1: 0.7625 - val_acc_2: 0.7641 - val_acc_3: 0.7598\n",
      "Epoch 42/50\n",
      "100/100 - 12s - loss_1: 0.0821 - loss_2: 0.1048 - loss_3: 0.1040 - acc_ensemble: 0.9300 - acc_1: 0.8600 - acc_2: 0.8560 - acc_3: 0.8640 - val_loss_1: 0.9967 - val_loss_2: 0.9343 - val_loss_3: 0.9306 - val_acc_ensemble: 0.8113 - val_acc_1: 0.7445 - val_acc_2: 0.7539 - val_acc_3: 0.7553\n",
      "Epoch 43/50\n",
      "100/100 - 12s - loss_1: 0.0804 - loss_2: 0.1152 - loss_3: 0.1063 - acc_ensemble: 0.9260 - acc_1: 0.8820 - acc_2: 0.8380 - acc_3: 0.8720 - val_loss_1: 0.9681 - val_loss_2: 0.9556 - val_loss_3: 0.9475 - val_acc_ensemble: 0.8135 - val_acc_1: 0.7595 - val_acc_2: 0.7547 - val_acc_3: 0.7511\n",
      "Epoch 44/50\n",
      "100/100 - 12s - loss_1: 0.0881 - loss_2: 0.1245 - loss_3: 0.1052 - acc_ensemble: 0.9240 - acc_1: 0.8440 - acc_2: 0.8560 - acc_3: 0.8540 - val_loss_1: 1.0381 - val_loss_2: 0.9510 - val_loss_3: 0.9702 - val_acc_ensemble: 0.8102 - val_acc_1: 0.7496 - val_acc_2: 0.7554 - val_acc_3: 0.7518\n",
      "Epoch 45/50\n",
      "100/100 - 12s - loss_1: 0.0794 - loss_2: 0.1207 - loss_3: 0.0676 - acc_ensemble: 0.9180 - acc_1: 0.8520 - acc_2: 0.8500 - acc_3: 0.8720 - val_loss_1: 1.0109 - val_loss_2: 0.9483 - val_loss_3: 0.9767 - val_acc_ensemble: 0.8164 - val_acc_1: 0.7595 - val_acc_2: 0.7652 - val_acc_3: 0.7599\n",
      "Epoch 46/50\n",
      "100/100 - 12s - loss_1: 0.0893 - loss_2: 0.0916 - loss_3: 0.0668 - acc_ensemble: 0.9140 - acc_1: 0.8460 - acc_2: 0.8720 - acc_3: 0.8640 - val_loss_1: 1.0550 - val_loss_2: 0.9448 - val_loss_3: 0.9996 - val_acc_ensemble: 0.8149 - val_acc_1: 0.7448 - val_acc_2: 0.7634 - val_acc_3: 0.7580\n",
      "Epoch 47/50\n",
      "100/100 - 12s - loss_1: 0.1031 - loss_2: 0.0536 - loss_3: 0.0823 - acc_ensemble: 0.9260 - acc_1: 0.8640 - acc_2: 0.8640 - acc_3: 0.8880 - val_loss_1: 1.0433 - val_loss_2: 0.9485 - val_loss_3: 1.0053 - val_acc_ensemble: 0.8138 - val_acc_1: 0.7534 - val_acc_2: 0.7662 - val_acc_3: 0.7573\n",
      "Epoch 48/50\n",
      "100/100 - 12s - loss_1: 0.1017 - loss_2: 0.0650 - loss_3: 0.0743 - acc_ensemble: 0.9280 - acc_1: 0.8780 - acc_2: 0.8800 - acc_3: 0.8700 - val_loss_1: 1.0033 - val_loss_2: 0.9606 - val_loss_3: 0.9891 - val_acc_ensemble: 0.8160 - val_acc_1: 0.7561 - val_acc_2: 0.7646 - val_acc_3: 0.7592\n",
      "Epoch 49/50\n",
      "100/100 - 12s - loss_1: 0.0993 - loss_2: 0.0637 - loss_3: 0.0635 - acc_ensemble: 0.9180 - acc_1: 0.8620 - acc_2: 0.8520 - acc_3: 0.8780 - val_loss_1: 1.0152 - val_loss_2: 1.0290 - val_loss_3: 1.0028 - val_acc_ensemble: 0.8165 - val_acc_1: 0.7622 - val_acc_2: 0.7557 - val_acc_3: 0.7605\n",
      "Epoch 50/50\n",
      "100/100 - 12s - loss_1: 0.0797 - loss_2: 0.0969 - loss_3: 0.0730 - acc_ensemble: 0.9200 - acc_1: 0.8540 - acc_2: 0.8440 - acc_3: 0.8560 - val_loss_1: 1.0182 - val_loss_2: 1.0535 - val_loss_3: 1.0775 - val_acc_ensemble: 0.8123 - val_acc_1: 0.7565 - val_acc_2: 0.7547 - val_acc_3: 0.7472\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B3/S0.75/model_1\n",
      "i   Layer name                      Output shape                     Num param  Inbound            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "0   conv2d_1_1 (Conv2D)             [None,32,32,24] [None,32,32,8]   1344       input              \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "1   bn_1_1 (BatchNormalization)     [None,32,32,24] [None,32,32,8]   96         conv2d_1_1         \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "2   relu_1_1 (Activation)           [None,32,32,24] [None,32,32,8]   0          bn_1_1             \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "3   conv2d_1_2 (Conv2D)             [None,32,32,24] [None,32,32,8]   17424      relu_1_1           \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "4   bn_1_2 (BatchNormalization)     [None,32,32,24] [None,32,32,8]   96         conv2d_1_2         \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "5   relu_1_2 (Activation)           [None,32,32,24] [None,32,32,8]   0          bn_1_2             \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "6   avg_pool2d_1 (AveragePooling2D  [None,16,16,24] [None,16,16,8]   0          relu_1_2           \n",
      "                                    [None,16,16,24] [None,16,16,8]                                 \n",
      "                                    [None,16,16,24] [None,16,16,8]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "7   conv2d_2_1 (Conv2D)             [None,16,16,48] [None,16,16,16]  34848      avg_pool2d_1       \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "8   bn_2_1 (BatchNormalization)     [None,16,16,48] [None,16,16,16]  192        conv2d_2_1         \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "9   relu_2_1 (Activation)           [None,16,16,48] [None,16,16,16]  0          bn_2_1             \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "10  conv2d_2_2 (Conv2D)             [None,16,16,48] [None,16,16,16]  69408      relu_2_1           \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "11  bn_2_2 (BatchNormalization)     [None,16,16,48] [None,16,16,16]  192        conv2d_2_2         \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "12  relu_2_2 (Activation)           [None,16,16,48] [None,16,16,16]  0          bn_2_2             \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "13  avg_pool2d_2 (AveragePooling2D  [None,8,8,48] [None,8,8,16]      0          relu_2_2           \n",
      "                                    [None,8,8,48] [None,8,8,16]                                    \n",
      "                                    [None,8,8,48] [None,8,8,16]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "14  conv2d_3_1 (Conv2D)             [None,8,8,96] [None,8,8,32]      138816     avg_pool2d_2       \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "15  bn_3_1 (BatchNormalization)     [None,8,8,96] [None,8,8,32]      384        conv2d_3_1         \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "16  relu_3_1 (Activation)           [None,8,8,96] [None,8,8,32]      0          bn_3_1             \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "17  conv2d_3_2 (Conv2D)             [None,8,8,96] [None,8,8,32]      277056     relu_3_1           \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "18  bn_3_2 (BatchNormalization)     [None,8,8,96] [None,8,8,32]      384        conv2d_3_2         \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "19  relu_3_2 (Activation)           [None,8,8,96] [None,8,8,32]      0          bn_3_2             \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "20  global_avg_pool2d (GlobalAvera  [None,96] [None,32]              0          relu_3_2           \n",
      "                                    [None,96] [None,32]                                            \n",
      "                                    [None,96] [None,32]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "21  fc1 (Dense)                     [None,96] [None,32]              31296      global_avg_pool2d  \n",
      "                                    [None,96] [None,32]                                            \n",
      "                                    [None,96] [None,32]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "22  bn_fc1 (BatchNormalization)     [None,96] [None,32]              384        fc1                \n",
      "                                    [None,96] [None,32]                                            \n",
      "                                    [None,96] [None,32]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "23  relu_fc1 (Activation)           [None,96] [None,32]              0          bn_fc1             \n",
      "                                    [None,96] [None,32]                                            \n",
      "                                    [None,96] [None,32]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "24  output (Dense)                  [None,10]                        2542       relu_fc1           \n",
      "                                    [None,10]                                                      \n",
      "                                    [None,10]                                                      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "Total parameters: 574462\n",
      "50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 - 20s - loss_1: 1.8089 - loss_2: 1.7914 - loss_3: 1.7542 - acc_ensemble: 0.4760 - acc_1: 0.4620 - acc_2: 0.4360 - acc_3: 0.4780 - val_loss_1: 1.5159 - val_loss_2: 1.5439 - val_loss_3: 1.5040 - val_acc_ensemble: 0.4649 - val_acc_1: 0.4374 - val_acc_2: 0.4229 - val_acc_3: 0.4474\n",
      "Epoch 2/50\n",
      "100/100 - 12s - loss_1: 1.4344 - loss_2: 1.4150 - loss_3: 1.3903 - acc_ensemble: 0.5820 - acc_1: 0.5460 - acc_2: 0.5660 - acc_3: 0.5160 - val_loss_1: 1.2764 - val_loss_2: 1.2672 - val_loss_3: 1.2996 - val_acc_ensemble: 0.5613 - val_acc_1: 0.5375 - val_acc_2: 0.5389 - val_acc_3: 0.5266\n",
      "Epoch 3/50\n",
      "100/100 - 12s - loss_1: 1.2662 - loss_2: 1.2504 - loss_3: 1.2315 - acc_ensemble: 0.6400 - acc_1: 0.5980 - acc_2: 0.6280 - acc_3: 0.6180 - val_loss_1: 1.1709 - val_loss_2: 1.1581 - val_loss_3: 1.1890 - val_acc_ensemble: 0.6098 - val_acc_1: 0.5768 - val_acc_2: 0.5823 - val_acc_3: 0.5709\n",
      "Epoch 4/50\n",
      "100/100 - 12s - loss_1: 1.1272 - loss_2: 1.0990 - loss_3: 1.1200 - acc_ensemble: 0.6760 - acc_1: 0.6400 - acc_2: 0.6240 - acc_3: 0.6380 - val_loss_1: 1.0857 - val_loss_2: 1.0757 - val_loss_3: 1.0899 - val_acc_ensemble: 0.6389 - val_acc_1: 0.6036 - val_acc_2: 0.6139 - val_acc_3: 0.6080\n",
      "Epoch 5/50\n",
      "100/100 - 12s - loss_1: 1.0271 - loss_2: 1.0100 - loss_3: 1.0414 - acc_ensemble: 0.7100 - acc_1: 0.6780 - acc_2: 0.6760 - acc_3: 0.6660 - val_loss_1: 1.0017 - val_loss_2: 1.0053 - val_loss_3: 1.0193 - val_acc_ensemble: 0.6668 - val_acc_1: 0.6384 - val_acc_2: 0.6378 - val_acc_3: 0.6316\n",
      "Epoch 6/50\n",
      "100/100 - 12s - loss_1: 0.9172 - loss_2: 0.9356 - loss_3: 0.9108 - acc_ensemble: 0.7160 - acc_1: 0.6960 - acc_2: 0.6860 - acc_3: 0.6620 - val_loss_1: 0.9448 - val_loss_2: 0.9486 - val_loss_3: 0.9623 - val_acc_ensemble: 0.6831 - val_acc_1: 0.6634 - val_acc_2: 0.6585 - val_acc_3: 0.6523\n",
      "Epoch 7/50\n",
      "100/100 - 12s - loss_1: 0.8661 - loss_2: 0.8924 - loss_3: 0.8687 - acc_ensemble: 0.7520 - acc_1: 0.7340 - acc_2: 0.7140 - acc_3: 0.7380 - val_loss_1: 0.9075 - val_loss_2: 0.9042 - val_loss_3: 0.9251 - val_acc_ensemble: 0.7064 - val_acc_1: 0.6787 - val_acc_2: 0.6792 - val_acc_3: 0.6719\n",
      "Epoch 8/50\n",
      "100/100 - 12s - loss_1: 0.7901 - loss_2: 0.8138 - loss_3: 0.7980 - acc_ensemble: 0.7440 - acc_1: 0.7220 - acc_2: 0.7300 - acc_3: 0.7040 - val_loss_1: 0.8742 - val_loss_2: 0.8597 - val_loss_3: 0.8566 - val_acc_ensemble: 0.7203 - val_acc_1: 0.6890 - val_acc_2: 0.6921 - val_acc_3: 0.6930\n",
      "Epoch 9/50\n",
      "100/100 - 12s - loss_1: 0.7651 - loss_2: 0.7571 - loss_3: 0.7374 - acc_ensemble: 0.7520 - acc_1: 0.7200 - acc_2: 0.7380 - acc_3: 0.7340 - val_loss_1: 0.8472 - val_loss_2: 0.8316 - val_loss_3: 0.8452 - val_acc_ensemble: 0.7330 - val_acc_1: 0.7031 - val_acc_2: 0.7084 - val_acc_3: 0.6997\n",
      "Epoch 10/50\n",
      "100/100 - 12s - loss_1: 0.6865 - loss_2: 0.6912 - loss_3: 0.7061 - acc_ensemble: 0.7880 - acc_1: 0.7700 - acc_2: 0.7380 - acc_3: 0.7800 - val_loss_1: 0.8059 - val_loss_2: 0.7913 - val_loss_3: 0.8052 - val_acc_ensemble: 0.7452 - val_acc_1: 0.7164 - val_acc_2: 0.7251 - val_acc_3: 0.7185\n",
      "Epoch 11/50\n",
      "100/100 - 12s - loss_1: 0.6854 - loss_2: 0.6593 - loss_3: 0.6257 - acc_ensemble: 0.7800 - acc_1: 0.7400 - acc_2: 0.7720 - acc_3: 0.7460 - val_loss_1: 0.7850 - val_loss_2: 0.7945 - val_loss_3: 0.7765 - val_acc_ensemble: 0.7479 - val_acc_1: 0.7221 - val_acc_2: 0.7205 - val_acc_3: 0.7269\n",
      "Epoch 12/50\n",
      "100/100 - 12s - loss_1: 0.6146 - loss_2: 0.6128 - loss_3: 0.6369 - acc_ensemble: 0.8100 - acc_1: 0.7880 - acc_2: 0.7720 - acc_3: 0.7760 - val_loss_1: 0.7874 - val_loss_2: 0.8220 - val_loss_3: 0.8064 - val_acc_ensemble: 0.7479 - val_acc_1: 0.7220 - val_acc_2: 0.7139 - val_acc_3: 0.7172\n",
      "Epoch 13/50\n",
      "100/100 - 12s - loss_1: 0.6043 - loss_2: 0.5825 - loss_3: 0.5853 - acc_ensemble: 0.8160 - acc_1: 0.7760 - acc_2: 0.8040 - acc_3: 0.7980 - val_loss_1: 0.7772 - val_loss_2: 0.7726 - val_loss_3: 0.7602 - val_acc_ensemble: 0.7582 - val_acc_1: 0.7290 - val_acc_2: 0.7311 - val_acc_3: 0.7315\n",
      "Epoch 14/50\n",
      "100/100 - 12s - loss_1: 0.5652 - loss_2: 0.5682 - loss_3: 0.5269 - acc_ensemble: 0.8300 - acc_1: 0.7860 - acc_2: 0.7860 - acc_3: 0.7640 - val_loss_1: 0.7565 - val_loss_2: 0.7544 - val_loss_3: 0.7874 - val_acc_ensemble: 0.7617 - val_acc_1: 0.7406 - val_acc_2: 0.7360 - val_acc_3: 0.7240\n",
      "Epoch 15/50\n",
      "100/100 - 12s - loss_1: 0.5086 - loss_2: 0.5133 - loss_3: 0.5051 - acc_ensemble: 0.8300 - acc_1: 0.8120 - acc_2: 0.8080 - acc_3: 0.8040 - val_loss_1: 0.7395 - val_loss_2: 0.7356 - val_loss_3: 0.7306 - val_acc_ensemble: 0.7720 - val_acc_1: 0.7465 - val_acc_2: 0.7458 - val_acc_3: 0.7461\n",
      "Epoch 16/50\n",
      "100/100 - 12s - loss_1: 0.5010 - loss_2: 0.4914 - loss_3: 0.4989 - acc_ensemble: 0.8260 - acc_1: 0.8000 - acc_2: 0.8060 - acc_3: 0.8260 - val_loss_1: 0.7314 - val_loss_2: 0.7199 - val_loss_3: 0.7151 - val_acc_ensemble: 0.7772 - val_acc_1: 0.7507 - val_acc_2: 0.7532 - val_acc_3: 0.7520\n",
      "Epoch 17/50\n",
      "100/100 - 12s - loss_1: 0.4661 - loss_2: 0.4504 - loss_3: 0.4398 - acc_ensemble: 0.8420 - acc_1: 0.8040 - acc_2: 0.8300 - acc_3: 0.8180 - val_loss_1: 0.7702 - val_loss_2: 0.7653 - val_loss_3: 0.7489 - val_acc_ensemble: 0.7710 - val_acc_1: 0.7421 - val_acc_2: 0.7451 - val_acc_3: 0.7477\n",
      "Epoch 18/50\n",
      "100/100 - 12s - loss_1: 0.4356 - loss_2: 0.4420 - loss_3: 0.4342 - acc_ensemble: 0.8640 - acc_1: 0.8300 - acc_2: 0.8260 - acc_3: 0.8320 - val_loss_1: 0.7289 - val_loss_2: 0.7166 - val_loss_3: 0.7299 - val_acc_ensemble: 0.7851 - val_acc_1: 0.7564 - val_acc_2: 0.7584 - val_acc_3: 0.7546\n",
      "Epoch 19/50\n",
      "100/100 - 12s - loss_1: 0.4225 - loss_2: 0.3715 - loss_3: 0.4133 - acc_ensemble: 0.8420 - acc_1: 0.8360 - acc_2: 0.8200 - acc_3: 0.8100 - val_loss_1: 0.7303 - val_loss_2: 0.7349 - val_loss_3: 0.7377 - val_acc_ensemble: 0.7817 - val_acc_1: 0.7551 - val_acc_2: 0.7549 - val_acc_3: 0.7505\n",
      "Epoch 20/50\n",
      "100/100 - 12s - loss_1: 0.4076 - loss_2: 0.3945 - loss_3: 0.4073 - acc_ensemble: 0.8540 - acc_1: 0.8380 - acc_2: 0.8280 - acc_3: 0.8140 - val_loss_1: 0.7121 - val_loss_2: 0.7249 - val_loss_3: 0.7214 - val_acc_ensemble: 0.7858 - val_acc_1: 0.7644 - val_acc_2: 0.7628 - val_acc_3: 0.7585\n",
      "Epoch 21/50\n",
      "100/100 - 12s - loss_1: 0.3591 - loss_2: 0.3531 - loss_3: 0.3489 - acc_ensemble: 0.8700 - acc_1: 0.8460 - acc_2: 0.8400 - acc_3: 0.8340 - val_loss_1: 0.7365 - val_loss_2: 0.7338 - val_loss_3: 0.7459 - val_acc_ensemble: 0.7832 - val_acc_1: 0.7583 - val_acc_2: 0.7623 - val_acc_3: 0.7562\n",
      "Epoch 22/50\n",
      "100/100 - 12s - loss_1: 0.3132 - loss_2: 0.3308 - loss_3: 0.3251 - acc_ensemble: 0.8760 - acc_1: 0.8240 - acc_2: 0.8360 - acc_3: 0.8480 - val_loss_1: 0.7464 - val_loss_2: 0.7514 - val_loss_3: 0.7385 - val_acc_ensemble: 0.7909 - val_acc_1: 0.7607 - val_acc_2: 0.7576 - val_acc_3: 0.7627\n",
      "Epoch 23/50\n",
      "100/100 - 12s - loss_1: 0.2936 - loss_2: 0.3020 - loss_3: 0.3209 - acc_ensemble: 0.8820 - acc_1: 0.8440 - acc_2: 0.8340 - acc_3: 0.8540 - val_loss_1: 0.7236 - val_loss_2: 0.7435 - val_loss_3: 0.7152 - val_acc_ensemble: 0.7956 - val_acc_1: 0.7642 - val_acc_2: 0.7630 - val_acc_3: 0.7683\n",
      "Epoch 24/50\n",
      "100/100 - 12s - loss_1: 0.2974 - loss_2: 0.2674 - loss_3: 0.2798 - acc_ensemble: 0.8860 - acc_1: 0.8280 - acc_2: 0.8400 - acc_3: 0.8640 - val_loss_1: 0.7897 - val_loss_2: 0.7630 - val_loss_3: 0.7359 - val_acc_ensemble: 0.7884 - val_acc_1: 0.7570 - val_acc_2: 0.7663 - val_acc_3: 0.7676\n",
      "Epoch 25/50\n",
      "100/100 - 12s - loss_1: 0.2652 - loss_2: 0.2764 - loss_3: 0.2581 - acc_ensemble: 0.8900 - acc_1: 0.8300 - acc_2: 0.8500 - acc_3: 0.8460 - val_loss_1: 0.7606 - val_loss_2: 0.7659 - val_loss_3: 0.7684 - val_acc_ensemble: 0.7949 - val_acc_1: 0.7591 - val_acc_2: 0.7659 - val_acc_3: 0.7573\n",
      "Epoch 26/50\n",
      "100/100 - 12s - loss_1: 0.2528 - loss_2: 0.2634 - loss_3: 0.2627 - acc_ensemble: 0.8940 - acc_1: 0.8460 - acc_2: 0.8540 - acc_3: 0.8560 - val_loss_1: 0.7565 - val_loss_2: 0.7628 - val_loss_3: 0.7493 - val_acc_ensemble: 0.7980 - val_acc_1: 0.7637 - val_acc_2: 0.7690 - val_acc_3: 0.7685\n",
      "Epoch 27/50\n",
      "100/100 - 12s - loss_1: 0.2224 - loss_2: 0.2189 - loss_3: 0.2291 - acc_ensemble: 0.8880 - acc_1: 0.8600 - acc_2: 0.8540 - acc_3: 0.8520 - val_loss_1: 0.7580 - val_loss_2: 0.7736 - val_loss_3: 0.7532 - val_acc_ensemble: 0.7966 - val_acc_1: 0.7664 - val_acc_2: 0.7670 - val_acc_3: 0.7672\n",
      "Epoch 28/50\n",
      "100/100 - 12s - loss_1: 0.2011 - loss_2: 0.1932 - loss_3: 0.1919 - acc_ensemble: 0.9040 - acc_1: 0.8580 - acc_2: 0.8620 - acc_3: 0.8520 - val_loss_1: 0.7682 - val_loss_2: 0.7850 - val_loss_3: 0.7913 - val_acc_ensemble: 0.7985 - val_acc_1: 0.7678 - val_acc_2: 0.7661 - val_acc_3: 0.7664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50\n",
      "100/100 - 12s - loss_1: 0.2120 - loss_2: 0.1838 - loss_3: 0.2063 - acc_ensemble: 0.9020 - acc_1: 0.8400 - acc_2: 0.8680 - acc_3: 0.8540 - val_loss_1: 0.8140 - val_loss_2: 0.8215 - val_loss_3: 0.7991 - val_acc_ensemble: 0.7957 - val_acc_1: 0.7621 - val_acc_2: 0.7622 - val_acc_3: 0.7639\n",
      "Epoch 30/50\n",
      "100/100 - 12s - loss_1: 0.2123 - loss_2: 0.2083 - loss_3: 0.2082 - acc_ensemble: 0.8960 - acc_1: 0.8380 - acc_2: 0.8500 - acc_3: 0.8580 - val_loss_1: 0.8134 - val_loss_2: 0.8275 - val_loss_3: 0.8300 - val_acc_ensemble: 0.7906 - val_acc_1: 0.7633 - val_acc_2: 0.7590 - val_acc_3: 0.7576\n",
      "Epoch 31/50\n",
      "100/100 - 12s - loss_1: 0.1723 - loss_2: 0.1941 - loss_3: 0.1700 - acc_ensemble: 0.8980 - acc_1: 0.8500 - acc_2: 0.8720 - acc_3: 0.8680 - val_loss_1: 0.8256 - val_loss_2: 0.8425 - val_loss_3: 0.8243 - val_acc_ensemble: 0.7955 - val_acc_1: 0.7626 - val_acc_2: 0.7603 - val_acc_3: 0.7665\n",
      "Epoch 32/50\n",
      "100/100 - 12s - loss_1: 0.1690 - loss_2: 0.1460 - loss_3: 0.1621 - acc_ensemble: 0.9200 - acc_1: 0.8820 - acc_2: 0.8680 - acc_3: 0.8740 - val_loss_1: 0.8241 - val_loss_2: 0.8026 - val_loss_3: 0.8203 - val_acc_ensemble: 0.8006 - val_acc_1: 0.7719 - val_acc_2: 0.7710 - val_acc_3: 0.7651\n",
      "Epoch 33/50\n",
      "100/100 - 12s - loss_1: 0.1431 - loss_2: 0.1767 - loss_3: 0.1404 - acc_ensemble: 0.9060 - acc_1: 0.8620 - acc_2: 0.8480 - acc_3: 0.8520 - val_loss_1: 0.8519 - val_loss_2: 0.8464 - val_loss_3: 0.8437 - val_acc_ensemble: 0.7968 - val_acc_1: 0.7666 - val_acc_2: 0.7664 - val_acc_3: 0.7674\n",
      "Epoch 34/50\n",
      "100/100 - 12s - loss_1: 0.1346 - loss_2: 0.1592 - loss_3: 0.1588 - acc_ensemble: 0.9040 - acc_1: 0.8700 - acc_2: 0.8620 - acc_3: 0.8660 - val_loss_1: 0.8670 - val_loss_2: 0.8720 - val_loss_3: 0.8582 - val_acc_ensemble: 0.7936 - val_acc_1: 0.7648 - val_acc_2: 0.7600 - val_acc_3: 0.7593\n",
      "Epoch 35/50\n",
      "100/100 - 12s - loss_1: 0.1412 - loss_2: 0.1356 - loss_3: 0.1330 - acc_ensemble: 0.8940 - acc_1: 0.8580 - acc_2: 0.8580 - acc_3: 0.8640 - val_loss_1: 0.8754 - val_loss_2: 0.8757 - val_loss_3: 0.8493 - val_acc_ensemble: 0.8019 - val_acc_1: 0.7670 - val_acc_2: 0.7645 - val_acc_3: 0.7702\n",
      "Epoch 36/50\n",
      "100/100 - 12s - loss_1: 0.1237 - loss_2: 0.1183 - loss_3: 0.1185 - acc_ensemble: 0.9160 - acc_1: 0.8560 - acc_2: 0.8680 - acc_3: 0.8780 - val_loss_1: 0.8787 - val_loss_2: 0.8504 - val_loss_3: 0.8450 - val_acc_ensemble: 0.8061 - val_acc_1: 0.7698 - val_acc_2: 0.7760 - val_acc_3: 0.7723\n",
      "Epoch 37/50\n",
      "100/100 - 12s - loss_1: 0.1213 - loss_2: 0.1158 - loss_3: 0.1306 - acc_ensemble: 0.9040 - acc_1: 0.8680 - acc_2: 0.8760 - acc_3: 0.8780 - val_loss_1: 0.8926 - val_loss_2: 0.8906 - val_loss_3: 0.8742 - val_acc_ensemble: 0.8022 - val_acc_1: 0.7700 - val_acc_2: 0.7705 - val_acc_3: 0.7729\n",
      "Epoch 38/50\n",
      "100/100 - 12s - loss_1: 0.0942 - loss_2: 0.1056 - loss_3: 0.1026 - acc_ensemble: 0.9160 - acc_1: 0.8680 - acc_2: 0.8700 - acc_3: 0.8640 - val_loss_1: 0.9076 - val_loss_2: 0.9183 - val_loss_3: 0.9028 - val_acc_ensemble: 0.8039 - val_acc_1: 0.7702 - val_acc_2: 0.7704 - val_acc_3: 0.7709\n",
      "Epoch 39/50\n",
      "100/100 - 13s - loss_1: 0.0877 - loss_2: 0.1352 - loss_3: 0.1155 - acc_ensemble: 0.9160 - acc_1: 0.8780 - acc_2: 0.8960 - acc_3: 0.8560 - val_loss_1: 0.9121 - val_loss_2: 0.9197 - val_loss_3: 0.9136 - val_acc_ensemble: 0.7991 - val_acc_1: 0.7715 - val_acc_2: 0.7684 - val_acc_3: 0.7636\n",
      "Epoch 40/50\n",
      "100/100 - 12s - loss_1: 0.1307 - loss_2: 0.1165 - loss_3: 0.0881 - acc_ensemble: 0.9180 - acc_1: 0.8600 - acc_2: 0.8620 - acc_3: 0.8760 - val_loss_1: 0.9631 - val_loss_2: 0.9282 - val_loss_3: 0.8996 - val_acc_ensemble: 0.7980 - val_acc_1: 0.7595 - val_acc_2: 0.7671 - val_acc_3: 0.7703\n",
      "Epoch 41/50\n",
      "100/100 - 12s - loss_1: 0.1356 - loss_2: 0.0987 - loss_3: 0.1082 - acc_ensemble: 0.9140 - acc_1: 0.8740 - acc_2: 0.8620 - acc_3: 0.8600 - val_loss_1: 0.9524 - val_loss_2: 0.9376 - val_loss_3: 0.9228 - val_acc_ensemble: 0.8029 - val_acc_1: 0.7683 - val_acc_2: 0.7727 - val_acc_3: 0.7711\n",
      "Epoch 42/50\n",
      "100/100 - 12s - loss_1: 0.0987 - loss_2: 0.0907 - loss_3: 0.1047 - acc_ensemble: 0.9160 - acc_1: 0.8820 - acc_2: 0.8780 - acc_3: 0.8420 - val_loss_1: 0.9267 - val_loss_2: 0.9485 - val_loss_3: 0.9261 - val_acc_ensemble: 0.8048 - val_acc_1: 0.7695 - val_acc_2: 0.7710 - val_acc_3: 0.7714\n",
      "Epoch 43/50\n",
      "100/100 - 12s - loss_1: 0.0691 - loss_2: 0.0832 - loss_3: 0.0735 - acc_ensemble: 0.9200 - acc_1: 0.8760 - acc_2: 0.8640 - acc_3: 0.8640 - val_loss_1: 0.9282 - val_loss_2: 0.9322 - val_loss_3: 0.9566 - val_acc_ensemble: 0.8072 - val_acc_1: 0.7722 - val_acc_2: 0.7759 - val_acc_3: 0.7705\n",
      "Epoch 44/50\n",
      "100/100 - 12s - loss_1: 0.0650 - loss_2: 0.0608 - loss_3: 0.0904 - acc_ensemble: 0.9060 - acc_1: 0.8840 - acc_2: 0.8920 - acc_3: 0.8740 - val_loss_1: 0.9940 - val_loss_2: 0.9683 - val_loss_3: 0.9956 - val_acc_ensemble: 0.7951 - val_acc_1: 0.7668 - val_acc_2: 0.7679 - val_acc_3: 0.7602\n",
      "Epoch 45/50\n",
      "100/100 - 12s - loss_1: 0.0642 - loss_2: 0.0633 - loss_3: 0.0630 - acc_ensemble: 0.9280 - acc_1: 0.8800 - acc_2: 0.8800 - acc_3: 0.8800 - val_loss_1: 0.9539 - val_loss_2: 0.9630 - val_loss_3: 0.9528 - val_acc_ensemble: 0.8053 - val_acc_1: 0.7761 - val_acc_2: 0.7736 - val_acc_3: 0.7725\n",
      "Epoch 46/50\n",
      "100/100 - 12s - loss_1: 0.0721 - loss_2: 0.0682 - loss_3: 0.0711 - acc_ensemble: 0.9220 - acc_1: 0.8880 - acc_2: 0.8860 - acc_3: 0.8740 - val_loss_1: 1.0042 - val_loss_2: 1.0175 - val_loss_3: 1.0275 - val_acc_ensemble: 0.7989 - val_acc_1: 0.7717 - val_acc_2: 0.7626 - val_acc_3: 0.7591\n",
      "Epoch 47/50\n",
      "100/100 - 12s - loss_1: 0.0858 - loss_2: 0.0864 - loss_3: 0.0685 - acc_ensemble: 0.9000 - acc_1: 0.8620 - acc_2: 0.8660 - acc_3: 0.8760 - val_loss_1: 1.0328 - val_loss_2: 1.0430 - val_loss_3: 1.0010 - val_acc_ensemble: 0.7976 - val_acc_1: 0.7624 - val_acc_2: 0.7646 - val_acc_3: 0.7666\n",
      "Epoch 48/50\n",
      "100/100 - 12s - loss_1: 0.0711 - loss_2: 0.0794 - loss_3: 0.0553 - acc_ensemble: 0.9160 - acc_1: 0.8660 - acc_2: 0.8680 - acc_3: 0.8780 - val_loss_1: 0.9941 - val_loss_2: 0.9888 - val_loss_3: 0.9820 - val_acc_ensemble: 0.8052 - val_acc_1: 0.7703 - val_acc_2: 0.7765 - val_acc_3: 0.7724\n",
      "Epoch 49/50\n",
      "100/100 - 12s - loss_1: 0.0647 - loss_2: 0.0565 - loss_3: 0.0525 - acc_ensemble: 0.9160 - acc_1: 0.8840 - acc_2: 0.8640 - acc_3: 0.8660 - val_loss_1: 1.0469 - val_loss_2: 1.0355 - val_loss_3: 1.0423 - val_acc_ensemble: 0.7996 - val_acc_1: 0.7660 - val_acc_2: 0.7691 - val_acc_3: 0.7640\n",
      "Epoch 50/50\n",
      "100/100 - 12s - loss_1: 0.0727 - loss_2: 0.0594 - loss_3: 0.0649 - acc_ensemble: 0.9200 - acc_1: 0.8640 - acc_2: 0.8860 - acc_3: 0.8740 - val_loss_1: 1.0688 - val_loss_2: 1.0198 - val_loss_3: 1.0254 - val_acc_ensemble: 0.8037 - val_acc_1: 0.7631 - val_acc_2: 0.7782 - val_acc_3: 0.7709\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B3/S0.75/model_2\n",
      "i   Layer name                      Output shape                     Num param  Inbound            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "0   conv2d_1_1 (Conv2D)             [None,32,32,24] [None,32,32,8]   1344       input              \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "1   bn_1_1 (BatchNormalization)     [None,32,32,24] [None,32,32,8]   96         conv2d_1_1         \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "2   relu_1_1 (Activation)           [None,32,32,24] [None,32,32,8]   0          bn_1_1             \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "3   conv2d_1_2 (Conv2D)             [None,32,32,24] [None,32,32,8]   17424      relu_1_1           \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "4   bn_1_2 (BatchNormalization)     [None,32,32,24] [None,32,32,8]   96         conv2d_1_2         \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "5   relu_1_2 (Activation)           [None,32,32,24] [None,32,32,8]   0          bn_1_2             \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "6   avg_pool2d_1 (AveragePooling2D  [None,16,16,24] [None,16,16,8]   0          relu_1_2           \n",
      "                                    [None,16,16,24] [None,16,16,8]                                 \n",
      "                                    [None,16,16,24] [None,16,16,8]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "7   conv2d_2_1 (Conv2D)             [None,16,16,48] [None,16,16,16]  34848      avg_pool2d_1       \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "8   bn_2_1 (BatchNormalization)     [None,16,16,48] [None,16,16,16]  192        conv2d_2_1         \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "9   relu_2_1 (Activation)           [None,16,16,48] [None,16,16,16]  0          bn_2_1             \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "10  conv2d_2_2 (Conv2D)             [None,16,16,48] [None,16,16,16]  69408      relu_2_1           \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "11  bn_2_2 (BatchNormalization)     [None,16,16,48] [None,16,16,16]  192        conv2d_2_2         \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "12  relu_2_2 (Activation)           [None,16,16,48] [None,16,16,16]  0          bn_2_2             \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "13  avg_pool2d_2 (AveragePooling2D  [None,8,8,48] [None,8,8,16]      0          relu_2_2           \n",
      "                                    [None,8,8,48] [None,8,8,16]                                    \n",
      "                                    [None,8,8,48] [None,8,8,16]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "14  conv2d_3_1 (Conv2D)             [None,8,8,96] [None,8,8,32]      138816     avg_pool2d_2       \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "15  bn_3_1 (BatchNormalization)     [None,8,8,96] [None,8,8,32]      384        conv2d_3_1         \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "16  relu_3_1 (Activation)           [None,8,8,96] [None,8,8,32]      0          bn_3_1             \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "17  conv2d_3_2 (Conv2D)             [None,8,8,96] [None,8,8,32]      277056     relu_3_1           \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "18  bn_3_2 (BatchNormalization)     [None,8,8,96] [None,8,8,32]      384        conv2d_3_2         \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "19  relu_3_2 (Activation)           [None,8,8,96] [None,8,8,32]      0          bn_3_2             \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "20  global_avg_pool2d (GlobalAvera  [None,96] [None,32]              0          relu_3_2           \n",
      "                                    [None,96] [None,32]                                            \n",
      "                                    [None,96] [None,32]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "21  fc1 (Dense)                     [None,96] [None,32]              31296      global_avg_pool2d  \n",
      "                                    [None,96] [None,32]                                            \n",
      "                                    [None,96] [None,32]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "22  bn_fc1 (BatchNormalization)     [None,96] [None,32]              384        fc1                \n",
      "                                    [None,96] [None,32]                                            \n",
      "                                    [None,96] [None,32]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "23  relu_fc1 (Activation)           [None,96] [None,32]              0          bn_fc1             \n",
      "                                    [None,96] [None,32]                                            \n",
      "                                    [None,96] [None,32]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "24  output (Dense)                  [None,10]                        2542       relu_fc1           \n",
      "                                    [None,10]                                                      \n",
      "                                    [None,10]                                                      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "Total parameters: 574462\n",
      "50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 - 20s - loss_1: 1.7509 - loss_2: 1.7598 - loss_3: 1.8017 - acc_ensemble: 0.4800 - acc_1: 0.4640 - acc_2: 0.4460 - acc_3: 0.4400 - val_loss_1: 1.5027 - val_loss_2: 1.4751 - val_loss_3: 1.5339 - val_acc_ensemble: 0.4733 - val_acc_1: 0.4444 - val_acc_2: 0.4559 - val_acc_3: 0.4293\n",
      "Epoch 2/50\n",
      "100/100 - 12s - loss_1: 1.3924 - loss_2: 1.4164 - loss_3: 1.4098 - acc_ensemble: 0.5660 - acc_1: 0.5380 - acc_2: 0.5560 - acc_3: 0.5460 - val_loss_1: 1.2860 - val_loss_2: 1.2806 - val_loss_3: 1.3020 - val_acc_ensemble: 0.5634 - val_acc_1: 0.5292 - val_acc_2: 0.5360 - val_acc_3: 0.5227\n",
      "Epoch 3/50\n",
      "100/100 - 12s - loss_1: 1.2434 - loss_2: 1.2442 - loss_3: 1.2462 - acc_ensemble: 0.6280 - acc_1: 0.5760 - acc_2: 0.5880 - acc_3: 0.6220 - val_loss_1: 1.1591 - val_loss_2: 1.1749 - val_loss_3: 1.1366 - val_acc_ensemble: 0.6054 - val_acc_1: 0.5800 - val_acc_2: 0.5799 - val_acc_3: 0.5870\n",
      "Epoch 4/50\n",
      "100/100 - 12s - loss_1: 1.1155 - loss_2: 1.1326 - loss_3: 1.1151 - acc_ensemble: 0.6780 - acc_1: 0.6100 - acc_2: 0.6160 - acc_3: 0.6480 - val_loss_1: 1.0895 - val_loss_2: 1.0878 - val_loss_3: 1.0879 - val_acc_ensemble: 0.6390 - val_acc_1: 0.6098 - val_acc_2: 0.6077 - val_acc_3: 0.6050\n",
      "Epoch 5/50\n",
      "100/100 - 12s - loss_1: 1.0160 - loss_2: 1.0316 - loss_3: 0.9971 - acc_ensemble: 0.6880 - acc_1: 0.6660 - acc_2: 0.6640 - acc_3: 0.6440 - val_loss_1: 1.0188 - val_loss_2: 1.0427 - val_loss_3: 1.0314 - val_acc_ensemble: 0.6529 - val_acc_1: 0.6335 - val_acc_2: 0.6191 - val_acc_3: 0.6333\n",
      "Epoch 6/50\n",
      "100/100 - 12s - loss_1: 0.9342 - loss_2: 0.9699 - loss_3: 0.9416 - acc_ensemble: 0.7200 - acc_1: 0.6820 - acc_2: 0.6860 - acc_3: 0.7120 - val_loss_1: 0.9437 - val_loss_2: 0.9476 - val_loss_3: 0.9436 - val_acc_ensemble: 0.6842 - val_acc_1: 0.6657 - val_acc_2: 0.6600 - val_acc_3: 0.6589\n",
      "Epoch 7/50\n",
      "100/100 - 12s - loss_1: 0.8964 - loss_2: 0.9040 - loss_3: 0.8811 - acc_ensemble: 0.7600 - acc_1: 0.7320 - acc_2: 0.7000 - acc_3: 0.7200 - val_loss_1: 0.8989 - val_loss_2: 0.8801 - val_loss_3: 0.8967 - val_acc_ensemble: 0.6949 - val_acc_1: 0.6742 - val_acc_2: 0.6823 - val_acc_3: 0.6735\n",
      "Epoch 8/50\n",
      "100/100 - 12s - loss_1: 0.8161 - loss_2: 0.8052 - loss_3: 0.8349 - acc_ensemble: 0.7460 - acc_1: 0.6940 - acc_2: 0.6880 - acc_3: 0.7360 - val_loss_1: 0.8964 - val_loss_2: 0.8959 - val_loss_3: 0.8783 - val_acc_ensemble: 0.7049 - val_acc_1: 0.6796 - val_acc_2: 0.6731 - val_acc_3: 0.6852\n",
      "Epoch 9/50\n",
      "100/100 - 12s - loss_1: 0.7563 - loss_2: 0.7734 - loss_3: 0.7834 - acc_ensemble: 0.7820 - acc_1: 0.7360 - acc_2: 0.7000 - acc_3: 0.7340 - val_loss_1: 0.8557 - val_loss_2: 0.8782 - val_loss_3: 0.8694 - val_acc_ensemble: 0.7153 - val_acc_1: 0.6974 - val_acc_2: 0.6920 - val_acc_3: 0.6859\n",
      "Epoch 10/50\n",
      "100/100 - 12s - loss_1: 0.7189 - loss_2: 0.7295 - loss_3: 0.7489 - acc_ensemble: 0.7840 - acc_1: 0.7520 - acc_2: 0.7400 - acc_3: 0.7380 - val_loss_1: 0.8339 - val_loss_2: 0.8562 - val_loss_3: 0.8409 - val_acc_ensemble: 0.7288 - val_acc_1: 0.7026 - val_acc_2: 0.6995 - val_acc_3: 0.7060\n",
      "Epoch 11/50\n",
      "100/100 - 12s - loss_1: 0.7016 - loss_2: 0.7098 - loss_3: 0.6630 - acc_ensemble: 0.8000 - acc_1: 0.7940 - acc_2: 0.7780 - acc_3: 0.7840 - val_loss_1: 0.7914 - val_loss_2: 0.7832 - val_loss_3: 0.7779 - val_acc_ensemble: 0.7438 - val_acc_1: 0.7204 - val_acc_2: 0.7247 - val_acc_3: 0.7211\n",
      "Epoch 12/50\n",
      "100/100 - 13s - loss_1: 0.6400 - loss_2: 0.6302 - loss_3: 0.6496 - acc_ensemble: 0.7920 - acc_1: 0.7500 - acc_2: 0.7760 - acc_3: 0.7820 - val_loss_1: 0.8136 - val_loss_2: 0.7732 - val_loss_3: 0.7998 - val_acc_ensemble: 0.7446 - val_acc_1: 0.7147 - val_acc_2: 0.7319 - val_acc_3: 0.7170\n",
      "Epoch 13/50\n",
      "100/100 - 12s - loss_1: 0.6055 - loss_2: 0.6018 - loss_3: 0.5685 - acc_ensemble: 0.8280 - acc_1: 0.7880 - acc_2: 0.7740 - acc_3: 0.7980 - val_loss_1: 0.7834 - val_loss_2: 0.7553 - val_loss_3: 0.7508 - val_acc_ensemble: 0.7575 - val_acc_1: 0.7242 - val_acc_2: 0.7322 - val_acc_3: 0.7378\n",
      "Epoch 14/50\n",
      "100/100 - 12s - loss_1: 0.5896 - loss_2: 0.5590 - loss_3: 0.5809 - acc_ensemble: 0.8400 - acc_1: 0.8020 - acc_2: 0.8200 - acc_3: 0.8080 - val_loss_1: 0.7715 - val_loss_2: 0.7614 - val_loss_3: 0.7469 - val_acc_ensemble: 0.7619 - val_acc_1: 0.7284 - val_acc_2: 0.7403 - val_acc_3: 0.7394\n",
      "Epoch 15/50\n",
      "100/100 - 13s - loss_1: 0.5284 - loss_2: 0.5439 - loss_3: 0.5196 - acc_ensemble: 0.8380 - acc_1: 0.8240 - acc_2: 0.7900 - acc_3: 0.8000 - val_loss_1: 0.7469 - val_loss_2: 0.7570 - val_loss_3: 0.7505 - val_acc_ensemble: 0.7663 - val_acc_1: 0.7393 - val_acc_2: 0.7374 - val_acc_3: 0.7354\n",
      "Epoch 16/50\n",
      "100/100 - 12s - loss_1: 0.4847 - loss_2: 0.5056 - loss_3: 0.4800 - acc_ensemble: 0.8640 - acc_1: 0.8300 - acc_2: 0.7880 - acc_3: 0.8380 - val_loss_1: 0.7266 - val_loss_2: 0.7591 - val_loss_3: 0.7286 - val_acc_ensemble: 0.7770 - val_acc_1: 0.7483 - val_acc_2: 0.7368 - val_acc_3: 0.7544\n",
      "Epoch 17/50\n",
      "100/100 - 12s - loss_1: 0.4655 - loss_2: 0.4668 - loss_3: 0.4894 - acc_ensemble: 0.8440 - acc_1: 0.8220 - acc_2: 0.8100 - acc_3: 0.8080 - val_loss_1: 0.7508 - val_loss_2: 0.7506 - val_loss_3: 0.7339 - val_acc_ensemble: 0.7748 - val_acc_1: 0.7416 - val_acc_2: 0.7467 - val_acc_3: 0.7513\n",
      "Epoch 18/50\n",
      "100/100 - 12s - loss_1: 0.4525 - loss_2: 0.4567 - loss_3: 0.4359 - acc_ensemble: 0.8680 - acc_1: 0.8200 - acc_2: 0.8280 - acc_3: 0.8240 - val_loss_1: 0.7285 - val_loss_2: 0.7473 - val_loss_3: 0.7318 - val_acc_ensemble: 0.7792 - val_acc_1: 0.7543 - val_acc_2: 0.7448 - val_acc_3: 0.7495\n",
      "Epoch 19/50\n",
      "100/100 - 13s - loss_1: 0.4370 - loss_2: 0.4427 - loss_3: 0.4293 - acc_ensemble: 0.8600 - acc_1: 0.8140 - acc_2: 0.8080 - acc_3: 0.8440 - val_loss_1: 0.7405 - val_loss_2: 0.7437 - val_loss_3: 0.7289 - val_acc_ensemble: 0.7786 - val_acc_1: 0.7492 - val_acc_2: 0.7480 - val_acc_3: 0.7535\n",
      "Epoch 20/50\n",
      "100/100 - 12s - loss_1: 0.3921 - loss_2: 0.4059 - loss_3: 0.3891 - acc_ensemble: 0.8760 - acc_1: 0.8560 - acc_2: 0.8420 - acc_3: 0.8420 - val_loss_1: 0.7017 - val_loss_2: 0.7191 - val_loss_3: 0.7144 - val_acc_ensemble: 0.7896 - val_acc_1: 0.7657 - val_acc_2: 0.7639 - val_acc_3: 0.7622\n",
      "Epoch 21/50\n",
      "100/100 - 13s - loss_1: 0.3429 - loss_2: 0.3740 - loss_3: 0.3668 - acc_ensemble: 0.8700 - acc_1: 0.8360 - acc_2: 0.8600 - acc_3: 0.8340 - val_loss_1: 0.7170 - val_loss_2: 0.7151 - val_loss_3: 0.7234 - val_acc_ensemble: 0.7869 - val_acc_1: 0.7635 - val_acc_2: 0.7647 - val_acc_3: 0.7611\n",
      "Epoch 22/50\n",
      "100/100 - 12s - loss_1: 0.3279 - loss_2: 0.3220 - loss_3: 0.3462 - acc_ensemble: 0.8860 - acc_1: 0.8420 - acc_2: 0.8320 - acc_3: 0.8460 - val_loss_1: 0.7573 - val_loss_2: 0.7583 - val_loss_3: 0.7323 - val_acc_ensemble: 0.7887 - val_acc_1: 0.7553 - val_acc_2: 0.7584 - val_acc_3: 0.7618\n",
      "Epoch 23/50\n",
      "100/100 - 13s - loss_1: 0.3343 - loss_2: 0.3395 - loss_3: 0.3132 - acc_ensemble: 0.8700 - acc_1: 0.8380 - acc_2: 0.8340 - acc_3: 0.8360 - val_loss_1: 0.7322 - val_loss_2: 0.7270 - val_loss_3: 0.7187 - val_acc_ensemble: 0.7913 - val_acc_1: 0.7622 - val_acc_2: 0.7637 - val_acc_3: 0.7657\n",
      "Epoch 24/50\n",
      "100/100 - 13s - loss_1: 0.3177 - loss_2: 0.2833 - loss_3: 0.3219 - acc_ensemble: 0.8760 - acc_1: 0.8480 - acc_2: 0.8300 - acc_3: 0.8460 - val_loss_1: 0.7394 - val_loss_2: 0.7671 - val_loss_3: 0.7429 - val_acc_ensemble: 0.7913 - val_acc_1: 0.7600 - val_acc_2: 0.7584 - val_acc_3: 0.7649\n",
      "Epoch 25/50\n",
      "100/100 - 12s - loss_1: 0.2668 - loss_2: 0.2723 - loss_3: 0.2540 - acc_ensemble: 0.8820 - acc_1: 0.8520 - acc_2: 0.8540 - acc_3: 0.8360 - val_loss_1: 0.7393 - val_loss_2: 0.7540 - val_loss_3: 0.7604 - val_acc_ensemble: 0.7993 - val_acc_1: 0.7687 - val_acc_2: 0.7617 - val_acc_3: 0.7614\n",
      "Epoch 26/50\n",
      "100/100 - 12s - loss_1: 0.2679 - loss_2: 0.2527 - loss_3: 0.2664 - acc_ensemble: 0.8820 - acc_1: 0.8560 - acc_2: 0.8460 - acc_3: 0.8540 - val_loss_1: 0.7513 - val_loss_2: 0.7461 - val_loss_3: 0.7384 - val_acc_ensemble: 0.8000 - val_acc_1: 0.7716 - val_acc_2: 0.7695 - val_acc_3: 0.7730\n",
      "Epoch 27/50\n",
      "100/100 - 13s - loss_1: 0.2770 - loss_2: 0.2417 - loss_3: 0.2352 - acc_ensemble: 0.9080 - acc_1: 0.8660 - acc_2: 0.8580 - acc_3: 0.8500 - val_loss_1: 0.7542 - val_loss_2: 0.7701 - val_loss_3: 0.7392 - val_acc_ensemble: 0.7981 - val_acc_1: 0.7647 - val_acc_2: 0.7643 - val_acc_3: 0.7701\n",
      "Epoch 28/50\n",
      "100/100 - 12s - loss_1: 0.2320 - loss_2: 0.2497 - loss_3: 0.2290 - acc_ensemble: 0.8920 - acc_1: 0.8500 - acc_2: 0.8560 - acc_3: 0.8480 - val_loss_1: 0.7709 - val_loss_2: 0.8020 - val_loss_3: 0.7897 - val_acc_ensemble: 0.7920 - val_acc_1: 0.7625 - val_acc_2: 0.7594 - val_acc_3: 0.7642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50\n",
      "100/100 - 12s - loss_1: 0.2035 - loss_2: 0.2203 - loss_3: 0.2510 - acc_ensemble: 0.9100 - acc_1: 0.8540 - acc_2: 0.8660 - acc_3: 0.8640 - val_loss_1: 0.7543 - val_loss_2: 0.7638 - val_loss_3: 0.7651 - val_acc_ensemble: 0.8023 - val_acc_1: 0.7713 - val_acc_2: 0.7671 - val_acc_3: 0.7684\n",
      "Epoch 30/50\n",
      "100/100 - 12s - loss_1: 0.2018 - loss_2: 0.2152 - loss_3: 0.2008 - acc_ensemble: 0.8700 - acc_1: 0.8280 - acc_2: 0.8480 - acc_3: 0.8520 - val_loss_1: 0.7994 - val_loss_2: 0.7861 - val_loss_3: 0.7787 - val_acc_ensemble: 0.7982 - val_acc_1: 0.7618 - val_acc_2: 0.7634 - val_acc_3: 0.7699\n",
      "Epoch 31/50\n",
      "100/100 - 13s - loss_1: 0.1952 - loss_2: 0.1993 - loss_3: 0.1909 - acc_ensemble: 0.8900 - acc_1: 0.8500 - acc_2: 0.8660 - acc_3: 0.8640 - val_loss_1: 0.8182 - val_loss_2: 0.8220 - val_loss_3: 0.8011 - val_acc_ensemble: 0.7985 - val_acc_1: 0.7606 - val_acc_2: 0.7655 - val_acc_3: 0.7696\n",
      "Epoch 32/50\n",
      "100/100 - 12s - loss_1: 0.1800 - loss_2: 0.1961 - loss_3: 0.1890 - acc_ensemble: 0.8940 - acc_1: 0.8420 - acc_2: 0.8400 - acc_3: 0.8640 - val_loss_1: 0.8075 - val_loss_2: 0.8341 - val_loss_3: 0.8083 - val_acc_ensemble: 0.7954 - val_acc_1: 0.7665 - val_acc_2: 0.7579 - val_acc_3: 0.7714\n",
      "Epoch 33/50\n",
      "100/100 - 12s - loss_1: 0.1576 - loss_2: 0.1698 - loss_3: 0.1547 - acc_ensemble: 0.8900 - acc_1: 0.8660 - acc_2: 0.8600 - acc_3: 0.8620 - val_loss_1: 0.8099 - val_loss_2: 0.8020 - val_loss_3: 0.8063 - val_acc_ensemble: 0.8023 - val_acc_1: 0.7667 - val_acc_2: 0.7734 - val_acc_3: 0.7709\n",
      "Epoch 34/50\n",
      "100/100 - 12s - loss_1: 0.1182 - loss_2: 0.1498 - loss_3: 0.1428 - acc_ensemble: 0.9080 - acc_1: 0.8600 - acc_2: 0.8620 - acc_3: 0.8660 - val_loss_1: 0.8351 - val_loss_2: 0.8422 - val_loss_3: 0.8261 - val_acc_ensemble: 0.8005 - val_acc_1: 0.7655 - val_acc_2: 0.7650 - val_acc_3: 0.7680\n",
      "Epoch 35/50\n",
      "100/100 - 13s - loss_1: 0.1394 - loss_2: 0.1395 - loss_3: 0.1197 - acc_ensemble: 0.9040 - acc_1: 0.8580 - acc_2: 0.8800 - acc_3: 0.8720 - val_loss_1: 0.8340 - val_loss_2: 0.8459 - val_loss_3: 0.8407 - val_acc_ensemble: 0.8041 - val_acc_1: 0.7720 - val_acc_2: 0.7664 - val_acc_3: 0.7732\n",
      "Epoch 36/50\n",
      "100/100 - 12s - loss_1: 0.1400 - loss_2: 0.1202 - loss_3: 0.1296 - acc_ensemble: 0.9240 - acc_1: 0.8600 - acc_2: 0.8860 - acc_3: 0.8680 - val_loss_1: 0.8447 - val_loss_2: 0.8488 - val_loss_3: 0.8600 - val_acc_ensemble: 0.8040 - val_acc_1: 0.7712 - val_acc_2: 0.7718 - val_acc_3: 0.7687\n",
      "Epoch 37/50\n",
      "100/100 - 12s - loss_1: 0.1204 - loss_2: 0.1055 - loss_3: 0.0949 - acc_ensemble: 0.9240 - acc_1: 0.8860 - acc_2: 0.8680 - acc_3: 0.8720 - val_loss_1: 0.9115 - val_loss_2: 0.8780 - val_loss_3: 0.8780 - val_acc_ensemble: 0.8007 - val_acc_1: 0.7637 - val_acc_2: 0.7709 - val_acc_3: 0.7699\n",
      "Epoch 38/50\n",
      "100/100 - 12s - loss_1: 0.1133 - loss_2: 0.1005 - loss_3: 0.1338 - acc_ensemble: 0.9100 - acc_1: 0.8740 - acc_2: 0.8800 - acc_3: 0.8540 - val_loss_1: 0.8755 - val_loss_2: 0.8967 - val_loss_3: 0.9089 - val_acc_ensemble: 0.8033 - val_acc_1: 0.7711 - val_acc_2: 0.7659 - val_acc_3: 0.7617\n",
      "Epoch 39/50\n",
      "100/100 - 12s - loss_1: 0.1060 - loss_2: 0.0982 - loss_3: 0.0952 - acc_ensemble: 0.9140 - acc_1: 0.8700 - acc_2: 0.8700 - acc_3: 0.8800 - val_loss_1: 0.8972 - val_loss_2: 0.8752 - val_loss_3: 0.8683 - val_acc_ensemble: 0.8063 - val_acc_1: 0.7705 - val_acc_2: 0.7732 - val_acc_3: 0.7752\n",
      "Epoch 40/50\n",
      "100/100 - 12s - loss_1: 0.0836 - loss_2: 0.1000 - loss_3: 0.0818 - acc_ensemble: 0.9100 - acc_1: 0.8620 - acc_2: 0.8640 - acc_3: 0.8680 - val_loss_1: 0.9382 - val_loss_2: 0.9194 - val_loss_3: 0.9260 - val_acc_ensemble: 0.8002 - val_acc_1: 0.7633 - val_acc_2: 0.7671 - val_acc_3: 0.7662\n",
      "Epoch 41/50\n",
      "100/100 - 12s - loss_1: 0.0943 - loss_2: 0.1032 - loss_3: 0.0840 - acc_ensemble: 0.9220 - acc_1: 0.8680 - acc_2: 0.8640 - acc_3: 0.8520 - val_loss_1: 0.9329 - val_loss_2: 0.9291 - val_loss_3: 0.9243 - val_acc_ensemble: 0.8012 - val_acc_1: 0.7687 - val_acc_2: 0.7651 - val_acc_3: 0.7681\n",
      "Epoch 42/50\n",
      "100/100 - 12s - loss_1: 0.0817 - loss_2: 0.1105 - loss_3: 0.0953 - acc_ensemble: 0.9320 - acc_1: 0.8860 - acc_2: 0.8660 - acc_3: 0.8700 - val_loss_1: 0.9353 - val_loss_2: 0.9428 - val_loss_3: 0.9171 - val_acc_ensemble: 0.8051 - val_acc_1: 0.7740 - val_acc_2: 0.7686 - val_acc_3: 0.7696\n",
      "Epoch 43/50\n",
      "100/100 - 12s - loss_1: 0.0883 - loss_2: 0.0910 - loss_3: 0.0992 - acc_ensemble: 0.9080 - acc_1: 0.8580 - acc_2: 0.8580 - acc_3: 0.8700 - val_loss_1: 0.9363 - val_loss_2: 0.9668 - val_loss_3: 0.9509 - val_acc_ensemble: 0.8009 - val_acc_1: 0.7635 - val_acc_2: 0.7664 - val_acc_3: 0.7633\n",
      "Epoch 44/50\n",
      "100/100 - 12s - loss_1: 0.0806 - loss_2: 0.0796 - loss_3: 0.0852 - acc_ensemble: 0.9160 - acc_1: 0.8740 - acc_2: 0.8880 - acc_3: 0.8640 - val_loss_1: 0.9648 - val_loss_2: 0.9293 - val_loss_3: 0.9292 - val_acc_ensemble: 0.8070 - val_acc_1: 0.7686 - val_acc_2: 0.7749 - val_acc_3: 0.7763\n",
      "Epoch 45/50\n",
      "100/100 - 12s - loss_1: 0.0944 - loss_2: 0.0884 - loss_3: 0.0849 - acc_ensemble: 0.9120 - acc_1: 0.8680 - acc_2: 0.8880 - acc_3: 0.8640 - val_loss_1: 0.9631 - val_loss_2: 0.9696 - val_loss_3: 0.9511 - val_acc_ensemble: 0.8026 - val_acc_1: 0.7628 - val_acc_2: 0.7664 - val_acc_3: 0.7687\n",
      "Epoch 46/50\n",
      "100/100 - 12s - loss_1: 0.0738 - loss_2: 0.0792 - loss_3: 0.0652 - acc_ensemble: 0.9240 - acc_1: 0.8920 - acc_2: 0.8700 - acc_3: 0.8780 - val_loss_1: 0.9539 - val_loss_2: 1.0135 - val_loss_3: 0.9782 - val_acc_ensemble: 0.8042 - val_acc_1: 0.7741 - val_acc_2: 0.7621 - val_acc_3: 0.7713\n",
      "Epoch 47/50\n",
      "100/100 - 13s - loss_1: 0.0795 - loss_2: 0.0704 - loss_3: 0.0735 - acc_ensemble: 0.9180 - acc_1: 0.8720 - acc_2: 0.8740 - acc_3: 0.8720 - val_loss_1: 0.9750 - val_loss_2: 1.0125 - val_loss_3: 0.9791 - val_acc_ensemble: 0.8036 - val_acc_1: 0.7707 - val_acc_2: 0.7651 - val_acc_3: 0.7709\n",
      "Epoch 48/50\n",
      "100/100 - 12s - loss_1: 0.0855 - loss_2: 0.0608 - loss_3: 0.0734 - acc_ensemble: 0.9240 - acc_1: 0.8740 - acc_2: 0.8820 - acc_3: 0.8820 - val_loss_1: 0.9738 - val_loss_2: 0.9940 - val_loss_3: 0.9590 - val_acc_ensemble: 0.8087 - val_acc_1: 0.7749 - val_acc_2: 0.7740 - val_acc_3: 0.7761\n",
      "Epoch 49/50\n",
      "100/100 - 12s - loss_1: 0.0706 - loss_2: 0.0646 - loss_3: 0.0624 - acc_ensemble: 0.9240 - acc_1: 0.8740 - acc_2: 0.8860 - acc_3: 0.8640 - val_loss_1: 0.9940 - val_loss_2: 1.0084 - val_loss_3: 0.9975 - val_acc_ensemble: 0.8042 - val_acc_1: 0.7708 - val_acc_2: 0.7710 - val_acc_3: 0.7715\n",
      "Epoch 50/50\n",
      "100/100 - 12s - loss_1: 0.0674 - loss_2: 0.0786 - loss_3: 0.0741 - acc_ensemble: 0.9160 - acc_1: 0.8720 - acc_2: 0.8700 - acc_3: 0.8600 - val_loss_1: 1.0179 - val_loss_2: 1.0372 - val_loss_3: 1.0665 - val_acc_ensemble: 0.8025 - val_acc_1: 0.7688 - val_acc_2: 0.7659 - val_acc_3: 0.7595\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B3/S0.75/model_3\n",
      "i   Layer name                      Output shape                     Num param  Inbound            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "0   conv2d_1_1 (Conv2D)             [None,32,32,24] [None,32,32,8]   1344       input              \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "1   bn_1_1 (BatchNormalization)     [None,32,32,24] [None,32,32,8]   96         conv2d_1_1         \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "2   relu_1_1 (Activation)           [None,32,32,24] [None,32,32,8]   0          bn_1_1             \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "3   conv2d_1_2 (Conv2D)             [None,32,32,24] [None,32,32,8]   17424      relu_1_1           \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "4   bn_1_2 (BatchNormalization)     [None,32,32,24] [None,32,32,8]   96         conv2d_1_2         \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "5   relu_1_2 (Activation)           [None,32,32,24] [None,32,32,8]   0          bn_1_2             \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "6   avg_pool2d_1 (AveragePooling2D  [None,16,16,24] [None,16,16,8]   0          relu_1_2           \n",
      "                                    [None,16,16,24] [None,16,16,8]                                 \n",
      "                                    [None,16,16,24] [None,16,16,8]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "7   conv2d_2_1 (Conv2D)             [None,16,16,48] [None,16,16,16]  34848      avg_pool2d_1       \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "8   bn_2_1 (BatchNormalization)     [None,16,16,48] [None,16,16,16]  192        conv2d_2_1         \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "9   relu_2_1 (Activation)           [None,16,16,48] [None,16,16,16]  0          bn_2_1             \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "10  conv2d_2_2 (Conv2D)             [None,16,16,48] [None,16,16,16]  69408      relu_2_1           \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "11  bn_2_2 (BatchNormalization)     [None,16,16,48] [None,16,16,16]  192        conv2d_2_2         \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "12  relu_2_2 (Activation)           [None,16,16,48] [None,16,16,16]  0          bn_2_2             \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "13  avg_pool2d_2 (AveragePooling2D  [None,8,8,48] [None,8,8,16]      0          relu_2_2           \n",
      "                                    [None,8,8,48] [None,8,8,16]                                    \n",
      "                                    [None,8,8,48] [None,8,8,16]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "14  conv2d_3_1 (Conv2D)             [None,8,8,96] [None,8,8,32]      138816     avg_pool2d_2       \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "15  bn_3_1 (BatchNormalization)     [None,8,8,96] [None,8,8,32]      384        conv2d_3_1         \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "16  relu_3_1 (Activation)           [None,8,8,96] [None,8,8,32]      0          bn_3_1             \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "17  conv2d_3_2 (Conv2D)             [None,8,8,96] [None,8,8,32]      277056     relu_3_1           \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "18  bn_3_2 (BatchNormalization)     [None,8,8,96] [None,8,8,32]      384        conv2d_3_2         \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "19  relu_3_2 (Activation)           [None,8,8,96] [None,8,8,32]      0          bn_3_2             \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "20  global_avg_pool2d (GlobalAvera  [None,96] [None,32]              0          relu_3_2           \n",
      "                                    [None,96] [None,32]                                            \n",
      "                                    [None,96] [None,32]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "21  fc1 (Dense)                     [None,96] [None,32]              31296      global_avg_pool2d  \n",
      "                                    [None,96] [None,32]                                            \n",
      "                                    [None,96] [None,32]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "22  bn_fc1 (BatchNormalization)     [None,96] [None,32]              384        fc1                \n",
      "                                    [None,96] [None,32]                                            \n",
      "                                    [None,96] [None,32]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "23  relu_fc1 (Activation)           [None,96] [None,32]              0          bn_fc1             \n",
      "                                    [None,96] [None,32]                                            \n",
      "                                    [None,96] [None,32]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "24  output (Dense)                  [None,10]                        2542       relu_fc1           \n",
      "                                    [None,10]                                                      \n",
      "                                    [None,10]                                                      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "Total parameters: 574462\n",
      "50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 - 20s - loss_1: 1.7838 - loss_2: 1.8030 - loss_3: 1.8347 - acc_ensemble: 0.4780 - acc_1: 0.4240 - acc_2: 0.4540 - acc_3: 0.4620 - val_loss_1: 1.5431 - val_loss_2: 1.5057 - val_loss_3: 1.5433 - val_acc_ensemble: 0.4689 - val_acc_1: 0.4341 - val_acc_2: 0.4418 - val_acc_3: 0.4311\n",
      "Epoch 2/50\n",
      "100/100 - 12s - loss_1: 1.4608 - loss_2: 1.4696 - loss_3: 1.4442 - acc_ensemble: 0.5640 - acc_1: 0.5400 - acc_2: 0.5260 - acc_3: 0.5160 - val_loss_1: 1.3569 - val_loss_2: 1.3174 - val_loss_3: 1.3550 - val_acc_ensemble: 0.5510 - val_acc_1: 0.4998 - val_acc_2: 0.5240 - val_acc_3: 0.5097\n",
      "Epoch 3/50\n",
      "100/100 - 12s - loss_1: 1.2676 - loss_2: 1.2496 - loss_3: 1.2808 - acc_ensemble: 0.6020 - acc_1: 0.5860 - acc_2: 0.6080 - acc_3: 0.5420 - val_loss_1: 1.1751 - val_loss_2: 1.1670 - val_loss_3: 1.2206 - val_acc_ensemble: 0.5945 - val_acc_1: 0.5756 - val_acc_2: 0.5698 - val_acc_3: 0.5518\n",
      "Epoch 4/50\n",
      "100/100 - 12s - loss_1: 1.1292 - loss_2: 1.1028 - loss_3: 1.1332 - acc_ensemble: 0.6600 - acc_1: 0.6100 - acc_2: 0.6520 - acc_3: 0.6140 - val_loss_1: 1.1146 - val_loss_2: 1.0713 - val_loss_3: 1.1006 - val_acc_ensemble: 0.6313 - val_acc_1: 0.5973 - val_acc_2: 0.6150 - val_acc_3: 0.6071\n",
      "Epoch 5/50\n",
      "100/100 - 12s - loss_1: 1.0172 - loss_2: 1.0034 - loss_3: 1.0297 - acc_ensemble: 0.6980 - acc_1: 0.6600 - acc_2: 0.6980 - acc_3: 0.6480 - val_loss_1: 1.0180 - val_loss_2: 0.9941 - val_loss_3: 0.9868 - val_acc_ensemble: 0.6703 - val_acc_1: 0.6273 - val_acc_2: 0.6450 - val_acc_3: 0.6502\n",
      "Epoch 6/50\n",
      "100/100 - 12s - loss_1: 0.9559 - loss_2: 0.9521 - loss_3: 0.9767 - acc_ensemble: 0.7200 - acc_1: 0.6860 - acc_2: 0.7220 - acc_3: 0.6740 - val_loss_1: 0.9623 - val_loss_2: 0.9478 - val_loss_3: 0.9476 - val_acc_ensemble: 0.6881 - val_acc_1: 0.6549 - val_acc_2: 0.6622 - val_acc_3: 0.6609\n",
      "Epoch 7/50\n",
      "100/100 - 12s - loss_1: 0.8923 - loss_2: 0.8643 - loss_3: 0.8835 - acc_ensemble: 0.7260 - acc_1: 0.6940 - acc_2: 0.7000 - acc_3: 0.7060 - val_loss_1: 0.9093 - val_loss_2: 0.9154 - val_loss_3: 0.9218 - val_acc_ensemble: 0.7043 - val_acc_1: 0.6765 - val_acc_2: 0.6759 - val_acc_3: 0.6762\n",
      "Epoch 8/50\n",
      "100/100 - 12s - loss_1: 0.8199 - loss_2: 0.7966 - loss_3: 0.8151 - acc_ensemble: 0.7540 - acc_1: 0.7160 - acc_2: 0.7020 - acc_3: 0.7060 - val_loss_1: 0.8683 - val_loss_2: 0.8725 - val_loss_3: 0.8753 - val_acc_ensemble: 0.7162 - val_acc_1: 0.6931 - val_acc_2: 0.6893 - val_acc_3: 0.6904\n",
      "Epoch 9/50\n",
      "100/100 - 12s - loss_1: 0.7682 - loss_2: 0.7682 - loss_3: 0.7855 - acc_ensemble: 0.7660 - acc_1: 0.7260 - acc_2: 0.7240 - acc_3: 0.7500 - val_loss_1: 0.8319 - val_loss_2: 0.8788 - val_loss_3: 0.8384 - val_acc_ensemble: 0.7270 - val_acc_1: 0.7021 - val_acc_2: 0.6878 - val_acc_3: 0.7027\n",
      "Epoch 10/50\n",
      "100/100 - 12s - loss_1: 0.7488 - loss_2: 0.7095 - loss_3: 0.7372 - acc_ensemble: 0.7540 - acc_1: 0.7440 - acc_2: 0.7500 - acc_3: 0.7480 - val_loss_1: 0.8267 - val_loss_2: 0.8292 - val_loss_3: 0.8237 - val_acc_ensemble: 0.7354 - val_acc_1: 0.7067 - val_acc_2: 0.7062 - val_acc_3: 0.7060\n",
      "Epoch 11/50\n",
      "100/100 - 13s - loss_1: 0.6710 - loss_2: 0.6601 - loss_3: 0.6826 - acc_ensemble: 0.7700 - acc_1: 0.7400 - acc_2: 0.7460 - acc_3: 0.7580 - val_loss_1: 0.8111 - val_loss_2: 0.8035 - val_loss_3: 0.8031 - val_acc_ensemble: 0.7399 - val_acc_1: 0.7156 - val_acc_2: 0.7149 - val_acc_3: 0.7144\n",
      "Epoch 12/50\n",
      "100/100 - 12s - loss_1: 0.6151 - loss_2: 0.6335 - loss_3: 0.6454 - acc_ensemble: 0.7980 - acc_1: 0.7600 - acc_2: 0.7800 - acc_3: 0.7640 - val_loss_1: 0.7838 - val_loss_2: 0.7752 - val_loss_3: 0.7776 - val_acc_ensemble: 0.7553 - val_acc_1: 0.7186 - val_acc_2: 0.7278 - val_acc_3: 0.7281\n",
      "Epoch 13/50\n",
      "100/100 - 12s - loss_1: 0.6086 - loss_2: 0.6104 - loss_3: 0.5860 - acc_ensemble: 0.7980 - acc_1: 0.7600 - acc_2: 0.7640 - acc_3: 0.7600 - val_loss_1: 0.7818 - val_loss_2: 0.7735 - val_loss_3: 0.8019 - val_acc_ensemble: 0.7503 - val_acc_1: 0.7268 - val_acc_2: 0.7343 - val_acc_3: 0.7207\n",
      "Epoch 14/50\n",
      "100/100 - 12s - loss_1: 0.5708 - loss_2: 0.5505 - loss_3: 0.5650 - acc_ensemble: 0.8060 - acc_1: 0.7640 - acc_2: 0.7880 - acc_3: 0.7820 - val_loss_1: 0.7769 - val_loss_2: 0.8011 - val_loss_3: 0.7860 - val_acc_ensemble: 0.7497 - val_acc_1: 0.7289 - val_acc_2: 0.7253 - val_acc_3: 0.7276\n",
      "Epoch 15/50\n",
      "100/100 - 12s - loss_1: 0.5407 - loss_2: 0.5328 - loss_3: 0.5238 - acc_ensemble: 0.8020 - acc_1: 0.7700 - acc_2: 0.7620 - acc_3: 0.7880 - val_loss_1: 0.7668 - val_loss_2: 0.7514 - val_loss_3: 0.7662 - val_acc_ensemble: 0.7664 - val_acc_1: 0.7372 - val_acc_2: 0.7404 - val_acc_3: 0.7351\n",
      "Epoch 16/50\n",
      "100/100 - 12s - loss_1: 0.5086 - loss_2: 0.4856 - loss_3: 0.5228 - acc_ensemble: 0.8320 - acc_1: 0.7940 - acc_2: 0.8000 - acc_3: 0.8100 - val_loss_1: 0.7483 - val_loss_2: 0.7347 - val_loss_3: 0.7407 - val_acc_ensemble: 0.7700 - val_acc_1: 0.7426 - val_acc_2: 0.7497 - val_acc_3: 0.7425\n",
      "Epoch 17/50\n",
      "100/100 - 12s - loss_1: 0.4692 - loss_2: 0.4472 - loss_3: 0.4748 - acc_ensemble: 0.8460 - acc_1: 0.8040 - acc_2: 0.8080 - acc_3: 0.8240 - val_loss_1: 0.7463 - val_loss_2: 0.7293 - val_loss_3: 0.7421 - val_acc_ensemble: 0.7747 - val_acc_1: 0.7496 - val_acc_2: 0.7575 - val_acc_3: 0.7480\n",
      "Epoch 18/50\n",
      "100/100 - 12s - loss_1: 0.4462 - loss_2: 0.4576 - loss_3: 0.4589 - acc_ensemble: 0.8460 - acc_1: 0.8100 - acc_2: 0.7880 - acc_3: 0.8160 - val_loss_1: 0.7695 - val_loss_2: 0.7335 - val_loss_3: 0.7428 - val_acc_ensemble: 0.7767 - val_acc_1: 0.7420 - val_acc_2: 0.7511 - val_acc_3: 0.7463\n",
      "Epoch 19/50\n",
      "100/100 - 12s - loss_1: 0.4018 - loss_2: 0.4204 - loss_3: 0.4273 - acc_ensemble: 0.8540 - acc_1: 0.8340 - acc_2: 0.8160 - acc_3: 0.8240 - val_loss_1: 0.7306 - val_loss_2: 0.7329 - val_loss_3: 0.7488 - val_acc_ensemble: 0.7783 - val_acc_1: 0.7539 - val_acc_2: 0.7531 - val_acc_3: 0.7492\n",
      "Epoch 20/50\n",
      "100/100 - 12s - loss_1: 0.4093 - loss_2: 0.4129 - loss_3: 0.4101 - acc_ensemble: 0.8500 - acc_1: 0.8080 - acc_2: 0.8240 - acc_3: 0.8280 - val_loss_1: 0.7547 - val_loss_2: 0.7646 - val_loss_3: 0.7431 - val_acc_ensemble: 0.7792 - val_acc_1: 0.7526 - val_acc_2: 0.7493 - val_acc_3: 0.7556\n",
      "Epoch 21/50\n",
      "100/100 - 12s - loss_1: 0.3727 - loss_2: 0.3696 - loss_3: 0.3880 - acc_ensemble: 0.8540 - acc_1: 0.8100 - acc_2: 0.8260 - acc_3: 0.8460 - val_loss_1: 0.7501 - val_loss_2: 0.7363 - val_loss_3: 0.7578 - val_acc_ensemble: 0.7853 - val_acc_1: 0.7525 - val_acc_2: 0.7598 - val_acc_3: 0.7501\n",
      "Epoch 22/50\n",
      "100/100 - 12s - loss_1: 0.3040 - loss_2: 0.3282 - loss_3: 0.3367 - acc_ensemble: 0.8440 - acc_1: 0.8140 - acc_2: 0.8060 - acc_3: 0.8400 - val_loss_1: 0.7492 - val_loss_2: 0.7421 - val_loss_3: 0.7445 - val_acc_ensemble: 0.7881 - val_acc_1: 0.7609 - val_acc_2: 0.7579 - val_acc_3: 0.7576\n",
      "Epoch 23/50\n",
      "100/100 - 12s - loss_1: 0.3123 - loss_2: 0.3146 - loss_3: 0.3444 - acc_ensemble: 0.8660 - acc_1: 0.8340 - acc_2: 0.8340 - acc_3: 0.8260 - val_loss_1: 0.7437 - val_loss_2: 0.7191 - val_loss_3: 0.7373 - val_acc_ensemble: 0.7890 - val_acc_1: 0.7578 - val_acc_2: 0.7658 - val_acc_3: 0.7562\n",
      "Epoch 24/50\n",
      "100/100 - 12s - loss_1: 0.2712 - loss_2: 0.2782 - loss_3: 0.3035 - acc_ensemble: 0.8840 - acc_1: 0.8280 - acc_2: 0.8460 - acc_3: 0.8580 - val_loss_1: 0.7687 - val_loss_2: 0.7373 - val_loss_3: 0.7471 - val_acc_ensemble: 0.7943 - val_acc_1: 0.7638 - val_acc_2: 0.7696 - val_acc_3: 0.7646\n",
      "Epoch 25/50\n",
      "100/100 - 12s - loss_1: 0.2674 - loss_2: 0.2783 - loss_3: 0.2748 - acc_ensemble: 0.8760 - acc_1: 0.8280 - acc_2: 0.8360 - acc_3: 0.8560 - val_loss_1: 0.7759 - val_loss_2: 0.7757 - val_loss_3: 0.7471 - val_acc_ensemble: 0.7902 - val_acc_1: 0.7632 - val_acc_2: 0.7565 - val_acc_3: 0.7672\n",
      "Epoch 26/50\n",
      "100/100 - 12s - loss_1: 0.2790 - loss_2: 0.2758 - loss_3: 0.2554 - acc_ensemble: 0.8760 - acc_1: 0.8580 - acc_2: 0.8400 - acc_3: 0.8500 - val_loss_1: 0.7766 - val_loss_2: 0.7705 - val_loss_3: 0.7593 - val_acc_ensemble: 0.7959 - val_acc_1: 0.7628 - val_acc_2: 0.7632 - val_acc_3: 0.7649\n",
      "Epoch 27/50\n",
      "100/100 - 12s - loss_1: 0.2259 - loss_2: 0.2619 - loss_3: 0.2452 - acc_ensemble: 0.8920 - acc_1: 0.8360 - acc_2: 0.8380 - acc_3: 0.8460 - val_loss_1: 0.7873 - val_loss_2: 0.7910 - val_loss_3: 0.8130 - val_acc_ensemble: 0.7911 - val_acc_1: 0.7609 - val_acc_2: 0.7607 - val_acc_3: 0.7541\n",
      "Epoch 28/50\n",
      "100/100 - 12s - loss_1: 0.2129 - loss_2: 0.2330 - loss_3: 0.2303 - acc_ensemble: 0.9040 - acc_1: 0.8500 - acc_2: 0.8620 - acc_3: 0.8600 - val_loss_1: 0.8108 - val_loss_2: 0.8039 - val_loss_3: 0.7914 - val_acc_ensemble: 0.7968 - val_acc_1: 0.7633 - val_acc_2: 0.7649 - val_acc_3: 0.7620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50\n",
      "100/100 - 12s - loss_1: 0.1912 - loss_2: 0.2071 - loss_3: 0.1937 - acc_ensemble: 0.8900 - acc_1: 0.8600 - acc_2: 0.8660 - acc_3: 0.8640 - val_loss_1: 0.8206 - val_loss_2: 0.7994 - val_loss_3: 0.7910 - val_acc_ensemble: 0.7965 - val_acc_1: 0.7625 - val_acc_2: 0.7687 - val_acc_3: 0.7674\n",
      "Epoch 30/50\n",
      "100/100 - 12s - loss_1: 0.1963 - loss_2: 0.1969 - loss_3: 0.2120 - acc_ensemble: 0.9060 - acc_1: 0.8540 - acc_2: 0.8700 - acc_3: 0.8540 - val_loss_1: 0.8515 - val_loss_2: 0.7995 - val_loss_3: 0.8389 - val_acc_ensemble: 0.7940 - val_acc_1: 0.7605 - val_acc_2: 0.7697 - val_acc_3: 0.7550\n",
      "Epoch 31/50\n",
      "100/100 - 12s - loss_1: 0.1869 - loss_2: 0.1895 - loss_3: 0.1917 - acc_ensemble: 0.9060 - acc_1: 0.8560 - acc_2: 0.8600 - acc_3: 0.8560 - val_loss_1: 0.8492 - val_loss_2: 0.8433 - val_loss_3: 0.8316 - val_acc_ensemble: 0.7926 - val_acc_1: 0.7636 - val_acc_2: 0.7573 - val_acc_3: 0.7582\n",
      "Epoch 32/50\n",
      "100/100 - 12s - loss_1: 0.1796 - loss_2: 0.1732 - loss_3: 0.1795 - acc_ensemble: 0.9080 - acc_1: 0.8760 - acc_2: 0.8680 - acc_3: 0.8420 - val_loss_1: 0.8606 - val_loss_2: 0.8218 - val_loss_3: 0.8414 - val_acc_ensemble: 0.7911 - val_acc_1: 0.7550 - val_acc_2: 0.7633 - val_acc_3: 0.7613\n",
      "Epoch 33/50\n",
      "100/100 - 12s - loss_1: 0.1625 - loss_2: 0.1829 - loss_3: 0.1829 - acc_ensemble: 0.9100 - acc_1: 0.8600 - acc_2: 0.8660 - acc_3: 0.8500 - val_loss_1: 0.8488 - val_loss_2: 0.8313 - val_loss_3: 0.8370 - val_acc_ensemble: 0.7988 - val_acc_1: 0.7654 - val_acc_2: 0.7639 - val_acc_3: 0.7616\n",
      "Epoch 34/50\n",
      "100/100 - 12s - loss_1: 0.1458 - loss_2: 0.1403 - loss_3: 0.1452 - acc_ensemble: 0.9180 - acc_1: 0.8880 - acc_2: 0.8820 - acc_3: 0.8840 - val_loss_1: 0.8506 - val_loss_2: 0.8252 - val_loss_3: 0.8482 - val_acc_ensemble: 0.8004 - val_acc_1: 0.7682 - val_acc_2: 0.7702 - val_acc_3: 0.7661\n",
      "Epoch 35/50\n",
      "100/100 - 13s - loss_1: 0.1462 - loss_2: 0.1433 - loss_3: 0.1489 - acc_ensemble: 0.9080 - acc_1: 0.8800 - acc_2: 0.8640 - acc_3: 0.8700 - val_loss_1: 0.9139 - val_loss_2: 0.8673 - val_loss_3: 0.8765 - val_acc_ensemble: 0.7926 - val_acc_1: 0.7598 - val_acc_2: 0.7641 - val_acc_3: 0.7661\n",
      "Epoch 36/50\n",
      "100/100 - 12s - loss_1: 0.1458 - loss_2: 0.1399 - loss_3: 0.1354 - acc_ensemble: 0.9040 - acc_1: 0.8700 - acc_2: 0.8840 - acc_3: 0.8600 - val_loss_1: 0.8666 - val_loss_2: 0.8545 - val_loss_3: 0.8601 - val_acc_ensemble: 0.7959 - val_acc_1: 0.7661 - val_acc_2: 0.7671 - val_acc_3: 0.7675\n",
      "Epoch 37/50\n",
      "100/100 - 12s - loss_1: 0.1177 - loss_2: 0.1174 - loss_3: 0.1128 - acc_ensemble: 0.9180 - acc_1: 0.8740 - acc_2: 0.8600 - acc_3: 0.8940 - val_loss_1: 0.8883 - val_loss_2: 0.8627 - val_loss_3: 0.8708 - val_acc_ensemble: 0.7998 - val_acc_1: 0.7657 - val_acc_2: 0.7662 - val_acc_3: 0.7650\n",
      "Epoch 38/50\n",
      "100/100 - 12s - loss_1: 0.1158 - loss_2: 0.1345 - loss_3: 0.1183 - acc_ensemble: 0.9020 - acc_1: 0.8720 - acc_2: 0.8520 - acc_3: 0.8720 - val_loss_1: 0.8849 - val_loss_2: 0.8813 - val_loss_3: 0.8862 - val_acc_ensemble: 0.7999 - val_acc_1: 0.7674 - val_acc_2: 0.7650 - val_acc_3: 0.7644\n",
      "Epoch 39/50\n",
      "100/100 - 12s - loss_1: 0.0979 - loss_2: 0.1141 - loss_3: 0.1055 - acc_ensemble: 0.9080 - acc_1: 0.8600 - acc_2: 0.8780 - acc_3: 0.8860 - val_loss_1: 0.9023 - val_loss_2: 0.8508 - val_loss_3: 0.8578 - val_acc_ensemble: 0.8091 - val_acc_1: 0.7684 - val_acc_2: 0.7802 - val_acc_3: 0.7766\n",
      "Epoch 40/50\n",
      "100/100 - 12s - loss_1: 0.0914 - loss_2: 0.0977 - loss_3: 0.0944 - acc_ensemble: 0.9100 - acc_1: 0.8680 - acc_2: 0.8740 - acc_3: 0.8860 - val_loss_1: 0.9214 - val_loss_2: 0.9200 - val_loss_3: 0.9148 - val_acc_ensemble: 0.8010 - val_acc_1: 0.7694 - val_acc_2: 0.7659 - val_acc_3: 0.7664\n",
      "Epoch 41/50\n",
      "100/100 - 12s - loss_1: 0.1161 - loss_2: 0.1277 - loss_3: 0.1139 - acc_ensemble: 0.9160 - acc_1: 0.8760 - acc_2: 0.8740 - acc_3: 0.8720 - val_loss_1: 0.9960 - val_loss_2: 0.9449 - val_loss_3: 0.9583 - val_acc_ensemble: 0.7954 - val_acc_1: 0.7612 - val_acc_2: 0.7628 - val_acc_3: 0.7612\n",
      "Epoch 42/50\n",
      "100/100 - 12s - loss_1: 0.0920 - loss_2: 0.1023 - loss_3: 0.1008 - acc_ensemble: 0.9160 - acc_1: 0.8780 - acc_2: 0.8740 - acc_3: 0.8800 - val_loss_1: 0.9394 - val_loss_2: 0.9493 - val_loss_3: 0.9304 - val_acc_ensemble: 0.8052 - val_acc_1: 0.7666 - val_acc_2: 0.7641 - val_acc_3: 0.7685\n",
      "Epoch 43/50\n",
      "100/100 - 12s - loss_1: 0.0727 - loss_2: 0.0882 - loss_3: 0.0758 - acc_ensemble: 0.9100 - acc_1: 0.8720 - acc_2: 0.8760 - acc_3: 0.8820 - val_loss_1: 0.9512 - val_loss_2: 0.9489 - val_loss_3: 0.9310 - val_acc_ensemble: 0.8053 - val_acc_1: 0.7716 - val_acc_2: 0.7690 - val_acc_3: 0.7725\n",
      "Epoch 44/50\n",
      "100/100 - 12s - loss_1: 0.0830 - loss_2: 0.0779 - loss_3: 0.0752 - acc_ensemble: 0.9400 - acc_1: 0.8820 - acc_2: 0.8800 - acc_3: 0.8820 - val_loss_1: 0.9658 - val_loss_2: 0.9427 - val_loss_3: 0.9515 - val_acc_ensemble: 0.8074 - val_acc_1: 0.7698 - val_acc_2: 0.7680 - val_acc_3: 0.7693\n",
      "Epoch 45/50\n",
      "100/100 - 12s - loss_1: 0.0858 - loss_2: 0.0605 - loss_3: 0.0517 - acc_ensemble: 0.9360 - acc_1: 0.8660 - acc_2: 0.8840 - acc_3: 0.8980 - val_loss_1: 0.9989 - val_loss_2: 0.9647 - val_loss_3: 0.9269 - val_acc_ensemble: 0.8034 - val_acc_1: 0.7686 - val_acc_2: 0.7685 - val_acc_3: 0.7762\n",
      "Epoch 46/50\n",
      "100/100 - 12s - loss_1: 0.0701 - loss_2: 0.0700 - loss_3: 0.0614 - acc_ensemble: 0.9200 - acc_1: 0.8620 - acc_2: 0.8980 - acc_3: 0.8840 - val_loss_1: 0.9887 - val_loss_2: 0.9661 - val_loss_3: 1.0026 - val_acc_ensemble: 0.7999 - val_acc_1: 0.7728 - val_acc_2: 0.7717 - val_acc_3: 0.7641\n",
      "Epoch 47/50\n",
      "100/100 - 12s - loss_1: 0.0786 - loss_2: 0.0744 - loss_3: 0.0972 - acc_ensemble: 0.9180 - acc_1: 0.8800 - acc_2: 0.8580 - acc_3: 0.8720 - val_loss_1: 1.0073 - val_loss_2: 0.9626 - val_loss_3: 1.0393 - val_acc_ensemble: 0.8015 - val_acc_1: 0.7674 - val_acc_2: 0.7714 - val_acc_3: 0.7661\n",
      "Epoch 48/50\n",
      "100/100 - 12s - loss_1: 0.0782 - loss_2: 0.0738 - loss_3: 0.0897 - acc_ensemble: 0.9300 - acc_1: 0.8700 - acc_2: 0.8700 - acc_3: 0.8760 - val_loss_1: 1.0184 - val_loss_2: 0.9882 - val_loss_3: 1.0105 - val_acc_ensemble: 0.8012 - val_acc_1: 0.7653 - val_acc_2: 0.7662 - val_acc_3: 0.7639\n",
      "Epoch 49/50\n",
      "100/100 - 12s - loss_1: 0.0585 - loss_2: 0.0692 - loss_3: 0.0628 - acc_ensemble: 0.9300 - acc_1: 0.8680 - acc_2: 0.8960 - acc_3: 0.8980 - val_loss_1: 1.0052 - val_loss_2: 1.0265 - val_loss_3: 0.9750 - val_acc_ensemble: 0.8056 - val_acc_1: 0.7779 - val_acc_2: 0.7703 - val_acc_3: 0.7707\n",
      "Epoch 50/50\n",
      "100/100 - 12s - loss_1: 0.0660 - loss_2: 0.0892 - loss_3: 0.0666 - acc_ensemble: 0.9260 - acc_1: 0.8560 - acc_2: 0.8720 - acc_3: 0.8740 - val_loss_1: 1.0420 - val_loss_2: 1.0327 - val_loss_3: 1.0203 - val_acc_ensemble: 0.8000 - val_acc_1: 0.7687 - val_acc_2: 0.7642 - val_acc_3: 0.7637\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B3/S0.75/model_4\n",
      "i   Layer name                      Output shape                     Num param  Inbound            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "0   conv2d_1_1 (Conv2D)             [None,32,32,24] [None,32,32,8]   1344       input              \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "1   bn_1_1 (BatchNormalization)     [None,32,32,24] [None,32,32,8]   96         conv2d_1_1         \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "2   relu_1_1 (Activation)           [None,32,32,24] [None,32,32,8]   0          bn_1_1             \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "3   conv2d_1_2 (Conv2D)             [None,32,32,24] [None,32,32,8]   17424      relu_1_1           \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "4   bn_1_2 (BatchNormalization)     [None,32,32,24] [None,32,32,8]   96         conv2d_1_2         \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "5   relu_1_2 (Activation)           [None,32,32,24] [None,32,32,8]   0          bn_1_2             \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "                                    [None,32,32,24] [None,32,32,8]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "6   avg_pool2d_1 (AveragePooling2D  [None,16,16,24] [None,16,16,8]   0          relu_1_2           \n",
      "                                    [None,16,16,24] [None,16,16,8]                                 \n",
      "                                    [None,16,16,24] [None,16,16,8]                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "7   conv2d_2_1 (Conv2D)             [None,16,16,48] [None,16,16,16]  34848      avg_pool2d_1       \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "8   bn_2_1 (BatchNormalization)     [None,16,16,48] [None,16,16,16]  192        conv2d_2_1         \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "9   relu_2_1 (Activation)           [None,16,16,48] [None,16,16,16]  0          bn_2_1             \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "10  conv2d_2_2 (Conv2D)             [None,16,16,48] [None,16,16,16]  69408      relu_2_1           \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "11  bn_2_2 (BatchNormalization)     [None,16,16,48] [None,16,16,16]  192        conv2d_2_2         \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "12  relu_2_2 (Activation)           [None,16,16,48] [None,16,16,16]  0          bn_2_2             \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "                                    [None,16,16,48] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "13  avg_pool2d_2 (AveragePooling2D  [None,8,8,48] [None,8,8,16]      0          relu_2_2           \n",
      "                                    [None,8,8,48] [None,8,8,16]                                    \n",
      "                                    [None,8,8,48] [None,8,8,16]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "14  conv2d_3_1 (Conv2D)             [None,8,8,96] [None,8,8,32]      138816     avg_pool2d_2       \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "15  bn_3_1 (BatchNormalization)     [None,8,8,96] [None,8,8,32]      384        conv2d_3_1         \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "16  relu_3_1 (Activation)           [None,8,8,96] [None,8,8,32]      0          bn_3_1             \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "17  conv2d_3_2 (Conv2D)             [None,8,8,96] [None,8,8,32]      277056     relu_3_1           \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "18  bn_3_2 (BatchNormalization)     [None,8,8,96] [None,8,8,32]      384        conv2d_3_2         \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "19  relu_3_2 (Activation)           [None,8,8,96] [None,8,8,32]      0          bn_3_2             \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "                                    [None,8,8,96] [None,8,8,32]                                    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "20  global_avg_pool2d (GlobalAvera  [None,96] [None,32]              0          relu_3_2           \n",
      "                                    [None,96] [None,32]                                            \n",
      "                                    [None,96] [None,32]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "21  fc1 (Dense)                     [None,96] [None,32]              31296      global_avg_pool2d  \n",
      "                                    [None,96] [None,32]                                            \n",
      "                                    [None,96] [None,32]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "22  bn_fc1 (BatchNormalization)     [None,96] [None,32]              384        fc1                \n",
      "                                    [None,96] [None,32]                                            \n",
      "                                    [None,96] [None,32]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "23  relu_fc1 (Activation)           [None,96] [None,32]              0          bn_fc1             \n",
      "                                    [None,96] [None,32]                                            \n",
      "                                    [None,96] [None,32]                                            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "24  output (Dense)                  [None,10]                        2542       relu_fc1           \n",
      "                                    [None,10]                                                      \n",
      "                                    [None,10]                                                      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "Total parameters: 574462\n",
      "50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 - 20s - loss_1: 1.7852 - loss_2: 1.7832 - loss_3: 1.7829 - acc_ensemble: 0.5040 - acc_1: 0.4820 - acc_2: 0.4820 - acc_3: 0.4540 - val_loss_1: 1.4932 - val_loss_2: 1.5271 - val_loss_3: 1.5562 - val_acc_ensemble: 0.4717 - val_acc_1: 0.4540 - val_acc_2: 0.4420 - val_acc_3: 0.4276\n",
      "Epoch 2/50\n",
      "100/100 - 12s - loss_1: 1.4068 - loss_2: 1.4173 - loss_3: 1.4245 - acc_ensemble: 0.5540 - acc_1: 0.5360 - acc_2: 0.5100 - acc_3: 0.5260 - val_loss_1: 1.2886 - val_loss_2: 1.2795 - val_loss_3: 1.3168 - val_acc_ensemble: 0.5618 - val_acc_1: 0.5222 - val_acc_2: 0.5328 - val_acc_3: 0.5187\n",
      "Epoch 3/50\n",
      "100/100 - 13s - loss_1: 1.2265 - loss_2: 1.2235 - loss_3: 1.2153 - acc_ensemble: 0.6240 - acc_1: 0.5960 - acc_2: 0.5600 - acc_3: 0.5700 - val_loss_1: 1.1466 - val_loss_2: 1.1780 - val_loss_3: 1.1580 - val_acc_ensemble: 0.6137 - val_acc_1: 0.5860 - val_acc_2: 0.5723 - val_acc_3: 0.5815\n",
      "Epoch 4/50\n",
      "100/100 - 12s - loss_1: 1.0941 - loss_2: 1.1060 - loss_3: 1.1068 - acc_ensemble: 0.6720 - acc_1: 0.6420 - acc_2: 0.6060 - acc_3: 0.6240 - val_loss_1: 1.0952 - val_loss_2: 1.1133 - val_loss_3: 1.0791 - val_acc_ensemble: 0.6295 - val_acc_1: 0.6005 - val_acc_2: 0.6034 - val_acc_3: 0.6134\n",
      "Epoch 5/50\n",
      "100/100 - 12s - loss_1: 1.0238 - loss_2: 1.0358 - loss_3: 1.0166 - acc_ensemble: 0.6820 - acc_1: 0.6480 - acc_2: 0.6600 - acc_3: 0.6480 - val_loss_1: 1.0058 - val_loss_2: 0.9989 - val_loss_3: 1.0362 - val_acc_ensemble: 0.6632 - val_acc_1: 0.6414 - val_acc_2: 0.6387 - val_acc_3: 0.6309\n",
      "Epoch 6/50\n",
      "100/100 - 12s - loss_1: 0.9407 - loss_2: 0.9494 - loss_3: 0.9829 - acc_ensemble: 0.6960 - acc_1: 0.6420 - acc_2: 0.6760 - acc_3: 0.6580 - val_loss_1: 0.9793 - val_loss_2: 0.9745 - val_loss_3: 0.9738 - val_acc_ensemble: 0.6776 - val_acc_1: 0.6454 - val_acc_2: 0.6468 - val_acc_3: 0.6494\n",
      "Epoch 7/50\n",
      "100/100 - 12s - loss_1: 0.8728 - loss_2: 0.8717 - loss_3: 0.8972 - acc_ensemble: 0.7540 - acc_1: 0.7000 - acc_2: 0.7140 - acc_3: 0.7140 - val_loss_1: 0.8883 - val_loss_2: 0.9167 - val_loss_3: 0.9057 - val_acc_ensemble: 0.7002 - val_acc_1: 0.6833 - val_acc_2: 0.6784 - val_acc_3: 0.6718\n",
      "Epoch 8/50\n",
      "100/100 - 12s - loss_1: 0.8018 - loss_2: 0.8078 - loss_3: 0.8326 - acc_ensemble: 0.7400 - acc_1: 0.7000 - acc_2: 0.7240 - acc_3: 0.6980 - val_loss_1: 0.8521 - val_loss_2: 0.8909 - val_loss_3: 0.8927 - val_acc_ensemble: 0.7164 - val_acc_1: 0.6971 - val_acc_2: 0.6843 - val_acc_3: 0.6820\n",
      "Epoch 9/50\n",
      "100/100 - 12s - loss_1: 0.7535 - loss_2: 0.7606 - loss_3: 0.7593 - acc_ensemble: 0.7540 - acc_1: 0.7180 - acc_2: 0.7080 - acc_3: 0.7140 - val_loss_1: 0.8669 - val_loss_2: 0.8684 - val_loss_3: 0.8590 - val_acc_ensemble: 0.7179 - val_acc_1: 0.6913 - val_acc_2: 0.6914 - val_acc_3: 0.6938\n",
      "Epoch 10/50\n",
      "100/100 - 12s - loss_1: 0.7268 - loss_2: 0.7442 - loss_3: 0.7161 - acc_ensemble: 0.7700 - acc_1: 0.7440 - acc_2: 0.7400 - acc_3: 0.7260 - val_loss_1: 0.8327 - val_loss_2: 0.8398 - val_loss_3: 0.8254 - val_acc_ensemble: 0.7282 - val_acc_1: 0.7090 - val_acc_2: 0.7033 - val_acc_3: 0.7023\n",
      "Epoch 11/50\n",
      "100/100 - 12s - loss_1: 0.6521 - loss_2: 0.6539 - loss_3: 0.6922 - acc_ensemble: 0.7720 - acc_1: 0.7440 - acc_2: 0.7620 - acc_3: 0.7320 - val_loss_1: 0.8062 - val_loss_2: 0.8183 - val_loss_3: 0.8482 - val_acc_ensemble: 0.7332 - val_acc_1: 0.7123 - val_acc_2: 0.7139 - val_acc_3: 0.7025\n",
      "Epoch 12/50\n",
      "100/100 - 12s - loss_1: 0.6445 - loss_2: 0.6696 - loss_3: 0.6407 - acc_ensemble: 0.7960 - acc_1: 0.7640 - acc_2: 0.7540 - acc_3: 0.7820 - val_loss_1: 0.7788 - val_loss_2: 0.7824 - val_loss_3: 0.7929 - val_acc_ensemble: 0.7461 - val_acc_1: 0.7252 - val_acc_2: 0.7252 - val_acc_3: 0.7216\n",
      "Epoch 13/50\n",
      "100/100 - 12s - loss_1: 0.5793 - loss_2: 0.5999 - loss_3: 0.6136 - acc_ensemble: 0.8080 - acc_1: 0.7680 - acc_2: 0.7660 - acc_3: 0.7900 - val_loss_1: 0.7959 - val_loss_2: 0.7876 - val_loss_3: 0.7861 - val_acc_ensemble: 0.7499 - val_acc_1: 0.7212 - val_acc_2: 0.7287 - val_acc_3: 0.7242\n",
      "Epoch 14/50\n",
      "100/100 - 12s - loss_1: 0.5782 - loss_2: 0.5698 - loss_3: 0.5777 - acc_ensemble: 0.8060 - acc_1: 0.7720 - acc_2: 0.8060 - acc_3: 0.7720 - val_loss_1: 0.7751 - val_loss_2: 0.7690 - val_loss_3: 0.7574 - val_acc_ensemble: 0.7571 - val_acc_1: 0.7326 - val_acc_2: 0.7349 - val_acc_3: 0.7321\n",
      "Epoch 15/50\n",
      "100/100 - 13s - loss_1: 0.5122 - loss_2: 0.5293 - loss_3: 0.5047 - acc_ensemble: 0.8340 - acc_1: 0.7860 - acc_2: 0.8160 - acc_3: 0.8120 - val_loss_1: 0.7510 - val_loss_2: 0.7535 - val_loss_3: 0.7677 - val_acc_ensemble: 0.7674 - val_acc_1: 0.7449 - val_acc_2: 0.7439 - val_acc_3: 0.7360\n",
      "Epoch 16/50\n",
      "100/100 - 12s - loss_1: 0.5066 - loss_2: 0.5268 - loss_3: 0.5184 - acc_ensemble: 0.8320 - acc_1: 0.7880 - acc_2: 0.8020 - acc_3: 0.8040 - val_loss_1: 0.7507 - val_loss_2: 0.7405 - val_loss_3: 0.7355 - val_acc_ensemble: 0.7673 - val_acc_1: 0.7421 - val_acc_2: 0.7434 - val_acc_3: 0.7463\n",
      "Epoch 17/50\n",
      "100/100 - 12s - loss_1: 0.4634 - loss_2: 0.4761 - loss_3: 0.4842 - acc_ensemble: 0.8400 - acc_1: 0.8120 - acc_2: 0.8220 - acc_3: 0.8000 - val_loss_1: 0.7455 - val_loss_2: 0.7539 - val_loss_3: 0.7676 - val_acc_ensemble: 0.7675 - val_acc_1: 0.7479 - val_acc_2: 0.7416 - val_acc_3: 0.7356\n",
      "Epoch 18/50\n",
      "100/100 - 12s - loss_1: 0.4622 - loss_2: 0.4663 - loss_3: 0.4344 - acc_ensemble: 0.8500 - acc_1: 0.8100 - acc_2: 0.8140 - acc_3: 0.8160 - val_loss_1: 0.7530 - val_loss_2: 0.7370 - val_loss_3: 0.7370 - val_acc_ensemble: 0.7700 - val_acc_1: 0.7482 - val_acc_2: 0.7487 - val_acc_3: 0.7464\n",
      "Epoch 19/50\n",
      "100/100 - 13s - loss_1: 0.4334 - loss_2: 0.4127 - loss_3: 0.4354 - acc_ensemble: 0.8520 - acc_1: 0.8300 - acc_2: 0.8220 - acc_3: 0.8200 - val_loss_1: 0.7635 - val_loss_2: 0.7577 - val_loss_3: 0.7244 - val_acc_ensemble: 0.7778 - val_acc_1: 0.7502 - val_acc_2: 0.7424 - val_acc_3: 0.7488\n",
      "Epoch 20/50\n",
      "100/100 - 12s - loss_1: 0.3765 - loss_2: 0.3679 - loss_3: 0.3904 - acc_ensemble: 0.8640 - acc_1: 0.8200 - acc_2: 0.8280 - acc_3: 0.8260 - val_loss_1: 0.7497 - val_loss_2: 0.7526 - val_loss_3: 0.7794 - val_acc_ensemble: 0.7740 - val_acc_1: 0.7512 - val_acc_2: 0.7466 - val_acc_3: 0.7405\n",
      "Epoch 21/50\n",
      "100/100 - 12s - loss_1: 0.3554 - loss_2: 0.3778 - loss_3: 0.3405 - acc_ensemble: 0.8520 - acc_1: 0.8220 - acc_2: 0.8280 - acc_3: 0.8440 - val_loss_1: 0.7480 - val_loss_2: 0.7439 - val_loss_3: 0.7433 - val_acc_ensemble: 0.7849 - val_acc_1: 0.7546 - val_acc_2: 0.7543 - val_acc_3: 0.7548\n",
      "Epoch 22/50\n",
      "100/100 - 12s - loss_1: 0.3475 - loss_2: 0.3361 - loss_3: 0.3491 - acc_ensemble: 0.8800 - acc_1: 0.8360 - acc_2: 0.8400 - acc_3: 0.8360 - val_loss_1: 0.7589 - val_loss_2: 0.7507 - val_loss_3: 0.7360 - val_acc_ensemble: 0.7870 - val_acc_1: 0.7563 - val_acc_2: 0.7557 - val_acc_3: 0.7623\n",
      "Epoch 23/50\n",
      "100/100 - 13s - loss_1: 0.3071 - loss_2: 0.3131 - loss_3: 0.3316 - acc_ensemble: 0.8720 - acc_1: 0.8440 - acc_2: 0.8360 - acc_3: 0.8340 - val_loss_1: 0.7344 - val_loss_2: 0.7575 - val_loss_3: 0.7432 - val_acc_ensemble: 0.7892 - val_acc_1: 0.7634 - val_acc_2: 0.7595 - val_acc_3: 0.7602\n",
      "Epoch 24/50\n",
      "100/100 - 12s - loss_1: 0.2821 - loss_2: 0.3192 - loss_3: 0.3009 - acc_ensemble: 0.8720 - acc_1: 0.8360 - acc_2: 0.8440 - acc_3: 0.8540 - val_loss_1: 0.7463 - val_loss_2: 0.7587 - val_loss_3: 0.7532 - val_acc_ensemble: 0.7904 - val_acc_1: 0.7633 - val_acc_2: 0.7595 - val_acc_3: 0.7633\n",
      "Epoch 25/50\n",
      "100/100 - 12s - loss_1: 0.2734 - loss_2: 0.2708 - loss_3: 0.2807 - acc_ensemble: 0.8820 - acc_1: 0.8220 - acc_2: 0.8620 - acc_3: 0.8540 - val_loss_1: 0.7488 - val_loss_2: 0.7453 - val_loss_3: 0.7620 - val_acc_ensemble: 0.7958 - val_acc_1: 0.7664 - val_acc_2: 0.7660 - val_acc_3: 0.7608\n",
      "Epoch 26/50\n",
      "100/100 - 12s - loss_1: 0.2684 - loss_2: 0.2431 - loss_3: 0.2672 - acc_ensemble: 0.8660 - acc_1: 0.8600 - acc_2: 0.8580 - acc_3: 0.8540 - val_loss_1: 0.7506 - val_loss_2: 0.7854 - val_loss_3: 0.7589 - val_acc_ensemble: 0.7924 - val_acc_1: 0.7667 - val_acc_2: 0.7598 - val_acc_3: 0.7663\n",
      "Epoch 27/50\n",
      "100/100 - 12s - loss_1: 0.2452 - loss_2: 0.2516 - loss_3: 0.2290 - acc_ensemble: 0.8660 - acc_1: 0.8600 - acc_2: 0.8340 - acc_3: 0.8520 - val_loss_1: 0.7834 - val_loss_2: 0.8100 - val_loss_3: 0.8115 - val_acc_ensemble: 0.7864 - val_acc_1: 0.7583 - val_acc_2: 0.7581 - val_acc_3: 0.7565\n",
      "Epoch 28/50\n",
      "100/100 - 12s - loss_1: 0.2111 - loss_2: 0.2200 - loss_3: 0.2261 - acc_ensemble: 0.8940 - acc_1: 0.8460 - acc_2: 0.8320 - acc_3: 0.8520 - val_loss_1: 0.7807 - val_loss_2: 0.8145 - val_loss_3: 0.8070 - val_acc_ensemble: 0.7920 - val_acc_1: 0.7651 - val_acc_2: 0.7555 - val_acc_3: 0.7563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50\n",
      "100/100 - 12s - loss_1: 0.1912 - loss_2: 0.1995 - loss_3: 0.2094 - acc_ensemble: 0.8900 - acc_1: 0.8540 - acc_2: 0.8500 - acc_3: 0.8660 - val_loss_1: 0.8000 - val_loss_2: 0.7992 - val_loss_3: 0.8166 - val_acc_ensemble: 0.7941 - val_acc_1: 0.7688 - val_acc_2: 0.7637 - val_acc_3: 0.7606\n",
      "Epoch 30/50\n",
      "100/100 - 12s - loss_1: 0.1806 - loss_2: 0.1799 - loss_3: 0.1763 - acc_ensemble: 0.9060 - acc_1: 0.8660 - acc_2: 0.8620 - acc_3: 0.8480 - val_loss_1: 0.8355 - val_loss_2: 0.8408 - val_loss_3: 0.8442 - val_acc_ensemble: 0.7950 - val_acc_1: 0.7610 - val_acc_2: 0.7597 - val_acc_3: 0.7618\n",
      "Epoch 31/50\n",
      "100/100 - 12s - loss_1: 0.1909 - loss_2: 0.2002 - loss_3: 0.1670 - acc_ensemble: 0.8940 - acc_1: 0.8740 - acc_2: 0.8700 - acc_3: 0.8740 - val_loss_1: 0.8111 - val_loss_2: 0.8103 - val_loss_3: 0.8070 - val_acc_ensemble: 0.7981 - val_acc_1: 0.7654 - val_acc_2: 0.7628 - val_acc_3: 0.7663\n",
      "Epoch 32/50\n",
      "100/100 - 12s - loss_1: 0.1674 - loss_2: 0.1725 - loss_3: 0.1789 - acc_ensemble: 0.9040 - acc_1: 0.8580 - acc_2: 0.8760 - acc_3: 0.8700 - val_loss_1: 0.8356 - val_loss_2: 0.8440 - val_loss_3: 0.8563 - val_acc_ensemble: 0.7902 - val_acc_1: 0.7613 - val_acc_2: 0.7564 - val_acc_3: 0.7581\n",
      "Epoch 33/50\n",
      "100/100 - 12s - loss_1: 0.1497 - loss_2: 0.1665 - loss_3: 0.1720 - acc_ensemble: 0.9060 - acc_1: 0.8740 - acc_2: 0.8620 - acc_3: 0.8900 - val_loss_1: 0.8583 - val_loss_2: 0.8380 - val_loss_3: 0.8021 - val_acc_ensemble: 0.8021 - val_acc_1: 0.7651 - val_acc_2: 0.7655 - val_acc_3: 0.7709\n",
      "Epoch 34/50\n",
      "100/100 - 12s - loss_1: 0.1646 - loss_2: 0.1252 - loss_3: 0.1431 - acc_ensemble: 0.9140 - acc_1: 0.8660 - acc_2: 0.8760 - acc_3: 0.8660 - val_loss_1: 0.8291 - val_loss_2: 0.8424 - val_loss_3: 0.8768 - val_acc_ensemble: 0.7989 - val_acc_1: 0.7699 - val_acc_2: 0.7658 - val_acc_3: 0.7615\n",
      "Epoch 35/50\n",
      "100/100 - 12s - loss_1: 0.1261 - loss_2: 0.1268 - loss_3: 0.1244 - acc_ensemble: 0.9080 - acc_1: 0.8680 - acc_2: 0.8700 - acc_3: 0.8740 - val_loss_1: 0.8862 - val_loss_2: 0.8837 - val_loss_3: 0.8622 - val_acc_ensemble: 0.7973 - val_acc_1: 0.7643 - val_acc_2: 0.7644 - val_acc_3: 0.7650\n",
      "Epoch 36/50\n",
      "100/100 - 12s - loss_1: 0.1396 - loss_2: 0.1327 - loss_3: 0.1244 - acc_ensemble: 0.9080 - acc_1: 0.8740 - acc_2: 0.8640 - acc_3: 0.8660 - val_loss_1: 0.8725 - val_loss_2: 0.9090 - val_loss_3: 0.8804 - val_acc_ensemble: 0.7986 - val_acc_1: 0.7667 - val_acc_2: 0.7586 - val_acc_3: 0.7662\n",
      "Epoch 37/50\n",
      "100/100 - 12s - loss_1: 0.1228 - loss_2: 0.1324 - loss_3: 0.1409 - acc_ensemble: 0.9080 - acc_1: 0.8860 - acc_2: 0.8500 - acc_3: 0.8640 - val_loss_1: 0.9115 - val_loss_2: 0.9007 - val_loss_3: 0.8931 - val_acc_ensemble: 0.7959 - val_acc_1: 0.7602 - val_acc_2: 0.7579 - val_acc_3: 0.7689\n",
      "Epoch 38/50\n",
      "100/100 - 12s - loss_1: 0.0967 - loss_2: 0.1112 - loss_3: 0.1260 - acc_ensemble: 0.9160 - acc_1: 0.8680 - acc_2: 0.8740 - acc_3: 0.8720 - val_loss_1: 0.9133 - val_loss_2: 0.9121 - val_loss_3: 0.8981 - val_acc_ensemble: 0.7953 - val_acc_1: 0.7641 - val_acc_2: 0.7629 - val_acc_3: 0.7663\n",
      "Epoch 39/50\n",
      "100/100 - 12s - loss_1: 0.1097 - loss_2: 0.0915 - loss_3: 0.0944 - acc_ensemble: 0.9180 - acc_1: 0.9020 - acc_2: 0.8760 - acc_3: 0.8820 - val_loss_1: 0.9240 - val_loss_2: 0.9015 - val_loss_3: 0.9013 - val_acc_ensemble: 0.8022 - val_acc_1: 0.7646 - val_acc_2: 0.7644 - val_acc_3: 0.7737\n",
      "Epoch 40/50\n",
      "100/100 - 12s - loss_1: 0.1018 - loss_2: 0.0949 - loss_3: 0.1251 - acc_ensemble: 0.9060 - acc_1: 0.8780 - acc_2: 0.8640 - acc_3: 0.8780 - val_loss_1: 0.9220 - val_loss_2: 0.9312 - val_loss_3: 0.9811 - val_acc_ensemble: 0.7982 - val_acc_1: 0.7705 - val_acc_2: 0.7614 - val_acc_3: 0.7581\n",
      "Epoch 41/50\n",
      "100/100 - 12s - loss_1: 0.0940 - loss_2: 0.1083 - loss_3: 0.0914 - acc_ensemble: 0.9280 - acc_1: 0.8800 - acc_2: 0.8780 - acc_3: 0.8880 - val_loss_1: 0.9146 - val_loss_2: 0.9456 - val_loss_3: 0.9395 - val_acc_ensemble: 0.8037 - val_acc_1: 0.7701 - val_acc_2: 0.7660 - val_acc_3: 0.7670\n",
      "Epoch 42/50\n",
      "100/100 - 12s - loss_1: 0.0756 - loss_2: 0.0680 - loss_3: 0.0961 - acc_ensemble: 0.9380 - acc_1: 0.8840 - acc_2: 0.8660 - acc_3: 0.8900 - val_loss_1: 0.9334 - val_loss_2: 0.9423 - val_loss_3: 0.9778 - val_acc_ensemble: 0.8016 - val_acc_1: 0.7733 - val_acc_2: 0.7674 - val_acc_3: 0.7641\n",
      "Epoch 43/50\n",
      "100/100 - 13s - loss_1: 0.0667 - loss_2: 0.0816 - loss_3: 0.0867 - acc_ensemble: 0.9140 - acc_1: 0.8800 - acc_2: 0.8760 - acc_3: 0.8740 - val_loss_1: 0.9762 - val_loss_2: 0.9783 - val_loss_3: 0.9818 - val_acc_ensemble: 0.8002 - val_acc_1: 0.7638 - val_acc_2: 0.7641 - val_acc_3: 0.7675\n",
      "Epoch 44/50\n",
      "100/100 - 12s - loss_1: 0.0873 - loss_2: 0.0851 - loss_3: 0.0789 - acc_ensemble: 0.9100 - acc_1: 0.8760 - acc_2: 0.8880 - acc_3: 0.8940 - val_loss_1: 0.9801 - val_loss_2: 0.9788 - val_loss_3: 0.9309 - val_acc_ensemble: 0.8062 - val_acc_1: 0.7668 - val_acc_2: 0.7648 - val_acc_3: 0.7762\n",
      "Epoch 45/50\n",
      "100/100 - 12s - loss_1: 0.0839 - loss_2: 0.0773 - loss_3: 0.0720 - acc_ensemble: 0.9160 - acc_1: 0.8860 - acc_2: 0.8840 - acc_3: 0.9000 - val_loss_1: 1.0086 - val_loss_2: 1.0011 - val_loss_3: 0.9808 - val_acc_ensemble: 0.7957 - val_acc_1: 0.7611 - val_acc_2: 0.7600 - val_acc_3: 0.7672\n",
      "Epoch 46/50\n",
      "100/100 - 12s - loss_1: 0.0872 - loss_2: 0.0642 - loss_3: 0.0718 - acc_ensemble: 0.9220 - acc_1: 0.8820 - acc_2: 0.8980 - acc_3: 0.8620 - val_loss_1: 0.9811 - val_loss_2: 0.9836 - val_loss_3: 0.9993 - val_acc_ensemble: 0.8052 - val_acc_1: 0.7716 - val_acc_2: 0.7686 - val_acc_3: 0.7675\n",
      "Epoch 47/50\n",
      "100/100 - 12s - loss_1: 0.0558 - loss_2: 0.0447 - loss_3: 0.0611 - acc_ensemble: 0.9340 - acc_1: 0.8900 - acc_2: 0.8900 - acc_3: 0.8740 - val_loss_1: 0.9708 - val_loss_2: 1.0172 - val_loss_3: 1.0194 - val_acc_ensemble: 0.8028 - val_acc_1: 0.7753 - val_acc_2: 0.7665 - val_acc_3: 0.7672\n",
      "Epoch 48/50\n",
      "100/100 - 12s - loss_1: 0.0570 - loss_2: 0.0578 - loss_3: 0.0593 - acc_ensemble: 0.9240 - acc_1: 0.8880 - acc_2: 0.8740 - acc_3: 0.8860 - val_loss_1: 1.0022 - val_loss_2: 1.0552 - val_loss_3: 1.0241 - val_acc_ensemble: 0.8025 - val_acc_1: 0.7715 - val_acc_2: 0.7652 - val_acc_3: 0.7728\n",
      "Epoch 49/50\n",
      "100/100 - 12s - loss_1: 0.0753 - loss_2: 0.0738 - loss_3: 0.0748 - acc_ensemble: 0.9100 - acc_1: 0.8760 - acc_2: 0.8880 - acc_3: 0.8620 - val_loss_1: 1.0566 - val_loss_2: 1.0550 - val_loss_3: 1.0631 - val_acc_ensemble: 0.7975 - val_acc_1: 0.7625 - val_acc_2: 0.7618 - val_acc_3: 0.7657\n",
      "Epoch 50/50\n",
      "100/100 - 12s - loss_1: 0.0715 - loss_2: 0.0725 - loss_3: 0.0481 - acc_ensemble: 0.9320 - acc_1: 0.8780 - acc_2: 0.8880 - acc_3: 0.8900 - val_loss_1: 1.0323 - val_loss_2: 1.0448 - val_loss_3: 1.0161 - val_acc_ensemble: 0.8038 - val_acc_1: 0.7700 - val_acc_2: 0.7694 - val_acc_3: 0.7754\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B3/S1.00/model_1\n",
      "i   Layer name                      Output shape        Num param  Inbound            \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                    \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                    \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                    \n",
      "--------------------------------------------------------------------------------------\n",
      "0   conv2d_1_1 (Conv2D)             [None,32,32,32] []  896        input              \n",
      "                                    [None,32,32,32] []                                \n",
      "                                    [None,32,32,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "1   bn_1_1 (BatchNormalization)     [None,32,32,32] []  64         conv2d_1_1         \n",
      "                                    [None,32,32,32] []                                \n",
      "                                    [None,32,32,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "2   relu_1_1 (Activation)           [None,32,32,32] []  0          bn_1_1             \n",
      "                                    [None,32,32,32] []                                \n",
      "                                    [None,32,32,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "3   conv2d_1_2 (Conv2D)             [None,32,32,32] []  9248       relu_1_1           \n",
      "                                    [None,32,32,32] []                                \n",
      "                                    [None,32,32,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "4   bn_1_2 (BatchNormalization)     [None,32,32,32] []  64         conv2d_1_2         \n",
      "                                    [None,32,32,32] []                                \n",
      "                                    [None,32,32,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "5   relu_1_2 (Activation)           [None,32,32,32] []  0          bn_1_2             \n",
      "                                    [None,32,32,32] []                                \n",
      "                                    [None,32,32,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "6   avg_pool2d_1 (AveragePooling2D  [None,16,16,32] []  0          relu_1_2           \n",
      "                                    [None,16,16,32] []                                \n",
      "                                    [None,16,16,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "7   conv2d_2_1 (Conv2D)             [None,16,16,64] []  18496      avg_pool2d_1       \n",
      "                                    [None,16,16,64] []                                \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "8   bn_2_1 (BatchNormalization)     [None,16,16,64] []  128        conv2d_2_1         \n",
      "                                    [None,16,16,64] []                                \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "9   relu_2_1 (Activation)           [None,16,16,64] []  0          bn_2_1             \n",
      "                                    [None,16,16,64] []                                \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "10  conv2d_2_2 (Conv2D)             [None,16,16,64] []  36928      relu_2_1           \n",
      "                                    [None,16,16,64] []                                \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "11  bn_2_2 (BatchNormalization)     [None,16,16,64] []  128        conv2d_2_2         \n",
      "                                    [None,16,16,64] []                                \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "12  relu_2_2 (Activation)           [None,16,16,64] []  0          bn_2_2             \n",
      "                                    [None,16,16,64] []                                \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "13  avg_pool2d_2 (AveragePooling2D  [None,8,8,64] []    0          relu_2_2           \n",
      "                                    [None,8,8,64] []                                  \n",
      "                                    [None,8,8,64] []                                  \n",
      "--------------------------------------------------------------------------------------\n",
      "14  conv2d_3_1 (Conv2D)             [None,8,8,128] []   73856      avg_pool2d_2       \n",
      "                                    [None,8,8,128] []                                 \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "15  bn_3_1 (BatchNormalization)     [None,8,8,128] []   256        conv2d_3_1         \n",
      "                                    [None,8,8,128] []                                 \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "16  relu_3_1 (Activation)           [None,8,8,128] []   0          bn_3_1             \n",
      "                                    [None,8,8,128] []                                 \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "17  conv2d_3_2 (Conv2D)             [None,8,8,128] []   147584     relu_3_1           \n",
      "                                    [None,8,8,128] []                                 \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "18  bn_3_2 (BatchNormalization)     [None,8,8,128] []   256        conv2d_3_2         \n",
      "                                    [None,8,8,128] []                                 \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "19  relu_3_2 (Activation)           [None,8,8,128] []   0          bn_3_2             \n",
      "                                    [None,8,8,128] []                                 \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "20  global_avg_pool2d (GlobalAvera  [None,128] []       0          relu_3_2           \n",
      "                                    [None,128] []                                     \n",
      "                                    [None,128] []                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "21  fc1 (Dense)                     [None,128] []       16512      global_avg_pool2d  \n",
      "                                    [None,128] []                                     \n",
      "                                    [None,128] []                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "22  bn_fc1 (BatchNormalization)     [None,128] []       256        fc1                \n",
      "                                    [None,128] []                                     \n",
      "                                    [None,128] []                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "23  relu_fc1 (Activation)           [None,128] []       0          bn_fc1             \n",
      "                                    [None,128] []                                     \n",
      "                                    [None,128] []                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "24  output (Dense)                  [None,10]           1290       relu_fc1           \n",
      "                                    [None,10]                                         \n",
      "                                    [None,10]                                         \n",
      "--------------------------------------------------------------------------------------\n",
      "Total parameters: 305962\n",
      "50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 - 10s - loss_1: 1.5914 - loss_2: 1.5899 - loss_3: 1.6056 - acc_ensemble: 0.5220 - acc_1: 0.5220 - acc_2: 0.5220 - acc_3: 0.5220 - val_loss_1: 1.3462 - val_loss_2: 1.3462 - val_loss_3: 1.3462 - val_acc_ensemble: 0.5074 - val_acc_1: 0.5074 - val_acc_2: 0.5074 - val_acc_3: 0.5074\n",
      "Epoch 2/50\n",
      "100/100 - 8s - loss_1: 1.2371 - loss_2: 1.2256 - loss_3: 1.2464 - acc_ensemble: 0.6000 - acc_1: 0.6000 - acc_2: 0.6000 - acc_3: 0.6000 - val_loss_1: 1.1411 - val_loss_2: 1.1411 - val_loss_3: 1.1411 - val_acc_ensemble: 0.5899 - val_acc_1: 0.5899 - val_acc_2: 0.5899 - val_acc_3: 0.5899\n",
      "Epoch 3/50\n",
      "100/100 - 8s - loss_1: 1.0799 - loss_2: 1.0598 - loss_3: 1.0748 - acc_ensemble: 0.6700 - acc_1: 0.6700 - acc_2: 0.6700 - acc_3: 0.6700 - val_loss_1: 1.0364 - val_loss_2: 1.0364 - val_loss_3: 1.0364 - val_acc_ensemble: 0.6285 - val_acc_1: 0.6285 - val_acc_2: 0.6285 - val_acc_3: 0.6285\n",
      "Epoch 4/50\n",
      "100/100 - 8s - loss_1: 0.9643 - loss_2: 0.9276 - loss_3: 0.9591 - acc_ensemble: 0.7220 - acc_1: 0.7220 - acc_2: 0.7220 - acc_3: 0.7220 - val_loss_1: 0.9731 - val_loss_2: 0.9731 - val_loss_3: 0.9731 - val_acc_ensemble: 0.6485 - val_acc_1: 0.6485 - val_acc_2: 0.6485 - val_acc_3: 0.6485\n",
      "Epoch 5/50\n",
      "100/100 - 8s - loss_1: 0.8891 - loss_2: 0.8329 - loss_3: 0.8684 - acc_ensemble: 0.7420 - acc_1: 0.7420 - acc_2: 0.7420 - acc_3: 0.7420 - val_loss_1: 0.9261 - val_loss_2: 0.9261 - val_loss_3: 0.9261 - val_acc_ensemble: 0.6693 - val_acc_1: 0.6693 - val_acc_2: 0.6693 - val_acc_3: 0.6693\n",
      "Epoch 6/50\n",
      "100/100 - 8s - loss_1: 0.7956 - loss_2: 0.7757 - loss_3: 0.7833 - acc_ensemble: 0.7760 - acc_1: 0.7760 - acc_2: 0.7760 - acc_3: 0.7760 - val_loss_1: 0.8582 - val_loss_2: 0.8582 - val_loss_3: 0.8582 - val_acc_ensemble: 0.6930 - val_acc_1: 0.6930 - val_acc_2: 0.6930 - val_acc_3: 0.6930\n",
      "Epoch 7/50\n",
      "100/100 - 8s - loss_1: 0.7168 - loss_2: 0.6877 - loss_3: 0.7268 - acc_ensemble: 0.7700 - acc_1: 0.7700 - acc_2: 0.7700 - acc_3: 0.7700 - val_loss_1: 0.8313 - val_loss_2: 0.8313 - val_loss_3: 0.8313 - val_acc_ensemble: 0.7081 - val_acc_1: 0.7081 - val_acc_2: 0.7081 - val_acc_3: 0.7081\n",
      "Epoch 8/50\n",
      "100/100 - 8s - loss_1: 0.6573 - loss_2: 0.6466 - loss_3: 0.6899 - acc_ensemble: 0.7860 - acc_1: 0.7860 - acc_2: 0.7860 - acc_3: 0.7860 - val_loss_1: 0.8278 - val_loss_2: 0.8278 - val_loss_3: 0.8278 - val_acc_ensemble: 0.7110 - val_acc_1: 0.7110 - val_acc_2: 0.7110 - val_acc_3: 0.7110\n",
      "Epoch 9/50\n",
      "100/100 - 8s - loss_1: 0.6323 - loss_2: 0.6229 - loss_3: 0.6198 - acc_ensemble: 0.8000 - acc_1: 0.8000 - acc_2: 0.8000 - acc_3: 0.8000 - val_loss_1: 0.7837 - val_loss_2: 0.7837 - val_loss_3: 0.7837 - val_acc_ensemble: 0.7239 - val_acc_1: 0.7239 - val_acc_2: 0.7239 - val_acc_3: 0.7239\n",
      "Epoch 10/50\n",
      "100/100 - 8s - loss_1: 0.5976 - loss_2: 0.5774 - loss_3: 0.5536 - acc_ensemble: 0.8060 - acc_1: 0.8060 - acc_2: 0.8060 - acc_3: 0.8060 - val_loss_1: 0.7902 - val_loss_2: 0.7902 - val_loss_3: 0.7902 - val_acc_ensemble: 0.7248 - val_acc_1: 0.7248 - val_acc_2: 0.7248 - val_acc_3: 0.7248\n",
      "Epoch 11/50\n",
      "100/100 - 8s - loss_1: 0.5226 - loss_2: 0.5069 - loss_3: 0.5150 - acc_ensemble: 0.8360 - acc_1: 0.8360 - acc_2: 0.8360 - acc_3: 0.8360 - val_loss_1: 0.7846 - val_loss_2: 0.7846 - val_loss_3: 0.7846 - val_acc_ensemble: 0.7285 - val_acc_1: 0.7285 - val_acc_2: 0.7285 - val_acc_3: 0.7285\n",
      "Epoch 12/50\n",
      "100/100 - 9s - loss_1: 0.4910 - loss_2: 0.5029 - loss_3: 0.5061 - acc_ensemble: 0.8200 - acc_1: 0.8200 - acc_2: 0.8200 - acc_3: 0.8200 - val_loss_1: 0.7723 - val_loss_2: 0.7723 - val_loss_3: 0.7723 - val_acc_ensemble: 0.7380 - val_acc_1: 0.7380 - val_acc_2: 0.7380 - val_acc_3: 0.7380\n",
      "Epoch 13/50\n",
      "100/100 - 8s - loss_1: 0.4493 - loss_2: 0.4438 - loss_3: 0.4573 - acc_ensemble: 0.8540 - acc_1: 0.8540 - acc_2: 0.8540 - acc_3: 0.8540 - val_loss_1: 0.7581 - val_loss_2: 0.7581 - val_loss_3: 0.7581 - val_acc_ensemble: 0.7411 - val_acc_1: 0.7411 - val_acc_2: 0.7411 - val_acc_3: 0.7411\n",
      "Epoch 14/50\n",
      "100/100 - 8s - loss_1: 0.4198 - loss_2: 0.4066 - loss_3: 0.4101 - acc_ensemble: 0.8680 - acc_1: 0.8680 - acc_2: 0.8680 - acc_3: 0.8680 - val_loss_1: 0.7381 - val_loss_2: 0.7381 - val_loss_3: 0.7381 - val_acc_ensemble: 0.7492 - val_acc_1: 0.7492 - val_acc_2: 0.7492 - val_acc_3: 0.7492\n",
      "Epoch 15/50\n",
      "100/100 - 8s - loss_1: 0.4077 - loss_2: 0.3857 - loss_3: 0.3982 - acc_ensemble: 0.8580 - acc_1: 0.8580 - acc_2: 0.8580 - acc_3: 0.8580 - val_loss_1: 0.7789 - val_loss_2: 0.7789 - val_loss_3: 0.7789 - val_acc_ensemble: 0.7476 - val_acc_1: 0.7476 - val_acc_2: 0.7476 - val_acc_3: 0.7476\n",
      "Epoch 16/50\n",
      "100/100 - 8s - loss_1: 0.3486 - loss_2: 0.3388 - loss_3: 0.3273 - acc_ensemble: 0.8740 - acc_1: 0.8740 - acc_2: 0.8740 - acc_3: 0.8740 - val_loss_1: 0.7741 - val_loss_2: 0.7741 - val_loss_3: 0.7741 - val_acc_ensemble: 0.7435 - val_acc_1: 0.7435 - val_acc_2: 0.7435 - val_acc_3: 0.7435\n",
      "Epoch 17/50\n",
      "100/100 - 8s - loss_1: 0.3261 - loss_2: 0.3114 - loss_3: 0.3361 - acc_ensemble: 0.8800 - acc_1: 0.8800 - acc_2: 0.8800 - acc_3: 0.8800 - val_loss_1: 0.7630 - val_loss_2: 0.7630 - val_loss_3: 0.7630 - val_acc_ensemble: 0.7519 - val_acc_1: 0.7519 - val_acc_2: 0.7519 - val_acc_3: 0.7519\n",
      "Epoch 18/50\n",
      "100/100 - 8s - loss_1: 0.3366 - loss_2: 0.2891 - loss_3: 0.3194 - acc_ensemble: 0.8740 - acc_1: 0.8740 - acc_2: 0.8740 - acc_3: 0.8740 - val_loss_1: 0.7647 - val_loss_2: 0.7647 - val_loss_3: 0.7647 - val_acc_ensemble: 0.7533 - val_acc_1: 0.7533 - val_acc_2: 0.7533 - val_acc_3: 0.7533\n",
      "Epoch 19/50\n",
      "100/100 - 8s - loss_1: 0.2954 - loss_2: 0.2795 - loss_3: 0.2721 - acc_ensemble: 0.8840 - acc_1: 0.8840 - acc_2: 0.8840 - acc_3: 0.8840 - val_loss_1: 0.7689 - val_loss_2: 0.7689 - val_loss_3: 0.7689 - val_acc_ensemble: 0.7529 - val_acc_1: 0.7529 - val_acc_2: 0.7529 - val_acc_3: 0.7529\n",
      "Epoch 20/50\n",
      "100/100 - 9s - loss_1: 0.2454 - loss_2: 0.2411 - loss_3: 0.2730 - acc_ensemble: 0.9060 - acc_1: 0.9060 - acc_2: 0.9060 - acc_3: 0.9060 - val_loss_1: 0.7648 - val_loss_2: 0.7648 - val_loss_3: 0.7648 - val_acc_ensemble: 0.7614 - val_acc_1: 0.7614 - val_acc_2: 0.7614 - val_acc_3: 0.7614\n",
      "Epoch 21/50\n",
      "100/100 - 8s - loss_1: 0.2240 - loss_2: 0.2231 - loss_3: 0.2315 - acc_ensemble: 0.9000 - acc_1: 0.9000 - acc_2: 0.9000 - acc_3: 0.9000 - val_loss_1: 0.7902 - val_loss_2: 0.7902 - val_loss_3: 0.7902 - val_acc_ensemble: 0.7578 - val_acc_1: 0.7578 - val_acc_2: 0.7578 - val_acc_3: 0.7578\n",
      "Epoch 22/50\n",
      "100/100 - 8s - loss_1: 0.2311 - loss_2: 0.2124 - loss_3: 0.2029 - acc_ensemble: 0.8960 - acc_1: 0.8960 - acc_2: 0.8960 - acc_3: 0.8960 - val_loss_1: 0.8268 - val_loss_2: 0.8268 - val_loss_3: 0.8268 - val_acc_ensemble: 0.7539 - val_acc_1: 0.7539 - val_acc_2: 0.7539 - val_acc_3: 0.7539\n",
      "Epoch 23/50\n",
      "100/100 - 8s - loss_1: 0.2174 - loss_2: 0.2160 - loss_3: 0.2060 - acc_ensemble: 0.8860 - acc_1: 0.8860 - acc_2: 0.8860 - acc_3: 0.8860 - val_loss_1: 0.8356 - val_loss_2: 0.8356 - val_loss_3: 0.8356 - val_acc_ensemble: 0.7508 - val_acc_1: 0.7508 - val_acc_2: 0.7508 - val_acc_3: 0.7508\n",
      "Epoch 24/50\n",
      "100/100 - 9s - loss_1: 0.2074 - loss_2: 0.1862 - loss_3: 0.1991 - acc_ensemble: 0.9000 - acc_1: 0.9000 - acc_2: 0.9000 - acc_3: 0.9000 - val_loss_1: 0.8330 - val_loss_2: 0.8330 - val_loss_3: 0.8330 - val_acc_ensemble: 0.7540 - val_acc_1: 0.7540 - val_acc_2: 0.7540 - val_acc_3: 0.7540\n",
      "Epoch 25/50\n",
      "100/100 - 8s - loss_1: 0.1907 - loss_2: 0.1699 - loss_3: 0.1806 - acc_ensemble: 0.9100 - acc_1: 0.9100 - acc_2: 0.9100 - acc_3: 0.9100 - val_loss_1: 0.8731 - val_loss_2: 0.8731 - val_loss_3: 0.8731 - val_acc_ensemble: 0.7489 - val_acc_1: 0.7489 - val_acc_2: 0.7489 - val_acc_3: 0.7489\n",
      "Epoch 26/50\n",
      "100/100 - 8s - loss_1: 0.1760 - loss_2: 0.1590 - loss_3: 0.1601 - acc_ensemble: 0.9160 - acc_1: 0.9160 - acc_2: 0.9160 - acc_3: 0.9160 - val_loss_1: 0.8383 - val_loss_2: 0.8383 - val_loss_3: 0.8383 - val_acc_ensemble: 0.7611 - val_acc_1: 0.7611 - val_acc_2: 0.7611 - val_acc_3: 0.7611\n",
      "Epoch 27/50\n",
      "100/100 - 8s - loss_1: 0.1569 - loss_2: 0.1526 - loss_3: 0.1702 - acc_ensemble: 0.9200 - acc_1: 0.9200 - acc_2: 0.9200 - acc_3: 0.9200 - val_loss_1: 0.8746 - val_loss_2: 0.8746 - val_loss_3: 0.8746 - val_acc_ensemble: 0.7573 - val_acc_1: 0.7573 - val_acc_2: 0.7573 - val_acc_3: 0.7573\n",
      "Epoch 28/50\n",
      "100/100 - 8s - loss_1: 0.1452 - loss_2: 0.1610 - loss_3: 0.1408 - acc_ensemble: 0.9060 - acc_1: 0.9060 - acc_2: 0.9060 - acc_3: 0.9060 - val_loss_1: 0.8693 - val_loss_2: 0.8693 - val_loss_3: 0.8693 - val_acc_ensemble: 0.7575 - val_acc_1: 0.7575 - val_acc_2: 0.7575 - val_acc_3: 0.7575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50\n",
      "100/100 - 8s - loss_1: 0.1597 - loss_2: 0.1371 - loss_3: 0.1348 - acc_ensemble: 0.9200 - acc_1: 0.9200 - acc_2: 0.9200 - acc_3: 0.9200 - val_loss_1: 0.9068 - val_loss_2: 0.9068 - val_loss_3: 0.9068 - val_acc_ensemble: 0.7590 - val_acc_1: 0.7590 - val_acc_2: 0.7590 - val_acc_3: 0.7590\n",
      "Epoch 30/50\n",
      "100/100 - 8s - loss_1: 0.1288 - loss_2: 0.1282 - loss_3: 0.1298 - acc_ensemble: 0.8960 - acc_1: 0.8960 - acc_2: 0.8960 - acc_3: 0.8960 - val_loss_1: 0.9057 - val_loss_2: 0.9057 - val_loss_3: 0.9057 - val_acc_ensemble: 0.7532 - val_acc_1: 0.7532 - val_acc_2: 0.7532 - val_acc_3: 0.7532\n",
      "Epoch 31/50\n",
      "100/100 - 8s - loss_1: 0.1128 - loss_2: 0.1066 - loss_3: 0.1226 - acc_ensemble: 0.9240 - acc_1: 0.9240 - acc_2: 0.9240 - acc_3: 0.9240 - val_loss_1: 0.9108 - val_loss_2: 0.9108 - val_loss_3: 0.9108 - val_acc_ensemble: 0.7589 - val_acc_1: 0.7589 - val_acc_2: 0.7589 - val_acc_3: 0.7589\n",
      "Epoch 32/50\n",
      "100/100 - 8s - loss_1: 0.1042 - loss_2: 0.1092 - loss_3: 0.1187 - acc_ensemble: 0.9040 - acc_1: 0.9040 - acc_2: 0.9040 - acc_3: 0.9040 - val_loss_1: 0.9478 - val_loss_2: 0.9478 - val_loss_3: 0.9478 - val_acc_ensemble: 0.7518 - val_acc_1: 0.7518 - val_acc_2: 0.7518 - val_acc_3: 0.7518\n",
      "Epoch 33/50\n",
      "100/100 - 8s - loss_1: 0.1050 - loss_2: 0.1116 - loss_3: 0.1097 - acc_ensemble: 0.9260 - acc_1: 0.9260 - acc_2: 0.9260 - acc_3: 0.9260 - val_loss_1: 0.9304 - val_loss_2: 0.9304 - val_loss_3: 0.9304 - val_acc_ensemble: 0.7608 - val_acc_1: 0.7608 - val_acc_2: 0.7608 - val_acc_3: 0.7608\n",
      "Epoch 34/50\n",
      "100/100 - 8s - loss_1: 0.1101 - loss_2: 0.0873 - loss_3: 0.1057 - acc_ensemble: 0.9240 - acc_1: 0.9240 - acc_2: 0.9240 - acc_3: 0.9240 - val_loss_1: 0.9685 - val_loss_2: 0.9685 - val_loss_3: 0.9685 - val_acc_ensemble: 0.7540 - val_acc_1: 0.7540 - val_acc_2: 0.7540 - val_acc_3: 0.7540\n",
      "Epoch 35/50\n",
      "100/100 - 8s - loss_1: 0.0894 - loss_2: 0.0885 - loss_3: 0.1034 - acc_ensemble: 0.9360 - acc_1: 0.9360 - acc_2: 0.9360 - acc_3: 0.9360 - val_loss_1: 0.9497 - val_loss_2: 0.9497 - val_loss_3: 0.9497 - val_acc_ensemble: 0.7586 - val_acc_1: 0.7586 - val_acc_2: 0.7586 - val_acc_3: 0.7586\n",
      "Epoch 36/50\n",
      "100/100 - 8s - loss_1: 0.0891 - loss_2: 0.0764 - loss_3: 0.0868 - acc_ensemble: 0.9440 - acc_1: 0.9440 - acc_2: 0.9440 - acc_3: 0.9440 - val_loss_1: 0.9624 - val_loss_2: 0.9624 - val_loss_3: 0.9624 - val_acc_ensemble: 0.7621 - val_acc_1: 0.7621 - val_acc_2: 0.7621 - val_acc_3: 0.7621\n",
      "Epoch 37/50\n",
      "100/100 - 8s - loss_1: 0.0808 - loss_2: 0.0748 - loss_3: 0.0716 - acc_ensemble: 0.9460 - acc_1: 0.9460 - acc_2: 0.9460 - acc_3: 0.9460 - val_loss_1: 0.9773 - val_loss_2: 0.9773 - val_loss_3: 0.9773 - val_acc_ensemble: 0.7618 - val_acc_1: 0.7618 - val_acc_2: 0.7618 - val_acc_3: 0.7618\n",
      "Epoch 38/50\n",
      "100/100 - 8s - loss_1: 0.0942 - loss_2: 0.0878 - loss_3: 0.0805 - acc_ensemble: 0.9140 - acc_1: 0.9140 - acc_2: 0.9140 - acc_3: 0.9140 - val_loss_1: 1.0191 - val_loss_2: 1.0191 - val_loss_3: 1.0191 - val_acc_ensemble: 0.7520 - val_acc_1: 0.7520 - val_acc_2: 0.7520 - val_acc_3: 0.7520\n",
      "Epoch 39/50\n",
      "100/100 - 8s - loss_1: 0.1044 - loss_2: 0.0893 - loss_3: 0.0967 - acc_ensemble: 0.9360 - acc_1: 0.9360 - acc_2: 0.9360 - acc_3: 0.9360 - val_loss_1: 0.9971 - val_loss_2: 0.9971 - val_loss_3: 0.9971 - val_acc_ensemble: 0.7589 - val_acc_1: 0.7589 - val_acc_2: 0.7589 - val_acc_3: 0.7589\n",
      "Epoch 40/50\n",
      "100/100 - 8s - loss_1: 0.0734 - loss_2: 0.0577 - loss_3: 0.0622 - acc_ensemble: 0.9460 - acc_1: 0.9460 - acc_2: 0.9460 - acc_3: 0.9460 - val_loss_1: 0.9722 - val_loss_2: 0.9722 - val_loss_3: 0.9722 - val_acc_ensemble: 0.7657 - val_acc_1: 0.7657 - val_acc_2: 0.7657 - val_acc_3: 0.7657\n",
      "Epoch 41/50\n",
      "100/100 - 8s - loss_1: 0.0775 - loss_2: 0.0715 - loss_3: 0.0714 - acc_ensemble: 0.9340 - acc_1: 0.9340 - acc_2: 0.9340 - acc_3: 0.9340 - val_loss_1: 1.0006 - val_loss_2: 1.0006 - val_loss_3: 1.0006 - val_acc_ensemble: 0.7626 - val_acc_1: 0.7626 - val_acc_2: 0.7626 - val_acc_3: 0.7626\n",
      "Epoch 42/50\n",
      "100/100 - 8s - loss_1: 0.0661 - loss_2: 0.0722 - loss_3: 0.0676 - acc_ensemble: 0.9340 - acc_1: 0.9340 - acc_2: 0.9340 - acc_3: 0.9340 - val_loss_1: 1.0320 - val_loss_2: 1.0320 - val_loss_3: 1.0320 - val_acc_ensemble: 0.7490 - val_acc_1: 0.7490 - val_acc_2: 0.7490 - val_acc_3: 0.7490\n",
      "Epoch 43/50\n",
      "100/100 - 8s - loss_1: 0.0697 - loss_2: 0.0789 - loss_3: 0.0753 - acc_ensemble: 0.9360 - acc_1: 0.9360 - acc_2: 0.9360 - acc_3: 0.9360 - val_loss_1: 1.0479 - val_loss_2: 1.0479 - val_loss_3: 1.0479 - val_acc_ensemble: 0.7593 - val_acc_1: 0.7593 - val_acc_2: 0.7593 - val_acc_3: 0.7593\n",
      "Epoch 44/50\n",
      "100/100 - 8s - loss_1: 0.0738 - loss_2: 0.0730 - loss_3: 0.0776 - acc_ensemble: 0.9260 - acc_1: 0.9260 - acc_2: 0.9260 - acc_3: 0.9260 - val_loss_1: 1.0370 - val_loss_2: 1.0370 - val_loss_3: 1.0370 - val_acc_ensemble: 0.7592 - val_acc_1: 0.7592 - val_acc_2: 0.7592 - val_acc_3: 0.7592\n",
      "Epoch 45/50\n",
      "100/100 - 8s - loss_1: 0.0697 - loss_2: 0.0671 - loss_3: 0.0689 - acc_ensemble: 0.9320 - acc_1: 0.9320 - acc_2: 0.9320 - acc_3: 0.9320 - val_loss_1: 1.0558 - val_loss_2: 1.0558 - val_loss_3: 1.0558 - val_acc_ensemble: 0.7571 - val_acc_1: 0.7571 - val_acc_2: 0.7571 - val_acc_3: 0.7571\n",
      "Epoch 46/50\n",
      "100/100 - 8s - loss_1: 0.0621 - loss_2: 0.0641 - loss_3: 0.0693 - acc_ensemble: 0.9260 - acc_1: 0.9260 - acc_2: 0.9260 - acc_3: 0.9260 - val_loss_1: 1.0919 - val_loss_2: 1.0919 - val_loss_3: 1.0919 - val_acc_ensemble: 0.7545 - val_acc_1: 0.7545 - val_acc_2: 0.7545 - val_acc_3: 0.7545\n",
      "Epoch 47/50\n",
      "100/100 - 8s - loss_1: 0.0656 - loss_2: 0.0648 - loss_3: 0.0581 - acc_ensemble: 0.9320 - acc_1: 0.9320 - acc_2: 0.9320 - acc_3: 0.9320 - val_loss_1: 1.0767 - val_loss_2: 1.0767 - val_loss_3: 1.0767 - val_acc_ensemble: 0.7629 - val_acc_1: 0.7629 - val_acc_2: 0.7629 - val_acc_3: 0.7629\n",
      "Epoch 48/50\n",
      "100/100 - 8s - loss_1: 0.0669 - loss_2: 0.0767 - loss_3: 0.0757 - acc_ensemble: 0.9260 - acc_1: 0.9260 - acc_2: 0.9260 - acc_3: 0.9260 - val_loss_1: 1.1061 - val_loss_2: 1.1061 - val_loss_3: 1.1061 - val_acc_ensemble: 0.7588 - val_acc_1: 0.7588 - val_acc_2: 0.7588 - val_acc_3: 0.7588\n",
      "Epoch 49/50\n",
      "100/100 - 8s - loss_1: 0.0795 - loss_2: 0.0676 - loss_3: 0.0733 - acc_ensemble: 0.9300 - acc_1: 0.9300 - acc_2: 0.9300 - acc_3: 0.9300 - val_loss_1: 1.0802 - val_loss_2: 1.0802 - val_loss_3: 1.0802 - val_acc_ensemble: 0.7633 - val_acc_1: 0.7633 - val_acc_2: 0.7633 - val_acc_3: 0.7633\n",
      "Epoch 50/50\n",
      "100/100 - 8s - loss_1: 0.0632 - loss_2: 0.0608 - loss_3: 0.0733 - acc_ensemble: 0.9280 - acc_1: 0.9280 - acc_2: 0.9280 - acc_3: 0.9280 - val_loss_1: 1.1475 - val_loss_2: 1.1475 - val_loss_3: 1.1475 - val_acc_ensemble: 0.7509 - val_acc_1: 0.7509 - val_acc_2: 0.7509 - val_acc_3: 0.7509\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B3/S1.00/model_2\n",
      "i   Layer name                      Output shape        Num param  Inbound            \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                    \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                    \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                    \n",
      "--------------------------------------------------------------------------------------\n",
      "0   conv2d_1_1 (Conv2D)             [None,32,32,32] []  896        input              \n",
      "                                    [None,32,32,32] []                                \n",
      "                                    [None,32,32,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "1   bn_1_1 (BatchNormalization)     [None,32,32,32] []  64         conv2d_1_1         \n",
      "                                    [None,32,32,32] []                                \n",
      "                                    [None,32,32,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "2   relu_1_1 (Activation)           [None,32,32,32] []  0          bn_1_1             \n",
      "                                    [None,32,32,32] []                                \n",
      "                                    [None,32,32,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "3   conv2d_1_2 (Conv2D)             [None,32,32,32] []  9248       relu_1_1           \n",
      "                                    [None,32,32,32] []                                \n",
      "                                    [None,32,32,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "4   bn_1_2 (BatchNormalization)     [None,32,32,32] []  64         conv2d_1_2         \n",
      "                                    [None,32,32,32] []                                \n",
      "                                    [None,32,32,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "5   relu_1_2 (Activation)           [None,32,32,32] []  0          bn_1_2             \n",
      "                                    [None,32,32,32] []                                \n",
      "                                    [None,32,32,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "6   avg_pool2d_1 (AveragePooling2D  [None,16,16,32] []  0          relu_1_2           \n",
      "                                    [None,16,16,32] []                                \n",
      "                                    [None,16,16,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "7   conv2d_2_1 (Conv2D)             [None,16,16,64] []  18496      avg_pool2d_1       \n",
      "                                    [None,16,16,64] []                                \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "8   bn_2_1 (BatchNormalization)     [None,16,16,64] []  128        conv2d_2_1         \n",
      "                                    [None,16,16,64] []                                \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "9   relu_2_1 (Activation)           [None,16,16,64] []  0          bn_2_1             \n",
      "                                    [None,16,16,64] []                                \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "10  conv2d_2_2 (Conv2D)             [None,16,16,64] []  36928      relu_2_1           \n",
      "                                    [None,16,16,64] []                                \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "11  bn_2_2 (BatchNormalization)     [None,16,16,64] []  128        conv2d_2_2         \n",
      "                                    [None,16,16,64] []                                \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "12  relu_2_2 (Activation)           [None,16,16,64] []  0          bn_2_2             \n",
      "                                    [None,16,16,64] []                                \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "13  avg_pool2d_2 (AveragePooling2D  [None,8,8,64] []    0          relu_2_2           \n",
      "                                    [None,8,8,64] []                                  \n",
      "                                    [None,8,8,64] []                                  \n",
      "--------------------------------------------------------------------------------------\n",
      "14  conv2d_3_1 (Conv2D)             [None,8,8,128] []   73856      avg_pool2d_2       \n",
      "                                    [None,8,8,128] []                                 \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "15  bn_3_1 (BatchNormalization)     [None,8,8,128] []   256        conv2d_3_1         \n",
      "                                    [None,8,8,128] []                                 \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "16  relu_3_1 (Activation)           [None,8,8,128] []   0          bn_3_1             \n",
      "                                    [None,8,8,128] []                                 \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "17  conv2d_3_2 (Conv2D)             [None,8,8,128] []   147584     relu_3_1           \n",
      "                                    [None,8,8,128] []                                 \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "18  bn_3_2 (BatchNormalization)     [None,8,8,128] []   256        conv2d_3_2         \n",
      "                                    [None,8,8,128] []                                 \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "19  relu_3_2 (Activation)           [None,8,8,128] []   0          bn_3_2             \n",
      "                                    [None,8,8,128] []                                 \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "20  global_avg_pool2d (GlobalAvera  [None,128] []       0          relu_3_2           \n",
      "                                    [None,128] []                                     \n",
      "                                    [None,128] []                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "21  fc1 (Dense)                     [None,128] []       16512      global_avg_pool2d  \n",
      "                                    [None,128] []                                     \n",
      "                                    [None,128] []                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "22  bn_fc1 (BatchNormalization)     [None,128] []       256        fc1                \n",
      "                                    [None,128] []                                     \n",
      "                                    [None,128] []                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "23  relu_fc1 (Activation)           [None,128] []       0          bn_fc1             \n",
      "                                    [None,128] []                                     \n",
      "                                    [None,128] []                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "24  output (Dense)                  [None,10]           1290       relu_fc1           \n",
      "                                    [None,10]                                         \n",
      "                                    [None,10]                                         \n",
      "--------------------------------------------------------------------------------------\n",
      "Total parameters: 305962\n",
      "50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 - 10s - loss_1: 1.6181 - loss_2: 1.6137 - loss_3: 1.6146 - acc_ensemble: 0.5220 - acc_1: 0.5220 - acc_2: 0.5220 - acc_3: 0.5220 - val_loss_1: 1.3432 - val_loss_2: 1.3432 - val_loss_3: 1.3432 - val_acc_ensemble: 0.5100 - val_acc_1: 0.5100 - val_acc_2: 0.5100 - val_acc_3: 0.5100\n",
      "Epoch 2/50\n",
      "100/100 - 8s - loss_1: 1.2336 - loss_2: 1.2262 - loss_3: 1.2393 - acc_ensemble: 0.6340 - acc_1: 0.6340 - acc_2: 0.6340 - acc_3: 0.6340 - val_loss_1: 1.1555 - val_loss_2: 1.1555 - val_loss_3: 1.1555 - val_acc_ensemble: 0.5817 - val_acc_1: 0.5817 - val_acc_2: 0.5817 - val_acc_3: 0.5817\n",
      "Epoch 3/50\n",
      "100/100 - 8s - loss_1: 1.0770 - loss_2: 1.1008 - loss_3: 1.0851 - acc_ensemble: 0.6600 - acc_1: 0.6600 - acc_2: 0.6600 - acc_3: 0.6600 - val_loss_1: 1.0260 - val_loss_2: 1.0260 - val_loss_3: 1.0260 - val_acc_ensemble: 0.6337 - val_acc_1: 0.6337 - val_acc_2: 0.6337 - val_acc_3: 0.6337\n",
      "Epoch 4/50\n",
      "100/100 - 8s - loss_1: 0.9836 - loss_2: 0.9453 - loss_3: 0.9676 - acc_ensemble: 0.6700 - acc_1: 0.6700 - acc_2: 0.6700 - acc_3: 0.6700 - val_loss_1: 0.9912 - val_loss_2: 0.9912 - val_loss_3: 0.9912 - val_acc_ensemble: 0.6458 - val_acc_1: 0.6458 - val_acc_2: 0.6458 - val_acc_3: 0.6458\n",
      "Epoch 5/50\n",
      "100/100 - 8s - loss_1: 0.9008 - loss_2: 0.8997 - loss_3: 0.8700 - acc_ensemble: 0.6860 - acc_1: 0.6860 - acc_2: 0.6860 - acc_3: 0.6860 - val_loss_1: 0.9177 - val_loss_2: 0.9177 - val_loss_3: 0.9177 - val_acc_ensemble: 0.6740 - val_acc_1: 0.6740 - val_acc_2: 0.6740 - val_acc_3: 0.6740\n",
      "Epoch 6/50\n",
      "100/100 - 8s - loss_1: 0.7933 - loss_2: 0.8272 - loss_3: 0.8157 - acc_ensemble: 0.7320 - acc_1: 0.7320 - acc_2: 0.7320 - acc_3: 0.7320 - val_loss_1: 0.8741 - val_loss_2: 0.8741 - val_loss_3: 0.8741 - val_acc_ensemble: 0.6907 - val_acc_1: 0.6907 - val_acc_2: 0.6907 - val_acc_3: 0.6907\n",
      "Epoch 7/50\n",
      "100/100 - 8s - loss_1: 0.7552 - loss_2: 0.7312 - loss_3: 0.7403 - acc_ensemble: 0.7360 - acc_1: 0.7360 - acc_2: 0.7360 - acc_3: 0.7360 - val_loss_1: 0.8560 - val_loss_2: 0.8560 - val_loss_3: 0.8560 - val_acc_ensemble: 0.7001 - val_acc_1: 0.7001 - val_acc_2: 0.7001 - val_acc_3: 0.7001\n",
      "Epoch 8/50\n",
      "100/100 - 8s - loss_1: 0.7196 - loss_2: 0.6916 - loss_3: 0.6962 - acc_ensemble: 0.7780 - acc_1: 0.7780 - acc_2: 0.7780 - acc_3: 0.7780 - val_loss_1: 0.8220 - val_loss_2: 0.8220 - val_loss_3: 0.8220 - val_acc_ensemble: 0.7145 - val_acc_1: 0.7145 - val_acc_2: 0.7145 - val_acc_3: 0.7145\n",
      "Epoch 9/50\n",
      "100/100 - 8s - loss_1: 0.6280 - loss_2: 0.6312 - loss_3: 0.6485 - acc_ensemble: 0.7980 - acc_1: 0.7980 - acc_2: 0.7980 - acc_3: 0.7980 - val_loss_1: 0.8007 - val_loss_2: 0.8007 - val_loss_3: 0.8007 - val_acc_ensemble: 0.7206 - val_acc_1: 0.7206 - val_acc_2: 0.7206 - val_acc_3: 0.7206\n",
      "Epoch 10/50\n",
      "100/100 - 8s - loss_1: 0.5911 - loss_2: 0.6050 - loss_3: 0.5748 - acc_ensemble: 0.7860 - acc_1: 0.7860 - acc_2: 0.7860 - acc_3: 0.7860 - val_loss_1: 0.7684 - val_loss_2: 0.7684 - val_loss_3: 0.7684 - val_acc_ensemble: 0.7356 - val_acc_1: 0.7356 - val_acc_2: 0.7356 - val_acc_3: 0.7356\n",
      "Epoch 11/50\n",
      "100/100 - 8s - loss_1: 0.5599 - loss_2: 0.5191 - loss_3: 0.5466 - acc_ensemble: 0.8380 - acc_1: 0.8380 - acc_2: 0.8380 - acc_3: 0.8380 - val_loss_1: 0.7863 - val_loss_2: 0.7863 - val_loss_3: 0.7863 - val_acc_ensemble: 0.7310 - val_acc_1: 0.7310 - val_acc_2: 0.7310 - val_acc_3: 0.7310\n",
      "Epoch 12/50\n",
      "100/100 - 8s - loss_1: 0.5110 - loss_2: 0.5075 - loss_3: 0.5075 - acc_ensemble: 0.8240 - acc_1: 0.8240 - acc_2: 0.8240 - acc_3: 0.8240 - val_loss_1: 0.7901 - val_loss_2: 0.7901 - val_loss_3: 0.7901 - val_acc_ensemble: 0.7333 - val_acc_1: 0.7333 - val_acc_2: 0.7333 - val_acc_3: 0.7333\n",
      "Epoch 13/50\n",
      "100/100 - 8s - loss_1: 0.4694 - loss_2: 0.4780 - loss_3: 0.4757 - acc_ensemble: 0.8320 - acc_1: 0.8320 - acc_2: 0.8320 - acc_3: 0.8320 - val_loss_1: 0.7821 - val_loss_2: 0.7821 - val_loss_3: 0.7821 - val_acc_ensemble: 0.7354 - val_acc_1: 0.7354 - val_acc_2: 0.7354 - val_acc_3: 0.7354\n",
      "Epoch 14/50\n",
      "100/100 - 8s - loss_1: 0.4421 - loss_2: 0.4256 - loss_3: 0.4206 - acc_ensemble: 0.8500 - acc_1: 0.8500 - acc_2: 0.8500 - acc_3: 0.8500 - val_loss_1: 0.7707 - val_loss_2: 0.7707 - val_loss_3: 0.7707 - val_acc_ensemble: 0.7426 - val_acc_1: 0.7426 - val_acc_2: 0.7426 - val_acc_3: 0.7426\n",
      "Epoch 15/50\n",
      "100/100 - 8s - loss_1: 0.4144 - loss_2: 0.3856 - loss_3: 0.3862 - acc_ensemble: 0.8720 - acc_1: 0.8720 - acc_2: 0.8720 - acc_3: 0.8720 - val_loss_1: 0.7559 - val_loss_2: 0.7559 - val_loss_3: 0.7559 - val_acc_ensemble: 0.7495 - val_acc_1: 0.7495 - val_acc_2: 0.7495 - val_acc_3: 0.7495\n",
      "Epoch 16/50\n",
      "100/100 - 8s - loss_1: 0.3823 - loss_2: 0.3823 - loss_3: 0.3795 - acc_ensemble: 0.8720 - acc_1: 0.8720 - acc_2: 0.8720 - acc_3: 0.8720 - val_loss_1: 0.7574 - val_loss_2: 0.7574 - val_loss_3: 0.7574 - val_acc_ensemble: 0.7524 - val_acc_1: 0.7524 - val_acc_2: 0.7524 - val_acc_3: 0.7524\n",
      "Epoch 17/50\n",
      "100/100 - 8s - loss_1: 0.3407 - loss_2: 0.3477 - loss_3: 0.3725 - acc_ensemble: 0.8720 - acc_1: 0.8720 - acc_2: 0.8720 - acc_3: 0.8720 - val_loss_1: 0.7673 - val_loss_2: 0.7673 - val_loss_3: 0.7673 - val_acc_ensemble: 0.7499 - val_acc_1: 0.7499 - val_acc_2: 0.7499 - val_acc_3: 0.7499\n",
      "Epoch 18/50\n",
      "100/100 - 8s - loss_1: 0.3149 - loss_2: 0.3059 - loss_3: 0.3003 - acc_ensemble: 0.8760 - acc_1: 0.8760 - acc_2: 0.8760 - acc_3: 0.8760 - val_loss_1: 0.7696 - val_loss_2: 0.7696 - val_loss_3: 0.7696 - val_acc_ensemble: 0.7535 - val_acc_1: 0.7535 - val_acc_2: 0.7535 - val_acc_3: 0.7535\n",
      "Epoch 19/50\n",
      "100/100 - 8s - loss_1: 0.3059 - loss_2: 0.2873 - loss_3: 0.3003 - acc_ensemble: 0.8900 - acc_1: 0.8900 - acc_2: 0.8900 - acc_3: 0.8900 - val_loss_1: 0.7467 - val_loss_2: 0.7467 - val_loss_3: 0.7467 - val_acc_ensemble: 0.7631 - val_acc_1: 0.7631 - val_acc_2: 0.7631 - val_acc_3: 0.7631\n",
      "Epoch 20/50\n",
      "100/100 - 8s - loss_1: 0.2634 - loss_2: 0.2490 - loss_3: 0.2826 - acc_ensemble: 0.8840 - acc_1: 0.8840 - acc_2: 0.8840 - acc_3: 0.8840 - val_loss_1: 0.7875 - val_loss_2: 0.7875 - val_loss_3: 0.7875 - val_acc_ensemble: 0.7507 - val_acc_1: 0.7507 - val_acc_2: 0.7507 - val_acc_3: 0.7507\n",
      "Epoch 21/50\n",
      "100/100 - 8s - loss_1: 0.2418 - loss_2: 0.2411 - loss_3: 0.2314 - acc_ensemble: 0.9060 - acc_1: 0.9060 - acc_2: 0.9060 - acc_3: 0.9060 - val_loss_1: 0.7984 - val_loss_2: 0.7984 - val_loss_3: 0.7984 - val_acc_ensemble: 0.7535 - val_acc_1: 0.7535 - val_acc_2: 0.7535 - val_acc_3: 0.7535\n",
      "Epoch 22/50\n",
      "100/100 - 8s - loss_1: 0.2394 - loss_2: 0.2215 - loss_3: 0.2200 - acc_ensemble: 0.9200 - acc_1: 0.9200 - acc_2: 0.9200 - acc_3: 0.9200 - val_loss_1: 0.8016 - val_loss_2: 0.8016 - val_loss_3: 0.8016 - val_acc_ensemble: 0.7572 - val_acc_1: 0.7572 - val_acc_2: 0.7572 - val_acc_3: 0.7572\n",
      "Epoch 23/50\n",
      "100/100 - 8s - loss_1: 0.2213 - loss_2: 0.2151 - loss_3: 0.2183 - acc_ensemble: 0.9020 - acc_1: 0.9020 - acc_2: 0.9020 - acc_3: 0.9020 - val_loss_1: 0.8204 - val_loss_2: 0.8204 - val_loss_3: 0.8204 - val_acc_ensemble: 0.7542 - val_acc_1: 0.7542 - val_acc_2: 0.7542 - val_acc_3: 0.7542\n",
      "Epoch 24/50\n",
      "100/100 - 8s - loss_1: 0.2011 - loss_2: 0.2152 - loss_3: 0.2032 - acc_ensemble: 0.9200 - acc_1: 0.9200 - acc_2: 0.9200 - acc_3: 0.9200 - val_loss_1: 0.8260 - val_loss_2: 0.8260 - val_loss_3: 0.8260 - val_acc_ensemble: 0.7608 - val_acc_1: 0.7608 - val_acc_2: 0.7608 - val_acc_3: 0.7608\n",
      "Epoch 25/50\n",
      "100/100 - 8s - loss_1: 0.1763 - loss_2: 0.1839 - loss_3: 0.1805 - acc_ensemble: 0.9120 - acc_1: 0.9120 - acc_2: 0.9120 - acc_3: 0.9120 - val_loss_1: 0.8481 - val_loss_2: 0.8481 - val_loss_3: 0.8481 - val_acc_ensemble: 0.7591 - val_acc_1: 0.7591 - val_acc_2: 0.7591 - val_acc_3: 0.7591\n",
      "Epoch 26/50\n",
      "100/100 - 8s - loss_1: 0.1772 - loss_2: 0.1648 - loss_3: 0.1769 - acc_ensemble: 0.9220 - acc_1: 0.9220 - acc_2: 0.9220 - acc_3: 0.9220 - val_loss_1: 0.8566 - val_loss_2: 0.8566 - val_loss_3: 0.8566 - val_acc_ensemble: 0.7599 - val_acc_1: 0.7599 - val_acc_2: 0.7599 - val_acc_3: 0.7599\n",
      "Epoch 27/50\n",
      "100/100 - 8s - loss_1: 0.1576 - loss_2: 0.1509 - loss_3: 0.1603 - acc_ensemble: 0.9380 - acc_1: 0.9380 - acc_2: 0.9380 - acc_3: 0.9380 - val_loss_1: 0.8507 - val_loss_2: 0.8507 - val_loss_3: 0.8507 - val_acc_ensemble: 0.7611 - val_acc_1: 0.7611 - val_acc_2: 0.7611 - val_acc_3: 0.7611\n",
      "Epoch 28/50\n",
      "100/100 - 8s - loss_1: 0.1503 - loss_2: 0.1573 - loss_3: 0.1567 - acc_ensemble: 0.9280 - acc_1: 0.9280 - acc_2: 0.9280 - acc_3: 0.9280 - val_loss_1: 0.8723 - val_loss_2: 0.8723 - val_loss_3: 0.8723 - val_acc_ensemble: 0.7565 - val_acc_1: 0.7565 - val_acc_2: 0.7565 - val_acc_3: 0.7565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50\n",
      "100/100 - 8s - loss_1: 0.1417 - loss_2: 0.1478 - loss_3: 0.1307 - acc_ensemble: 0.9200 - acc_1: 0.9200 - acc_2: 0.9200 - acc_3: 0.9200 - val_loss_1: 0.8818 - val_loss_2: 0.8818 - val_loss_3: 0.8818 - val_acc_ensemble: 0.7633 - val_acc_1: 0.7633 - val_acc_2: 0.7633 - val_acc_3: 0.7633\n",
      "Epoch 30/50\n",
      "100/100 - 8s - loss_1: 0.1235 - loss_2: 0.1254 - loss_3: 0.1418 - acc_ensemble: 0.9220 - acc_1: 0.9220 - acc_2: 0.9220 - acc_3: 0.9220 - val_loss_1: 0.8976 - val_loss_2: 0.8976 - val_loss_3: 0.8976 - val_acc_ensemble: 0.7622 - val_acc_1: 0.7622 - val_acc_2: 0.7622 - val_acc_3: 0.7622\n",
      "Epoch 31/50\n",
      "100/100 - 8s - loss_1: 0.1192 - loss_2: 0.1080 - loss_3: 0.1237 - acc_ensemble: 0.9240 - acc_1: 0.9240 - acc_2: 0.9240 - acc_3: 0.9240 - val_loss_1: 0.8910 - val_loss_2: 0.8910 - val_loss_3: 0.8910 - val_acc_ensemble: 0.7617 - val_acc_1: 0.7617 - val_acc_2: 0.7617 - val_acc_3: 0.7617\n",
      "Epoch 32/50\n",
      "100/100 - 8s - loss_1: 0.1051 - loss_2: 0.1026 - loss_3: 0.1099 - acc_ensemble: 0.9380 - acc_1: 0.9380 - acc_2: 0.9380 - acc_3: 0.9380 - val_loss_1: 0.9284 - val_loss_2: 0.9284 - val_loss_3: 0.9284 - val_acc_ensemble: 0.7577 - val_acc_1: 0.7577 - val_acc_2: 0.7577 - val_acc_3: 0.7577\n",
      "Epoch 33/50\n",
      "100/100 - 8s - loss_1: 0.1092 - loss_2: 0.1153 - loss_3: 0.1072 - acc_ensemble: 0.9220 - acc_1: 0.9220 - acc_2: 0.9220 - acc_3: 0.9220 - val_loss_1: 0.9402 - val_loss_2: 0.9402 - val_loss_3: 0.9402 - val_acc_ensemble: 0.7587 - val_acc_1: 0.7587 - val_acc_2: 0.7587 - val_acc_3: 0.7587\n",
      "Epoch 34/50\n",
      "100/100 - 8s - loss_1: 0.0988 - loss_2: 0.0943 - loss_3: 0.0939 - acc_ensemble: 0.9360 - acc_1: 0.9360 - acc_2: 0.9360 - acc_3: 0.9360 - val_loss_1: 0.9382 - val_loss_2: 0.9382 - val_loss_3: 0.9382 - val_acc_ensemble: 0.7602 - val_acc_1: 0.7602 - val_acc_2: 0.7602 - val_acc_3: 0.7602\n",
      "Epoch 35/50\n",
      "100/100 - 8s - loss_1: 0.0979 - loss_2: 0.0942 - loss_3: 0.0896 - acc_ensemble: 0.9400 - acc_1: 0.9400 - acc_2: 0.9400 - acc_3: 0.9400 - val_loss_1: 0.9825 - val_loss_2: 0.9825 - val_loss_3: 0.9825 - val_acc_ensemble: 0.7552 - val_acc_1: 0.7552 - val_acc_2: 0.7552 - val_acc_3: 0.7552\n",
      "Epoch 36/50\n",
      "100/100 - 8s - loss_1: 0.0992 - loss_2: 0.1011 - loss_3: 0.1033 - acc_ensemble: 0.9600 - acc_1: 0.9600 - acc_2: 0.9600 - acc_3: 0.9600 - val_loss_1: 0.9724 - val_loss_2: 0.9724 - val_loss_3: 0.9724 - val_acc_ensemble: 0.7663 - val_acc_1: 0.7663 - val_acc_2: 0.7663 - val_acc_3: 0.7663\n",
      "Epoch 37/50\n",
      "100/100 - 8s - loss_1: 0.0831 - loss_2: 0.0824 - loss_3: 0.0961 - acc_ensemble: 0.9440 - acc_1: 0.9440 - acc_2: 0.9440 - acc_3: 0.9440 - val_loss_1: 0.9718 - val_loss_2: 0.9718 - val_loss_3: 0.9718 - val_acc_ensemble: 0.7662 - val_acc_1: 0.7662 - val_acc_2: 0.7662 - val_acc_3: 0.7662\n",
      "Epoch 38/50\n",
      "100/100 - 8s - loss_1: 0.0827 - loss_2: 0.0693 - loss_3: 0.0876 - acc_ensemble: 0.9360 - acc_1: 0.9360 - acc_2: 0.9360 - acc_3: 0.9360 - val_loss_1: 1.0259 - val_loss_2: 1.0259 - val_loss_3: 1.0259 - val_acc_ensemble: 0.7584 - val_acc_1: 0.7584 - val_acc_2: 0.7584 - val_acc_3: 0.7584\n",
      "Epoch 39/50\n",
      "100/100 - 8s - loss_1: 0.0765 - loss_2: 0.0687 - loss_3: 0.0764 - acc_ensemble: 0.9340 - acc_1: 0.9340 - acc_2: 0.9340 - acc_3: 0.9340 - val_loss_1: 1.0101 - val_loss_2: 1.0101 - val_loss_3: 1.0101 - val_acc_ensemble: 0.7630 - val_acc_1: 0.7630 - val_acc_2: 0.7630 - val_acc_3: 0.7630\n",
      "Epoch 40/50\n",
      "100/100 - 8s - loss_1: 0.0847 - loss_2: 0.0789 - loss_3: 0.0715 - acc_ensemble: 0.9520 - acc_1: 0.9520 - acc_2: 0.9520 - acc_3: 0.9520 - val_loss_1: 0.9982 - val_loss_2: 0.9982 - val_loss_3: 0.9982 - val_acc_ensemble: 0.7618 - val_acc_1: 0.7618 - val_acc_2: 0.7618 - val_acc_3: 0.7618\n",
      "Epoch 41/50\n",
      "100/100 - 8s - loss_1: 0.0727 - loss_2: 0.0761 - loss_3: 0.0850 - acc_ensemble: 0.9540 - acc_1: 0.9540 - acc_2: 0.9540 - acc_3: 0.9540 - val_loss_1: 1.0160 - val_loss_2: 1.0160 - val_loss_3: 1.0160 - val_acc_ensemble: 0.7533 - val_acc_1: 0.7533 - val_acc_2: 0.7533 - val_acc_3: 0.7533\n",
      "Epoch 42/50\n",
      "100/100 - 8s - loss_1: 0.0774 - loss_2: 0.0717 - loss_3: 0.0756 - acc_ensemble: 0.9480 - acc_1: 0.9480 - acc_2: 0.9480 - acc_3: 0.9480 - val_loss_1: 1.0327 - val_loss_2: 1.0327 - val_loss_3: 1.0327 - val_acc_ensemble: 0.7614 - val_acc_1: 0.7614 - val_acc_2: 0.7614 - val_acc_3: 0.7614\n",
      "Epoch 43/50\n",
      "100/100 - 8s - loss_1: 0.0629 - loss_2: 0.0664 - loss_3: 0.0696 - acc_ensemble: 0.9420 - acc_1: 0.9420 - acc_2: 0.9420 - acc_3: 0.9420 - val_loss_1: 1.0281 - val_loss_2: 1.0281 - val_loss_3: 1.0281 - val_acc_ensemble: 0.7650 - val_acc_1: 0.7650 - val_acc_2: 0.7650 - val_acc_3: 0.7650\n",
      "Epoch 44/50\n",
      "100/100 - 8s - loss_1: 0.0659 - loss_2: 0.0680 - loss_3: 0.0760 - acc_ensemble: 0.9480 - acc_1: 0.9480 - acc_2: 0.9480 - acc_3: 0.9480 - val_loss_1: 1.0545 - val_loss_2: 1.0545 - val_loss_3: 1.0545 - val_acc_ensemble: 0.7631 - val_acc_1: 0.7631 - val_acc_2: 0.7631 - val_acc_3: 0.7631\n",
      "Epoch 45/50\n",
      "100/100 - 8s - loss_1: 0.0669 - loss_2: 0.0722 - loss_3: 0.0696 - acc_ensemble: 0.9500 - acc_1: 0.9500 - acc_2: 0.9500 - acc_3: 0.9500 - val_loss_1: 1.0414 - val_loss_2: 1.0414 - val_loss_3: 1.0414 - val_acc_ensemble: 0.7649 - val_acc_1: 0.7649 - val_acc_2: 0.7649 - val_acc_3: 0.7649\n",
      "Epoch 46/50\n",
      "100/100 - 8s - loss_1: 0.0729 - loss_2: 0.0637 - loss_3: 0.0722 - acc_ensemble: 0.9400 - acc_1: 0.9400 - acc_2: 0.9400 - acc_3: 0.9400 - val_loss_1: 1.0723 - val_loss_2: 1.0723 - val_loss_3: 1.0723 - val_acc_ensemble: 0.7624 - val_acc_1: 0.7624 - val_acc_2: 0.7624 - val_acc_3: 0.7624\n",
      "Epoch 47/50\n",
      "100/100 - 8s - loss_1: 0.0650 - loss_2: 0.0588 - loss_3: 0.0743 - acc_ensemble: 0.9580 - acc_1: 0.9580 - acc_2: 0.9580 - acc_3: 0.9580 - val_loss_1: 1.0807 - val_loss_2: 1.0807 - val_loss_3: 1.0807 - val_acc_ensemble: 0.7646 - val_acc_1: 0.7646 - val_acc_2: 0.7646 - val_acc_3: 0.7646\n",
      "Epoch 48/50\n",
      "100/100 - 8s - loss_1: 0.0704 - loss_2: 0.0540 - loss_3: 0.0672 - acc_ensemble: 0.9380 - acc_1: 0.9380 - acc_2: 0.9380 - acc_3: 0.9380 - val_loss_1: 1.0969 - val_loss_2: 1.0969 - val_loss_3: 1.0969 - val_acc_ensemble: 0.7609 - val_acc_1: 0.7609 - val_acc_2: 0.7609 - val_acc_3: 0.7609\n",
      "Epoch 49/50\n",
      "100/100 - 8s - loss_1: 0.0500 - loss_2: 0.0469 - loss_3: 0.0521 - acc_ensemble: 0.9560 - acc_1: 0.9560 - acc_2: 0.9560 - acc_3: 0.9560 - val_loss_1: 1.0453 - val_loss_2: 1.0453 - val_loss_3: 1.0453 - val_acc_ensemble: 0.7747 - val_acc_1: 0.7747 - val_acc_2: 0.7747 - val_acc_3: 0.7747\n",
      "Epoch 50/50\n",
      "100/100 - 8s - loss_1: 0.0542 - loss_2: 0.0561 - loss_3: 0.0517 - acc_ensemble: 0.9380 - acc_1: 0.9380 - acc_2: 0.9380 - acc_3: 0.9380 - val_loss_1: 1.0994 - val_loss_2: 1.0994 - val_loss_3: 1.0994 - val_acc_ensemble: 0.7648 - val_acc_1: 0.7648 - val_acc_2: 0.7648 - val_acc_3: 0.7648\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B3/S1.00/model_3\n",
      "i   Layer name                      Output shape        Num param  Inbound            \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                    \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                    \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                    \n",
      "--------------------------------------------------------------------------------------\n",
      "0   conv2d_1_1 (Conv2D)             [None,32,32,32] []  896        input              \n",
      "                                    [None,32,32,32] []                                \n",
      "                                    [None,32,32,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "1   bn_1_1 (BatchNormalization)     [None,32,32,32] []  64         conv2d_1_1         \n",
      "                                    [None,32,32,32] []                                \n",
      "                                    [None,32,32,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "2   relu_1_1 (Activation)           [None,32,32,32] []  0          bn_1_1             \n",
      "                                    [None,32,32,32] []                                \n",
      "                                    [None,32,32,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "3   conv2d_1_2 (Conv2D)             [None,32,32,32] []  9248       relu_1_1           \n",
      "                                    [None,32,32,32] []                                \n",
      "                                    [None,32,32,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "4   bn_1_2 (BatchNormalization)     [None,32,32,32] []  64         conv2d_1_2         \n",
      "                                    [None,32,32,32] []                                \n",
      "                                    [None,32,32,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "5   relu_1_2 (Activation)           [None,32,32,32] []  0          bn_1_2             \n",
      "                                    [None,32,32,32] []                                \n",
      "                                    [None,32,32,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "6   avg_pool2d_1 (AveragePooling2D  [None,16,16,32] []  0          relu_1_2           \n",
      "                                    [None,16,16,32] []                                \n",
      "                                    [None,16,16,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "7   conv2d_2_1 (Conv2D)             [None,16,16,64] []  18496      avg_pool2d_1       \n",
      "                                    [None,16,16,64] []                                \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "8   bn_2_1 (BatchNormalization)     [None,16,16,64] []  128        conv2d_2_1         \n",
      "                                    [None,16,16,64] []                                \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "9   relu_2_1 (Activation)           [None,16,16,64] []  0          bn_2_1             \n",
      "                                    [None,16,16,64] []                                \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "10  conv2d_2_2 (Conv2D)             [None,16,16,64] []  36928      relu_2_1           \n",
      "                                    [None,16,16,64] []                                \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "11  bn_2_2 (BatchNormalization)     [None,16,16,64] []  128        conv2d_2_2         \n",
      "                                    [None,16,16,64] []                                \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "12  relu_2_2 (Activation)           [None,16,16,64] []  0          bn_2_2             \n",
      "                                    [None,16,16,64] []                                \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "13  avg_pool2d_2 (AveragePooling2D  [None,8,8,64] []    0          relu_2_2           \n",
      "                                    [None,8,8,64] []                                  \n",
      "                                    [None,8,8,64] []                                  \n",
      "--------------------------------------------------------------------------------------\n",
      "14  conv2d_3_1 (Conv2D)             [None,8,8,128] []   73856      avg_pool2d_2       \n",
      "                                    [None,8,8,128] []                                 \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "15  bn_3_1 (BatchNormalization)     [None,8,8,128] []   256        conv2d_3_1         \n",
      "                                    [None,8,8,128] []                                 \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "16  relu_3_1 (Activation)           [None,8,8,128] []   0          bn_3_1             \n",
      "                                    [None,8,8,128] []                                 \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "17  conv2d_3_2 (Conv2D)             [None,8,8,128] []   147584     relu_3_1           \n",
      "                                    [None,8,8,128] []                                 \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "18  bn_3_2 (BatchNormalization)     [None,8,8,128] []   256        conv2d_3_2         \n",
      "                                    [None,8,8,128] []                                 \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "19  relu_3_2 (Activation)           [None,8,8,128] []   0          bn_3_2             \n",
      "                                    [None,8,8,128] []                                 \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "20  global_avg_pool2d (GlobalAvera  [None,128] []       0          relu_3_2           \n",
      "                                    [None,128] []                                     \n",
      "                                    [None,128] []                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "21  fc1 (Dense)                     [None,128] []       16512      global_avg_pool2d  \n",
      "                                    [None,128] []                                     \n",
      "                                    [None,128] []                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "22  bn_fc1 (BatchNormalization)     [None,128] []       256        fc1                \n",
      "                                    [None,128] []                                     \n",
      "                                    [None,128] []                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "23  relu_fc1 (Activation)           [None,128] []       0          bn_fc1             \n",
      "                                    [None,128] []                                     \n",
      "                                    [None,128] []                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "24  output (Dense)                  [None,10]           1290       relu_fc1           \n",
      "                                    [None,10]                                         \n",
      "                                    [None,10]                                         \n",
      "--------------------------------------------------------------------------------------\n",
      "Total parameters: 305962\n",
      "50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 - 10s - loss_1: 1.5990 - loss_2: 1.5962 - loss_3: 1.6149 - acc_ensemble: 0.5340 - acc_1: 0.5340 - acc_2: 0.5340 - acc_3: 0.5340 - val_loss_1: 1.3425 - val_loss_2: 1.3425 - val_loss_3: 1.3425 - val_acc_ensemble: 0.5145 - val_acc_1: 0.5145 - val_acc_2: 0.5145 - val_acc_3: 0.5145\n",
      "Epoch 2/50\n",
      "100/100 - 8s - loss_1: 1.2423 - loss_2: 1.2245 - loss_3: 1.2609 - acc_ensemble: 0.6160 - acc_1: 0.6160 - acc_2: 0.6160 - acc_3: 0.6160 - val_loss_1: 1.1627 - val_loss_2: 1.1627 - val_loss_3: 1.1627 - val_acc_ensemble: 0.5888 - val_acc_1: 0.5888 - val_acc_2: 0.5888 - val_acc_3: 0.5888\n",
      "Epoch 3/50\n",
      "100/100 - 8s - loss_1: 1.0778 - loss_2: 1.0571 - loss_3: 1.0810 - acc_ensemble: 0.6660 - acc_1: 0.6660 - acc_2: 0.6660 - acc_3: 0.6660 - val_loss_1: 1.0346 - val_loss_2: 1.0346 - val_loss_3: 1.0346 - val_acc_ensemble: 0.6292 - val_acc_1: 0.6292 - val_acc_2: 0.6292 - val_acc_3: 0.6292\n",
      "Epoch 4/50\n",
      "100/100 - 8s - loss_1: 0.9664 - loss_2: 0.9328 - loss_3: 0.9520 - acc_ensemble: 0.7100 - acc_1: 0.7100 - acc_2: 0.7100 - acc_3: 0.7100 - val_loss_1: 0.9725 - val_loss_2: 0.9725 - val_loss_3: 0.9725 - val_acc_ensemble: 0.6576 - val_acc_1: 0.6576 - val_acc_2: 0.6576 - val_acc_3: 0.6576\n",
      "Epoch 5/50\n",
      "100/100 - 8s - loss_1: 0.8601 - loss_2: 0.8467 - loss_3: 0.8587 - acc_ensemble: 0.7380 - acc_1: 0.7380 - acc_2: 0.7380 - acc_3: 0.7380 - val_loss_1: 0.8881 - val_loss_2: 0.8881 - val_loss_3: 0.8881 - val_acc_ensemble: 0.6827 - val_acc_1: 0.6827 - val_acc_2: 0.6827 - val_acc_3: 0.6827\n",
      "Epoch 6/50\n",
      "100/100 - 8s - loss_1: 0.7712 - loss_2: 0.7964 - loss_3: 0.8135 - acc_ensemble: 0.7380 - acc_1: 0.7380 - acc_2: 0.7380 - acc_3: 0.7380 - val_loss_1: 0.8681 - val_loss_2: 0.8681 - val_loss_3: 0.8681 - val_acc_ensemble: 0.6908 - val_acc_1: 0.6908 - val_acc_2: 0.6908 - val_acc_3: 0.6908\n",
      "Epoch 7/50\n",
      "100/100 - 8s - loss_1: 0.7504 - loss_2: 0.7189 - loss_3: 0.7319 - acc_ensemble: 0.7720 - acc_1: 0.7720 - acc_2: 0.7720 - acc_3: 0.7720 - val_loss_1: 0.8306 - val_loss_2: 0.8306 - val_loss_3: 0.8306 - val_acc_ensemble: 0.7063 - val_acc_1: 0.7063 - val_acc_2: 0.7063 - val_acc_3: 0.7063\n",
      "Epoch 8/50\n",
      "100/100 - 9s - loss_1: 0.6423 - loss_2: 0.6577 - loss_3: 0.6608 - acc_ensemble: 0.7980 - acc_1: 0.7980 - acc_2: 0.7980 - acc_3: 0.7980 - val_loss_1: 0.8075 - val_loss_2: 0.8075 - val_loss_3: 0.8075 - val_acc_ensemble: 0.7171 - val_acc_1: 0.7171 - val_acc_2: 0.7171 - val_acc_3: 0.7171\n",
      "Epoch 9/50\n",
      "100/100 - 8s - loss_1: 0.6257 - loss_2: 0.6244 - loss_3: 0.6387 - acc_ensemble: 0.7940 - acc_1: 0.7940 - acc_2: 0.7940 - acc_3: 0.7940 - val_loss_1: 0.7822 - val_loss_2: 0.7822 - val_loss_3: 0.7822 - val_acc_ensemble: 0.7240 - val_acc_1: 0.7240 - val_acc_2: 0.7240 - val_acc_3: 0.7240\n",
      "Epoch 10/50\n",
      "100/100 - 8s - loss_1: 0.5877 - loss_2: 0.5874 - loss_3: 0.5653 - acc_ensemble: 0.7980 - acc_1: 0.7980 - acc_2: 0.7980 - acc_3: 0.7980 - val_loss_1: 0.7982 - val_loss_2: 0.7982 - val_loss_3: 0.7982 - val_acc_ensemble: 0.7261 - val_acc_1: 0.7261 - val_acc_2: 0.7261 - val_acc_3: 0.7261\n",
      "Epoch 11/50\n",
      "100/100 - 8s - loss_1: 0.5335 - loss_2: 0.5319 - loss_3: 0.5421 - acc_ensemble: 0.8240 - acc_1: 0.8240 - acc_2: 0.8240 - acc_3: 0.8240 - val_loss_1: 0.7658 - val_loss_2: 0.7658 - val_loss_3: 0.7658 - val_acc_ensemble: 0.7368 - val_acc_1: 0.7368 - val_acc_2: 0.7368 - val_acc_3: 0.7368\n",
      "Epoch 12/50\n",
      "100/100 - 9s - loss_1: 0.4908 - loss_2: 0.4792 - loss_3: 0.4901 - acc_ensemble: 0.8200 - acc_1: 0.8200 - acc_2: 0.8200 - acc_3: 0.8200 - val_loss_1: 0.7678 - val_loss_2: 0.7678 - val_loss_3: 0.7678 - val_acc_ensemble: 0.7401 - val_acc_1: 0.7401 - val_acc_2: 0.7401 - val_acc_3: 0.7401\n",
      "Epoch 13/50\n",
      "100/100 - 8s - loss_1: 0.4548 - loss_2: 0.4549 - loss_3: 0.4566 - acc_ensemble: 0.8240 - acc_1: 0.8240 - acc_2: 0.8240 - acc_3: 0.8240 - val_loss_1: 0.7654 - val_loss_2: 0.7654 - val_loss_3: 0.7654 - val_acc_ensemble: 0.7433 - val_acc_1: 0.7433 - val_acc_2: 0.7433 - val_acc_3: 0.7433\n",
      "Epoch 14/50\n",
      "100/100 - 8s - loss_1: 0.4249 - loss_2: 0.4019 - loss_3: 0.4150 - acc_ensemble: 0.8360 - acc_1: 0.8360 - acc_2: 0.8360 - acc_3: 0.8360 - val_loss_1: 0.7596 - val_loss_2: 0.7596 - val_loss_3: 0.7596 - val_acc_ensemble: 0.7486 - val_acc_1: 0.7486 - val_acc_2: 0.7486 - val_acc_3: 0.7486\n",
      "Epoch 15/50\n",
      "100/100 - 8s - loss_1: 0.3937 - loss_2: 0.3864 - loss_3: 0.3904 - acc_ensemble: 0.8520 - acc_1: 0.8520 - acc_2: 0.8520 - acc_3: 0.8520 - val_loss_1: 0.7426 - val_loss_2: 0.7426 - val_loss_3: 0.7426 - val_acc_ensemble: 0.7566 - val_acc_1: 0.7566 - val_acc_2: 0.7566 - val_acc_3: 0.7566\n",
      "Epoch 16/50\n",
      "100/100 - 8s - loss_1: 0.3462 - loss_2: 0.3408 - loss_3: 0.3639 - acc_ensemble: 0.8640 - acc_1: 0.8640 - acc_2: 0.8640 - acc_3: 0.8640 - val_loss_1: 0.7623 - val_loss_2: 0.7623 - val_loss_3: 0.7623 - val_acc_ensemble: 0.7515 - val_acc_1: 0.7515 - val_acc_2: 0.7515 - val_acc_3: 0.7515\n",
      "Epoch 17/50\n",
      "100/100 - 8s - loss_1: 0.3703 - loss_2: 0.3504 - loss_3: 0.3284 - acc_ensemble: 0.8760 - acc_1: 0.8760 - acc_2: 0.8760 - acc_3: 0.8760 - val_loss_1: 0.7710 - val_loss_2: 0.7710 - val_loss_3: 0.7710 - val_acc_ensemble: 0.7554 - val_acc_1: 0.7554 - val_acc_2: 0.7554 - val_acc_3: 0.7554\n",
      "Epoch 18/50\n",
      "100/100 - 9s - loss_1: 0.3163 - loss_2: 0.3028 - loss_3: 0.3062 - acc_ensemble: 0.8780 - acc_1: 0.8780 - acc_2: 0.8780 - acc_3: 0.8780 - val_loss_1: 0.7645 - val_loss_2: 0.7645 - val_loss_3: 0.7645 - val_acc_ensemble: 0.7567 - val_acc_1: 0.7567 - val_acc_2: 0.7567 - val_acc_3: 0.7567\n",
      "Epoch 19/50\n",
      "100/100 - 8s - loss_1: 0.2446 - loss_2: 0.2708 - loss_3: 0.2726 - acc_ensemble: 0.8760 - acc_1: 0.8760 - acc_2: 0.8760 - acc_3: 0.8760 - val_loss_1: 0.7688 - val_loss_2: 0.7688 - val_loss_3: 0.7688 - val_acc_ensemble: 0.7585 - val_acc_1: 0.7585 - val_acc_2: 0.7585 - val_acc_3: 0.7585\n",
      "Epoch 20/50\n",
      "100/100 - 9s - loss_1: 0.2824 - loss_2: 0.2819 - loss_3: 0.2693 - acc_ensemble: 0.8800 - acc_1: 0.8800 - acc_2: 0.8800 - acc_3: 0.8800 - val_loss_1: 0.7943 - val_loss_2: 0.7943 - val_loss_3: 0.7943 - val_acc_ensemble: 0.7554 - val_acc_1: 0.7554 - val_acc_2: 0.7554 - val_acc_3: 0.7554\n",
      "Epoch 21/50\n",
      "100/100 - 8s - loss_1: 0.2326 - loss_2: 0.2526 - loss_3: 0.2478 - acc_ensemble: 0.8780 - acc_1: 0.8780 - acc_2: 0.8780 - acc_3: 0.8780 - val_loss_1: 0.7798 - val_loss_2: 0.7798 - val_loss_3: 0.7798 - val_acc_ensemble: 0.7599 - val_acc_1: 0.7599 - val_acc_2: 0.7599 - val_acc_3: 0.7599\n",
      "Epoch 22/50\n",
      "100/100 - 9s - loss_1: 0.2297 - loss_2: 0.2250 - loss_3: 0.2236 - acc_ensemble: 0.8960 - acc_1: 0.8960 - acc_2: 0.8960 - acc_3: 0.8960 - val_loss_1: 0.7889 - val_loss_2: 0.7889 - val_loss_3: 0.7889 - val_acc_ensemble: 0.7627 - val_acc_1: 0.7627 - val_acc_2: 0.7627 - val_acc_3: 0.7627\n",
      "Epoch 23/50\n",
      "100/100 - 8s - loss_1: 0.2061 - loss_2: 0.2092 - loss_3: 0.2192 - acc_ensemble: 0.9180 - acc_1: 0.9180 - acc_2: 0.9180 - acc_3: 0.9180 - val_loss_1: 0.7999 - val_loss_2: 0.7999 - val_loss_3: 0.7999 - val_acc_ensemble: 0.7634 - val_acc_1: 0.7634 - val_acc_2: 0.7634 - val_acc_3: 0.7634\n",
      "Epoch 24/50\n",
      "100/100 - 9s - loss_1: 0.1918 - loss_2: 0.1862 - loss_3: 0.2039 - acc_ensemble: 0.9020 - acc_1: 0.9020 - acc_2: 0.9020 - acc_3: 0.9020 - val_loss_1: 0.8387 - val_loss_2: 0.8387 - val_loss_3: 0.8387 - val_acc_ensemble: 0.7576 - val_acc_1: 0.7576 - val_acc_2: 0.7576 - val_acc_3: 0.7576\n",
      "Epoch 25/50\n",
      "100/100 - 8s - loss_1: 0.1722 - loss_2: 0.1869 - loss_3: 0.1639 - acc_ensemble: 0.9120 - acc_1: 0.9120 - acc_2: 0.9120 - acc_3: 0.9120 - val_loss_1: 0.8132 - val_loss_2: 0.8132 - val_loss_3: 0.8132 - val_acc_ensemble: 0.7680 - val_acc_1: 0.7680 - val_acc_2: 0.7680 - val_acc_3: 0.7680\n",
      "Epoch 26/50\n",
      "100/100 - 9s - loss_1: 0.1792 - loss_2: 0.1686 - loss_3: 0.1547 - acc_ensemble: 0.8920 - acc_1: 0.8920 - acc_2: 0.8920 - acc_3: 0.8920 - val_loss_1: 0.8546 - val_loss_2: 0.8546 - val_loss_3: 0.8546 - val_acc_ensemble: 0.7596 - val_acc_1: 0.7596 - val_acc_2: 0.7596 - val_acc_3: 0.7596\n",
      "Epoch 27/50\n",
      "100/100 - 8s - loss_1: 0.1543 - loss_2: 0.1526 - loss_3: 0.1474 - acc_ensemble: 0.9060 - acc_1: 0.9060 - acc_2: 0.9060 - acc_3: 0.9060 - val_loss_1: 0.8375 - val_loss_2: 0.8375 - val_loss_3: 0.8375 - val_acc_ensemble: 0.7652 - val_acc_1: 0.7652 - val_acc_2: 0.7652 - val_acc_3: 0.7652\n",
      "Epoch 28/50\n",
      "100/100 - 9s - loss_1: 0.1468 - loss_2: 0.1405 - loss_3: 0.1252 - acc_ensemble: 0.9000 - acc_1: 0.9000 - acc_2: 0.9000 - acc_3: 0.9000 - val_loss_1: 0.8482 - val_loss_2: 0.8482 - val_loss_3: 0.8482 - val_acc_ensemble: 0.7683 - val_acc_1: 0.7683 - val_acc_2: 0.7683 - val_acc_3: 0.7683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50\n",
      "100/100 - 8s - loss_1: 0.1303 - loss_2: 0.1386 - loss_3: 0.1327 - acc_ensemble: 0.9140 - acc_1: 0.9140 - acc_2: 0.9140 - acc_3: 0.9140 - val_loss_1: 0.8931 - val_loss_2: 0.8931 - val_loss_3: 0.8931 - val_acc_ensemble: 0.7592 - val_acc_1: 0.7592 - val_acc_2: 0.7592 - val_acc_3: 0.7592\n",
      "Epoch 30/50\n",
      "100/100 - 9s - loss_1: 0.1300 - loss_2: 0.1235 - loss_3: 0.1328 - acc_ensemble: 0.9120 - acc_1: 0.9120 - acc_2: 0.9120 - acc_3: 0.9120 - val_loss_1: 0.9098 - val_loss_2: 0.9098 - val_loss_3: 0.9098 - val_acc_ensemble: 0.7612 - val_acc_1: 0.7612 - val_acc_2: 0.7612 - val_acc_3: 0.7612\n",
      "Epoch 31/50\n",
      "100/100 - 9s - loss_1: 0.1283 - loss_2: 0.1204 - loss_3: 0.1209 - acc_ensemble: 0.9240 - acc_1: 0.9240 - acc_2: 0.9240 - acc_3: 0.9240 - val_loss_1: 0.8977 - val_loss_2: 0.8977 - val_loss_3: 0.8977 - val_acc_ensemble: 0.7607 - val_acc_1: 0.7607 - val_acc_2: 0.7607 - val_acc_3: 0.7607\n",
      "Epoch 32/50\n",
      "100/100 - 8s - loss_1: 0.1200 - loss_2: 0.1022 - loss_3: 0.1047 - acc_ensemble: 0.9320 - acc_1: 0.9320 - acc_2: 0.9320 - acc_3: 0.9320 - val_loss_1: 0.9340 - val_loss_2: 0.9340 - val_loss_3: 0.9340 - val_acc_ensemble: 0.7608 - val_acc_1: 0.7608 - val_acc_2: 0.7608 - val_acc_3: 0.7608\n",
      "Epoch 33/50\n",
      "100/100 - 8s - loss_1: 0.1052 - loss_2: 0.1099 - loss_3: 0.1059 - acc_ensemble: 0.9220 - acc_1: 0.9220 - acc_2: 0.9220 - acc_3: 0.9220 - val_loss_1: 0.9101 - val_loss_2: 0.9101 - val_loss_3: 0.9101 - val_acc_ensemble: 0.7700 - val_acc_1: 0.7700 - val_acc_2: 0.7700 - val_acc_3: 0.7700\n",
      "Epoch 34/50\n",
      "100/100 - 8s - loss_1: 0.1178 - loss_2: 0.1147 - loss_3: 0.1119 - acc_ensemble: 0.9160 - acc_1: 0.9160 - acc_2: 0.9160 - acc_3: 0.9160 - val_loss_1: 0.9295 - val_loss_2: 0.9295 - val_loss_3: 0.9295 - val_acc_ensemble: 0.7667 - val_acc_1: 0.7667 - val_acc_2: 0.7667 - val_acc_3: 0.7667\n",
      "Epoch 35/50\n",
      "100/100 - 8s - loss_1: 0.1204 - loss_2: 0.1087 - loss_3: 0.1096 - acc_ensemble: 0.9280 - acc_1: 0.9280 - acc_2: 0.9280 - acc_3: 0.9280 - val_loss_1: 0.9386 - val_loss_2: 0.9386 - val_loss_3: 0.9386 - val_acc_ensemble: 0.7646 - val_acc_1: 0.7646 - val_acc_2: 0.7646 - val_acc_3: 0.7646\n",
      "Epoch 36/50\n",
      "100/100 - 8s - loss_1: 0.0902 - loss_2: 0.0953 - loss_3: 0.1098 - acc_ensemble: 0.9120 - acc_1: 0.9120 - acc_2: 0.9120 - acc_3: 0.9120 - val_loss_1: 0.9660 - val_loss_2: 0.9660 - val_loss_3: 0.9660 - val_acc_ensemble: 0.7603 - val_acc_1: 0.7603 - val_acc_2: 0.7603 - val_acc_3: 0.7603\n",
      "Epoch 37/50\n",
      "100/100 - 8s - loss_1: 0.0878 - loss_2: 0.0903 - loss_3: 0.0888 - acc_ensemble: 0.9460 - acc_1: 0.9460 - acc_2: 0.9460 - acc_3: 0.9460 - val_loss_1: 0.9637 - val_loss_2: 0.9637 - val_loss_3: 0.9637 - val_acc_ensemble: 0.7677 - val_acc_1: 0.7677 - val_acc_2: 0.7677 - val_acc_3: 0.7677\n",
      "Epoch 38/50\n",
      "100/100 - 8s - loss_1: 0.0883 - loss_2: 0.0902 - loss_3: 0.0823 - acc_ensemble: 0.9400 - acc_1: 0.9400 - acc_2: 0.9400 - acc_3: 0.9400 - val_loss_1: 0.9533 - val_loss_2: 0.9533 - val_loss_3: 0.9533 - val_acc_ensemble: 0.7651 - val_acc_1: 0.7651 - val_acc_2: 0.7651 - val_acc_3: 0.7651\n",
      "Epoch 39/50\n",
      "100/100 - 8s - loss_1: 0.0730 - loss_2: 0.0805 - loss_3: 0.0726 - acc_ensemble: 0.9300 - acc_1: 0.9300 - acc_2: 0.9300 - acc_3: 0.9300 - val_loss_1: 0.9993 - val_loss_2: 0.9993 - val_loss_3: 0.9993 - val_acc_ensemble: 0.7688 - val_acc_1: 0.7688 - val_acc_2: 0.7688 - val_acc_3: 0.7688\n",
      "Epoch 40/50\n",
      "100/100 - 8s - loss_1: 0.0646 - loss_2: 0.0692 - loss_3: 0.0708 - acc_ensemble: 0.9300 - acc_1: 0.9300 - acc_2: 0.9300 - acc_3: 0.9300 - val_loss_1: 0.9703 - val_loss_2: 0.9703 - val_loss_3: 0.9703 - val_acc_ensemble: 0.7728 - val_acc_1: 0.7728 - val_acc_2: 0.7728 - val_acc_3: 0.7728\n",
      "Epoch 41/50\n",
      "100/100 - 8s - loss_1: 0.0744 - loss_2: 0.0717 - loss_3: 0.0778 - acc_ensemble: 0.9300 - acc_1: 0.9300 - acc_2: 0.9300 - acc_3: 0.9300 - val_loss_1: 1.0057 - val_loss_2: 1.0057 - val_loss_3: 1.0057 - val_acc_ensemble: 0.7627 - val_acc_1: 0.7627 - val_acc_2: 0.7627 - val_acc_3: 0.7627\n",
      "Epoch 42/50\n",
      "100/100 - 9s - loss_1: 0.0853 - loss_2: 0.0763 - loss_3: 0.0844 - acc_ensemble: 0.9320 - acc_1: 0.9320 - acc_2: 0.9320 - acc_3: 0.9320 - val_loss_1: 1.0119 - val_loss_2: 1.0119 - val_loss_3: 1.0119 - val_acc_ensemble: 0.7622 - val_acc_1: 0.7622 - val_acc_2: 0.7622 - val_acc_3: 0.7622\n",
      "Epoch 43/50\n",
      "100/100 - 8s - loss_1: 0.0743 - loss_2: 0.0691 - loss_3: 0.0820 - acc_ensemble: 0.9300 - acc_1: 0.9300 - acc_2: 0.9300 - acc_3: 0.9300 - val_loss_1: 1.0043 - val_loss_2: 1.0043 - val_loss_3: 1.0043 - val_acc_ensemble: 0.7660 - val_acc_1: 0.7660 - val_acc_2: 0.7660 - val_acc_3: 0.7660\n",
      "Epoch 44/50\n",
      "100/100 - 8s - loss_1: 0.0652 - loss_2: 0.0775 - loss_3: 0.0711 - acc_ensemble: 0.9240 - acc_1: 0.9240 - acc_2: 0.9240 - acc_3: 0.9240 - val_loss_1: 1.0279 - val_loss_2: 1.0279 - val_loss_3: 1.0279 - val_acc_ensemble: 0.7600 - val_acc_1: 0.7600 - val_acc_2: 0.7600 - val_acc_3: 0.7600\n",
      "Epoch 45/50\n",
      "100/100 - 8s - loss_1: 0.0652 - loss_2: 0.0631 - loss_3: 0.0632 - acc_ensemble: 0.9300 - acc_1: 0.9300 - acc_2: 0.9300 - acc_3: 0.9300 - val_loss_1: 1.0253 - val_loss_2: 1.0253 - val_loss_3: 1.0253 - val_acc_ensemble: 0.7684 - val_acc_1: 0.7684 - val_acc_2: 0.7684 - val_acc_3: 0.7684\n",
      "Epoch 46/50\n",
      "100/100 - 8s - loss_1: 0.0755 - loss_2: 0.0558 - loss_3: 0.0576 - acc_ensemble: 0.9340 - acc_1: 0.9340 - acc_2: 0.9340 - acc_3: 0.9340 - val_loss_1: 1.0253 - val_loss_2: 1.0253 - val_loss_3: 1.0253 - val_acc_ensemble: 0.7720 - val_acc_1: 0.7720 - val_acc_2: 0.7720 - val_acc_3: 0.7720\n",
      "Epoch 47/50\n",
      "100/100 - 8s - loss_1: 0.0776 - loss_2: 0.0731 - loss_3: 0.0862 - acc_ensemble: 0.9280 - acc_1: 0.9280 - acc_2: 0.9280 - acc_3: 0.9280 - val_loss_1: 1.0513 - val_loss_2: 1.0513 - val_loss_3: 1.0513 - val_acc_ensemble: 0.7688 - val_acc_1: 0.7688 - val_acc_2: 0.7688 - val_acc_3: 0.7688\n",
      "Epoch 48/50\n",
      "100/100 - 8s - loss_1: 0.0682 - loss_2: 0.0679 - loss_3: 0.0710 - acc_ensemble: 0.9360 - acc_1: 0.9360 - acc_2: 0.9360 - acc_3: 0.9360 - val_loss_1: 1.0729 - val_loss_2: 1.0729 - val_loss_3: 1.0729 - val_acc_ensemble: 0.7688 - val_acc_1: 0.7688 - val_acc_2: 0.7688 - val_acc_3: 0.7688\n",
      "Epoch 49/50\n",
      "100/100 - 8s - loss_1: 0.0653 - loss_2: 0.0625 - loss_3: 0.0584 - acc_ensemble: 0.9340 - acc_1: 0.9340 - acc_2: 0.9340 - acc_3: 0.9340 - val_loss_1: 1.0616 - val_loss_2: 1.0616 - val_loss_3: 1.0616 - val_acc_ensemble: 0.7693 - val_acc_1: 0.7693 - val_acc_2: 0.7693 - val_acc_3: 0.7693\n",
      "Epoch 50/50\n",
      "100/100 - 9s - loss_1: 0.0678 - loss_2: 0.0561 - loss_3: 0.0542 - acc_ensemble: 0.9240 - acc_1: 0.9240 - acc_2: 0.9240 - acc_3: 0.9240 - val_loss_1: 1.0683 - val_loss_2: 1.0683 - val_loss_3: 1.0683 - val_acc_ensemble: 0.7675 - val_acc_1: 0.7675 - val_acc_2: 0.7675 - val_acc_3: 0.7675\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B3/S1.00/model_4\n",
      "i   Layer name                      Output shape        Num param  Inbound            \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                    \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                    \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                    \n",
      "--------------------------------------------------------------------------------------\n",
      "0   conv2d_1_1 (Conv2D)             [None,32,32,32] []  896        input              \n",
      "                                    [None,32,32,32] []                                \n",
      "                                    [None,32,32,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "1   bn_1_1 (BatchNormalization)     [None,32,32,32] []  64         conv2d_1_1         \n",
      "                                    [None,32,32,32] []                                \n",
      "                                    [None,32,32,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "2   relu_1_1 (Activation)           [None,32,32,32] []  0          bn_1_1             \n",
      "                                    [None,32,32,32] []                                \n",
      "                                    [None,32,32,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "3   conv2d_1_2 (Conv2D)             [None,32,32,32] []  9248       relu_1_1           \n",
      "                                    [None,32,32,32] []                                \n",
      "                                    [None,32,32,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "4   bn_1_2 (BatchNormalization)     [None,32,32,32] []  64         conv2d_1_2         \n",
      "                                    [None,32,32,32] []                                \n",
      "                                    [None,32,32,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "5   relu_1_2 (Activation)           [None,32,32,32] []  0          bn_1_2             \n",
      "                                    [None,32,32,32] []                                \n",
      "                                    [None,32,32,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "6   avg_pool2d_1 (AveragePooling2D  [None,16,16,32] []  0          relu_1_2           \n",
      "                                    [None,16,16,32] []                                \n",
      "                                    [None,16,16,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "7   conv2d_2_1 (Conv2D)             [None,16,16,64] []  18496      avg_pool2d_1       \n",
      "                                    [None,16,16,64] []                                \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "8   bn_2_1 (BatchNormalization)     [None,16,16,64] []  128        conv2d_2_1         \n",
      "                                    [None,16,16,64] []                                \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "9   relu_2_1 (Activation)           [None,16,16,64] []  0          bn_2_1             \n",
      "                                    [None,16,16,64] []                                \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "10  conv2d_2_2 (Conv2D)             [None,16,16,64] []  36928      relu_2_1           \n",
      "                                    [None,16,16,64] []                                \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "11  bn_2_2 (BatchNormalization)     [None,16,16,64] []  128        conv2d_2_2         \n",
      "                                    [None,16,16,64] []                                \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "12  relu_2_2 (Activation)           [None,16,16,64] []  0          bn_2_2             \n",
      "                                    [None,16,16,64] []                                \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "13  avg_pool2d_2 (AveragePooling2D  [None,8,8,64] []    0          relu_2_2           \n",
      "                                    [None,8,8,64] []                                  \n",
      "                                    [None,8,8,64] []                                  \n",
      "--------------------------------------------------------------------------------------\n",
      "14  conv2d_3_1 (Conv2D)             [None,8,8,128] []   73856      avg_pool2d_2       \n",
      "                                    [None,8,8,128] []                                 \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "15  bn_3_1 (BatchNormalization)     [None,8,8,128] []   256        conv2d_3_1         \n",
      "                                    [None,8,8,128] []                                 \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "16  relu_3_1 (Activation)           [None,8,8,128] []   0          bn_3_1             \n",
      "                                    [None,8,8,128] []                                 \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "17  conv2d_3_2 (Conv2D)             [None,8,8,128] []   147584     relu_3_1           \n",
      "                                    [None,8,8,128] []                                 \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "18  bn_3_2 (BatchNormalization)     [None,8,8,128] []   256        conv2d_3_2         \n",
      "                                    [None,8,8,128] []                                 \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "19  relu_3_2 (Activation)           [None,8,8,128] []   0          bn_3_2             \n",
      "                                    [None,8,8,128] []                                 \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "20  global_avg_pool2d (GlobalAvera  [None,128] []       0          relu_3_2           \n",
      "                                    [None,128] []                                     \n",
      "                                    [None,128] []                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "21  fc1 (Dense)                     [None,128] []       16512      global_avg_pool2d  \n",
      "                                    [None,128] []                                     \n",
      "                                    [None,128] []                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "22  bn_fc1 (BatchNormalization)     [None,128] []       256        fc1                \n",
      "                                    [None,128] []                                     \n",
      "                                    [None,128] []                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "23  relu_fc1 (Activation)           [None,128] []       0          bn_fc1             \n",
      "                                    [None,128] []                                     \n",
      "                                    [None,128] []                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "24  output (Dense)                  [None,10]           1290       relu_fc1           \n",
      "                                    [None,10]                                         \n",
      "                                    [None,10]                                         \n",
      "--------------------------------------------------------------------------------------\n",
      "Total parameters: 305962\n",
      "50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 - 10s - loss_1: 1.6603 - loss_2: 1.6553 - loss_3: 1.6438 - acc_ensemble: 0.5120 - acc_1: 0.5120 - acc_2: 0.5120 - acc_3: 0.5120 - val_loss_1: 1.3888 - val_loss_2: 1.3888 - val_loss_3: 1.3888 - val_acc_ensemble: 0.4945 - val_acc_1: 0.4945 - val_acc_2: 0.4945 - val_acc_3: 0.4945\n",
      "Epoch 2/50\n",
      "100/100 - 8s - loss_1: 1.2982 - loss_2: 1.2970 - loss_3: 1.2894 - acc_ensemble: 0.5920 - acc_1: 0.5920 - acc_2: 0.5920 - acc_3: 0.5920 - val_loss_1: 1.1979 - val_loss_2: 1.1979 - val_loss_3: 1.1979 - val_acc_ensemble: 0.5661 - val_acc_1: 0.5661 - val_acc_2: 0.5661 - val_acc_3: 0.5661\n",
      "Epoch 3/50\n",
      "100/100 - 8s - loss_1: 1.1284 - loss_2: 1.1147 - loss_3: 1.1385 - acc_ensemble: 0.6400 - acc_1: 0.6400 - acc_2: 0.6400 - acc_3: 0.6400 - val_loss_1: 1.0667 - val_loss_2: 1.0667 - val_loss_3: 1.0667 - val_acc_ensemble: 0.6188 - val_acc_1: 0.6188 - val_acc_2: 0.6188 - val_acc_3: 0.6188\n",
      "Epoch 4/50\n",
      "100/100 - 8s - loss_1: 0.9840 - loss_2: 0.9796 - loss_3: 0.9838 - acc_ensemble: 0.6540 - acc_1: 0.6540 - acc_2: 0.6540 - acc_3: 0.6540 - val_loss_1: 1.0069 - val_loss_2: 1.0069 - val_loss_3: 1.0069 - val_acc_ensemble: 0.6408 - val_acc_1: 0.6408 - val_acc_2: 0.6408 - val_acc_3: 0.6408\n",
      "Epoch 5/50\n",
      "100/100 - 8s - loss_1: 0.8873 - loss_2: 0.9223 - loss_3: 0.8997 - acc_ensemble: 0.7100 - acc_1: 0.7100 - acc_2: 0.7100 - acc_3: 0.7100 - val_loss_1: 0.9453 - val_loss_2: 0.9453 - val_loss_3: 0.9453 - val_acc_ensemble: 0.6618 - val_acc_1: 0.6618 - val_acc_2: 0.6618 - val_acc_3: 0.6618\n",
      "Epoch 6/50\n",
      "100/100 - 9s - loss_1: 0.8033 - loss_2: 0.8282 - loss_3: 0.8216 - acc_ensemble: 0.7300 - acc_1: 0.7300 - acc_2: 0.7300 - acc_3: 0.7300 - val_loss_1: 0.8926 - val_loss_2: 0.8926 - val_loss_3: 0.8926 - val_acc_ensemble: 0.6796 - val_acc_1: 0.6796 - val_acc_2: 0.6796 - val_acc_3: 0.6796\n",
      "Epoch 7/50\n",
      "100/100 - 8s - loss_1: 0.7745 - loss_2: 0.7474 - loss_3: 0.7564 - acc_ensemble: 0.7560 - acc_1: 0.7560 - acc_2: 0.7560 - acc_3: 0.7560 - val_loss_1: 0.8580 - val_loss_2: 0.8580 - val_loss_3: 0.8580 - val_acc_ensemble: 0.6960 - val_acc_1: 0.6960 - val_acc_2: 0.6960 - val_acc_3: 0.6960\n",
      "Epoch 8/50\n",
      "100/100 - 8s - loss_1: 0.7089 - loss_2: 0.7174 - loss_3: 0.6935 - acc_ensemble: 0.7700 - acc_1: 0.7700 - acc_2: 0.7700 - acc_3: 0.7700 - val_loss_1: 0.8269 - val_loss_2: 0.8269 - val_loss_3: 0.8269 - val_acc_ensemble: 0.7066 - val_acc_1: 0.7066 - val_acc_2: 0.7066 - val_acc_3: 0.7066\n",
      "Epoch 9/50\n",
      "100/100 - 9s - loss_1: 0.6262 - loss_2: 0.6448 - loss_3: 0.6581 - acc_ensemble: 0.7720 - acc_1: 0.7720 - acc_2: 0.7720 - acc_3: 0.7720 - val_loss_1: 0.8324 - val_loss_2: 0.8324 - val_loss_3: 0.8324 - val_acc_ensemble: 0.7168 - val_acc_1: 0.7168 - val_acc_2: 0.7168 - val_acc_3: 0.7168\n",
      "Epoch 10/50\n",
      "100/100 - 9s - loss_1: 0.5912 - loss_2: 0.6061 - loss_3: 0.6134 - acc_ensemble: 0.7920 - acc_1: 0.7920 - acc_2: 0.7920 - acc_3: 0.7920 - val_loss_1: 0.8150 - val_loss_2: 0.8150 - val_loss_3: 0.8150 - val_acc_ensemble: 0.7111 - val_acc_1: 0.7111 - val_acc_2: 0.7111 - val_acc_3: 0.7111\n",
      "Epoch 11/50\n",
      "100/100 - 8s - loss_1: 0.5516 - loss_2: 0.5425 - loss_3: 0.5439 - acc_ensemble: 0.8040 - acc_1: 0.8040 - acc_2: 0.8040 - acc_3: 0.8040 - val_loss_1: 0.7881 - val_loss_2: 0.7881 - val_loss_3: 0.7881 - val_acc_ensemble: 0.7278 - val_acc_1: 0.7278 - val_acc_2: 0.7278 - val_acc_3: 0.7278\n",
      "Epoch 12/50\n",
      "100/100 - 8s - loss_1: 0.5244 - loss_2: 0.5164 - loss_3: 0.5264 - acc_ensemble: 0.7940 - acc_1: 0.7940 - acc_2: 0.7940 - acc_3: 0.7940 - val_loss_1: 0.8023 - val_loss_2: 0.8023 - val_loss_3: 0.8023 - val_acc_ensemble: 0.7210 - val_acc_1: 0.7210 - val_acc_2: 0.7210 - val_acc_3: 0.7210\n",
      "Epoch 13/50\n",
      "100/100 - 8s - loss_1: 0.4854 - loss_2: 0.4925 - loss_3: 0.4889 - acc_ensemble: 0.8220 - acc_1: 0.8220 - acc_2: 0.8220 - acc_3: 0.8220 - val_loss_1: 0.7713 - val_loss_2: 0.7713 - val_loss_3: 0.7713 - val_acc_ensemble: 0.7380 - val_acc_1: 0.7380 - val_acc_2: 0.7380 - val_acc_3: 0.7380\n",
      "Epoch 14/50\n",
      "100/100 - 8s - loss_1: 0.4345 - loss_2: 0.4550 - loss_3: 0.4282 - acc_ensemble: 0.8360 - acc_1: 0.8360 - acc_2: 0.8360 - acc_3: 0.8360 - val_loss_1: 0.7624 - val_loss_2: 0.7624 - val_loss_3: 0.7624 - val_acc_ensemble: 0.7386 - val_acc_1: 0.7386 - val_acc_2: 0.7386 - val_acc_3: 0.7386\n",
      "Epoch 15/50\n",
      "100/100 - 9s - loss_1: 0.4193 - loss_2: 0.4290 - loss_3: 0.4191 - acc_ensemble: 0.8380 - acc_1: 0.8380 - acc_2: 0.8380 - acc_3: 0.8380 - val_loss_1: 0.7536 - val_loss_2: 0.7536 - val_loss_3: 0.7536 - val_acc_ensemble: 0.7462 - val_acc_1: 0.7462 - val_acc_2: 0.7462 - val_acc_3: 0.7462\n",
      "Epoch 16/50\n",
      "100/100 - 9s - loss_1: 0.3902 - loss_2: 0.3870 - loss_3: 0.3711 - acc_ensemble: 0.8420 - acc_1: 0.8420 - acc_2: 0.8420 - acc_3: 0.8420 - val_loss_1: 0.7654 - val_loss_2: 0.7654 - val_loss_3: 0.7654 - val_acc_ensemble: 0.7422 - val_acc_1: 0.7422 - val_acc_2: 0.7422 - val_acc_3: 0.7422\n",
      "Epoch 17/50\n",
      "100/100 - 8s - loss_1: 0.3513 - loss_2: 0.3623 - loss_3: 0.3467 - acc_ensemble: 0.8580 - acc_1: 0.8580 - acc_2: 0.8580 - acc_3: 0.8580 - val_loss_1: 0.7708 - val_loss_2: 0.7708 - val_loss_3: 0.7708 - val_acc_ensemble: 0.7491 - val_acc_1: 0.7491 - val_acc_2: 0.7491 - val_acc_3: 0.7491\n",
      "Epoch 18/50\n",
      "100/100 - 9s - loss_1: 0.3130 - loss_2: 0.3104 - loss_3: 0.3250 - acc_ensemble: 0.8640 - acc_1: 0.8640 - acc_2: 0.8640 - acc_3: 0.8640 - val_loss_1: 0.7936 - val_loss_2: 0.7936 - val_loss_3: 0.7936 - val_acc_ensemble: 0.7485 - val_acc_1: 0.7485 - val_acc_2: 0.7485 - val_acc_3: 0.7485\n",
      "Epoch 19/50\n",
      "100/100 - 8s - loss_1: 0.3006 - loss_2: 0.3062 - loss_3: 0.3036 - acc_ensemble: 0.8560 - acc_1: 0.8560 - acc_2: 0.8560 - acc_3: 0.8560 - val_loss_1: 0.8018 - val_loss_2: 0.8018 - val_loss_3: 0.8018 - val_acc_ensemble: 0.7426 - val_acc_1: 0.7426 - val_acc_2: 0.7426 - val_acc_3: 0.7426\n",
      "Epoch 20/50\n",
      "100/100 - 8s - loss_1: 0.2834 - loss_2: 0.2862 - loss_3: 0.2860 - acc_ensemble: 0.8840 - acc_1: 0.8840 - acc_2: 0.8840 - acc_3: 0.8840 - val_loss_1: 0.7885 - val_loss_2: 0.7885 - val_loss_3: 0.7885 - val_acc_ensemble: 0.7492 - val_acc_1: 0.7492 - val_acc_2: 0.7492 - val_acc_3: 0.7492\n",
      "Epoch 21/50\n",
      "100/100 - 9s - loss_1: 0.2606 - loss_2: 0.2516 - loss_3: 0.2593 - acc_ensemble: 0.8580 - acc_1: 0.8580 - acc_2: 0.8580 - acc_3: 0.8580 - val_loss_1: 0.8243 - val_loss_2: 0.8243 - val_loss_3: 0.8243 - val_acc_ensemble: 0.7495 - val_acc_1: 0.7495 - val_acc_2: 0.7495 - val_acc_3: 0.7495\n",
      "Epoch 22/50\n",
      "100/100 - 9s - loss_1: 0.2200 - loss_2: 0.2576 - loss_3: 0.2407 - acc_ensemble: 0.8680 - acc_1: 0.8680 - acc_2: 0.8680 - acc_3: 0.8680 - val_loss_1: 0.8322 - val_loss_2: 0.8322 - val_loss_3: 0.8322 - val_acc_ensemble: 0.7458 - val_acc_1: 0.7458 - val_acc_2: 0.7458 - val_acc_3: 0.7458\n",
      "Epoch 23/50\n",
      "100/100 - 9s - loss_1: 0.2339 - loss_2: 0.2153 - loss_3: 0.2195 - acc_ensemble: 0.8940 - acc_1: 0.8940 - acc_2: 0.8940 - acc_3: 0.8940 - val_loss_1: 0.8528 - val_loss_2: 0.8528 - val_loss_3: 0.8528 - val_acc_ensemble: 0.7471 - val_acc_1: 0.7471 - val_acc_2: 0.7471 - val_acc_3: 0.7471\n",
      "Epoch 24/50\n",
      "100/100 - 8s - loss_1: 0.2084 - loss_2: 0.1975 - loss_3: 0.2034 - acc_ensemble: 0.8980 - acc_1: 0.8980 - acc_2: 0.8980 - acc_3: 0.8980 - val_loss_1: 0.8230 - val_loss_2: 0.8230 - val_loss_3: 0.8230 - val_acc_ensemble: 0.7594 - val_acc_1: 0.7594 - val_acc_2: 0.7594 - val_acc_3: 0.7594\n",
      "Epoch 25/50\n",
      "100/100 - 9s - loss_1: 0.1942 - loss_2: 0.2059 - loss_3: 0.2104 - acc_ensemble: 0.8960 - acc_1: 0.8960 - acc_2: 0.8960 - acc_3: 0.8960 - val_loss_1: 0.8757 - val_loss_2: 0.8757 - val_loss_3: 0.8757 - val_acc_ensemble: 0.7521 - val_acc_1: 0.7521 - val_acc_2: 0.7521 - val_acc_3: 0.7521\n",
      "Epoch 26/50\n",
      "100/100 - 8s - loss_1: 0.1841 - loss_2: 0.1849 - loss_3: 0.1978 - acc_ensemble: 0.9040 - acc_1: 0.9040 - acc_2: 0.9040 - acc_3: 0.9040 - val_loss_1: 0.8402 - val_loss_2: 0.8402 - val_loss_3: 0.8402 - val_acc_ensemble: 0.7567 - val_acc_1: 0.7567 - val_acc_2: 0.7567 - val_acc_3: 0.7567\n",
      "Epoch 27/50\n",
      "100/100 - 9s - loss_1: 0.1503 - loss_2: 0.1437 - loss_3: 0.1576 - acc_ensemble: 0.9140 - acc_1: 0.9140 - acc_2: 0.9140 - acc_3: 0.9140 - val_loss_1: 0.8857 - val_loss_2: 0.8857 - val_loss_3: 0.8857 - val_acc_ensemble: 0.7498 - val_acc_1: 0.7498 - val_acc_2: 0.7498 - val_acc_3: 0.7498\n",
      "Epoch 28/50\n",
      "100/100 - 8s - loss_1: 0.1385 - loss_2: 0.1461 - loss_3: 0.1400 - acc_ensemble: 0.9200 - acc_1: 0.9200 - acc_2: 0.9200 - acc_3: 0.9200 - val_loss_1: 0.9060 - val_loss_2: 0.9060 - val_loss_3: 0.9060 - val_acc_ensemble: 0.7505 - val_acc_1: 0.7505 - val_acc_2: 0.7505 - val_acc_3: 0.7505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50\n",
      "100/100 - 8s - loss_1: 0.1341 - loss_2: 0.1329 - loss_3: 0.1437 - acc_ensemble: 0.9220 - acc_1: 0.9220 - acc_2: 0.9220 - acc_3: 0.9220 - val_loss_1: 0.9080 - val_loss_2: 0.9080 - val_loss_3: 0.9080 - val_acc_ensemble: 0.7501 - val_acc_1: 0.7501 - val_acc_2: 0.7501 - val_acc_3: 0.7501\n",
      "Epoch 30/50\n",
      "100/100 - 8s - loss_1: 0.1422 - loss_2: 0.1441 - loss_3: 0.1403 - acc_ensemble: 0.9220 - acc_1: 0.9220 - acc_2: 0.9220 - acc_3: 0.9220 - val_loss_1: 0.9448 - val_loss_2: 0.9448 - val_loss_3: 0.9448 - val_acc_ensemble: 0.7457 - val_acc_1: 0.7457 - val_acc_2: 0.7457 - val_acc_3: 0.7457\n",
      "Epoch 31/50\n",
      "100/100 - 8s - loss_1: 0.1360 - loss_2: 0.1575 - loss_3: 0.1382 - acc_ensemble: 0.9180 - acc_1: 0.9180 - acc_2: 0.9180 - acc_3: 0.9180 - val_loss_1: 0.9137 - val_loss_2: 0.9137 - val_loss_3: 0.9137 - val_acc_ensemble: 0.7607 - val_acc_1: 0.7607 - val_acc_2: 0.7607 - val_acc_3: 0.7607\n",
      "Epoch 32/50\n",
      "100/100 - 8s - loss_1: 0.1241 - loss_2: 0.1153 - loss_3: 0.1173 - acc_ensemble: 0.9280 - acc_1: 0.9280 - acc_2: 0.9280 - acc_3: 0.9280 - val_loss_1: 0.9116 - val_loss_2: 0.9116 - val_loss_3: 0.9116 - val_acc_ensemble: 0.7618 - val_acc_1: 0.7618 - val_acc_2: 0.7618 - val_acc_3: 0.7618\n",
      "Epoch 33/50\n",
      "100/100 - 8s - loss_1: 0.1017 - loss_2: 0.1048 - loss_3: 0.1122 - acc_ensemble: 0.9080 - acc_1: 0.9080 - acc_2: 0.9080 - acc_3: 0.9080 - val_loss_1: 0.9675 - val_loss_2: 0.9675 - val_loss_3: 0.9675 - val_acc_ensemble: 0.7513 - val_acc_1: 0.7513 - val_acc_2: 0.7513 - val_acc_3: 0.7513\n",
      "Epoch 34/50\n",
      "100/100 - 9s - loss_1: 0.0929 - loss_2: 0.1041 - loss_3: 0.0999 - acc_ensemble: 0.9240 - acc_1: 0.9240 - acc_2: 0.9240 - acc_3: 0.9240 - val_loss_1: 0.9616 - val_loss_2: 0.9616 - val_loss_3: 0.9616 - val_acc_ensemble: 0.7536 - val_acc_1: 0.7536 - val_acc_2: 0.7536 - val_acc_3: 0.7536\n",
      "Epoch 35/50\n",
      "100/100 - 9s - loss_1: 0.1036 - loss_2: 0.0934 - loss_3: 0.0865 - acc_ensemble: 0.9240 - acc_1: 0.9240 - acc_2: 0.9240 - acc_3: 0.9240 - val_loss_1: 0.9819 - val_loss_2: 0.9819 - val_loss_3: 0.9819 - val_acc_ensemble: 0.7555 - val_acc_1: 0.7555 - val_acc_2: 0.7555 - val_acc_3: 0.7555\n",
      "Epoch 36/50\n",
      "100/100 - 8s - loss_1: 0.0904 - loss_2: 0.0872 - loss_3: 0.0921 - acc_ensemble: 0.9400 - acc_1: 0.9400 - acc_2: 0.9400 - acc_3: 0.9400 - val_loss_1: 0.9673 - val_loss_2: 0.9673 - val_loss_3: 0.9673 - val_acc_ensemble: 0.7601 - val_acc_1: 0.7601 - val_acc_2: 0.7601 - val_acc_3: 0.7601\n",
      "Epoch 37/50\n",
      "100/100 - 8s - loss_1: 0.0911 - loss_2: 0.0858 - loss_3: 0.0912 - acc_ensemble: 0.9200 - acc_1: 0.9200 - acc_2: 0.9200 - acc_3: 0.9200 - val_loss_1: 1.0398 - val_loss_2: 1.0398 - val_loss_3: 1.0398 - val_acc_ensemble: 0.7435 - val_acc_1: 0.7435 - val_acc_2: 0.7435 - val_acc_3: 0.7435\n",
      "Epoch 38/50\n",
      "100/100 - 8s - loss_1: 0.1018 - loss_2: 0.1198 - loss_3: 0.1086 - acc_ensemble: 0.9100 - acc_1: 0.9100 - acc_2: 0.9100 - acc_3: 0.9100 - val_loss_1: 1.0658 - val_loss_2: 1.0658 - val_loss_3: 1.0658 - val_acc_ensemble: 0.7423 - val_acc_1: 0.7423 - val_acc_2: 0.7423 - val_acc_3: 0.7423\n",
      "Epoch 39/50\n",
      "100/100 - 9s - loss_1: 0.0926 - loss_2: 0.0903 - loss_3: 0.0853 - acc_ensemble: 0.9200 - acc_1: 0.9200 - acc_2: 0.9200 - acc_3: 0.9200 - val_loss_1: 1.0435 - val_loss_2: 1.0435 - val_loss_3: 1.0435 - val_acc_ensemble: 0.7520 - val_acc_1: 0.7520 - val_acc_2: 0.7520 - val_acc_3: 0.7520\n",
      "Epoch 40/50\n",
      "100/100 - 8s - loss_1: 0.0880 - loss_2: 0.0858 - loss_3: 0.0912 - acc_ensemble: 0.9260 - acc_1: 0.9260 - acc_2: 0.9260 - acc_3: 0.9260 - val_loss_1: 1.0414 - val_loss_2: 1.0414 - val_loss_3: 1.0414 - val_acc_ensemble: 0.7531 - val_acc_1: 0.7531 - val_acc_2: 0.7531 - val_acc_3: 0.7531\n",
      "Epoch 41/50\n",
      "100/100 - 8s - loss_1: 0.0742 - loss_2: 0.0656 - loss_3: 0.0714 - acc_ensemble: 0.9260 - acc_1: 0.9260 - acc_2: 0.9260 - acc_3: 0.9260 - val_loss_1: 1.0371 - val_loss_2: 1.0371 - val_loss_3: 1.0371 - val_acc_ensemble: 0.7588 - val_acc_1: 0.7588 - val_acc_2: 0.7588 - val_acc_3: 0.7588\n",
      "Epoch 42/50\n",
      "100/100 - 8s - loss_1: 0.0607 - loss_2: 0.0659 - loss_3: 0.0734 - acc_ensemble: 0.9240 - acc_1: 0.9240 - acc_2: 0.9240 - acc_3: 0.9240 - val_loss_1: 1.0524 - val_loss_2: 1.0524 - val_loss_3: 1.0524 - val_acc_ensemble: 0.7584 - val_acc_1: 0.7584 - val_acc_2: 0.7584 - val_acc_3: 0.7584\n",
      "Epoch 43/50\n",
      "100/100 - 9s - loss_1: 0.0686 - loss_2: 0.0711 - loss_3: 0.0613 - acc_ensemble: 0.9300 - acc_1: 0.9300 - acc_2: 0.9300 - acc_3: 0.9300 - val_loss_1: 1.0834 - val_loss_2: 1.0834 - val_loss_3: 1.0834 - val_acc_ensemble: 0.7594 - val_acc_1: 0.7594 - val_acc_2: 0.7594 - val_acc_3: 0.7594\n",
      "Epoch 44/50\n",
      "100/100 - 9s - loss_1: 0.0740 - loss_2: 0.0719 - loss_3: 0.0851 - acc_ensemble: 0.9320 - acc_1: 0.9320 - acc_2: 0.9320 - acc_3: 0.9320 - val_loss_1: 1.0659 - val_loss_2: 1.0659 - val_loss_3: 1.0659 - val_acc_ensemble: 0.7600 - val_acc_1: 0.7600 - val_acc_2: 0.7600 - val_acc_3: 0.7600\n",
      "Epoch 45/50\n",
      "100/100 - 8s - loss_1: 0.0856 - loss_2: 0.0747 - loss_3: 0.0745 - acc_ensemble: 0.9280 - acc_1: 0.9280 - acc_2: 0.9280 - acc_3: 0.9280 - val_loss_1: 1.1227 - val_loss_2: 1.1227 - val_loss_3: 1.1227 - val_acc_ensemble: 0.7532 - val_acc_1: 0.7532 - val_acc_2: 0.7532 - val_acc_3: 0.7532\n",
      "Epoch 46/50\n",
      "100/100 - 9s - loss_1: 0.0737 - loss_2: 0.0743 - loss_3: 0.0667 - acc_ensemble: 0.9220 - acc_1: 0.9220 - acc_2: 0.9220 - acc_3: 0.9220 - val_loss_1: 1.1096 - val_loss_2: 1.1096 - val_loss_3: 1.1096 - val_acc_ensemble: 0.7520 - val_acc_1: 0.7520 - val_acc_2: 0.7520 - val_acc_3: 0.7520\n",
      "Epoch 47/50\n",
      "100/100 - 8s - loss_1: 0.0589 - loss_2: 0.0809 - loss_3: 0.0533 - acc_ensemble: 0.9380 - acc_1: 0.9380 - acc_2: 0.9380 - acc_3: 0.9380 - val_loss_1: 1.1138 - val_loss_2: 1.1138 - val_loss_3: 1.1138 - val_acc_ensemble: 0.7575 - val_acc_1: 0.7575 - val_acc_2: 0.7575 - val_acc_3: 0.7575\n",
      "Epoch 48/50\n",
      "100/100 - 9s - loss_1: 0.0590 - loss_2: 0.0589 - loss_3: 0.0496 - acc_ensemble: 0.9200 - acc_1: 0.9200 - acc_2: 0.9200 - acc_3: 0.9200 - val_loss_1: 1.1178 - val_loss_2: 1.1178 - val_loss_3: 1.1178 - val_acc_ensemble: 0.7581 - val_acc_1: 0.7581 - val_acc_2: 0.7581 - val_acc_3: 0.7581\n",
      "Epoch 49/50\n",
      "100/100 - 8s - loss_1: 0.0580 - loss_2: 0.0608 - loss_3: 0.0603 - acc_ensemble: 0.9440 - acc_1: 0.9440 - acc_2: 0.9440 - acc_3: 0.9440 - val_loss_1: 1.1092 - val_loss_2: 1.1092 - val_loss_3: 1.1092 - val_acc_ensemble: 0.7548 - val_acc_1: 0.7548 - val_acc_2: 0.7548 - val_acc_3: 0.7548\n",
      "Epoch 50/50\n",
      "100/100 - 8s - loss_1: 0.0598 - loss_2: 0.0563 - loss_3: 0.0637 - acc_ensemble: 0.9300 - acc_1: 0.9300 - acc_2: 0.9300 - acc_3: 0.9300 - val_loss_1: 1.1305 - val_loss_2: 1.1305 - val_loss_3: 1.1305 - val_acc_ensemble: 0.7571 - val_acc_1: 0.7571 - val_acc_2: 0.7571 - val_acc_3: 0.7571\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B4/S0.00/model_1\n",
      "i   Layer name                      Output shape        Num param  Inbound            \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                    \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                    \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                    \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                    \n",
      "--------------------------------------------------------------------------------------\n",
      "0   conv2d_1_1 (Conv2D)             [] [None,32,32,32]  3584       input              \n",
      "                                    [] [None,32,32,32]                                \n",
      "                                    [] [None,32,32,32]                                \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "1   bn_1_1 (BatchNormalization)     [] [None,32,32,32]  256        conv2d_1_1         \n",
      "                                    [] [None,32,32,32]                                \n",
      "                                    [] [None,32,32,32]                                \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "2   relu_1_1 (Activation)           [] [None,32,32,32]  0          bn_1_1             \n",
      "                                    [] [None,32,32,32]                                \n",
      "                                    [] [None,32,32,32]                                \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "3   conv2d_1_2 (Conv2D)             [] [None,32,32,32]  36992      relu_1_1           \n",
      "                                    [] [None,32,32,32]                                \n",
      "                                    [] [None,32,32,32]                                \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "4   bn_1_2 (BatchNormalization)     [] [None,32,32,32]  256        conv2d_1_2         \n",
      "                                    [] [None,32,32,32]                                \n",
      "                                    [] [None,32,32,32]                                \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "5   relu_1_2 (Activation)           [] [None,32,32,32]  0          bn_1_2             \n",
      "                                    [] [None,32,32,32]                                \n",
      "                                    [] [None,32,32,32]                                \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "6   avg_pool2d_1 (AveragePooling2D  [] [None,16,16,32]  0          relu_1_2           \n",
      "                                    [] [None,16,16,32]                                \n",
      "                                    [] [None,16,16,32]                                \n",
      "                                    [] [None,16,16,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "7   conv2d_2_1 (Conv2D)             [] [None,16,16,64]  73984      avg_pool2d_1       \n",
      "                                    [] [None,16,16,64]                                \n",
      "                                    [] [None,16,16,64]                                \n",
      "                                    [] [None,16,16,64]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "8   bn_2_1 (BatchNormalization)     [] [None,16,16,64]  512        conv2d_2_1         \n",
      "                                    [] [None,16,16,64]                                \n",
      "                                    [] [None,16,16,64]                                \n",
      "                                    [] [None,16,16,64]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "9   relu_2_1 (Activation)           [] [None,16,16,64]  0          bn_2_1             \n",
      "                                    [] [None,16,16,64]                                \n",
      "                                    [] [None,16,16,64]                                \n",
      "                                    [] [None,16,16,64]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "10  conv2d_2_2 (Conv2D)             [] [None,16,16,64]  147712     relu_2_1           \n",
      "                                    [] [None,16,16,64]                                \n",
      "                                    [] [None,16,16,64]                                \n",
      "                                    [] [None,16,16,64]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "11  bn_2_2 (BatchNormalization)     [] [None,16,16,64]  512        conv2d_2_2         \n",
      "                                    [] [None,16,16,64]                                \n",
      "                                    [] [None,16,16,64]                                \n",
      "                                    [] [None,16,16,64]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "12  relu_2_2 (Activation)           [] [None,16,16,64]  0          bn_2_2             \n",
      "                                    [] [None,16,16,64]                                \n",
      "                                    [] [None,16,16,64]                                \n",
      "                                    [] [None,16,16,64]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "13  avg_pool2d_2 (AveragePooling2D  [] [None,8,8,64]    0          relu_2_2           \n",
      "                                    [] [None,8,8,64]                                  \n",
      "                                    [] [None,8,8,64]                                  \n",
      "                                    [] [None,8,8,64]                                  \n",
      "--------------------------------------------------------------------------------------\n",
      "14  conv2d_3_1 (Conv2D)             [] [None,8,8,128]   295424     avg_pool2d_2       \n",
      "                                    [] [None,8,8,128]                                 \n",
      "                                    [] [None,8,8,128]                                 \n",
      "                                    [] [None,8,8,128]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "15  bn_3_1 (BatchNormalization)     [] [None,8,8,128]   1024       conv2d_3_1         \n",
      "                                    [] [None,8,8,128]                                 \n",
      "                                    [] [None,8,8,128]                                 \n",
      "                                    [] [None,8,8,128]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "16  relu_3_1 (Activation)           [] [None,8,8,128]   0          bn_3_1             \n",
      "                                    [] [None,8,8,128]                                 \n",
      "                                    [] [None,8,8,128]                                 \n",
      "                                    [] [None,8,8,128]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "17  conv2d_3_2 (Conv2D)             [] [None,8,8,128]   590336     relu_3_1           \n",
      "                                    [] [None,8,8,128]                                 \n",
      "                                    [] [None,8,8,128]                                 \n",
      "                                    [] [None,8,8,128]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "18  bn_3_2 (BatchNormalization)     [] [None,8,8,128]   1024       conv2d_3_2         \n",
      "                                    [] [None,8,8,128]                                 \n",
      "                                    [] [None,8,8,128]                                 \n",
      "                                    [] [None,8,8,128]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "19  relu_3_2 (Activation)           [] [None,8,8,128]   0          bn_3_2             \n",
      "                                    [] [None,8,8,128]                                 \n",
      "                                    [] [None,8,8,128]                                 \n",
      "                                    [] [None,8,8,128]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "20  global_avg_pool2d (GlobalAvera  [] [None,128]       0          relu_3_2           \n",
      "                                    [] [None,128]                                     \n",
      "                                    [] [None,128]                                     \n",
      "                                    [] [None,128]                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "21  fc1 (Dense)                     [] [None,128]       66048      global_avg_pool2d  \n",
      "                                    [] [None,128]                                     \n",
      "                                    [] [None,128]                                     \n",
      "                                    [] [None,128]                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "22  bn_fc1 (BatchNormalization)     [] [None,128]       1024       fc1                \n",
      "                                    [] [None,128]                                     \n",
      "                                    [] [None,128]                                     \n",
      "                                    [] [None,128]                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "23  relu_fc1 (Activation)           [] [None,128]       0          bn_fc1             \n",
      "                                    [] [None,128]                                     \n",
      "                                    [] [None,128]                                     \n",
      "                                    [] [None,128]                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "24  output (Dense)                  [None,10]           5160       relu_fc1           \n",
      "                                    [None,10]                                         \n",
      "                                    [None,10]                                         \n",
      "                                    [None,10]                                         \n",
      "--------------------------------------------------------------------------------------\n",
      "Total parameters: 1223848\n",
      "50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    }
   ],
   "source": [
    "for n_branches in range(2, 5):\n",
    "    for shared_frac in [0., 0.25, 0.5, 0.75, 1.]:\n",
    "        for t in range(4):\n",
    "            train(n_branches, shared_frac, model_id=t+1)\n",
    "# history = train(n_branches=1, shared_frac=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from vbranch.utils.generic import get_model_path, get_vb_model_path\n",
    "from vbranch.utils.test import baseline_classification, compute_correlation_strength, compute_acc_from_logits\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation and Strength"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For classification, we can compute the correlation between models and their strength. The formulas used are from the Random Forest paper:\n",
    "\n",
    "https://www.stat.berkeley.edu/~breiman/randomforest2001.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_strength(n_branches, shared_frac, model_id):\n",
    "    model_path = os.path.join('models', path(n_branches, shared_frac), \n",
    "                              'model_{}'.format(model_id))\n",
    "    print(model_path)\n",
    "\n",
    "    test_init_ops = []\n",
    "    tensors = []\n",
    "    for i in range(n_branches):\n",
    "        test_init_ops.append('test_init_op_{}'.format(i+1))\n",
    "        tensors.append('model/output/vb{}/output:0'.format(i+1))\n",
    "\n",
    "    with TFSessionGrow() as sess:\n",
    "        restore_sess(sess, model_path)\n",
    "        sess.run(test_init_ops, feed_dict={'x:0':X_test, 'y:0': y_test, \n",
    "                                           'batch_size:0':len(X_test)})\n",
    "        outputs = sess.run(tensors)\n",
    "\n",
    "    return compute_correlation_strength(outputs, y_test, NUM_CLASSES, n_branches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0804 19:23:25.682195 139826173404928 deprecation_wrapper.py:119] From /home/gong/research/vbranch/vbranch/utils/generic.py:9: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0804 19:23:25.685863 139826173404928 deprecation_wrapper.py:119] From /home/gong/research/vbranch/vbranch/utils/generic.py:11: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/sensitivity-Ba64/vb-cifar10-cnn/B2/S0.00/model_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0804 19:23:27.805045 139826173404928 deprecation_wrapper.py:119] From /home/gong/research/vbranch/vbranch/utils/generic.py:17: The name tf.train.import_meta_graph is deprecated. Please use tf.compat.v1.train.import_meta_graph instead.\n",
      "\n",
      "W0804 19:23:28.515814 139826173404928 deprecation.py:323] From /home/gong/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/sensitivity-Ba64/vb-cifar10-cnn/B2/S0.00/model_2\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B2/S0.00/model_3\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B2/S0.00/model_4\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B2/S0.25/model_1\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B2/S0.25/model_2\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B2/S0.25/model_3\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B2/S0.25/model_4\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B2/S0.50/model_1\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B2/S0.50/model_2\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B2/S0.50/model_3\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B2/S0.50/model_4\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B2/S0.75/model_1\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B2/S0.75/model_2\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B2/S0.75/model_3\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B2/S0.75/model_4\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B2/S1.00/model_1\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B2/S1.00/model_2\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B2/S1.00/model_3\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B2/S1.00/model_4\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B3/S0.00/model_1\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B3/S0.00/model_2\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B3/S0.00/model_3\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B3/S0.00/model_4\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B3/S0.25/model_1\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B3/S0.25/model_2\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B3/S0.25/model_3\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B3/S0.25/model_4\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B3/S0.50/model_1\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B3/S0.50/model_2\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B3/S0.50/model_3\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B3/S0.50/model_4\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B3/S0.75/model_1\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B3/S0.75/model_2\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B3/S0.75/model_3\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B3/S0.75/model_4\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B3/S1.00/model_1\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B3/S1.00/model_2\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B3/S1.00/model_3\n",
      "models/sensitivity-Ba64/vb-cifar10-cnn/B3/S1.00/model_4\n"
     ]
    }
   ],
   "source": [
    "correlation_results = {}\n",
    "strength_results = {}\n",
    "\n",
    "# num_branches = 4\n",
    "shared_frac_list = [0., 0.25, 0.5, 0.75, 1.]\n",
    "# shared_correlation_list = []\n",
    "# shared_strength_list = []\n",
    "n_trials = 4\n",
    "\n",
    "for b in range(2, 4):\n",
    "    correlation_results[b] = {}\n",
    "    strength_results[b] = {}\n",
    "    \n",
    "    for shared in shared_frac_list:\n",
    "        correlation_list = []\n",
    "        strength_list = []\n",
    "\n",
    "        for model_id in range(1, n_trials + 1):\n",
    "            tf.reset_default_graph()\n",
    "            c, s = correlation_strength(b, shared, model_id)\n",
    "            correlation_list.append(c)\n",
    "            strength_list.append(s)\n",
    "\n",
    "        correlation_results[b][shared] = [np.mean(correlation_list), np.std(correlation_list)]\n",
    "        strength_results[b][shared] = [np.mean(strength_list), np.std(strength_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'results/sensitivity-Ba64/correlation-{DATASET}-{ARCHITECTURE}.json', 'w') as f:\n",
    "    json.dump(correlation_results, f, indent=4)\n",
    "with open(f'results/sensitivity-Ba64/strength-{DATASET}-{ARCHITECTURE}.json', 'w') as f:\n",
    "    json.dump(strength_results, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture = ['cnn'] #, 'cnnx'] #, 'fcn2', 'fcn3', 'fcn2A', 'fcn3A']\n",
    "correlation = []\n",
    "strength = []\n",
    "\n",
    "for arch in architecture:\n",
    "    with open(f'results/sensitivity-Ba64/correlation-{DATASET}-{arch}.json', 'r') as f:\n",
    "        correlation.append(json.load(f))\n",
    "    with open(f'results/sensitivity-Ba64/strength-{DATASET}-{arch}.json', 'r') as f:\n",
    "        strength.append(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_corr_strength(n_branches):\n",
    "    def mean_std(data):\n",
    "        mean = []\n",
    "        std = []\n",
    "        for frac in shared_frac_list:\n",
    "            mean.append(data[str(frac)][0])\n",
    "            std.append(data[str(frac)][1])\n",
    "        return np.array(mean), np.array(std)\n",
    "    \n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.subplot(1,2,1)\n",
    "    for i, arch in enumerate(architecture):\n",
    "        data = correlation[i][str(n_branches)]\n",
    "        mean, std = mean_std(data)    \n",
    "        plt.errorbar(shared_frac_list, mean, 2*std / np.sqrt(n_trials), label=arch)\n",
    "        plt.legend()\n",
    "        \n",
    "    plt.subplot(1,2,2)\n",
    "    for i, arch in enumerate(architecture):\n",
    "        data = strength[i][str(n_branches)]\n",
    "        mean, std = mean_std(data)    \n",
    "        plt.errorbar(shared_frac_list, mean, 2*std / np.sqrt(n_trials), label=arch)    \n",
    "        plt.legend()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_corr_strength(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i   Layer name                      Output shape        Num param  Inbound            \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                    \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                    \n",
      "--------------------------------------------------------------------------------------\n",
      "0   conv2d_1_1 (Conv2D)             [] [None,32,32,32]  1792       input              \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "1   bn_1_1 (BatchNormalization)     [] [None,32,32,32]  128        conv2d_1_1         \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "2   relu_1_1 (Activation)           [] [None,32,32,32]  0          bn_1_1             \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "3   conv2d_1_2 (Conv2D)             [] [None,32,32,32]  18496      relu_1_1           \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "4   bn_1_2 (BatchNormalization)     [] [None,32,32,32]  128        conv2d_1_2         \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "5   relu_1_2 (Activation)           [] [None,32,32,32]  0          bn_1_2             \n",
      "                                    [] [None,32,32,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "6   avg_pool2d_1 (AveragePooling2D  [] [None,16,16,32]  0          relu_1_2           \n",
      "                                    [] [None,16,16,32]                                \n",
      "--------------------------------------------------------------------------------------\n",
      "7   conv2d_2_1 (Conv2D)             [None,16,16,64] []  18496      avg_pool2d_1       \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "8   bn_2_1 (BatchNormalization)     [None,16,16,64] []  128        conv2d_2_1         \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "9   relu_2_1 (Activation)           [None,16,16,64] []  0          bn_2_1             \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "10  conv2d_2_2 (Conv2D)             [None,16,16,64] []  36928      relu_2_1           \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "11  bn_2_2 (BatchNormalization)     [None,16,16,64] []  128        conv2d_2_2         \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "12  relu_2_2 (Activation)           [None,16,16,64] []  0          bn_2_2             \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "13  avg_pool2d_2 (AveragePooling2D  [None,8,8,64] []    0          relu_2_2           \n",
      "                                    [None,8,8,64] []                                  \n",
      "--------------------------------------------------------------------------------------\n",
      "14  conv2d_3_1 (Conv2D)             [None,8,8,128] []   73856      avg_pool2d_2       \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "15  bn_3_1 (BatchNormalization)     [None,8,8,128] []   256        conv2d_3_1         \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "16  relu_3_1 (Activation)           [None,8,8,128] []   0          bn_3_1             \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "17  conv2d_3_2 (Conv2D)             [None,8,8,128] []   147584     relu_3_1           \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "18  bn_3_2 (BatchNormalization)     [None,8,8,128] []   256        conv2d_3_2         \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "19  relu_3_2 (Activation)           [None,8,8,128] []   0          bn_3_2             \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "20  global_avg_pool2d (GlobalAvera  [None,128] []       0          relu_3_2           \n",
      "                                    [None,128] []                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "21  fc1 (Dense)                     [None,128] []       16512      global_avg_pool2d  \n",
      "                                    [None,128] []                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "22  bn_fc1 (BatchNormalization)     [None,128] []       256        fc1                \n",
      "                                    [None,128] []                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "23  relu_fc1 (Activation)           [None,128] []       0          bn_fc1             \n",
      "                                    [None,128] []                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "24  output (Dense)                  [None,10]           2580       relu_fc1           \n",
      "                                    [None,10]                                         \n",
      "--------------------------------------------------------------------------------------\n",
      "Total parameters: 317524\n",
      "i   Layer name                      Output shape                    Num param  Inbound            \n",
      "--------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                \n",
      "--------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                \n",
      "--------------------------------------------------------------------------------------------------\n",
      "0   conv2d_1_1 (Conv2D)             [None,32,32,8] [None,32,32,24]  1568       input              \n",
      "                                    [None,32,32,8] [None,32,32,24]                                \n",
      "--------------------------------------------------------------------------------------------------\n",
      "1   bn_1_1 (BatchNormalization)     [None,32,32,8] [None,32,32,24]  112        conv2d_1_1         \n",
      "                                    [None,32,32,8] [None,32,32,24]                                \n",
      "--------------------------------------------------------------------------------------------------\n",
      "2   relu_1_1 (Activation)           [None,32,32,8] [None,32,32,24]  0          bn_1_1             \n",
      "                                    [None,32,32,8] [None,32,32,24]                                \n",
      "--------------------------------------------------------------------------------------------------\n",
      "3   conv2d_1_2 (Conv2D)             [None,32,32,8] [None,32,32,24]  17976      relu_1_1           \n",
      "                                    [None,32,32,8] [None,32,32,24]                                \n",
      "--------------------------------------------------------------------------------------------------\n",
      "4   bn_1_2 (BatchNormalization)     [None,32,32,8] [None,32,32,24]  112        conv2d_1_2         \n",
      "                                    [None,32,32,8] [None,32,32,24]                                \n",
      "--------------------------------------------------------------------------------------------------\n",
      "5   relu_1_2 (Activation)           [None,32,32,8] [None,32,32,24]  0          bn_1_2             \n",
      "                                    [None,32,32,8] [None,32,32,24]                                \n",
      "--------------------------------------------------------------------------------------------------\n",
      "6   avg_pool2d_1 (AveragePooling2D  [None,16,16,8] [None,16,16,24]  0          relu_1_2           \n",
      "                                    [None,16,16,8] [None,16,16,24]                                \n",
      "--------------------------------------------------------------------------------------------------\n",
      "7   conv2d_2_1 (Conv2D)             [None,16,16,64] []              18496      avg_pool2d_1       \n",
      "                                    [None,16,16,64] []                                            \n",
      "--------------------------------------------------------------------------------------------------\n",
      "8   bn_2_1 (BatchNormalization)     [None,16,16,64] []              128        conv2d_2_1         \n",
      "                                    [None,16,16,64] []                                            \n",
      "--------------------------------------------------------------------------------------------------\n",
      "9   relu_2_1 (Activation)           [None,16,16,64] []              0          bn_2_1             \n",
      "                                    [None,16,16,64] []                                            \n",
      "--------------------------------------------------------------------------------------------------\n",
      "10  conv2d_2_2 (Conv2D)             [None,16,16,64] []              36928      relu_2_1           \n",
      "                                    [None,16,16,64] []                                            \n",
      "--------------------------------------------------------------------------------------------------\n",
      "11  bn_2_2 (BatchNormalization)     [None,16,16,64] []              128        conv2d_2_2         \n",
      "                                    [None,16,16,64] []                                            \n",
      "--------------------------------------------------------------------------------------------------\n",
      "12  relu_2_2 (Activation)           [None,16,16,64] []              0          bn_2_2             \n",
      "                                    [None,16,16,64] []                                            \n",
      "--------------------------------------------------------------------------------------------------\n",
      "13  avg_pool2d_2 (AveragePooling2D  [None,8,8,64] []                0          relu_2_2           \n",
      "                                    [None,8,8,64] []                                              \n",
      "--------------------------------------------------------------------------------------------------\n",
      "14  conv2d_3_1 (Conv2D)             [None,8,8,128] []               73856      avg_pool2d_2       \n",
      "                                    [None,8,8,128] []                                             \n",
      "--------------------------------------------------------------------------------------------------\n",
      "15  bn_3_1 (BatchNormalization)     [None,8,8,128] []               256        conv2d_3_1         \n",
      "                                    [None,8,8,128] []                                             \n",
      "--------------------------------------------------------------------------------------------------\n",
      "16  relu_3_1 (Activation)           [None,8,8,128] []               0          bn_3_1             \n",
      "                                    [None,8,8,128] []                                             \n",
      "--------------------------------------------------------------------------------------------------\n",
      "17  conv2d_3_2 (Conv2D)             [None,8,8,128] []               147584     relu_3_1           \n",
      "                                    [None,8,8,128] []                                             \n",
      "--------------------------------------------------------------------------------------------------\n",
      "18  bn_3_2 (BatchNormalization)     [None,8,8,128] []               256        conv2d_3_2         \n",
      "                                    [None,8,8,128] []                                             \n",
      "--------------------------------------------------------------------------------------------------\n",
      "19  relu_3_2 (Activation)           [None,8,8,128] []               0          bn_3_2             \n",
      "                                    [None,8,8,128] []                                             \n",
      "--------------------------------------------------------------------------------------------------\n",
      "20  global_avg_pool2d (GlobalAvera  [None,128] []                   0          relu_3_2           \n",
      "                                    [None,128] []                                                 \n",
      "--------------------------------------------------------------------------------------------------\n",
      "21  fc1 (Dense)                     [None,128] []                   16512      global_avg_pool2d  \n",
      "                                    [None,128] []                                                 \n",
      "--------------------------------------------------------------------------------------------------\n",
      "22  bn_fc1 (BatchNormalization)     [None,128] []                   256        fc1                \n",
      "                                    [None,128] []                                                 \n",
      "--------------------------------------------------------------------------------------------------\n",
      "23  relu_fc1 (Activation)           [None,128] []                   0          bn_fc1             \n",
      "                                    [None,128] []                                                 \n",
      "--------------------------------------------------------------------------------------------------\n",
      "24  output (Dense)                  [None,10]                       2322       relu_fc1           \n",
      "                                    [None,10]                                                     \n",
      "--------------------------------------------------------------------------------------------------\n",
      "Total parameters: 316490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i   Layer name                      Output shape                     Num param  Inbound            \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                 \n",
      "---------------------------------------------------------------------------------------------------\n",
      "0   conv2d_1_1 (Conv2D)             [None,32,32,16] [None,32,32,16]  1344       input              \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "1   bn_1_1 (BatchNormalization)     [None,32,32,16] [None,32,32,16]  96         conv2d_1_1         \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "2   relu_1_1 (Activation)           [None,32,32,16] [None,32,32,16]  0          bn_1_1             \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "3   conv2d_1_2 (Conv2D)             [None,32,32,16] [None,32,32,16]  16240      relu_1_1           \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "4   bn_1_2 (BatchNormalization)     [None,32,32,16] [None,32,32,16]  96         conv2d_1_2         \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "5   relu_1_2 (Activation)           [None,32,32,16] [None,32,32,16]  0          bn_1_2             \n",
      "                                    [None,32,32,16] [None,32,32,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "6   avg_pool2d_1 (AveragePooling2D  [None,16,16,16] [None,16,16,16]  0          relu_1_2           \n",
      "                                    [None,16,16,16] [None,16,16,16]                                \n",
      "---------------------------------------------------------------------------------------------------\n",
      "7   conv2d_2_1 (Conv2D)             [None,16,16,64] []               18496      avg_pool2d_1       \n",
      "                                    [None,16,16,64] []                                             \n",
      "---------------------------------------------------------------------------------------------------\n",
      "8   bn_2_1 (BatchNormalization)     [None,16,16,64] []               128        conv2d_2_1         \n",
      "                                    [None,16,16,64] []                                             \n",
      "---------------------------------------------------------------------------------------------------\n",
      "9   relu_2_1 (Activation)           [None,16,16,64] []               0          bn_2_1             \n",
      "                                    [None,16,16,64] []                                             \n",
      "---------------------------------------------------------------------------------------------------\n",
      "10  conv2d_2_2 (Conv2D)             [None,16,16,64] []               36928      relu_2_1           \n",
      "                                    [None,16,16,64] []                                             \n",
      "---------------------------------------------------------------------------------------------------\n",
      "11  bn_2_2 (BatchNormalization)     [None,16,16,64] []               128        conv2d_2_2         \n",
      "                                    [None,16,16,64] []                                             \n",
      "---------------------------------------------------------------------------------------------------\n",
      "12  relu_2_2 (Activation)           [None,16,16,64] []               0          bn_2_2             \n",
      "                                    [None,16,16,64] []                                             \n",
      "---------------------------------------------------------------------------------------------------\n",
      "13  avg_pool2d_2 (AveragePooling2D  [None,8,8,64] []                 0          relu_2_2           \n",
      "                                    [None,8,8,64] []                                               \n",
      "---------------------------------------------------------------------------------------------------\n",
      "14  conv2d_3_1 (Conv2D)             [None,8,8,128] []                73856      avg_pool2d_2       \n",
      "                                    [None,8,8,128] []                                              \n",
      "---------------------------------------------------------------------------------------------------\n",
      "15  bn_3_1 (BatchNormalization)     [None,8,8,128] []                256        conv2d_3_1         \n",
      "                                    [None,8,8,128] []                                              \n",
      "---------------------------------------------------------------------------------------------------\n",
      "16  relu_3_1 (Activation)           [None,8,8,128] []                0          bn_3_1             \n",
      "                                    [None,8,8,128] []                                              \n",
      "---------------------------------------------------------------------------------------------------\n",
      "17  conv2d_3_2 (Conv2D)             [None,8,8,128] []                147584     relu_3_1           \n",
      "                                    [None,8,8,128] []                                              \n",
      "---------------------------------------------------------------------------------------------------\n",
      "18  bn_3_2 (BatchNormalization)     [None,8,8,128] []                256        conv2d_3_2         \n",
      "                                    [None,8,8,128] []                                              \n",
      "---------------------------------------------------------------------------------------------------\n",
      "19  relu_3_2 (Activation)           [None,8,8,128] []                0          bn_3_2             \n",
      "                                    [None,8,8,128] []                                              \n",
      "---------------------------------------------------------------------------------------------------\n",
      "20  global_avg_pool2d (GlobalAvera  [None,128] []                    0          relu_3_2           \n",
      "                                    [None,128] []                                                  \n",
      "---------------------------------------------------------------------------------------------------\n",
      "21  fc1 (Dense)                     [None,128] []                    16512      global_avg_pool2d  \n",
      "                                    [None,128] []                                                  \n",
      "---------------------------------------------------------------------------------------------------\n",
      "22  bn_fc1 (BatchNormalization)     [None,128] []                    256        fc1                \n",
      "                                    [None,128] []                                                  \n",
      "---------------------------------------------------------------------------------------------------\n",
      "23  relu_fc1 (Activation)           [None,128] []                    0          bn_fc1             \n",
      "                                    [None,128] []                                                  \n",
      "---------------------------------------------------------------------------------------------------\n",
      "24  output (Dense)                  [None,10]                        1935       relu_fc1           \n",
      "                                    [None,10]                                                      \n",
      "---------------------------------------------------------------------------------------------------\n",
      "Total parameters: 314111\n",
      "i   Layer name                      Output shape                    Num param  Inbound            \n",
      "--------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                \n",
      "--------------------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                                \n",
      "--------------------------------------------------------------------------------------------------\n",
      "0   conv2d_1_1 (Conv2D)             [None,32,32,24] [None,32,32,8]  1120       input              \n",
      "                                    [None,32,32,24] [None,32,32,8]                                \n",
      "--------------------------------------------------------------------------------------------------\n",
      "1   bn_1_1 (BatchNormalization)     [None,32,32,24] [None,32,32,8]  80         conv2d_1_1         \n",
      "                                    [None,32,32,24] [None,32,32,8]                                \n",
      "--------------------------------------------------------------------------------------------------\n",
      "2   relu_1_1 (Activation)           [None,32,32,24] [None,32,32,8]  0          bn_1_1             \n",
      "                                    [None,32,32,24] [None,32,32,8]                                \n",
      "--------------------------------------------------------------------------------------------------\n",
      "3   conv2d_1_2 (Conv2D)             [None,32,32,24] [None,32,32,8]  13352      relu_1_1           \n",
      "                                    [None,32,32,24] [None,32,32,8]                                \n",
      "--------------------------------------------------------------------------------------------------\n",
      "4   bn_1_2 (BatchNormalization)     [None,32,32,24] [None,32,32,8]  80         conv2d_1_2         \n",
      "                                    [None,32,32,24] [None,32,32,8]                                \n",
      "--------------------------------------------------------------------------------------------------\n",
      "5   relu_1_2 (Activation)           [None,32,32,24] [None,32,32,8]  0          bn_1_2             \n",
      "                                    [None,32,32,24] [None,32,32,8]                                \n",
      "--------------------------------------------------------------------------------------------------\n",
      "6   avg_pool2d_1 (AveragePooling2D  [None,16,16,24] [None,16,16,8]  0          relu_1_2           \n",
      "                                    [None,16,16,24] [None,16,16,8]                                \n",
      "--------------------------------------------------------------------------------------------------\n",
      "7   conv2d_2_1 (Conv2D)             [None,16,16,64] []              18496      avg_pool2d_1       \n",
      "                                    [None,16,16,64] []                                            \n",
      "--------------------------------------------------------------------------------------------------\n",
      "8   bn_2_1 (BatchNormalization)     [None,16,16,64] []              128        conv2d_2_1         \n",
      "                                    [None,16,16,64] []                                            \n",
      "--------------------------------------------------------------------------------------------------\n",
      "9   relu_2_1 (Activation)           [None,16,16,64] []              0          bn_2_1             \n",
      "                                    [None,16,16,64] []                                            \n",
      "--------------------------------------------------------------------------------------------------\n",
      "10  conv2d_2_2 (Conv2D)             [None,16,16,64] []              36928      relu_2_1           \n",
      "                                    [None,16,16,64] []                                            \n",
      "--------------------------------------------------------------------------------------------------\n",
      "11  bn_2_2 (BatchNormalization)     [None,16,16,64] []              128        conv2d_2_2         \n",
      "                                    [None,16,16,64] []                                            \n",
      "--------------------------------------------------------------------------------------------------\n",
      "12  relu_2_2 (Activation)           [None,16,16,64] []              0          bn_2_2             \n",
      "                                    [None,16,16,64] []                                            \n",
      "--------------------------------------------------------------------------------------------------\n",
      "13  avg_pool2d_2 (AveragePooling2D  [None,8,8,64] []                0          relu_2_2           \n",
      "                                    [None,8,8,64] []                                              \n",
      "--------------------------------------------------------------------------------------------------\n",
      "14  conv2d_3_1 (Conv2D)             [None,8,8,128] []               73856      avg_pool2d_2       \n",
      "                                    [None,8,8,128] []                                             \n",
      "--------------------------------------------------------------------------------------------------\n",
      "15  bn_3_1 (BatchNormalization)     [None,8,8,128] []               256        conv2d_3_1         \n",
      "                                    [None,8,8,128] []                                             \n",
      "--------------------------------------------------------------------------------------------------\n",
      "16  relu_3_1 (Activation)           [None,8,8,128] []               0          bn_3_1             \n",
      "                                    [None,8,8,128] []                                             \n",
      "--------------------------------------------------------------------------------------------------\n",
      "17  conv2d_3_2 (Conv2D)             [None,8,8,128] []               147584     relu_3_1           \n",
      "                                    [None,8,8,128] []                                             \n",
      "--------------------------------------------------------------------------------------------------\n",
      "18  bn_3_2 (BatchNormalization)     [None,8,8,128] []               256        conv2d_3_2         \n",
      "                                    [None,8,8,128] []                                             \n",
      "--------------------------------------------------------------------------------------------------\n",
      "19  relu_3_2 (Activation)           [None,8,8,128] []               0          bn_3_2             \n",
      "                                    [None,8,8,128] []                                             \n",
      "--------------------------------------------------------------------------------------------------\n",
      "20  global_avg_pool2d (GlobalAvera  [None,128] []                   0          relu_3_2           \n",
      "                                    [None,128] []                                                 \n",
      "--------------------------------------------------------------------------------------------------\n",
      "21  fc1 (Dense)                     [None,128] []                   16512      global_avg_pool2d  \n",
      "                                    [None,128] []                                                 \n",
      "--------------------------------------------------------------------------------------------------\n",
      "22  bn_fc1 (BatchNormalization)     [None,128] []                   256        fc1                \n",
      "                                    [None,128] []                                                 \n",
      "--------------------------------------------------------------------------------------------------\n",
      "23  relu_fc1 (Activation)           [None,128] []                   0          bn_fc1             \n",
      "                                    [None,128] []                                                 \n",
      "--------------------------------------------------------------------------------------------------\n",
      "24  output (Dense)                  [None,10]                       1677       relu_fc1           \n",
      "                                    [None,10]                                                     \n",
      "--------------------------------------------------------------------------------------------------\n",
      "Total parameters: 310709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i   Layer name                      Output shape        Num param  Inbound            \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                    \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input                           [None,32,32,3]                                    \n",
      "--------------------------------------------------------------------------------------\n",
      "0   conv2d_1_1 (Conv2D)             [None,32,32,32] []  896        input              \n",
      "                                    [None,32,32,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "1   bn_1_1 (BatchNormalization)     [None,32,32,32] []  64         conv2d_1_1         \n",
      "                                    [None,32,32,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "2   relu_1_1 (Activation)           [None,32,32,32] []  0          bn_1_1             \n",
      "                                    [None,32,32,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "3   conv2d_1_2 (Conv2D)             [None,32,32,32] []  9248       relu_1_1           \n",
      "                                    [None,32,32,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "4   bn_1_2 (BatchNormalization)     [None,32,32,32] []  64         conv2d_1_2         \n",
      "                                    [None,32,32,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "5   relu_1_2 (Activation)           [None,32,32,32] []  0          bn_1_2             \n",
      "                                    [None,32,32,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "6   avg_pool2d_1 (AveragePooling2D  [None,16,16,32] []  0          relu_1_2           \n",
      "                                    [None,16,16,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "7   conv2d_2_1 (Conv2D)             [None,16,16,64] []  18496      avg_pool2d_1       \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "8   bn_2_1 (BatchNormalization)     [None,16,16,64] []  128        conv2d_2_1         \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "9   relu_2_1 (Activation)           [None,16,16,64] []  0          bn_2_1             \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "10  conv2d_2_2 (Conv2D)             [None,16,16,64] []  36928      relu_2_1           \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "11  bn_2_2 (BatchNormalization)     [None,16,16,64] []  128        conv2d_2_2         \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "12  relu_2_2 (Activation)           [None,16,16,64] []  0          bn_2_2             \n",
      "                                    [None,16,16,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "13  avg_pool2d_2 (AveragePooling2D  [None,8,8,64] []    0          relu_2_2           \n",
      "                                    [None,8,8,64] []                                  \n",
      "--------------------------------------------------------------------------------------\n",
      "14  conv2d_3_1 (Conv2D)             [None,8,8,128] []   73856      avg_pool2d_2       \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "15  bn_3_1 (BatchNormalization)     [None,8,8,128] []   256        conv2d_3_1         \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "16  relu_3_1 (Activation)           [None,8,8,128] []   0          bn_3_1             \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "17  conv2d_3_2 (Conv2D)             [None,8,8,128] []   147584     relu_3_1           \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "18  bn_3_2 (BatchNormalization)     [None,8,8,128] []   256        conv2d_3_2         \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "19  relu_3_2 (Activation)           [None,8,8,128] []   0          bn_3_2             \n",
      "                                    [None,8,8,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "20  global_avg_pool2d (GlobalAvera  [None,128] []       0          relu_3_2           \n",
      "                                    [None,128] []                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "21  fc1 (Dense)                     [None,128] []       16512      global_avg_pool2d  \n",
      "                                    [None,128] []                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "22  bn_fc1 (BatchNormalization)     [None,128] []       256        fc1                \n",
      "                                    [None,128] []                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "23  relu_fc1 (Activation)           [None,128] []       0          bn_fc1             \n",
      "                                    [None,128] []                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "24  output (Dense)                  [None,10]           1290       relu_fc1           \n",
      "                                    [None,10]                                         \n",
      "--------------------------------------------------------------------------------------\n",
      "Total parameters: 305962\n"
     ]
    }
   ],
   "source": [
    "# Vbranch params\n",
    "shared_frac_list = [0., 0.25, 0.5, 0.75, 1.]\n",
    "num_branches = 2\n",
    "\n",
    "vbranch_params = []\n",
    "for frac in shared_frac_list:\n",
    "    tf.reset_default_graph()\n",
    "    inputs = tf.placeholder('float32', [None, 32,32,3])\n",
    "    model = build_model(num_branches, frac, compile_loss=False)\n",
    "    model.summary()\n",
    "    vbranch_params.append(model.count_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_ratio = [p / vbranch_params[-1] for p in vbranch_params]\n",
    "ideal_ratio = num_branches - np.array(shared_frac_list)**2 * (num_branches-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(shared_frac_list, param_ratio, color='orange')\n",
    "# plt.plot(shared_frac_list, [1]*len(shared_frac_list))\n",
    "plt.plot(shared_frac_list, ideal_ratio)\n",
    "\n",
    "plt.xlabel('shared frac')\n",
    "plt.ylabel('params / baseline')\n",
    "plt.title('{} parameter count'.format(ARCHITECTURE))\n",
    "\n",
    "plt.savefig('figs/cnn-small-parameter-count.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
