{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with Virtual Branching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vbranch as vb\n",
    "from vbranch.utils.training_utils import get_data, bag_samples, get_data_iterator\n",
    "from vbranch.utils import TFSessionGrow, restore_sess\n",
    "from vbranch.callbacks import classification_acc\n",
    "from vbranch.applications.fcn import SimpleFCNv1, SimpleFCNv2\n",
    "from vbranch.applications.cnn import SimpleCNNSmall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE = False\n",
    "MODEL_ID = 1\n",
    "ARCHITECTURE = 'fcn2'\n",
    "DATASET = 'mnist'\n",
    "NUM_CLASSES = 10\n",
    "NUM_FEATURES = 784\n",
    "SAMPLES_PER_CLASS = 100\n",
    "BAGGING_SAMPLES = 1\n",
    "\n",
    "NUM_BRANCHES = 1\n",
    "SHARED_FRAC = 0.25\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 15\n",
    "STEPS_PER_EPOCH = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = get_data(DATASET, ARCHITECTURE, NUM_CLASSES,\n",
    "                                                NUM_FEATURES, SAMPLES_PER_CLASS)\n",
    "x_shape = (None,) + X_train.shape[1:]\n",
    "y_shape = (None, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform bagging\n",
    "x_train_list, y_train_list = bag_samples(X_train, y_train, NUM_BRANCHES, \n",
    "                                         max_samples=BAGGING_SAMPLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/mnist-fcn2_1\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir('models'):\n",
    "    os.system('mkdir models')\n",
    "\n",
    "if NUM_BRANCHES == 1:\n",
    "    model_name = '{}-{}_{:d}'.format(DATASET, ARCHITECTURE, MODEL_ID)\n",
    "else:\n",
    "    model_name = 'vb-{}-{}-B{:d}-S{:.2f}_{:d}'.format(DATASET, ARCHITECTURE,\n",
    "                                                      NUM_BRANCHES, SHARED_FRAC, MODEL_ID)\n",
    "model_path = os.path.join('models', model_name)\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/gong/anaconda3/lib/python3.5/site-packages/tensorflow/python/data/ops/iterator_ops.py:358: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "inputs, labels_one_hot, train_init_op, test_init_op = get_data_iterator(x_shape, y_shape, batch_size=BATCH_SIZE, \n",
    "                                                      n=NUM_BRANCHES, share_xy=BAGGING_SAMPLES == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Operation 'test_init_op' type=MakeIterator>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_init_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(architecture,inputs,labels, num_classes,num_branches,model_id, shared_frac):\n",
    "    if num_branches > 1 and isinstance(inputs, tf.Tensor):\n",
    "        inputs = [inputs] * num_branches\n",
    "        \n",
    "    name = 'model'\n",
    "    \n",
    "    with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n",
    "        if architecture == 'fcn':\n",
    "            model = SimpleFCNv1(inputs, num_classes, name=name, shared_frac=shared_frac)\n",
    "        elif architecture == 'fcn2':\n",
    "            model = SimpleFCNv2(inputs, num_classes, name=name, shared_frac=shared_frac)\n",
    "        elif architecture == 'cnn':\n",
    "            model = SimpleCNNSmall(inputs, num_classes, name=name, shared_frac=shared_frac)\n",
    "        else:\n",
    "            raise ValueError('invalid model')\n",
    "\n",
    "        if type(labels) is list or num_branches == 1:\n",
    "            labels_list = labels\n",
    "        else:\n",
    "            labels_list = [labels] * num_branches\n",
    "\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "        model.compile(optimizer, 'softmax_cross_entropy_with_logits', \n",
    "                      train_init_op, test_init_op, \n",
    "                      labels_one_hot=labels_list, \n",
    "                      callbacks={'acc':classification_acc(NUM_BRANCHES)})\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/gong/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "i  Layer name                Output shape  Parameters       Num param  Inbound  \n",
      "--------------------------------------------------------------------------------\n",
      "   Input                     [None,784]                                         \n",
      "--------------------------------------------------------------------------------\n",
      "0  fc1 (Dense)               [None,512]    [784,512] [512]  401920     input:0  \n",
      "--------------------------------------------------------------------------------\n",
      "1  bn1 (BatchNormalization)  [None,512]    [512] [512]      1024       fc1      \n",
      "--------------------------------------------------------------------------------\n",
      "2  relu1 (Activation)        [None,512]                     0          bn1      \n",
      "--------------------------------------------------------------------------------\n",
      "3  fc2 (Dense)               [None,256]    [512,256] [256]  131328     relu1    \n",
      "--------------------------------------------------------------------------------\n",
      "4  bn2 (BatchNormalization)  [None,256]    [256] [256]      512        fc2      \n",
      "--------------------------------------------------------------------------------\n",
      "5  relu2 (Activation)        [None,256]                     0          bn2      \n",
      "--------------------------------------------------------------------------------\n",
      "6  output (Dense)            [None,10]     [256,10] [10]    2570       relu2    \n",
      "--------------------------------------------------------------------------------\n",
      "Total parameters: 537354\n"
     ]
    }
   ],
   "source": [
    "model = build_model(ARCHITECTURE, inputs, labels_one_hot, NUM_CLASSES,\n",
    "                    NUM_BRANCHES, MODEL_ID, SHARED_FRAC)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"model/output/output:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(model.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      " - 1s - loss: 0.4878 - acc: 0.9156 - val_loss: 0.2815 - val_acc: 0.9140\n",
      "Epoch 2/15\n",
      " - 1s - loss: 0.1792 - acc: 0.9307 - val_loss: 0.2297 - val_acc: 0.9264\n",
      "Epoch 3/15\n",
      " - 1s - loss: 0.1050 - acc: 0.9373 - val_loss: 0.2113 - val_acc: 0.9321\n",
      "Epoch 4/15\n",
      " - 1s - loss: 0.0940 - acc: 0.9385 - val_loss: 0.2027 - val_acc: 0.9346\n",
      "Epoch 5/15\n",
      " - 1s - loss: 0.0767 - acc: 0.9426 - val_loss: 0.1954 - val_acc: 0.9399\n",
      "Epoch 6/15\n",
      " - 1s - loss: 0.0500 - acc: 0.9496 - val_loss: 0.1780 - val_acc: 0.9427\n",
      "Epoch 7/15\n",
      " - 1s - loss: 0.0448 - acc: 0.9470 - val_loss: 0.1826 - val_acc: 0.9437\n",
      "Epoch 8/15\n",
      " - 1s - loss: 0.0331 - acc: 0.9511 - val_loss: 0.1750 - val_acc: 0.9455\n",
      "Epoch 9/15\n",
      " - 1s - loss: 0.0276 - acc: 0.9523 - val_loss: 0.1675 - val_acc: 0.9490\n",
      "Epoch 10/15\n",
      " - 1s - loss: 0.0277 - acc: 0.9510 - val_loss: 0.1712 - val_acc: 0.9488\n",
      "Epoch 11/15\n",
      " - 1s - loss: 0.0234 - acc: 0.9458 - val_loss: 0.1791 - val_acc: 0.9459\n",
      "Epoch 12/15\n",
      " - 1s - loss: 0.0201 - acc: 0.9482 - val_loss: 0.1855 - val_acc: 0.9436\n",
      "Epoch 13/15\n",
      " - 1s - loss: 0.0143 - acc: 0.9533 - val_loss: 0.1631 - val_acc: 0.9505\n",
      "Epoch 14/15\n",
      " - 1s - loss: 0.0102 - acc: 0.9543 - val_loss: 0.1669 - val_acc: 0.9495\n",
      "Epoch 15/15\n",
      " - 1s - loss: 0.0059 - acc: 0.9554 - val_loss: 0.1686 - val_acc: 0.9507\n"
     ]
    }
   ],
   "source": [
    "if NUM_BRANCHES == 1 or BAGGING_SAMPLES == 1:\n",
    "    train_dict = {'x:0': X_train, 'y:0': y_train, 'batch_size:0': BATCH_SIZE}\n",
    "else:\n",
    "    train_dict = {}\n",
    "    for i in range(NUM_BRANCHES):\n",
    "        train_dict['vb{}_x:0'.format(i+1)] = x_train_list[i]\n",
    "        train_dict['vb{}_y:0'.format(i+1)] = y_train_list[i]\n",
    "    train_dict['batch_size:0'] = BATCH_SIZE\n",
    "    \n",
    "val_dict = {'x:0': X_test, 'y:0': y_test, 'batch_size:0': len(X_test)}\n",
    "\n",
    "history = model.fit(train_dict, EPOCHS, STEPS_PER_EPOCH,\n",
    "                    val_dict=val_dict, log_path=model_path if SAVE else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/gong/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from models/mnist-fcn_1/ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/gong/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-13-cf44fd73e05c>\", line 14, in <module>\n",
      "    model_name='model_'+str(model_id)+'_1')\n",
      "TypeError: baseline_classification() got multiple values for argument 'model_name'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/gong/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/gong/anaconda3/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/gong/anaconda3/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/gong/anaconda3/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/gong/anaconda3/lib/python3.5/inspect.py\", line 1459, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/gong/anaconda3/lib/python3.5/inspect.py\", line 1417, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/gong/anaconda3/lib/python3.5/inspect.py\", line 677, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/gong/anaconda3/lib/python3.5/inspect.py\", line 716, in getmodule\n",
      "    if f == _filesbymodname.get(modname, None):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "baseline_classification() got multiple values for argument 'model_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "assert NUM_BRANCHES == 1\n",
    "\n",
    "model_id_list = [1]\n",
    "baseline_acc_list = []\n",
    "\n",
    "for model_id in model_id_list:\n",
    "    tf.reset_default_graph()\n",
    "    model_name = '{}-{}_{:d}'.format(DATASET, ARCHITECTURE, model_id)\n",
    "    model_path = os.path.join('models', model_name)\n",
    "    \n",
    "    with TFSessionGrow() as sess:\n",
    "        restore_sess(sess, model_path)\n",
    "        acc = baseline_classification(sess, X_test, y_test)\n",
    "        print('Model {} acc:'.format(model_id), acc)\n",
    "        baseline_acc_list.append(acc)\n",
    "        \n",
    "print('Mean acc:', np.mean(baseline_acc_list), ', std:', np.std(baseline_acc_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_outputs = []\n",
    "test_losses = []\n",
    "test_accs = []\n",
    "\n",
    "num_models = 4\n",
    "graphs = [tf.Graph() for _ in range(5)]\n",
    "sessions = [tf.Session(graph=g) for g in graphs]\n",
    "\n",
    "for i in np.random.choice(5, num_models, replace=False):\n",
    "    with graphs[i].as_default():\n",
    "        model_path = 'models/mnist-{}_{}'.format(architecture, i + 1)\n",
    "        meta_path = os.path.join(model_path, 'ckpt.meta')\n",
    "        ckpt = tf.train.get_checkpoint_state(model_path)\n",
    "        \n",
    "        imported_graph = tf.train.import_meta_graph(meta_path)\n",
    "        imported_graph.restore(sessions[i], ckpt.model_checkpoint_path)\n",
    "                \n",
    "        sessions[i].run('test_init_op', feed_dict={'batch_size:0': len(X_test)})\n",
    "        \n",
    "        output, loss, acc = sessions[i].run(['model_%d'%(i+1)+'/'+'output:0', \n",
    "                                             'loss:0', 'acc:0'])\n",
    "        test_outputs.append(output)\n",
    "        test_losses.append(loss)\n",
    "        test_accs.append(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Virtual Branching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id_list = [1]\n",
    "vbranch_acc_list = []\n",
    "\n",
    "for model_id in model_id_list:\n",
    "    tf.reset_default_graph()\n",
    "    model_name = 'vb-{}-{}-B{:d}-S{:.2f}_{:d}'.format(DATASET, ARCHITECTURE,\n",
    "                                            NUM_BRANCHES, SHARED_FRAC, model_id)\n",
    "    model_path = os.path.join('models', model_name)\n",
    "    \n",
    "    with TFSessionGrow() as sess:\n",
    "        restore_sess(sess, model_path)\n",
    "        acc, branch_acc = vbranch_classification(sess, X_test, y_test, \n",
    "                                     model_name='model_'+str(model_id)+'_1', \n",
    "                                     num_classes=NUM_CLASSES, \n",
    "                                     n_branches=NUM_BRANCHES)\n",
    "        print('Model {} acc:'.format(model_id), acc, branch_acc)\n",
    "        vbranch_acc_list.append(acc)\n",
    "        \n",
    "print('Mean acc:', np.mean(vbranch_acc_list), ', std:', np.std(vbranch_acc_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tsne(features):\n",
    "    start = time.time()\n",
    "    tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
    "    tsne_results = tsne.fit_transform(features)\n",
    "\n",
    "    print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-start))\n",
    "    return tsne_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample, y_sample = bag_samples(X_train, y_train, 1, max_samples=250)\n",
    "print(X_sample.shape, y_sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "model_name = '{}-{}_{:d}'.format(DATASET, ARCHITECTURE, MODEL_ID)\n",
    "model_path = os.path.join('models', model_name)\n",
    "\n",
    "with TFSessionGrow() as sess:\n",
    "    restore_sess(sess, model_path)\n",
    "    baseline_features = sess.run('model_{}_1/output/output:0'.format(MODEL_ID), \n",
    "                                 feed_dict={'x_test:0':X_sample})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "model_name = 'vb-{}-{}-B{:d}-S{:.2f}_{:d}'.format(DATASET, ARCHITECTURE,\n",
    "                                            NUM_BRANCHES, SHARED_FRAC, MODEL_ID)\n",
    "model_path = os.path.join('models', model_name)\n",
    "    \n",
    "with TFSessionGrow() as sess:\n",
    "    restore_sess(sess, model_path)\n",
    "    \n",
    "    outputs = []\n",
    "    for i in range(NUM_BRANCHES):\n",
    "        name = os.path.join('model_{}_1/output/vb{}/output:0'.format(MODEL_ID, i+1))\n",
    "        outputs.append(name)\n",
    "        \n",
    "    vbranch_features = sess.run(outputs, feed_dict={'x_test:0':X_sample})\n",
    "    mean_vbranch_features = np.mean(vbranch_features, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_tsne = get_tsne(baseline_features)\n",
    "vbranch_tsne = get_tsne(mean_vbranch_features)\n",
    "sample_labels = np.argmax(y_sample, axis=-1)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(baseline_tsne[:,0], baseline_tsne[:,1], c=sample_labels, cmap=plt.cm.jet)\n",
    "plt.colorbar()\n",
    "plt.title('Baseline')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(vbranch_tsne[:,0], vbranch_tsne[:,1], c=sample_labels, cmap=plt.cm.jet)\n",
    "plt.colorbar()\n",
    "plt.title('Virtual Branching')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation and Strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vbranch.utils.generic_utils import get_model_path, get_vb_model_path\n",
    "from vbranch.utils.test_utils import compute_correlation_strength, compute_acc_from_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_labels = np.argmax(y_test, axis=-1)\n",
    "\n",
    "model_id_list = range(1, 9)\n",
    "output_list = []\n",
    "acc_list = []\n",
    "pred_list = []\n",
    "\n",
    "for model_id in model_id_list:\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        model_path = get_model_path(DATASET, ARCHITECTURE, NUM_CLASSES, \n",
    "                                    SAMPLES_PER_CLASS, model_id)\n",
    "        restore_sess(sess, model_path)\n",
    "        output = sess.run('model_{}_1/output:0'.format(model_id),\n",
    "            feed_dict={'x_test:0':X_test})\n",
    "\n",
    "    output_list.append(output)\n",
    "    acc_list.append(compute_acc_from_logits(output, y_test, NUM_CLASSES))\n",
    "    pred_list.append(np.argmax(output, axis=1))\n",
    "    \n",
    "model_preds = np.array(pred_list).transpose(1,0)\n",
    "baseline_corr, baseline_strength = compute_correlation_strength(model_preds, y_labels, \n",
    "                                                                NUM_CLASSES, \n",
    "                                                                len(model_id_list))\n",
    "\n",
    "print('Mean correlation:', baseline_corr)\n",
    "print('Strength:' , baseline_strength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_frac_list = [0, 0.25, 0.5, 0.75, 1]\n",
    "shared_correlation_list = []\n",
    "shared_strength_list = []\n",
    "\n",
    "for shared in shared_frac_list:\n",
    "    mean_correlation_list = []\n",
    "    strength_list = []\n",
    "    \n",
    "    for model_id in range(1, 5):\n",
    "        model_path = get_vb_model_path(DATASET, ARCHITECTURE, NUM_BRANCHES, shared, \n",
    "                                       NUM_CLASSES, SAMPLES_PER_CLASS, model_id)\n",
    "\n",
    "        tensors = []\n",
    "        for i in range(NUM_BRANCHES):\n",
    "            if shared == 0:\n",
    "                t = 'model_{}_1/output_vb{}:0'.format(model_id, i+1)\n",
    "            else:\n",
    "                t = 'model_{}_1/output_{}:0'.format(model_id, i+1)\n",
    "            tensors.append(t)\n",
    "\n",
    "        tf.reset_default_graph()\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            restore_sess(sess, model_path)\n",
    "            feed_dict = feed_dict={'x_test:0': X_test, 'y_test:0': y_test}\n",
    "            outputs, acc = sess.run([tensors, 'acc_ensemble_1:0'], feed_dict=feed_dict)\n",
    "            \n",
    "        preds = np.array([np.argmax(x, axis=1) for x in outputs]).transpose(1,0)\n",
    "        mean_correlation, strength = compute_correlation_strength(preds, y_labels, NUM_CLASSES, NUM_BRANCHES)\n",
    "        \n",
    "        mean_correlation_list.append(mean_correlation)\n",
    "        strength_list.append(strength)\n",
    "        \n",
    "    shared_correlation_list.append([np.mean(mean_correlation_list), np.std(mean_correlation_list)])\n",
    "    shared_strength_list.append([np.mean(strength_list), np.std(strength_list)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(shared_frac_list, np.array(shared_correlation_list)[:, 0], label='correlation')\n",
    "plt.plot(shared_frac_list, np.array(shared_strength_list)[:, 0], label='strength')\n",
    "\n",
    "# Baseline\n",
    "plt.plot(shared_frac_list, [baseline_corr]* len(shared_correlation_list), \n",
    "         label='baseline correlation', linestyle='--')\n",
    "plt.plot(shared_frac_list, [baseline_strength]* len(shared_correlation_list), \n",
    "         label='baseline strength', linestyle='--')\n",
    "\n",
    "plt.xlabel('shared frac')\n",
    "plt.title('Correlation and Strength')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig('figs/correlation-strength.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
