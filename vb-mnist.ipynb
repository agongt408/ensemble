{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST with Virtual Branching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.special import softmax\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vbranch as vb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = True\n",
    "model_id = 1\n",
    "architecture = 'cnn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'mnist'\n",
    "num_classes = 10\n",
    "num_features = 784\n",
    "samples_per_class = 200\n",
    "(X_train, y_train), (X_test, y_test) = vb.utils.get_data(dataset, architecture, num_classes,\n",
    "                                                         num_features, samples_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_shape = (None,) + X_train.shape[1:]\n",
    "y_shape = (None, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 30\n",
    "STEPS_PER_EPOCH = 100\n",
    "NUM_BRANCHES = 4\n",
    "SHARED_FRAC = 0\n",
    "model_path = os.path.join('models', 'vb-{}-{}-B{:d}-S{:.2f}_{:d}'.format(dataset, architecture,\n",
    "    NUM_BRANCHES, SHARED_FRAC, model_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'models/vb-mnist-cnn-B4-S0.00_1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder('float32', x_shape, name='x')\n",
    "y = tf.placeholder('float32', y_shape, name='y')\n",
    "\n",
    "batch_size = tf.placeholder('int64', name='batch_size')\n",
    "\n",
    "iterators = [None] * NUM_BRANCHES\n",
    "inputs = [None] * NUM_BRANCHES\n",
    "labels_one_hot = [None] * NUM_BRANCHES\n",
    "\n",
    "for i in range(NUM_BRANCHES):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x,y)).\\\n",
    "        repeat().batch(batch_size).shuffle(buffer_size=4*BATCH_SIZE)\n",
    "\n",
    "    iterators[i] = dataset.make_initializable_iterator()\n",
    "    inputs[i], labels_one_hot[i] = iterators[i].get_next('input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(architecture,inputs,labels, num_classes,num_branches,model_id,\n",
    "        shared_frac, test=False):\n",
    "        \n",
    "    if architecture == 'fcn':\n",
    "        model = vb.vbranch_simple_fcn(inputs,\n",
    "            ([128]*num_branches, int(128*shared_frac)),\n",
    "            ([num_classes]*num_branches, int(num_classes*shared_frac)),\n",
    "            branches=num_branches, name='model_' + str(model_id))\n",
    "    elif architecture == 'cnn':\n",
    "        model = vb.vbranch_simple_cnn(inputs, (num_classes, 0),\n",
    "            ([16]*num_branches, int(16*shared_frac)),\n",
    "            ([32]*num_branches, int(32*shared_frac)),\n",
    "            branches=num_branches, name='model_' + str(model_id))\n",
    "    else:\n",
    "        raise ValueError('invalid model')\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "    model.compile(optimizer, 'softmax_cross_entropy_with_logits',\n",
    "                    labels_one_hot=labels, test=test)\n",
    "#     if not test:\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i   Layer name         Output shape                     Num param  Inbound            \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input              [None,28,28,1]                                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input              [None,28,28,1]                                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input              [None,28,28,1]                                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input              [None,28,28,1]                                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "0   conv2d_1_1         [None,26,26,12] [None,26,26,4]   280        input              \n",
      "                       [None,26,26,12] [None,26,26,4]                                 \n",
      "                       [None,26,26,12] [None,26,26,4]                                 \n",
      "                       [None,26,26,12] [None,26,26,4]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "1   bn_1_1             [None,26,26,12] [None,26,26,4]   56         conv2d_1_1         \n",
      "                       [None,26,26,12] [None,26,26,4]                                 \n",
      "                       [None,26,26,12] [None,26,26,4]                                 \n",
      "                       [None,26,26,12] [None,26,26,4]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "2   relu_1_1           [None,26,26,12] [None,26,26,4]   0          bn_1_1             \n",
      "                       [None,26,26,12] [None,26,26,4]                                 \n",
      "                       [None,26,26,12] [None,26,26,4]                                 \n",
      "                       [None,26,26,12] [None,26,26,4]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "3   conv2d_1_2         [None,24,24,12] [None,24,24,4]   5420       relu_1_1           \n",
      "                       [None,24,24,12] [None,24,24,4]                                 \n",
      "                       [None,24,24,12] [None,24,24,4]                                 \n",
      "                       [None,24,24,12] [None,24,24,4]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "4   bn_1_2             [None,24,24,12] [None,24,24,4]   56         conv2d_1_2         \n",
      "                       [None,24,24,12] [None,24,24,4]                                 \n",
      "                       [None,24,24,12] [None,24,24,4]                                 \n",
      "                       [None,24,24,12] [None,24,24,4]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "5   relu_1_2           [None,24,24,12] [None,24,24,4]   0          bn_1_2             \n",
      "                       [None,24,24,12] [None,24,24,4]                                 \n",
      "                       [None,24,24,12] [None,24,24,4]                                 \n",
      "                       [None,24,24,12] [None,24,24,4]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "6   avg_pool2d_1       [None,12,12,12] [None,12,12,4]   0          relu_1_2           \n",
      "                       [None,12,12,12] [None,12,12,4]                                 \n",
      "                       [None,12,12,12] [None,12,12,4]                                 \n",
      "                       [None,12,12,12] [None,12,12,4]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "7   conv2d_2_1         [None,10,10,24] [None,10,10,8]   10840      avg_pool2d_1       \n",
      "                       [None,10,10,24] [None,10,10,8]                                 \n",
      "                       [None,10,10,24] [None,10,10,8]                                 \n",
      "                       [None,10,10,24] [None,10,10,8]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "8   bn_2_1             [None,10,10,24] [None,10,10,8]   112        conv2d_2_1         \n",
      "                       [None,10,10,24] [None,10,10,8]                                 \n",
      "                       [None,10,10,24] [None,10,10,8]                                 \n",
      "                       [None,10,10,24] [None,10,10,8]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "9   relu_2_1           [None,10,10,24] [None,10,10,8]   0          bn_2_1             \n",
      "                       [None,10,10,24] [None,10,10,8]                                 \n",
      "                       [None,10,10,24] [None,10,10,8]                                 \n",
      "                       [None,10,10,24] [None,10,10,8]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "10  conv2d_2_2         [None,8,8,24] [None,8,8,8]       21496      relu_2_1           \n",
      "                       [None,8,8,24] [None,8,8,8]                                     \n",
      "                       [None,8,8,24] [None,8,8,8]                                     \n",
      "                       [None,8,8,24] [None,8,8,8]                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "11  bn_2_2             [None,8,8,24] [None,8,8,8]       112        conv2d_2_2         \n",
      "                       [None,8,8,24] [None,8,8,8]                                     \n",
      "                       [None,8,8,24] [None,8,8,8]                                     \n",
      "                       [None,8,8,24] [None,8,8,8]                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "12  relu_2_2           [None,8,8,24] [None,8,8,8]       0          bn_2_2             \n",
      "                       [None,8,8,24] [None,8,8,8]                                     \n",
      "                       [None,8,8,24] [None,8,8,8]                                     \n",
      "                       [None,8,8,24] [None,8,8,8]                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "13  global_avg_pool2d  [None,24] [None,8]               0          relu_2_2           \n",
      "                       [None,24] [None,8]                                             \n",
      "                       [None,24] [None,8]                                             \n",
      "                       [None,24] [None,8]                                             \n",
      "--------------------------------------------------------------------------------------\n",
      "14  fc1                [None,24] [None,8]               2552       global_avg_pool2d  \n",
      "                       [None,24] [None,8]                                             \n",
      "                       [None,24] [None,8]                                             \n",
      "                       [None,24] [None,8]                                             \n",
      "--------------------------------------------------------------------------------------\n",
      "15  bn_fc1             [None,24] [None,8]               112        fc1                \n",
      "                       [None,24] [None,8]                                             \n",
      "                       [None,24] [None,8]                                             \n",
      "                       [None,24] [None,8]                                             \n",
      "--------------------------------------------------------------------------------------\n",
      "16  relu_fc1           [None,24] [None,8]               0          bn_fc1             \n",
      "                       [None,24] [None,8]                                             \n",
      "                       [None,24] [None,8]                                             \n",
      "                       [None,24] [None,8]                                             \n",
      "--------------------------------------------------------------------------------------\n",
      "17  output             [None,10]                        1320       relu_fc1           \n",
      "                       [None,10]                                                      \n",
      "                       [None,10]                                                      \n",
      "                       [None,10]                                                      \n",
      "--------------------------------------------------------------------------------------\n",
      "Total parameters: 42356\n"
     ]
    }
   ],
   "source": [
    "model = build_model(architecture, inputs, labels_one_hot, num_classes,\n",
    "        NUM_BRANCHES, model_id, SHARED_FRAC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i   Layer name         Output shape                     Num param  Inbound            \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input              [None,28,28,1]                                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input              [None,28,28,1]                                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input              [None,28,28,1]                                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input              [None,28,28,1]                                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "0   conv2d_1_1         [None,26,26,12] [None,26,26,4]   280        input              \n",
      "                       [None,26,26,12] [None,26,26,4]                                 \n",
      "                       [None,26,26,12] [None,26,26,4]                                 \n",
      "                       [None,26,26,12] [None,26,26,4]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "1   bn_1_1             [None,26,26,12] [None,26,26,4]   56         conv2d_1_1         \n",
      "                       [None,26,26,12] [None,26,26,4]                                 \n",
      "                       [None,26,26,12] [None,26,26,4]                                 \n",
      "                       [None,26,26,12] [None,26,26,4]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "2   relu_1_1           [None,26,26,12] [None,26,26,4]   0          bn_1_1             \n",
      "                       [None,26,26,12] [None,26,26,4]                                 \n",
      "                       [None,26,26,12] [None,26,26,4]                                 \n",
      "                       [None,26,26,12] [None,26,26,4]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "3   conv2d_1_2         [None,24,24,12] [None,24,24,4]   5420       relu_1_1           \n",
      "                       [None,24,24,12] [None,24,24,4]                                 \n",
      "                       [None,24,24,12] [None,24,24,4]                                 \n",
      "                       [None,24,24,12] [None,24,24,4]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "4   bn_1_2             [None,24,24,12] [None,24,24,4]   56         conv2d_1_2         \n",
      "                       [None,24,24,12] [None,24,24,4]                                 \n",
      "                       [None,24,24,12] [None,24,24,4]                                 \n",
      "                       [None,24,24,12] [None,24,24,4]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "5   relu_1_2           [None,24,24,12] [None,24,24,4]   0          bn_1_2             \n",
      "                       [None,24,24,12] [None,24,24,4]                                 \n",
      "                       [None,24,24,12] [None,24,24,4]                                 \n",
      "                       [None,24,24,12] [None,24,24,4]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "6   avg_pool2d_1       [None,12,12,12] [None,12,12,4]   0          relu_1_2           \n",
      "                       [None,12,12,12] [None,12,12,4]                                 \n",
      "                       [None,12,12,12] [None,12,12,4]                                 \n",
      "                       [None,12,12,12] [None,12,12,4]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "7   conv2d_2_1         [None,10,10,24] [None,10,10,8]   10840      avg_pool2d_1       \n",
      "                       [None,10,10,24] [None,10,10,8]                                 \n",
      "                       [None,10,10,24] [None,10,10,8]                                 \n",
      "                       [None,10,10,24] [None,10,10,8]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "8   bn_2_1             [None,10,10,24] [None,10,10,8]   112        conv2d_2_1         \n",
      "                       [None,10,10,24] [None,10,10,8]                                 \n",
      "                       [None,10,10,24] [None,10,10,8]                                 \n",
      "                       [None,10,10,24] [None,10,10,8]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "9   relu_2_1           [None,10,10,24] [None,10,10,8]   0          bn_2_1             \n",
      "                       [None,10,10,24] [None,10,10,8]                                 \n",
      "                       [None,10,10,24] [None,10,10,8]                                 \n",
      "                       [None,10,10,24] [None,10,10,8]                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "10  conv2d_2_2         [None,8,8,24] [None,8,8,8]       21496      relu_2_1           \n",
      "                       [None,8,8,24] [None,8,8,8]                                     \n",
      "                       [None,8,8,24] [None,8,8,8]                                     \n",
      "                       [None,8,8,24] [None,8,8,8]                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "11  bn_2_2             [None,8,8,24] [None,8,8,8]       112        conv2d_2_2         \n",
      "                       [None,8,8,24] [None,8,8,8]                                     \n",
      "                       [None,8,8,24] [None,8,8,8]                                     \n",
      "                       [None,8,8,24] [None,8,8,8]                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "12  relu_2_2           [None,8,8,24] [None,8,8,8]       0          bn_2_2             \n",
      "                       [None,8,8,24] [None,8,8,8]                                     \n",
      "                       [None,8,8,24] [None,8,8,8]                                     \n",
      "                       [None,8,8,24] [None,8,8,8]                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "13  global_avg_pool2d  [None,24] [None,8]               0          relu_2_2           \n",
      "                       [None,24] [None,8]                                             \n",
      "                       [None,24] [None,8]                                             \n",
      "                       [None,24] [None,8]                                             \n",
      "--------------------------------------------------------------------------------------\n",
      "14  fc1                [None,24] [None,8]               2552       global_avg_pool2d  \n",
      "                       [None,24] [None,8]                                             \n",
      "                       [None,24] [None,8]                                             \n",
      "                       [None,24] [None,8]                                             \n",
      "--------------------------------------------------------------------------------------\n",
      "15  bn_fc1             [None,24] [None,8]               112        fc1                \n",
      "                       [None,24] [None,8]                                             \n",
      "                       [None,24] [None,8]                                             \n",
      "                       [None,24] [None,8]                                             \n",
      "--------------------------------------------------------------------------------------\n",
      "16  relu_fc1           [None,24] [None,8]               0          bn_fc1             \n",
      "                       [None,24] [None,8]                                             \n",
      "                       [None,24] [None,8]                                             \n",
      "                       [None,24] [None,8]                                             \n",
      "--------------------------------------------------------------------------------------\n",
      "17  output             [None,10]                        1320       relu_fc1           \n",
      "                       [None,10]                                                      \n",
      "                       [None,10]                                                      \n",
      "                       [None,10]                                                      \n",
      "--------------------------------------------------------------------------------------\n",
      "Total parameters: 42356\n"
     ]
    }
   ],
   "source": [
    "# Build copy of model for testing\n",
    "x_place = tf.placeholder('float32', x_shape, name='x_test')\n",
    "y_place = tf.placeholder('float32', y_shape, name='y_test')\n",
    "test_model = build_model(architecture, x_place, [y_place]*NUM_BRANCHES, num_classes,\n",
    "    NUM_BRANCHES, model_id, SHARED_FRAC, test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " - 11s - train_loss_1: 1.3854 - train_loss_3: 1.4921 - train_acc_3: 0.5609 - train_acc_1: 0.5891 - train_loss_2: 1.4145 - train_loss_4: 1.4631 - train_acc_2: 0.5678 - train_acc_ensemble: 0.2569 - train_acc_4: 0.5619 - val_loss_2: 0.6716 - val_loss_3: 0.7341 - val_acc_2: 0.8636 - val_acc_4: 0.8657 - val_acc_ensemble: 0.9139 - val_loss_1: 0.7313 - val_loss_4: 0.6974 - val_acc_1: 0.8435 - val_acc_3: 0.8464\n",
      "Epoch 2/30\n",
      " - 4s - train_loss_1: 0.5838 - train_loss_3: 0.5581 - train_acc_3: 0.8684 - train_acc_1: 0.8638 - train_loss_2: 0.5499 - train_loss_4: 0.5547 - train_acc_2: 0.8666 - train_acc_ensemble: 0.3297 - train_acc_4: 0.8659 - val_loss_2: 0.3284 - val_loss_3: 0.3381 - val_acc_2: 0.9276 - val_acc_4: 0.9269 - val_acc_ensemble: 0.9503 - val_loss_1: 0.3768 - val_loss_4: 0.3319 - val_acc_1: 0.9129 - val_acc_3: 0.9252\n",
      "Epoch 3/30\n",
      " - 4s - train_loss_1: 0.3583 - train_loss_3: 0.3166 - train_acc_3: 0.9234 - train_acc_1: 0.9147 - train_loss_2: 0.3238 - train_loss_4: 0.3308 - train_acc_2: 0.9184 - train_acc_ensemble: 0.3497 - train_acc_4: 0.9163 - val_loss_2: 0.2205 - val_loss_3: 0.2312 - val_acc_2: 0.9482 - val_acc_4: 0.9382 - val_acc_ensemble: 0.9635 - val_loss_1: 0.2626 - val_loss_4: 0.2491 - val_acc_1: 0.9335 - val_acc_3: 0.9426\n",
      "Epoch 4/30\n",
      " - 4s - train_loss_1: 0.2763 - train_loss_3: 0.2322 - train_acc_3: 0.9403 - train_acc_1: 0.9275 - train_loss_2: 0.2466 - train_loss_4: 0.2617 - train_acc_2: 0.9369 - train_acc_ensemble: 0.3475 - train_acc_4: 0.9337 - val_loss_2: 0.1698 - val_loss_3: 0.1989 - val_acc_2: 0.9546 - val_acc_4: 0.9476 - val_acc_ensemble: 0.9656 - val_loss_1: 0.2079 - val_loss_4: 0.1959 - val_acc_1: 0.9433 - val_acc_3: 0.9473\n",
      "Epoch 5/30\n",
      " - 4s - train_loss_1: 0.2204 - train_loss_3: 0.1930 - train_acc_3: 0.9509 - train_acc_1: 0.9384 - train_loss_2: 0.1963 - train_loss_4: 0.2065 - train_acc_2: 0.9450 - train_acc_ensemble: 0.3544 - train_acc_4: 0.9491 - val_loss_2: 0.1599 - val_loss_3: 0.1516 - val_acc_2: 0.9552 - val_acc_4: 0.9540 - val_acc_ensemble: 0.9715 - val_loss_1: 0.1678 - val_loss_4: 0.1683 - val_acc_1: 0.9566 - val_acc_3: 0.9584\n",
      "Epoch 6/30\n",
      " - 4s - train_loss_1: 0.1816 - train_loss_3: 0.1541 - train_acc_3: 0.9628 - train_acc_1: 0.9506 - train_loss_2: 0.1650 - train_loss_4: 0.1708 - train_acc_2: 0.9600 - train_acc_ensemble: 0.3419 - train_acc_4: 0.9575 - val_loss_2: 0.1314 - val_loss_3: 0.1417 - val_acc_2: 0.9639 - val_acc_4: 0.9529 - val_acc_ensemble: 0.9744 - val_loss_1: 0.1475 - val_loss_4: 0.1616 - val_acc_1: 0.9610 - val_acc_3: 0.9614\n",
      "Epoch 7/30\n",
      " - 4s - train_loss_1: 0.1575 - train_loss_3: 0.1427 - train_acc_3: 0.9622 - train_acc_1: 0.9606 - train_loss_2: 0.1449 - train_loss_4: 0.1444 - train_acc_2: 0.9628 - train_acc_ensemble: 0.3600 - train_acc_4: 0.9616 - val_loss_2: 0.1389 - val_loss_3: 0.1163 - val_acc_2: 0.9586 - val_acc_4: 0.9597 - val_acc_ensemble: 0.9750 - val_loss_1: 0.1467 - val_loss_4: 0.1385 - val_acc_1: 0.9577 - val_acc_3: 0.9648\n",
      "Epoch 8/30\n",
      " - 4s - train_loss_1: 0.1255 - train_loss_3: 0.1006 - train_acc_3: 0.9756 - train_acc_1: 0.9703 - train_loss_2: 0.1097 - train_loss_4: 0.1279 - train_acc_2: 0.9716 - train_acc_ensemble: 0.3678 - train_acc_4: 0.9641 - val_loss_2: 0.1266 - val_loss_3: 0.1303 - val_acc_2: 0.9621 - val_acc_4: 0.9568 - val_acc_ensemble: 0.9763 - val_loss_1: 0.1358 - val_loss_4: 0.1398 - val_acc_1: 0.9617 - val_acc_3: 0.9623\n",
      "Epoch 9/30\n",
      " - 4s - train_loss_1: 0.1186 - train_loss_3: 0.0933 - train_acc_3: 0.9772 - train_acc_1: 0.9700 - train_loss_2: 0.1083 - train_loss_4: 0.1144 - train_acc_2: 0.9706 - train_acc_ensemble: 0.3488 - train_acc_4: 0.9728 - val_loss_2: 0.1168 - val_loss_3: 0.1212 - val_acc_2: 0.9656 - val_acc_4: 0.9583 - val_acc_ensemble: 0.9758 - val_loss_1: 0.1203 - val_loss_4: 0.1329 - val_acc_1: 0.9655 - val_acc_3: 0.9627\n",
      "Epoch 10/30\n",
      " - 4s - train_loss_1: 0.1013 - train_loss_3: 0.0927 - train_acc_3: 0.9788 - train_acc_1: 0.9734 - train_loss_2: 0.0956 - train_loss_4: 0.1085 - train_acc_2: 0.9762 - train_acc_ensemble: 0.3616 - train_acc_4: 0.9709 - val_loss_2: 0.1091 - val_loss_3: 0.1038 - val_acc_2: 0.9690 - val_acc_4: 0.9598 - val_acc_ensemble: 0.9788 - val_loss_1: 0.1191 - val_loss_4: 0.1329 - val_acc_1: 0.9670 - val_acc_3: 0.9690\n",
      "Epoch 11/30\n",
      " - 4s - train_loss_1: 0.0857 - train_loss_3: 0.0908 - train_acc_3: 0.9753 - train_acc_1: 0.9800 - train_loss_2: 0.0849 - train_loss_4: 0.0951 - train_acc_2: 0.9803 - train_acc_ensemble: 0.3672 - train_acc_4: 0.9728 - val_loss_2: 0.0955 - val_loss_3: 0.1071 - val_acc_2: 0.9729 - val_acc_4: 0.9673 - val_acc_ensemble: 0.9798 - val_loss_1: 0.1056 - val_loss_4: 0.1073 - val_acc_1: 0.9681 - val_acc_3: 0.9661\n",
      "Epoch 12/30\n",
      " - 4s - train_loss_1: 0.0930 - train_loss_3: 0.0610 - train_acc_3: 0.9878 - train_acc_1: 0.9759 - train_loss_2: 0.0730 - train_loss_4: 0.0762 - train_acc_2: 0.9803 - train_acc_ensemble: 0.3600 - train_acc_4: 0.9819 - val_loss_2: 0.0965 - val_loss_3: 0.1000 - val_acc_2: 0.9712 - val_acc_4: 0.9689 - val_acc_ensemble: 0.9803 - val_loss_1: 0.1089 - val_loss_4: 0.1009 - val_acc_1: 0.9664 - val_acc_3: 0.9694\n",
      "Epoch 13/30\n",
      " - 4s - train_loss_1: 0.0697 - train_loss_3: 0.0513 - train_acc_3: 0.9878 - train_acc_1: 0.9831 - train_loss_2: 0.0544 - train_loss_4: 0.0743 - train_acc_2: 0.9903 - train_acc_ensemble: 0.3625 - train_acc_4: 0.9803 - val_loss_2: 0.0928 - val_loss_3: 0.1016 - val_acc_2: 0.9727 - val_acc_4: 0.9647 - val_acc_ensemble: 0.9790 - val_loss_1: 0.1159 - val_loss_4: 0.1084 - val_acc_1: 0.9631 - val_acc_3: 0.9674\n",
      "Epoch 14/30\n",
      " - 4s - train_loss_1: 0.0647 - train_loss_3: 0.0493 - train_acc_3: 0.9884 - train_acc_1: 0.9862 - train_loss_2: 0.0541 - train_loss_4: 0.0645 - train_acc_2: 0.9878 - train_acc_ensemble: 0.3563 - train_acc_4: 0.9838 - val_loss_2: 0.0953 - val_loss_3: 0.1067 - val_acc_2: 0.9716 - val_acc_4: 0.9664 - val_acc_ensemble: 0.9816 - val_loss_1: 0.0975 - val_loss_4: 0.1064 - val_acc_1: 0.9707 - val_acc_3: 0.9660\n",
      "Epoch 15/30\n",
      " - 4s - train_loss_1: 0.0562 - train_loss_3: 0.0503 - train_acc_3: 0.9909 - train_acc_1: 0.9853 - train_loss_2: 0.0528 - train_loss_4: 0.0648 - train_acc_2: 0.9859 - train_acc_ensemble: 0.3803 - train_acc_4: 0.9822 - val_loss_2: 0.0843 - val_loss_3: 0.0930 - val_acc_2: 0.9758 - val_acc_4: 0.9670 - val_acc_ensemble: 0.9811 - val_loss_1: 0.1014 - val_loss_4: 0.1041 - val_acc_1: 0.9684 - val_acc_3: 0.9729\n",
      "Epoch 16/30\n",
      " - 4s - train_loss_1: 0.0568 - train_loss_3: 0.0443 - train_acc_3: 0.9909 - train_acc_1: 0.9869 - train_loss_2: 0.0458 - train_loss_4: 0.0600 - train_acc_2: 0.9903 - train_acc_ensemble: 0.3566 - train_acc_4: 0.9862 - val_loss_2: 0.1003 - val_loss_3: 0.0923 - val_acc_2: 0.9694 - val_acc_4: 0.9651 - val_acc_ensemble: 0.9805 - val_loss_1: 0.1013 - val_loss_4: 0.1114 - val_acc_1: 0.9667 - val_acc_3: 0.9713\n",
      "Epoch 17/30\n",
      " - 4s - train_loss_1: 0.0561 - train_loss_3: 0.0419 - train_acc_3: 0.9916 - train_acc_1: 0.9862 - train_loss_2: 0.0426 - train_loss_4: 0.0457 - train_acc_2: 0.9903 - train_acc_ensemble: 0.3425 - train_acc_4: 0.9906 - val_loss_2: 0.0864 - val_loss_3: 0.1001 - val_acc_2: 0.9746 - val_acc_4: 0.9685 - val_acc_ensemble: 0.9822 - val_loss_1: 0.1164 - val_loss_4: 0.1012 - val_acc_1: 0.9662 - val_acc_3: 0.9691\n",
      "Epoch 18/30\n",
      " - 4s - train_loss_1: 0.0419 - train_loss_3: 0.0403 - train_acc_3: 0.9900 - train_acc_1: 0.9916 - train_loss_2: 0.0458 - train_loss_4: 0.0343 - train_acc_2: 0.9866 - train_acc_ensemble: 0.3563 - train_acc_4: 0.9938 - val_loss_2: 0.0990 - val_loss_3: 0.0966 - val_acc_2: 0.9684 - val_acc_4: 0.9686 - val_acc_ensemble: 0.9816 - val_loss_1: 0.0900 - val_loss_4: 0.0982 - val_acc_1: 0.9726 - val_acc_3: 0.9698\n",
      "Epoch 19/30\n",
      " - 4s - train_loss_1: 0.0431 - train_loss_3: 0.0370 - train_acc_3: 0.9925 - train_acc_1: 0.9909 - train_loss_2: 0.0447 - train_loss_4: 0.0326 - train_acc_2: 0.9881 - train_acc_ensemble: 0.3638 - train_acc_4: 0.9941 - val_loss_2: 0.1107 - val_loss_3: 0.1080 - val_acc_2: 0.9668 - val_acc_4: 0.9652 - val_acc_ensemble: 0.9781 - val_loss_1: 0.1040 - val_loss_4: 0.1094 - val_acc_1: 0.9676 - val_acc_3: 0.9660\n",
      "Epoch 20/30\n",
      " - 4s - train_loss_1: 0.0411 - train_loss_3: 0.0339 - train_acc_3: 0.9919 - train_acc_1: 0.9912 - train_loss_2: 0.0420 - train_loss_4: 0.0307 - train_acc_2: 0.9900 - train_acc_ensemble: 0.3491 - train_acc_4: 0.9938 - val_loss_2: 0.0957 - val_loss_3: 0.1033 - val_acc_2: 0.9690 - val_acc_4: 0.9708 - val_acc_ensemble: 0.9798 - val_loss_1: 0.1276 - val_loss_4: 0.0931 - val_acc_1: 0.9610 - val_acc_3: 0.9690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30\n",
      " - 4s - train_loss_1: 0.0386 - train_loss_3: 0.0243 - train_acc_3: 0.9956 - train_acc_1: 0.9897 - train_loss_2: 0.0376 - train_loss_4: 0.0279 - train_acc_2: 0.9903 - train_acc_ensemble: 0.3694 - train_acc_4: 0.9962 - val_loss_2: 0.1083 - val_loss_3: 0.0883 - val_acc_2: 0.9664 - val_acc_4: 0.9689 - val_acc_ensemble: 0.9821 - val_loss_1: 0.1099 - val_loss_4: 0.0946 - val_acc_1: 0.9655 - val_acc_3: 0.9733\n",
      "Epoch 22/30\n",
      " - 4s - train_loss_1: 0.0293 - train_loss_3: 0.0229 - train_acc_3: 0.9950 - train_acc_1: 0.9931 - train_loss_2: 0.0291 - train_loss_4: 0.0222 - train_acc_2: 0.9931 - train_acc_ensemble: 0.3744 - train_acc_4: 0.9978 - val_loss_2: 0.0822 - val_loss_3: 0.1033 - val_acc_2: 0.9749 - val_acc_4: 0.9710 - val_acc_ensemble: 0.9824 - val_loss_1: 0.0956 - val_loss_4: 0.0916 - val_acc_1: 0.9714 - val_acc_3: 0.9686\n",
      "Epoch 23/30\n",
      " - 4s - train_loss_1: 0.0272 - train_loss_3: 0.0221 - train_acc_3: 0.9956 - train_acc_1: 0.9953 - train_loss_2: 0.0297 - train_loss_4: 0.0251 - train_acc_2: 0.9938 - train_acc_ensemble: 0.3716 - train_acc_4: 0.9941 - val_loss_2: 0.0885 - val_loss_3: 0.0993 - val_acc_2: 0.9729 - val_acc_4: 0.9718 - val_acc_ensemble: 0.9820 - val_loss_1: 0.0993 - val_loss_4: 0.0943 - val_acc_1: 0.9690 - val_acc_3: 0.9709\n",
      "Epoch 24/30\n",
      " - 4s - train_loss_1: 0.0227 - train_loss_3: 0.0216 - train_acc_3: 0.9969 - train_acc_1: 0.9978 - train_loss_2: 0.0296 - train_loss_4: 0.0185 - train_acc_2: 0.9916 - train_acc_ensemble: 0.3634 - train_acc_4: 0.9962 - val_loss_2: 0.0932 - val_loss_3: 0.0902 - val_acc_2: 0.9706 - val_acc_4: 0.9724 - val_acc_ensemble: 0.9827 - val_loss_1: 0.0952 - val_loss_4: 0.0891 - val_acc_1: 0.9694 - val_acc_3: 0.9719\n",
      "Epoch 25/30\n",
      " - 4s - train_loss_1: 0.0248 - train_loss_3: 0.0252 - train_acc_3: 0.9950 - train_acc_1: 0.9934 - train_loss_2: 0.0245 - train_loss_4: 0.0232 - train_acc_2: 0.9947 - train_acc_ensemble: 0.3509 - train_acc_4: 0.9956 - val_loss_2: 0.1041 - val_loss_3: 0.0855 - val_acc_2: 0.9670 - val_acc_4: 0.9678 - val_acc_ensemble: 0.9812 - val_loss_1: 0.1025 - val_loss_4: 0.0947 - val_acc_1: 0.9685 - val_acc_3: 0.9734\n",
      "Epoch 26/30\n",
      " - 4s - train_loss_1: 0.0363 - train_loss_3: 0.0250 - train_acc_3: 0.9941 - train_acc_1: 0.9894 - train_loss_2: 0.0202 - train_loss_4: 0.0220 - train_acc_2: 0.9950 - train_acc_ensemble: 0.3681 - train_acc_4: 0.9953 - val_loss_2: 0.0876 - val_loss_3: 0.1209 - val_acc_2: 0.9732 - val_acc_4: 0.9678 - val_acc_ensemble: 0.9820 - val_loss_1: 0.0996 - val_loss_4: 0.1048 - val_acc_1: 0.9676 - val_acc_3: 0.9642\n",
      "Epoch 27/30\n",
      " - 4s - train_loss_1: 0.0222 - train_loss_3: 0.0235 - train_acc_3: 0.9938 - train_acc_1: 0.9962 - train_loss_2: 0.0239 - train_loss_4: 0.0215 - train_acc_2: 0.9938 - train_acc_ensemble: 0.3766 - train_acc_4: 0.9956 - val_loss_2: 0.0866 - val_loss_3: 0.0948 - val_acc_2: 0.9749 - val_acc_4: 0.9723 - val_acc_ensemble: 0.9834 - val_loss_1: 0.0951 - val_loss_4: 0.0920 - val_acc_1: 0.9703 - val_acc_3: 0.9693\n",
      "Epoch 28/30\n",
      " - 4s - train_loss_1: 0.0195 - train_loss_3: 0.0178 - train_acc_3: 0.9962 - train_acc_1: 0.9959 - train_loss_2: 0.0153 - train_loss_4: 0.0211 - train_acc_2: 0.9981 - train_acc_ensemble: 0.3722 - train_acc_4: 0.9956 - val_loss_2: 0.0910 - val_loss_3: 0.0791 - val_acc_2: 0.9739 - val_acc_4: 0.9685 - val_acc_ensemble: 0.9839 - val_loss_1: 0.0843 - val_loss_4: 0.1020 - val_acc_1: 0.9739 - val_acc_3: 0.9767\n",
      "Epoch 29/30\n",
      " - 4s - train_loss_1: 0.0199 - train_loss_3: 0.0179 - train_acc_3: 0.9962 - train_acc_1: 0.9972 - train_loss_2: 0.0183 - train_loss_4: 0.0222 - train_acc_2: 0.9959 - train_acc_ensemble: 0.3716 - train_acc_4: 0.9956 - val_loss_2: 0.0809 - val_loss_3: 0.0917 - val_acc_2: 0.9754 - val_acc_4: 0.9703 - val_acc_ensemble: 0.9832 - val_loss_1: 0.0933 - val_loss_4: 0.1012 - val_acc_1: 0.9717 - val_acc_3: 0.9732\n",
      "Epoch 30/30\n",
      " - 4s - train_loss_1: 0.0203 - train_loss_3: 0.0110 - train_acc_3: 0.9991 - train_acc_1: 0.9956 - train_loss_2: 0.0185 - train_loss_4: 0.0261 - train_acc_2: 0.9969 - train_acc_ensemble: 0.3609 - train_acc_4: 0.9956 - val_loss_2: 0.0780 - val_loss_3: 0.0879 - val_acc_2: 0.9767 - val_acc_4: 0.9705 - val_acc_ensemble: 0.9842 - val_loss_1: 0.1086 - val_loss_4: 0.0956 - val_acc_1: 0.9683 - val_acc_3: 0.9724\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(iterators, X_train, y_train, EPOCHS, STEPS_PER_EPOCH,\n",
    "        BATCH_SIZE, validation=(X_test, y_test), test_model=test_model,\n",
    "        save_model_path=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"ensemble-history.pkl\",\"wb\") as f:\n",
    "#     pickle.dump(history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# with open('baseline-history.pkl', 'rb') as f:\n",
    "#     data = pickle.load(f)\n",
    "\n",
    "# with open('baseline-history-2.pkl', 'rb') as f:\n",
    "#     data2 = pickle.load(f)\n",
    "# with open('baseline-history-3.pkl', 'rb') as f:\n",
    "#     data3 = pickle.load(f)\n",
    "\n",
    "# with open('ensemble-history.pkl', 'rb') as f:\n",
    "#     ensemble = pickle.load(f)\n",
    "    \n",
    "# # plt.plot(history['train_acc_ensemble'])\n",
    "# plt.plot(ensemble['val_acc_ensemble'])\n",
    "# plt.plot(data['val_acc'])\n",
    "# plt.plot(data2['val_acc'])\n",
    "# plt.plot(data3['val_acc'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_init_ops = ['test_init_op_'+str(i+1) for i in range(NUM_BRANCHES)]\n",
    "# losses = ['loss_'+str(i+1)+':0' for i in range(NUM_BRANCHES)]\n",
    "# train_acc_ops = ['train_acc_'+str(i+1)+':0' for i in range(NUM_BRANCHES)]\n",
    "\n",
    "# inputs = ['input_{}:0'.format(i+1) for i in range(NUM_BRANCHES)]\n",
    "# labels_one_hot = ['input_{}:1'.format(i+1) for i in range(NUM_BRANCHES)]\n",
    "outputs = ['model_{}_1/output_vb{}:0'.format(model_id, i+1) for i in range(NUM_BRANCHES)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/vb-mnist-cnn-B4-S0.00_1/ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    model_path = os.path.join('models', 'vb-mnist-{}-B{:d}-S{:.2f}_{:d}'.format(architecture,\n",
    "        NUM_BRANCHES, SHARED_FRAC, model_id))\n",
    "    meta_path = os.path.join(model_path, 'ckpt.meta')\n",
    "    ckpt = tf.train.get_checkpoint_state(model_path)\n",
    "\n",
    "    imported_graph = tf.train.import_meta_graph(meta_path)\n",
    "    imported_graph.restore(sess, ckpt.model_checkpoint_path)\n",
    "\n",
    "#     sess.run(test_init_ops, feed_dict={'batch_size:0': len(X_test)})\n",
    "    features = sess.run(outputs, feed_dict={'x_test:0':X_test})\n",
    "    \n",
    "#     sample_size = 250\n",
    "#     sess.run(test_init_ops, feed_dict={'batch_size:0':sample_size})\n",
    "#     X_test_samples, y_test_samples, features = sess.run([inputs, labels_one_hot, outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Loss:', np.mean(val_losses))\n",
    "# print('Acc:', val_acc)\n",
    "# print('Indiv accs:', indiv_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_features = np.mean(features, axis=0)\n",
    "print(mean_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
    "tsne_results = tsne.fit_transform(mean_features)\n",
    "\n",
    "print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.argmax(y_test_samples[0], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tsne_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-e3e121595d2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtsne_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtsne_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tsne_results' is not defined"
     ]
    }
   ],
   "source": [
    "plt.scatter(tsne_results[:,0], tsne_results[:,1], c=labels, cmap=plt.cm.jet)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [branch[2] for branch in features]\n",
    "# samples = [branch[np.argmax(y_test, axis=1) == 0] for branch in features]\n",
    "# samples = features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 10)\n"
     ]
    }
   ],
   "source": [
    "corr= np.corrcoef(samples, rowvar=False)\n",
    "# corr = np.corrcoef(np.concatenate(samples), rowvar=False)\n",
    "print(corr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(corr, cmap=plt.cm.coolwarm)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(corr, cmap=plt.cm.coolwarm)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
