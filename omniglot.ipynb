{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Omnigot One-Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import cv2\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vbranch as vb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = False\n",
    "model_id = 4\n",
    "architecture = 'simple'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images extracted from omniglot/python/images_evaluation.zip\n"
     ]
    }
   ],
   "source": [
    "train_generator = vb.datasets.omniglot.load_generator('train')\n",
    "test_generator = vb.datasets.omniglot.load_generator('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = test_generator.next(4, 4, 4, flatten=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(batch[2, 3, 0].squeeze(), cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 90\n",
    "T_0 = 30\n",
    "STEPS_PER_EPOCH = 100\n",
    "model_path = './models/omniglot_' + str(model_id)\n",
    "A, P, K = 4, 8, 4 # triplet batch specs\n",
    "output_dim = 128\n",
    "input_dim = [None, 105, 105, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('./models'):\n",
    "    os.system('mkdir models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_gen(A, P, K):\n",
    "    def func():\n",
    "        while True:\n",
    "            batch = train_generator.next(A, P, K)\n",
    "            batch = batch.astype('float32')\n",
    "            yield batch\n",
    "    return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(batch_gen(A, P, K), 'float32', \n",
    "                                                 output_shapes=input_dim)\n",
    "\n",
    "# Dataset for feeding non-triplet batched images from memory\n",
    "batch_size = tf.placeholder('int64', name='batch_size')\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(x).batch(batch_size)\n",
    "\n",
    "iter_ = tf.data.Iterator.from_structure('float32', input_dim)\n",
    "train_init_op = iter_.make_initializer(train_dataset)\n",
    "test_init_op = iter_.make_initializer(test_dataset, name='test_init_op')\n",
    "\n",
    "inputs = iter_.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('model_' + str(model_id)):\n",
    "    if architecture == 'simple':\n",
    "        model = vb.functional.simple_cnn(inputs, output_dim, 32, 64, 128, 256)\n",
    "    elif architecture == 'res':\n",
    "        model = vb.functional.res_cnn(inputs, output_dim, 32, 64, 128, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i   Layer name         Output shape       Parameters            Num param  Inbound            \n",
      "----------------------------------------------------------------------------------------------\n",
      "    Input              [None,105,105,1]                                                       \n",
      "----------------------------------------------------------------------------------------------\n",
      "0   conv2d_1_1         [None,103,103,32]  [3,3,1,32] [32]       320        IteratorGetNext:0  \n",
      "----------------------------------------------------------------------------------------------\n",
      "1   bn_1_1             [None,103,103,32]  [32] [32]             64         conv2d_1_1         \n",
      "----------------------------------------------------------------------------------------------\n",
      "2   relu_1_1           [None,103,103,32]                        0          bn_1_1             \n",
      "----------------------------------------------------------------------------------------------\n",
      "3   conv2d_1_2         [None,101,101,32]  [3,3,32,32] [32]      9248       relu_1_1           \n",
      "----------------------------------------------------------------------------------------------\n",
      "4   bn_1_2             [None,101,101,32]  [32] [32]             64         conv2d_1_2         \n",
      "----------------------------------------------------------------------------------------------\n",
      "5   relu_1_2           [None,101,101,32]                        0          bn_1_2             \n",
      "----------------------------------------------------------------------------------------------\n",
      "6   avg_pool2d_1       [None,50,50,32]                          0          relu_1_2           \n",
      "----------------------------------------------------------------------------------------------\n",
      "7   conv2d_2_1         [None,48,48,64]    [3,3,32,64] [64]      18496      avg_pool2d_1       \n",
      "----------------------------------------------------------------------------------------------\n",
      "8   bn_2_1             [None,48,48,64]    [64] [64]             128        conv2d_2_1         \n",
      "----------------------------------------------------------------------------------------------\n",
      "9   relu_2_1           [None,48,48,64]                          0          bn_2_1             \n",
      "----------------------------------------------------------------------------------------------\n",
      "10  conv2d_2_2         [None,46,46,64]    [3,3,64,64] [64]      36928      relu_2_1           \n",
      "----------------------------------------------------------------------------------------------\n",
      "11  bn_2_2             [None,46,46,64]    [64] [64]             128        conv2d_2_2         \n",
      "----------------------------------------------------------------------------------------------\n",
      "12  relu_2_2           [None,46,46,64]                          0          bn_2_2             \n",
      "----------------------------------------------------------------------------------------------\n",
      "13  avg_pool2d_2       [None,23,23,64]                          0          relu_2_2           \n",
      "----------------------------------------------------------------------------------------------\n",
      "14  conv2d_3_1         [None,21,21,128]   [3,3,64,128] [128]    73856      avg_pool2d_2       \n",
      "----------------------------------------------------------------------------------------------\n",
      "15  bn_3_1             [None,21,21,128]   [128] [128]           256        conv2d_3_1         \n",
      "----------------------------------------------------------------------------------------------\n",
      "16  relu_3_1           [None,21,21,128]                         0          bn_3_1             \n",
      "----------------------------------------------------------------------------------------------\n",
      "17  conv2d_3_2         [None,19,19,128]   [3,3,128,128] [128]   147584     relu_3_1           \n",
      "----------------------------------------------------------------------------------------------\n",
      "18  bn_3_2             [None,19,19,128]   [128] [128]           256        conv2d_3_2         \n",
      "----------------------------------------------------------------------------------------------\n",
      "19  relu_3_2           [None,19,19,128]                         0          bn_3_2             \n",
      "----------------------------------------------------------------------------------------------\n",
      "20  avg_pool2d_3       [None,9,9,128]                           0          relu_3_2           \n",
      "----------------------------------------------------------------------------------------------\n",
      "21  conv2d_4_1         [None,7,7,256]     [3,3,128,256] [256]   295168     avg_pool2d_3       \n",
      "----------------------------------------------------------------------------------------------\n",
      "22  bn_4_1             [None,7,7,256]     [256] [256]           512        conv2d_4_1         \n",
      "----------------------------------------------------------------------------------------------\n",
      "23  relu_4_1           [None,7,7,256]                           0          bn_4_1             \n",
      "----------------------------------------------------------------------------------------------\n",
      "24  conv2d_4_2         [None,5,5,256]     [3,3,256,256] [256]   590080     relu_4_1           \n",
      "----------------------------------------------------------------------------------------------\n",
      "25  bn_4_2             [None,5,5,256]     [256] [256]           512        conv2d_4_2         \n",
      "----------------------------------------------------------------------------------------------\n",
      "26  relu_4_2           [None,5,5,256]                           0          bn_4_2             \n",
      "----------------------------------------------------------------------------------------------\n",
      "27  global_avg_pool2d  [None,256]                               0          relu_4_2           \n",
      "----------------------------------------------------------------------------------------------\n",
      "28  fc1                [None,256]         [256,256] [256]       65792      global_avg_pool2d  \n",
      "----------------------------------------------------------------------------------------------\n",
      "29  bn_fc1             [None,256]         [256] [256]           512        fc1                \n",
      "----------------------------------------------------------------------------------------------\n",
      "30  relu_fc1           [None,256]                               0          bn_fc1             \n",
      "----------------------------------------------------------------------------------------------\n",
      "31  output             [None,128]         [256,128] [128]       32896      relu_fc1           \n",
      "----------------------------------------------------------------------------------------------\n",
      "Total parameters: 1272800\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_exp_decay_scheduler(init_lr, t0, t1, decay):\n",
    "    \"\"\"NOTE: `episode` starts from 1\"\"\"\n",
    "    def func(episode):\n",
    "        if episode < t0:\n",
    "            return init_lr\n",
    "        lr = init_lr * np.power(decay, (episode - t0) / (t1 - t0))\n",
    "        return lr\n",
    "    return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_scheduler = lr_exp_decay_scheduler(0.001, T_0, EPOCHS, 0.001)\n",
    "lr_steps = [lr_scheduler(e + 1) for e in range(EPOCHS)]\n",
    "plt.plot(lr_steps)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = vb.losses.triplet_omniglot(model.output, A, P, K, 'loss')\n",
    "lr = tf.placeholder('float32', name='lr')\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90\n",
      "100/100 [==============================] - 30s 301ms/step - loss: 203.2345 - lr: 0.0010\n",
      "Epoch 2/90\n",
      "100/100 [==============================] - 17s 171ms/step - loss: 34.3832 - lr: 0.0010\n",
      "Epoch 3/90\n",
      "100/100 [==============================] - 17s 171ms/step - loss: 30.9500 - lr: 0.0010\n",
      "Epoch 4/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 28.1805 - lr: 0.0010\n",
      "Epoch 5/90\n",
      "100/100 [==============================] - 17s 171ms/step - loss: 26.9174 - lr: 0.0010\n",
      "Epoch 6/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 25.4925 - lr: 0.0010\n",
      "Epoch 7/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 24.4774 - lr: 0.0010\n",
      "Epoch 8/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 23.0067 - lr: 0.0010\n",
      "Epoch 9/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 20.2327 - lr: 0.0010\n",
      "Epoch 10/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 18.7231 - lr: 0.0010\n",
      "Epoch 11/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 18.1981 - lr: 0.0010\n",
      "Epoch 12/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 18.2818 - lr: 0.0010\n",
      "Epoch 13/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 18.4706 - lr: 0.0010\n",
      "Epoch 14/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 21.3396 - lr: 0.0010\n",
      "Epoch 15/90\n",
      "100/100 [==============================] - 17s 171ms/step - loss: 17.6926 - lr: 0.0010\n",
      "Epoch 16/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 16.7432 - lr: 0.0010\n",
      "Epoch 17/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 15.9965 - lr: 0.0010\n",
      "Epoch 18/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 14.9217 - lr: 0.0010\n",
      "Epoch 19/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 16.6859 - lr: 0.0010\n",
      "Epoch 20/90\n",
      "100/100 [==============================] - 17s 171ms/step - loss: 17.3265 - lr: 0.0010\n",
      "Epoch 21/90\n",
      "100/100 [==============================] - 17s 172ms/step - loss: 17.7059 - lr: 0.0010\n",
      "Epoch 22/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 14.5998 - lr: 0.0010\n",
      "Epoch 23/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 16.0596 - lr: 0.0010\n",
      "Epoch 24/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 15.8467 - lr: 0.0010\n",
      "Epoch 25/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 14.3008 - lr: 0.0010\n",
      "Epoch 26/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 15.3702 - lr: 0.0010\n",
      "Epoch 27/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 16.5934 - lr: 0.0010\n",
      "Epoch 28/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 12.8635 - lr: 0.0010\n",
      "Epoch 29/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 14.1854 - lr: 0.0010\n",
      "Epoch 30/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 12.9952 - lr: 0.0010\n",
      "Epoch 31/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 11.1737 - lr: 8.9125e-04\n",
      "Epoch 32/90\n",
      "100/100 [==============================] - 17s 171ms/step - loss: 9.6740 - lr: 7.9433e-04\n",
      "Epoch 33/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 8.5724 - lr: 7.0795e-04\n",
      "Epoch 34/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 8.3749 - lr: 6.3096e-04\n",
      "Epoch 35/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 7.0713 - lr: 5.6234e-04\n",
      "Epoch 36/90\n",
      "100/100 [==============================] - 17s 171ms/step - loss: 6.8322 - lr: 5.0119e-04\n",
      "Epoch 37/90\n",
      "100/100 [==============================] - 17s 171ms/step - loss: 5.8118 - lr: 4.4668e-04\n",
      "Epoch 38/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 5.6723 - lr: 3.9811e-04\n",
      "Epoch 39/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 4.7676 - lr: 3.5481e-04\n",
      "Epoch 40/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 4.9218 - lr: 3.1623e-04\n",
      "Epoch 41/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 3.7571 - lr: 2.8184e-04\n",
      "Epoch 42/90\n",
      "100/100 [==============================] - 17s 171ms/step - loss: 3.8978 - lr: 2.5119e-04\n",
      "Epoch 43/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 3.4133 - lr: 2.2387e-04\n",
      "Epoch 44/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 3.5054 - lr: 1.9953e-04\n",
      "Epoch 45/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 3.1187 - lr: 1.7783e-04\n",
      "Epoch 46/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 3.2970 - lr: 1.5849e-04\n",
      "Epoch 47/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 2.8588 - lr: 1.4125e-04\n",
      "Epoch 48/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 2.6963 - lr: 1.2589e-04\n",
      "Epoch 49/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 2.3675 - lr: 1.1220e-04\n",
      "Epoch 50/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 2.5333 - lr: 1.0000e-04\n",
      "Epoch 51/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 2.2246 - lr: 8.9125e-05\n",
      "Epoch 52/90\n",
      "100/100 [==============================] - 17s 171ms/step - loss: 2.3380 - lr: 7.9433e-05\n",
      "Epoch 53/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 2.3777 - lr: 7.0795e-05\n",
      "Epoch 54/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 2.2656 - lr: 6.3096e-05\n",
      "Epoch 55/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 2.0346 - lr: 5.6234e-05\n",
      "Epoch 56/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 1.9217 - lr: 5.0119e-05\n",
      "Epoch 57/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 2.1567 - lr: 4.4668e-05\n",
      "Epoch 58/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 1.9040 - lr: 3.9811e-05\n",
      "Epoch 59/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 1.9650 - lr: 3.5481e-05\n",
      "Epoch 60/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 1.9719 - lr: 3.1623e-05\n",
      "Epoch 61/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 1.8095 - lr: 2.8184e-05\n",
      "Epoch 62/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 2.0159 - lr: 2.5119e-05\n",
      "Epoch 63/90\n",
      "100/100 [==============================] - 17s 171ms/step - loss: 1.5719 - lr: 2.2387e-05\n",
      "Epoch 64/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 1.7234 - lr: 1.9953e-05\n",
      "Epoch 65/90\n",
      "100/100 [==============================] - 17s 171ms/step - loss: 1.5348 - lr: 1.7783e-05\n",
      "Epoch 66/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 1.7610 - lr: 1.5849e-05\n",
      "Epoch 67/90\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 1.6748 - lr: 1.4125e-05\n",
      "Epoch 68/90\n",
      "100/100 [==============================] - 17s 173ms/step - loss: 1.7791 - lr: 1.2589e-05\n",
      "Epoch 69/90\n",
      "100/100 [==============================] - 17s 175ms/step - loss: 1.6820 - lr: 1.1220e-05\n",
      "Epoch 70/90\n",
      "100/100 [==============================] - 17s 172ms/step - loss: 1.7199 - lr: 1.0000e-05\n",
      "Epoch 71/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 1.8953 - lr: 8.9125e-06\n",
      "Epoch 72/90\n",
      "100/100 [==============================] - 17s 171ms/step - loss: 1.6850 - lr: 7.9433e-06\n",
      "Epoch 73/90\n",
      "100/100 [==============================] - 17s 171ms/step - loss: 1.7150 - lr: 7.0795e-06\n",
      "Epoch 74/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 1.5930 - lr: 6.3096e-06\n",
      "Epoch 75/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 1.6698 - lr: 5.6234e-06\n",
      "Epoch 76/90\n",
      "100/100 [==============================] - 17s 171ms/step - loss: 1.5004 - lr: 5.0119e-06\n",
      "Epoch 77/90\n",
      "100/100 [==============================] - 17s 171ms/step - loss: 1.4696 - lr: 4.4668e-06\n",
      "Epoch 78/90\n",
      "100/100 [==============================] - 17s 171ms/step - loss: 1.7950 - lr: 3.9811e-06\n",
      "Epoch 79/90\n",
      "100/100 [==============================] - 17s 171ms/step - loss: 1.6429 - lr: 3.5481e-06\n",
      "Epoch 80/90\n",
      "100/100 [==============================] - 17s 171ms/step - loss: 1.5495 - lr: 3.1623e-06\n",
      "Epoch 81/90\n",
      "100/100 [==============================] - 17s 171ms/step - loss: 1.6078 - lr: 2.8184e-06\n",
      "Epoch 82/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 1.6950 - lr: 2.5119e-06\n",
      "Epoch 83/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 1.7604 - lr: 2.2387e-06\n",
      "Epoch 84/90\n",
      "100/100 [==============================] - 17s 171ms/step - loss: 1.4979 - lr: 1.9953e-06\n",
      "Epoch 85/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 1.7408 - lr: 1.7783e-06\n",
      "Epoch 86/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 1.6331 - lr: 1.5849e-06\n",
      "Epoch 87/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 1.7148 - lr: 1.4125e-06\n",
      "Epoch 88/90\n",
      "100/100 [==============================] - 17s 171ms/step - loss: 1.5886 - lr: 1.2589e-06\n",
      "Epoch 89/90\n",
      "100/100 [==============================] - 17s 172ms/step - loss: 1.7311 - lr: 1.1220e-06\n",
      "Epoch 90/90\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 1.5580 - lr: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(train_init_op)\n",
    "\n",
    "    for e in range(EPOCHS):\n",
    "        print(\"Epoch {}/{}\".format(e + 1, EPOCHS))\n",
    "        progbar = tf.keras.utils.Progbar(STEPS_PER_EPOCH)\n",
    "        \n",
    "        learning_rate = lr_scheduler(e + 1)\n",
    "        for i in range(STEPS_PER_EPOCH):\n",
    "            _, loss_value = sess.run([train_op, loss], feed_dict={lr:learning_rate})\n",
    "            progbar.update(i + 1, values=[('loss', loss_value), ('lr', learning_rate)])\n",
    "    \n",
    "    if save:\n",
    "        saver = tf.train.Saver()\n",
    "        path = os.path.join(model_path, 'ckpt')\n",
    "        saver.save(sess, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_sess(sess, model_path):\n",
    "    meta_path = os.path.join(model_path, 'ckpt.meta')\n",
    "    ckpt = tf.train.get_checkpoint_state(model_path)\n",
    "\n",
    "    imported_graph = tf.train.import_meta_graph(meta_path)\n",
    "    imported_graph.restore(sess, ckpt.model_checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run(n_run):\n",
    "    all_runs = './omniglot/python/one-shot-classification/all_runs'\n",
    "    \n",
    "    if not os.path.isdir(all_runs):\n",
    "        with zipfile.ZipFile(all_runs + '.zip','r') as zip_ref:\n",
    "            zip_ref.extractall(all_runs)\n",
    "    \n",
    "    run_path = os.path.join(all_runs,'run%02d'%n_run,'class_labels.txt')\n",
    "    with open(run_path) as f:\n",
    "        content = f.read().splitlines()\n",
    "\n",
    "    pairs = [line.split() for line in content]\n",
    "    test_files  = [pair[0] for pair in pairs]\n",
    "    train_files = [pair[1] for pair in pairs]\n",
    "\n",
    "    answers_files = copy.copy(train_files)\n",
    "    test_files.sort()\n",
    "    train_files.sort()\n",
    "    \n",
    "    def f_load(f):\n",
    "        path = os.path.join(all_runs, f)\n",
    "        return cv2.imread(path)[..., 0]\n",
    "\n",
    "    train_imgs = np.stack([f_load(f) for f in train_files]).\\\n",
    "                        astype('float32')[..., np.newaxis]\n",
    "    test_imgs  = np.stack([f_load(f) for f in test_files]).\\\n",
    "                        astype('float32')[..., np.newaxis]\n",
    "\n",
    "    return train_files, test_files, train_imgs, test_imgs, answers_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_one_shot_acc(test_pred, train_pred, train_files, answers_files):\n",
    "    n_test = len(test_pred)\n",
    "    n_train = len(train_pred)\n",
    "    \n",
    "    distM = np.zeros((n_test, n_train))\n",
    "    for i in range(n_test):\n",
    "        for c in range(n_train):\n",
    "            distM[i,c] = distance.euclidean(test_pred[i],train_pred[c])\n",
    "            \n",
    "    YHAT = np.argmin(distM, axis=1)\n",
    "    \n",
    "    # compute the error rate\n",
    "    correct = 0.0\n",
    "    for i in range(n_test):\n",
    "        if train_files[YHAT[i]] == answers_files[i]:\n",
    "            correct += 1.0\n",
    "        \n",
    "    return correct / n_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/omniglot_1/ckpt\n",
      "INFO:tensorflow:Restoring parameters from ./models/omniglot_2/ckpt\n",
      "INFO:tensorflow:Restoring parameters from ./models/omniglot_3/ckpt\n",
      "INFO:tensorflow:Restoring parameters from ./models/omniglot_4/ckpt\n"
     ]
    }
   ],
   "source": [
    "total_runs = 20\n",
    "train_pred_runs = [[] for _ in range(total_runs)]\n",
    "test_pred_runs = [[] for _ in range(total_runs)]\n",
    "\n",
    "run_data = [get_run(r+1) for r in range(total_runs)]\n",
    "\n",
    "num_models = model_id\n",
    "\n",
    "for i in range(num_models):\n",
    "    graph = tf.Graph()\n",
    "    sess = tf.Session(graph=graph)\n",
    "    \n",
    "    with sess.as_default(), graph.as_default():\n",
    "        restore_sess(sess, './models/omniglot_' + str(i + 1))\n",
    "        \n",
    "        for r in range(total_runs):\n",
    "            train_files,test_files,train_imgs,test_imgs,answers_files = run_data[r]\n",
    "            \n",
    "            feed_dict = {'x:0':train_imgs, 'batch_size:0':len(train_imgs)}\n",
    "            sess.run('test_init_op', feed_dict=feed_dict)\n",
    "            train_pred_runs[r].append(sess.run('model_%d'%(i+1)+'/'+'output:0'))\n",
    "    \n",
    "            feed_dict = {'x:0':test_imgs, 'batch_size:0':len(test_imgs)}\n",
    "            sess.run('test_init_op', feed_dict=feed_dict)\n",
    "            test_pred_runs[r].append(sess.run('model_%d'%(i+1)+'/'+'output:0'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_acc_runs = []\n",
    "for r in range(total_runs):\n",
    "    test_embed = np.mean(test_pred_runs[r], axis=0)\n",
    "    train_embed = np.mean(train_pred_runs[r], axis=0)\n",
    "    train_files = run_data[r][0]\n",
    "    answers_files = run_data[r][-1]\n",
    "    \n",
    "    acc = compute_one_shot_acc(test_embed, train_embed,train_files, answers_files)\n",
    "    mean_acc_runs.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8, 0.7, 0.95, 0.8, 0.85, 0.95, 0.75, 0.65, 0.65, 0.75, 1.0, 0.7, 0.65, 0.9, 0.95, 1.0, 0.8, 0.95, 0.7, 0.75]\n",
      "0.8125\n"
     ]
    }
   ],
   "source": [
    "print(mean_acc_runs)\n",
    "print(np.mean(mean_acc_runs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_acc_runs = []\n",
    "for r in range(total_runs):\n",
    "    test_embed = np.concatenate(test_pred_runs[r], axis=-1)\n",
    "    train_embed = np.concatenate(train_pred_runs[r], axis=-1)\n",
    "    train_files = run_data[r][0]\n",
    "    answers_files = run_data[r][-1]\n",
    "    \n",
    "    acc = compute_one_shot_acc(test_embed, train_embed,train_files, answers_files)\n",
    "    concat_acc_runs.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9, 0.8, 0.95, 0.85, 0.95, 0.9, 0.8, 0.65, 0.7, 0.85, 1.0, 0.85, 0.7, 0.9, 0.95, 1.0, 0.8, 1.0, 0.85, 0.8]\n",
      "0.8600000000000001\n"
     ]
    }
   ],
   "source": [
    "print(concat_acc_runs)\n",
    "print(np.mean(concat_acc_runs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
