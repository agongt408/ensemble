{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Omnigot One-Shot with Virtual Branching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from vbranch.applications.resnet import ResNet18\n",
    "from vbranch.applications.cnn import SimpleCNNLarge\n",
    "from vbranch.datasets import omniglot\n",
    "\n",
    "from vbranch.utils import *\n",
    "from vbranch.callbacks import one_shot_acc\n",
    "from vbranch.losses import triplet_omniglot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE = False\n",
    "MODEL_ID = 1\n",
    "ARCHITECTURE = 'simple'\n",
    "DATASET = 'omniglot'\n",
    "NUM_BRANCHES = 4\n",
    "SHARED_FRAC = 1.0\n",
    "\n",
    "EPOCHS = 60\n",
    "STEPS_PER_EPOCH = 100\n",
    "T_0 = 40\n",
    "OUTPUT_DIM = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyncGenerator(object):\n",
    "    def __init__(self, A, P, K, n_branches):\n",
    "        self.A = A\n",
    "        self.P = P\n",
    "        self.K = K\n",
    "        self.n_branches = n_branches\n",
    "        self.gen = omniglot.load_generator('train', A*n_branches, P, K)\n",
    "        self.batch = None\n",
    "        self.requests = 0\n",
    "        \n",
    "    def get(self, i):\n",
    "        if self.batch is None:\n",
    "            self.batch = next(self.gen)\n",
    "            self.requests = self.n_branches\n",
    "            \n",
    "        branch_batch = self.batch[i*self.A*self.P*self.K:(i+1)*self.A*self.P*self.K]\n",
    "        self.requests -= 1\n",
    "        \n",
    "        if self.requests == 0:\n",
    "            self.batch = None\n",
    "            \n",
    "        return branch_batch\n",
    "    \n",
    "class Slicer(object):\n",
    "    def __init__(self, parent, branch):\n",
    "        self.parent = parent\n",
    "        self.branch = branch\n",
    "        \n",
    "    def __next__(self):\n",
    "        return self.parent.get(self.branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET == 'omniglot':\n",
    "    A, P, K = 1, 8, 4\n",
    "    train_generator = omniglot.load_generator('train', A*NUM_BRANCHES, P, K)\n",
    "\n",
    "    sync_gen = SyncGenerator(A, P, K, NUM_BRANCHES)\n",
    "    branch_gen = [Slicer(sync_gen, i) for i in range(NUM_BRANCHES)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(branch_gen[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch = train_generator.sample(4, 4, 4, flatten=False, preprocess=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(batch[0].squeeze(), cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/vb-omniglot-simple-B4-S1.00_1\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir('models'):\n",
    "    os.system('mkdir models')\n",
    "\n",
    "if NUM_BRANCHES == 1:\n",
    "    model_name = '{}-{}_{:d}'.format(DATASET, ARCHITECTURE, MODEL_ID)\n",
    "else:\n",
    "    model_name = 'vb-{}-{}-B{:d}-S{:.2f}_{:d}'.format(DATASET, ARCHITECTURE,\n",
    "                                        NUM_BRANCHES, SHARED_FRAC, MODEL_ID)\n",
    "model_path = os.path.join('models', model_name)\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 105, 105, 1)\n",
      "WARNING:tensorflow:From /home/gong/anaconda3/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py:429: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "WARNING:tensorflow:From /home/gong/anaconda3/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py:358: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "input_dim = (None,) + batch.shape[-3:]\n",
    "print(input_dim)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "inputs, train_init_op, test_init_op = get_data_iterator_from_generator(branch_gen, input_dim, \n",
    "                                                                       n=NUM_BRANCHES)\n",
    "# combined_input, train_init_op, test_init_op = get_data_iterator_from_generator(train_generator, \n",
    "#                                                                                input_dim, n=NUM_BRANCHES)\n",
    "# inputs = [combined_input[0][i*A*P*K:(i+1)*A*P*K] for i in range(NUM_BRANCHES)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'input_1:0' shape=(?, 105, 105, 1) dtype=float32>,\n",
       " <tf.Tensor 'input_2:0' shape=(?, 105, 105, 1) dtype=float32>,\n",
       " <tf.Tensor 'input_3:0' shape=(?, 105, 105, 1) dtype=float32>,\n",
       " <tf.Tensor 'input_4:0' shape=(?, 105, 105, 1) dtype=float32>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/gong/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/gong/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "i   Layer name                      Output shape        Num param  Inbound            \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input                           [None,105,105,1]                                  \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input                           [None,105,105,1]                                  \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input                           [None,105,105,1]                                  \n",
      "--------------------------------------------------------------------------------------\n",
      "    Input                           [None,105,105,1]                                  \n",
      "--------------------------------------------------------------------------------------\n",
      "0   conv1_pad (ZeroPadding2D)       [None,111,111,1]    0          input              \n",
      "                                    [None,111,111,1]                                  \n",
      "                                    [None,111,111,1]                                  \n",
      "                                    [None,111,111,1]                                  \n",
      "--------------------------------------------------------------------------------------\n",
      "1   conv1 (Conv2D)                  [None,53,53,32] []  1600       conv1_pad          \n",
      "                                    [None,53,53,32] []                                \n",
      "                                    [None,53,53,32] []                                \n",
      "                                    [None,53,53,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "2   bn_conv1 (BatchNormalization)   [None,53,53,32] []  64         conv1              \n",
      "                                    [None,53,53,32] []                                \n",
      "                                    [None,53,53,32] []                                \n",
      "                                    [None,53,53,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "3   relu (Activation)               [None,53,53,32] []  0          bn_conv1           \n",
      "                                    [None,53,53,32] []                                \n",
      "                                    [None,53,53,32] []                                \n",
      "                                    [None,53,53,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "4   pool1_pad (ZeroPadding2D)       [None,55,55,32] []  0          relu               \n",
      "                                    [None,55,55,32] []                                \n",
      "                                    [None,55,55,32] []                                \n",
      "                                    [None,55,55,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "5   max_pool2d (MaxPooling2D)       [None,27,27,32] []  0          pool1_pad          \n",
      "                                    [None,27,27,32] []                                \n",
      "                                    [None,27,27,32] []                                \n",
      "                                    [None,27,27,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "6   conv2d_1_1 (Conv2D)             [None,27,27,32] []  9248       max_pool2d         \n",
      "                                    [None,27,27,32] []                                \n",
      "                                    [None,27,27,32] []                                \n",
      "                                    [None,27,27,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "7   bn_1_1 (BatchNormalization)     [None,27,27,32] []  64         conv2d_1_1         \n",
      "                                    [None,27,27,32] []                                \n",
      "                                    [None,27,27,32] []                                \n",
      "                                    [None,27,27,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "8   relu_1_1 (Activation)           [None,27,27,32] []  0          bn_1_1             \n",
      "                                    [None,27,27,32] []                                \n",
      "                                    [None,27,27,32] []                                \n",
      "                                    [None,27,27,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "9   conv2d_1_2 (Conv2D)             [None,27,27,32] []  9248       relu_1_1           \n",
      "                                    [None,27,27,32] []                                \n",
      "                                    [None,27,27,32] []                                \n",
      "                                    [None,27,27,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "10  bn_1_2 (BatchNormalization)     [None,27,27,32] []  64         conv2d_1_2         \n",
      "                                    [None,27,27,32] []                                \n",
      "                                    [None,27,27,32] []                                \n",
      "                                    [None,27,27,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "11  relu_1_2 (Activation)           [None,27,27,32] []  0          bn_1_2             \n",
      "                                    [None,27,27,32] []                                \n",
      "                                    [None,27,27,32] []                                \n",
      "                                    [None,27,27,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "12  avg_pool2d_1 (AveragePooling2D  [None,13,13,32] []  0          relu_1_2           \n",
      "                                    [None,13,13,32] []                                \n",
      "                                    [None,13,13,32] []                                \n",
      "                                    [None,13,13,32] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "13  conv2d_2_1 (Conv2D)             [None,13,13,64] []  18496      avg_pool2d_1       \n",
      "                                    [None,13,13,64] []                                \n",
      "                                    [None,13,13,64] []                                \n",
      "                                    [None,13,13,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "14  bn_2_1 (BatchNormalization)     [None,13,13,64] []  128        conv2d_2_1         \n",
      "                                    [None,13,13,64] []                                \n",
      "                                    [None,13,13,64] []                                \n",
      "                                    [None,13,13,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "15  relu_2_1 (Activation)           [None,13,13,64] []  0          bn_2_1             \n",
      "                                    [None,13,13,64] []                                \n",
      "                                    [None,13,13,64] []                                \n",
      "                                    [None,13,13,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "16  conv2d_2_2 (Conv2D)             [None,13,13,64] []  36928      relu_2_1           \n",
      "                                    [None,13,13,64] []                                \n",
      "                                    [None,13,13,64] []                                \n",
      "                                    [None,13,13,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "17  bn_2_2 (BatchNormalization)     [None,13,13,64] []  128        conv2d_2_2         \n",
      "                                    [None,13,13,64] []                                \n",
      "                                    [None,13,13,64] []                                \n",
      "                                    [None,13,13,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "18  relu_2_2 (Activation)           [None,13,13,64] []  0          bn_2_2             \n",
      "                                    [None,13,13,64] []                                \n",
      "                                    [None,13,13,64] []                                \n",
      "                                    [None,13,13,64] []                                \n",
      "--------------------------------------------------------------------------------------\n",
      "19  avg_pool2d_2 (AveragePooling2D  [None,6,6,64] []    0          relu_2_2           \n",
      "                                    [None,6,6,64] []                                  \n",
      "                                    [None,6,6,64] []                                  \n",
      "                                    [None,6,6,64] []                                  \n",
      "--------------------------------------------------------------------------------------\n",
      "20  conv2d_3_1 (Conv2D)             [None,6,6,128] []   73856      avg_pool2d_2       \n",
      "                                    [None,6,6,128] []                                 \n",
      "                                    [None,6,6,128] []                                 \n",
      "                                    [None,6,6,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "21  bn_3_1 (BatchNormalization)     [None,6,6,128] []   256        conv2d_3_1         \n",
      "                                    [None,6,6,128] []                                 \n",
      "                                    [None,6,6,128] []                                 \n",
      "                                    [None,6,6,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "22  relu_3_1 (Activation)           [None,6,6,128] []   0          bn_3_1             \n",
      "                                    [None,6,6,128] []                                 \n",
      "                                    [None,6,6,128] []                                 \n",
      "                                    [None,6,6,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "23  conv2d_3_2 (Conv2D)             [None,6,6,128] []   147584     relu_3_1           \n",
      "                                    [None,6,6,128] []                                 \n",
      "                                    [None,6,6,128] []                                 \n",
      "                                    [None,6,6,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "24  bn_3_2 (BatchNormalization)     [None,6,6,128] []   256        conv2d_3_2         \n",
      "                                    [None,6,6,128] []                                 \n",
      "                                    [None,6,6,128] []                                 \n",
      "                                    [None,6,6,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "25  relu_3_2 (Activation)           [None,6,6,128] []   0          bn_3_2             \n",
      "                                    [None,6,6,128] []                                 \n",
      "                                    [None,6,6,128] []                                 \n",
      "                                    [None,6,6,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "26  avg_pool2d_3 (AveragePooling2D  [None,3,3,128] []   0          relu_3_2           \n",
      "                                    [None,3,3,128] []                                 \n",
      "                                    [None,3,3,128] []                                 \n",
      "                                    [None,3,3,128] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "27  conv2d_4_1 (Conv2D)             [None,3,3,256] []   295168     avg_pool2d_3       \n",
      "                                    [None,3,3,256] []                                 \n",
      "                                    [None,3,3,256] []                                 \n",
      "                                    [None,3,3,256] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "28  bn_4_1 (BatchNormalization)     [None,3,3,256] []   512        conv2d_4_1         \n",
      "                                    [None,3,3,256] []                                 \n",
      "                                    [None,3,3,256] []                                 \n",
      "                                    [None,3,3,256] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "29  relu_4_1 (Activation)           [None,3,3,256] []   0          bn_4_1             \n",
      "                                    [None,3,3,256] []                                 \n",
      "                                    [None,3,3,256] []                                 \n",
      "                                    [None,3,3,256] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "30  conv2d_4_2 (Conv2D)             [None,3,3,256] []   590080     relu_4_1           \n",
      "                                    [None,3,3,256] []                                 \n",
      "                                    [None,3,3,256] []                                 \n",
      "                                    [None,3,3,256] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "31  bn_4_2 (BatchNormalization)     [None,3,3,256] []   512        conv2d_4_2         \n",
      "                                    [None,3,3,256] []                                 \n",
      "                                    [None,3,3,256] []                                 \n",
      "                                    [None,3,3,256] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "32  relu_4_2 (Activation)           [None,3,3,256] []   0          bn_4_2             \n",
      "                                    [None,3,3,256] []                                 \n",
      "                                    [None,3,3,256] []                                 \n",
      "                                    [None,3,3,256] []                                 \n",
      "--------------------------------------------------------------------------------------\n",
      "33  global_avg_pool2d (GlobalAvera  [None,256] []       0          relu_4_2           \n",
      "                                    [None,256] []                                     \n",
      "                                    [None,256] []                                     \n",
      "                                    [None,256] []                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "34  fc1 (Dense)                     [None,256] []       65792      global_avg_pool2d  \n",
      "                                    [None,256] []                                     \n",
      "                                    [None,256] []                                     \n",
      "                                    [None,256] []                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "35  bn_fc1 (BatchNormalization)     [None,256] []       512        fc1                \n",
      "                                    [None,256] []                                     \n",
      "                                    [None,256] []                                     \n",
      "                                    [None,256] []                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "36  relu_fc1 (Activation)           [None,256] []       0          bn_fc1             \n",
      "                                    [None,256] []                                     \n",
      "                                    [None,256] []                                     \n",
      "                                    [None,256] []                                     \n",
      "--------------------------------------------------------------------------------------\n",
      "37  output (Dense)                  [None,128]          32896      relu_fc1           \n",
      "                                    [None,128]                                        \n",
      "                                    [None,128]                                        \n",
      "                                    [None,128]                                        \n",
      "--------------------------------------------------------------------------------------\n",
      "Total parameters: 1283392\n"
     ]
    }
   ],
   "source": [
    "lr = tf.placeholder('float32', name='lr')\n",
    "lr_scheduler = lr_exp_decay_scheduler(0.001, T_0, EPOCHS, 0.001)\n",
    "\n",
    "name = 'model'\n",
    "\n",
    "with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n",
    "    if ARCHITECTURE == 'simple':\n",
    "        model = SimpleCNNLarge(inputs, OUTPUT_DIM, name=name, shared_frac=SHARED_FRAC)\n",
    "    elif ARCHITECTURE == 'res':\n",
    "        model = ResNet18(inputs, OUTPUT_DIM, name=name, shared_frac=SHARED_FRAC)\n",
    "        \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer, triplet_omniglot(A, P, K), \n",
    "                  train_init_op, test_init_op, \n",
    "                  callbacks={'acc': one_shot_acc(NUM_BRANCHES)}, \n",
    "                  schedulers={'lr:0': lr_scheduler})\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'model/output/vb1/output:0' shape=(?, 128) dtype=float32>, <tf.Tensor 'model/output/vb2/output:0' shape=(?, 128) dtype=float32>, <tf.Tensor 'model/output/vb3/output:0' shape=(?, 128) dtype=float32>, <tf.Tensor 'model/output/vb4/output:0' shape=(?, 128) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "print(model.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_steps = [lr_scheduler(e + 1) for e in range(EPOCHS)]\n",
    "plt.plot(lr_steps)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'test_init_op_1' type=MakeIterator>,\n",
       " <tf.Operation 'test_init_op_2' type=MakeIterator>,\n",
       " <tf.Operation 'test_init_op_3' type=MakeIterator>,\n",
       " <tf.Operation 'test_init_op_4' type=MakeIterator>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.test_init_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      " - 29s - lr:0: 0.0010 - loss_1: 270.6875 - loss_2: 253.0603 - loss_3: 234.5373 - loss_4: 255.8024 - acc_ensemble: 0.5850 - acc_1: 0.5850 - acc_2: 0.5850 - acc_3: 0.5850 - acc_4: 0.5850\n",
      "Epoch 2/60\n",
      " - 10s - lr:0: 0.0010 - loss_1: 70.6240 - loss_2: 74.9567 - loss_3: 66.8438 - loss_4: 70.3890 - acc_ensemble: 0.6800 - acc_1: 0.6800 - acc_2: 0.6800 - acc_3: 0.6800 - acc_4: 0.6800\n",
      "Epoch 3/60\n",
      " - 10s - lr:0: 0.0010 - loss_1: 41.8302 - loss_2: 41.0904 - loss_3: 42.5982 - loss_4: 45.9606 - acc_ensemble: 0.7050 - acc_1: 0.7050 - acc_2: 0.7050 - acc_3: 0.7050 - acc_4: 0.7050\n",
      "Epoch 4/60\n",
      " - 10s - lr:0: 0.0010 - loss_1: 42.7190 - loss_2: 41.0183 - loss_3: 46.9236 - loss_4: 45.6100 - acc_ensemble: 0.6950 - acc_1: 0.6950 - acc_2: 0.6950 - acc_3: 0.6950 - acc_4: 0.6950\n",
      "Epoch 5/60\n",
      " - 10s - lr:0: 0.0010 - loss_1: 33.4798 - loss_2: 33.0463 - loss_3: 33.1161 - loss_4: 39.7262 - acc_ensemble: 0.7225 - acc_1: 0.7225 - acc_2: 0.7225 - acc_3: 0.7225 - acc_4: 0.7225\n",
      "Epoch 6/60\n",
      " - 10s - lr:0: 0.0010 - loss_1: 34.0678 - loss_2: 29.0353 - loss_3: 25.5850 - loss_4: 27.1586 - acc_ensemble: 0.7475 - acc_1: 0.7475 - acc_2: 0.7475 - acc_3: 0.7475 - acc_4: 0.7475\n",
      "Epoch 7/60\n",
      " - 10s - lr:0: 0.0010 - loss_1: 28.9520 - loss_2: 27.1917 - loss_3: 31.1795 - loss_4: 33.4236 - acc_ensemble: 0.7900 - acc_1: 0.7900 - acc_2: 0.7900 - acc_3: 0.7900 - acc_4: 0.7900\n",
      "Epoch 8/60\n",
      " - 10s - lr:0: 0.0010 - loss_1: 40.0467 - loss_2: 38.4500 - loss_3: 36.8950 - loss_4: 33.4518 - acc_ensemble: 0.7500 - acc_1: 0.7500 - acc_2: 0.7500 - acc_3: 0.7500 - acc_4: 0.7500\n",
      "Epoch 9/60\n",
      " - 10s - lr:0: 0.0010 - loss_1: 31.6319 - loss_2: 31.1276 - loss_3: 28.7293 - loss_4: 31.5079 - acc_ensemble: 0.7800 - acc_1: 0.7800 - acc_2: 0.7800 - acc_3: 0.7800 - acc_4: 0.7800\n",
      "Epoch 10/60\n",
      " - 10s - lr:0: 0.0010 - loss_1: 24.1249 - loss_2: 27.3347 - loss_3: 33.0862 - loss_4: 33.3215 - acc_ensemble: 0.8025 - acc_1: 0.8025 - acc_2: 0.8025 - acc_3: 0.8025 - acc_4: 0.8025\n",
      "Epoch 11/60\n",
      " - 10s - lr:0: 0.0010 - loss_1: 25.4783 - loss_2: 20.2709 - loss_3: 31.1167 - loss_4: 25.2783 - acc_ensemble: 0.8100 - acc_1: 0.8100 - acc_2: 0.8100 - acc_3: 0.8100 - acc_4: 0.8100\n",
      "Epoch 12/60\n",
      " - 10s - lr:0: 0.0010 - loss_1: 21.3160 - loss_2: 22.9008 - loss_3: 20.6815 - loss_4: 19.7486 - acc_ensemble: 0.8200 - acc_1: 0.8200 - acc_2: 0.8200 - acc_3: 0.8200 - acc_4: 0.8200\n",
      "Epoch 13/60\n",
      " - 10s - lr:0: 0.0010 - loss_1: 20.0316 - loss_2: 18.6676 - loss_3: 20.1789 - loss_4: 22.5353 - acc_ensemble: 0.8125 - acc_1: 0.8125 - acc_2: 0.8125 - acc_3: 0.8125 - acc_4: 0.8125\n",
      "Epoch 14/60\n",
      " - 10s - lr:0: 0.0010 - loss_1: 23.9246 - loss_2: 18.0701 - loss_3: 23.9525 - loss_4: 19.9375 - acc_ensemble: 0.8425 - acc_1: 0.8425 - acc_2: 0.8425 - acc_3: 0.8425 - acc_4: 0.8425\n",
      "Epoch 15/60\n",
      " - 10s - lr:0: 0.0010 - loss_1: 21.0015 - loss_2: 17.2915 - loss_3: 16.8764 - loss_4: 19.3190 - acc_ensemble: 0.8350 - acc_1: 0.8350 - acc_2: 0.8350 - acc_3: 0.8350 - acc_4: 0.8350\n",
      "Epoch 16/60\n",
      " - 10s - lr:0: 0.0010 - loss_1: 17.5535 - loss_2: 18.5584 - loss_3: 17.3782 - loss_4: 19.5504 - acc_ensemble: 0.8500 - acc_1: 0.8500 - acc_2: 0.8500 - acc_3: 0.8500 - acc_4: 0.8500\n",
      "Epoch 17/60\n",
      " - 10s - lr:0: 0.0010 - loss_1: 19.4122 - loss_2: 15.8001 - loss_3: 15.7440 - loss_4: 17.3290 - acc_ensemble: 0.8475 - acc_1: 0.8475 - acc_2: 0.8475 - acc_3: 0.8475 - acc_4: 0.8475\n",
      "Epoch 18/60\n",
      " - 10s - lr:0: 0.0010 - loss_1: 16.4945 - loss_2: 16.9395 - loss_3: 14.0892 - loss_4: 16.0950 - acc_ensemble: 0.8725 - acc_1: 0.8725 - acc_2: 0.8725 - acc_3: 0.8725 - acc_4: 0.8725\n",
      "Epoch 19/60\n",
      " - 11s - lr:0: 0.0010 - loss_1: 17.8973 - loss_2: 18.5562 - loss_3: 19.0218 - loss_4: 15.5217 - acc_ensemble: 0.8525 - acc_1: 0.8525 - acc_2: 0.8525 - acc_3: 0.8525 - acc_4: 0.8525\n",
      "Epoch 20/60\n",
      " - 10s - lr:0: 0.0010 - loss_1: 17.2158 - loss_2: 15.2091 - loss_3: 13.3750 - loss_4: 14.3941 - acc_ensemble: 0.8800 - acc_1: 0.8800 - acc_2: 0.8800 - acc_3: 0.8800 - acc_4: 0.8800\n",
      "Epoch 21/60\n",
      " - 10s - lr:0: 0.0010 - loss_1: 11.2723 - loss_2: 16.0655 - loss_3: 15.3655 - loss_4: 12.2683 - acc_ensemble: 0.8700 - acc_1: 0.8700 - acc_2: 0.8700 - acc_3: 0.8700 - acc_4: 0.8700\n",
      "Epoch 22/60\n",
      " - 10s - lr:0: 0.0010 - loss_1: 12.8951 - loss_2: 13.9719 - loss_3: 13.7310 - loss_4: 12.6225 - acc_ensemble: 0.8975 - acc_1: 0.8975 - acc_2: 0.8975 - acc_3: 0.8975 - acc_4: 0.8975\n",
      "Epoch 23/60\n",
      " - 10s - lr:0: 0.0010 - loss_1: 11.3786 - loss_2: 11.9697 - loss_3: 12.6664 - loss_4: 11.7426 - acc_ensemble: 0.9025 - acc_1: 0.9025 - acc_2: 0.9025 - acc_3: 0.9025 - acc_4: 0.9025\n",
      "Epoch 24/60\n",
      " - 10s - lr:0: 0.0010 - loss_1: 14.0131 - loss_2: 14.8978 - loss_3: 13.5103 - loss_4: 13.1655 - acc_ensemble: 0.8700 - acc_1: 0.8700 - acc_2: 0.8700 - acc_3: 0.8700 - acc_4: 0.8700\n",
      "Epoch 25/60\n",
      " - 10s - lr:0: 0.0010 - loss_1: 13.2356 - loss_2: 15.5407 - loss_3: 12.1802 - loss_4: 13.4731 - acc_ensemble: 0.8800 - acc_1: 0.8800 - acc_2: 0.8800 - acc_3: 0.8800 - acc_4: 0.8800\n",
      "Epoch 26/60\n",
      " - 10s - lr:0: 0.0010 - loss_1: 9.8163 - loss_2: 9.2311 - loss_3: 14.6948 - loss_4: 9.2637 - acc_ensemble: 0.8550 - acc_1: 0.8550 - acc_2: 0.8550 - acc_3: 0.8550 - acc_4: 0.8550\n",
      "Epoch 27/60\n",
      " - 10s - lr:0: 0.0010 - loss_1: 13.1870 - loss_2: 13.1296 - loss_3: 14.3269 - loss_4: 13.1058 - acc_ensemble: 0.9125 - acc_1: 0.9125 - acc_2: 0.9125 - acc_3: 0.9125 - acc_4: 0.9125\n",
      "Epoch 28/60\n",
      " - 10s - lr:0: 0.0010 - loss_1: 10.8740 - loss_2: 12.3040 - loss_3: 9.7037 - loss_4: 12.5873 - acc_ensemble: 0.8950 - acc_1: 0.8950 - acc_2: 0.8950 - acc_3: 0.8950 - acc_4: 0.8950\n",
      "Epoch 29/60\n",
      " - 10s - lr:0: 0.0010 - loss_1: 10.9898 - loss_2: 10.8949 - loss_3: 10.9837 - loss_4: 10.3583 - acc_ensemble: 0.8900 - acc_1: 0.8900 - acc_2: 0.8900 - acc_3: 0.8900 - acc_4: 0.8900\n",
      "Epoch 30/60\n",
      " - 10s - lr:0: 0.0010 - loss_1: 8.4948 - loss_2: 9.9609 - loss_3: 12.7619 - loss_4: 9.3255 - acc_ensemble: 0.8950 - acc_1: 0.8950 - acc_2: 0.8950 - acc_3: 0.8950 - acc_4: 0.8950\n",
      "Epoch 31/60\n",
      " - 10s - lr:0: 0.0010 - loss_1: 9.6098 - loss_2: 10.5481 - loss_3: 8.4437 - loss_4: 10.7310 - acc_ensemble: 0.8725 - acc_1: 0.8725 - acc_2: 0.8725 - acc_3: 0.8725 - acc_4: 0.8725\n",
      "Epoch 32/60\n",
      " - 10s - lr:0: 0.0010 - loss_1: 15.4865 - loss_2: 12.8882 - loss_3: 11.2380 - loss_4: 11.1121 - acc_ensemble: 0.8975 - acc_1: 0.8975 - acc_2: 0.8975 - acc_3: 0.8975 - acc_4: 0.8975\n",
      "Epoch 33/60\n",
      " - 10s - lr:0: 0.0010 - loss_1: 13.6971 - loss_2: 13.5893 - loss_3: 15.5426 - loss_4: 13.7578 - acc_ensemble: 0.9150 - acc_1: 0.9150 - acc_2: 0.9150 - acc_3: 0.9150 - acc_4: 0.9150\n",
      "Epoch 34/60\n",
      " - 10s - lr:0: 0.0010 - loss_1: 14.1887 - loss_2: 10.6342 - loss_3: 12.3611 - loss_4: 12.4647 - acc_ensemble: 0.8975 - acc_1: 0.8975 - acc_2: 0.8975 - acc_3: 0.8975 - acc_4: 0.8975\n",
      "Epoch 35/60\n",
      " - 10s - lr:0: 0.0010 - loss_1: 12.3709 - loss_2: 10.9757 - loss_3: 9.8841 - loss_4: 9.7980 - acc_ensemble: 0.8825 - acc_1: 0.8825 - acc_2: 0.8825 - acc_3: 0.8825 - acc_4: 0.8825\n",
      "Epoch 36/60\n",
      " - 10s - lr:0: 0.0010 - loss_1: 10.3032 - loss_2: 10.9347 - loss_3: 10.9525 - loss_4: 11.8314 - acc_ensemble: 0.9050 - acc_1: 0.9050 - acc_2: 0.9050 - acc_3: 0.9050 - acc_4: 0.9050\n",
      "Epoch 37/60\n",
      " - 10s - lr:0: 0.0010 - loss_1: 7.7879 - loss_2: 12.6551 - loss_3: 9.6878 - loss_4: 10.6027 - acc_ensemble: 0.8775 - acc_1: 0.8775 - acc_2: 0.8775 - acc_3: 0.8775 - acc_4: 0.8775\n",
      "Epoch 38/60\n",
      " - 10s - lr:0: 0.0010 - loss_1: 11.3915 - loss_2: 8.2241 - loss_3: 12.4203 - loss_4: 9.7987 - acc_ensemble: 0.8850 - acc_1: 0.8850 - acc_2: 0.8850 - acc_3: 0.8850 - acc_4: 0.8850\n",
      "Epoch 39/60\n",
      " - 10s - lr:0: 0.0010 - loss_1: 8.0339 - loss_2: 8.9171 - loss_3: 7.2989 - loss_4: 9.6046 - acc_ensemble: 0.9000 - acc_1: 0.9000 - acc_2: 0.9000 - acc_3: 0.9000 - acc_4: 0.9000\n",
      "Epoch 40/60\n",
      " - 10s - lr:0: 0.0010 - loss_1: 8.5963 - loss_2: 10.2729 - loss_3: 10.3055 - loss_4: 10.4980 - acc_ensemble: 0.9050 - acc_1: 0.9050 - acc_2: 0.9050 - acc_3: 0.9050 - acc_4: 0.9050\n",
      "Epoch 41/60\n",
      " - 10s - lr:0: 7.0795e-04 - loss_1: 5.6375 - loss_2: 6.0552 - loss_3: 5.8833 - loss_4: 6.6943 - acc_ensemble: 0.9200 - acc_1: 0.9200 - acc_2: 0.9200 - acc_3: 0.9200 - acc_4: 0.9200\n",
      "Epoch 42/60\n",
      " - 10s - lr:0: 5.0119e-04 - loss_1: 5.9565 - loss_2: 5.3849 - loss_3: 5.7113 - loss_4: 6.6454 - acc_ensemble: 0.9250 - acc_1: 0.9250 - acc_2: 0.9250 - acc_3: 0.9250 - acc_4: 0.9250\n",
      "Epoch 43/60\n",
      " - 10s - lr:0: 3.5481e-04 - loss_1: 3.7058 - loss_2: 4.4772 - loss_3: 4.3210 - loss_4: 3.6863 - acc_ensemble: 0.9475 - acc_1: 0.9475 - acc_2: 0.9475 - acc_3: 0.9475 - acc_4: 0.9475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/60\n",
      " - 10s - lr:0: 2.5119e-04 - loss_1: 3.0346 - loss_2: 2.7732 - loss_3: 3.8132 - loss_4: 2.6526 - acc_ensemble: 0.9425 - acc_1: 0.9425 - acc_2: 0.9425 - acc_3: 0.9425 - acc_4: 0.9425\n",
      "Epoch 45/60\n",
      " - 10s - lr:0: 1.7783e-04 - loss_1: 2.4013 - loss_2: 2.8626 - loss_3: 2.3771 - loss_4: 3.8731 - acc_ensemble: 0.9375 - acc_1: 0.9375 - acc_2: 0.9375 - acc_3: 0.9375 - acc_4: 0.9375\n",
      "Epoch 46/60\n",
      " - 10s - lr:0: 1.2589e-04 - loss_1: 2.6814 - loss_2: 2.5624 - loss_3: 3.0887 - loss_4: 2.8880 - acc_ensemble: 0.9475 - acc_1: 0.9475 - acc_2: 0.9475 - acc_3: 0.9475 - acc_4: 0.9475\n",
      "Epoch 47/60\n",
      " - 10s - lr:0: 8.9125e-05 - loss_1: 3.3756 - loss_2: 3.1148 - loss_3: 2.2191 - loss_4: 2.9057 - acc_ensemble: 0.9475 - acc_1: 0.9475 - acc_2: 0.9475 - acc_3: 0.9475 - acc_4: 0.9475\n",
      "Epoch 48/60\n",
      " - 10s - lr:0: 6.3096e-05 - loss_1: 3.1896 - loss_2: 2.2885 - loss_3: 2.7946 - loss_4: 2.4543 - acc_ensemble: 0.9400 - acc_1: 0.9400 - acc_2: 0.9400 - acc_3: 0.9400 - acc_4: 0.9400\n",
      "Epoch 49/60\n",
      " - 10s - lr:0: 4.4668e-05 - loss_1: 2.4426 - loss_2: 2.4049 - loss_3: 2.3477 - loss_4: 1.6718 - acc_ensemble: 0.9425 - acc_1: 0.9425 - acc_2: 0.9425 - acc_3: 0.9425 - acc_4: 0.9425\n",
      "Epoch 50/60\n",
      " - 10s - lr:0: 3.1623e-05 - loss_1: 1.3358 - loss_2: 1.8018 - loss_3: 2.0022 - loss_4: 2.0013 - acc_ensemble: 0.9425 - acc_1: 0.9425 - acc_2: 0.9425 - acc_3: 0.9425 - acc_4: 0.9425\n",
      "Epoch 51/60\n",
      " - 10s - lr:0: 2.2387e-05 - loss_1: 1.3356 - loss_2: 2.5087 - loss_3: 1.6731 - loss_4: 2.0737 - acc_ensemble: 0.9325 - acc_1: 0.9325 - acc_2: 0.9325 - acc_3: 0.9325 - acc_4: 0.9325\n",
      "Epoch 52/60\n",
      " - 10s - lr:0: 1.5849e-05 - loss_1: 1.5567 - loss_2: 2.6386 - loss_3: 1.9699 - loss_4: 2.3293 - acc_ensemble: 0.9375 - acc_1: 0.9375 - acc_2: 0.9375 - acc_3: 0.9375 - acc_4: 0.9375\n",
      "Epoch 53/60\n",
      " - 10s - lr:0: 1.1220e-05 - loss_1: 2.1053 - loss_2: 2.2106 - loss_3: 3.3299 - loss_4: 3.0825 - acc_ensemble: 0.9375 - acc_1: 0.9375 - acc_2: 0.9375 - acc_3: 0.9375 - acc_4: 0.9375\n",
      "Epoch 54/60\n",
      " - 10s - lr:0: 7.9433e-06 - loss_1: 2.7062 - loss_2: 2.1260 - loss_3: 2.4552 - loss_4: 2.3127 - acc_ensemble: 0.9375 - acc_1: 0.9375 - acc_2: 0.9375 - acc_3: 0.9375 - acc_4: 0.9375\n",
      "Epoch 55/60\n",
      " - 10s - lr:0: 5.6234e-06 - loss_1: 1.5616 - loss_2: 2.4772 - loss_3: 2.6020 - loss_4: 1.8030 - acc_ensemble: 0.9375 - acc_1: 0.9375 - acc_2: 0.9375 - acc_3: 0.9375 - acc_4: 0.9375\n",
      "Epoch 56/60\n",
      " - 10s - lr:0: 3.9811e-06 - loss_1: 2.3710 - loss_2: 2.1879 - loss_3: 1.6821 - loss_4: 2.2488 - acc_ensemble: 0.9375 - acc_1: 0.9375 - acc_2: 0.9375 - acc_3: 0.9375 - acc_4: 0.9375\n",
      "Epoch 57/60\n",
      " - 10s - lr:0: 2.8184e-06 - loss_1: 1.3304 - loss_2: 2.6479 - loss_3: 2.0042 - loss_4: 1.5720 - acc_ensemble: 0.9375 - acc_1: 0.9375 - acc_2: 0.9375 - acc_3: 0.9375 - acc_4: 0.9375\n",
      "Epoch 58/60\n",
      " - 10s - lr:0: 1.9953e-06 - loss_1: 2.5347 - loss_2: 1.9309 - loss_3: 2.7035 - loss_4: 1.6869 - acc_ensemble: 0.9400 - acc_1: 0.9400 - acc_2: 0.9400 - acc_3: 0.9400 - acc_4: 0.9400\n",
      "Epoch 59/60\n",
      " - 10s - lr:0: 1.4125e-06 - loss_1: 1.9640 - loss_2: 1.9729 - loss_3: 1.7108 - loss_4: 2.7484 - acc_ensemble: 0.9400 - acc_1: 0.9400 - acc_2: 0.9400 - acc_3: 0.9400 - acc_4: 0.9400\n",
      "Epoch 60/60\n",
      " - 10s - lr:0: 1.0000e-06 - loss_1: 1.7383 - loss_2: 1.7992 - loss_3: 2.4760 - loss_4: 1.7433 - acc_ensemble: 0.9400 - acc_1: 0.9400 - acc_2: 0.9400 - acc_3: 0.9400 - acc_4: 0.9400\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(EPOCHS, STEPS_PER_EPOCH, train_dict=None, \n",
    "                    log_path=model_path if SAVE else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/gong/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from models/omniglot-res_1/ckpt\n",
      "Model 1 acc: 0.8049999999999999\n",
      "Mean acc: 0.8049999999999999 , std: 0.0\n"
     ]
    }
   ],
   "source": [
    "assert NUM_BRANCHES == 1\n",
    "\n",
    "model_id_list = [1]\n",
    "baseline_acc_list = []\n",
    "\n",
    "for model_id in model_id_list:\n",
    "    tf.reset_default_graph()\n",
    "    model_name = '{}-{}_{:d}'.format(DATASET, ARCHITECTURE, MODEL_ID)\n",
    "    model_path = os.path.join('models', model_name)\n",
    "    \n",
    "    with TFSessionGrow() as sess:\n",
    "        restore_sess(sess, model_path)\n",
    "        acc = baseline_one_shot(sess, model_name='model_'+str(model_id))\n",
    "        print('Model {} acc:'.format(model_id), acc)\n",
    "        baseline_acc_list.append(acc)\n",
    "        \n",
    "print('Mean acc:', np.mean(baseline_acc_list), ', std:', np.std(baseline_acc_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Virtual Branching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/gong/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from models/vb-omniglot-res-B2-S0.25_1/ckpt\n",
      "Model 1 acc: 0.8375 [0.7849999999999999, 0.8125]\n",
      "Mean acc: 0.8375 , std: 0.0\n"
     ]
    }
   ],
   "source": [
    "model_id_list = [1]\n",
    "vbranch_acc_list = []\n",
    "\n",
    "for model_id in model_id_list:\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    model_name = 'vb-{}-{}-B{:d}-S{:.2f}_{:d}'.format(dataset, architecture,\n",
    "                                            NUM_BRANCHES, SHARED_FRAC, model_id)\n",
    "    model_path = os.path.join('models', model_name)\n",
    "    \n",
    "    with TFSessionGrow() as sess:\n",
    "        restore_sess(sess, model_path)    \n",
    "        acc, branch_acc = vbranch_one_shot(sess, model_name='model_'+str(model_id), \n",
    "                                           n_branches=NUM_BRANCHES)\n",
    "        print('Model {} acc:'.format(model_id), acc, branch_acc)\n",
    "        vbranch_acc_list.append(acc)\n",
    "        \n",
    "print('Mean acc:', np.mean(vbranch_acc_list), ', std:', np.std(vbranch_acc_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
